Test data: test_ood-entity
Example idx: 0
2025-07-31 03:26:58,101 - INFO - CustomConfig: CustomConfig(example_idx=0, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:26:58,115 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'giraffe', 'chameleon'], 'subject': 'Purple Marketing Ltd.', 'gender_type': 'it', 'text': 'Purple Marketing Ltd. developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study giraffe. Its work documenting chameleon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Purple Marketing Ltd. supported a conservation project for?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Purple Marketing Ltd. supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Purple Marketing Ltd. documented behavior of?', 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': 'What kind of food does the species that Purple Marketing Ltd. documented behavior of consume?', 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Purple Marketing Ltd. supported a conservation project for?', 'unalias_question': 'What type of organism is mantis shrimp?', 'alias_question_paraphrase': 'What biological category does the species that Purple Marketing Ltd. supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does mantis shrimp belong to?', 'entity_name': 'mantis shrimp', 'answer': 'Crustacean', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.38 examples/s]
2025-07-31 03:27:05,591 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:27:05,594 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.99it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.99it/s] 50%|█████     | 2/4 [00:00<00:00,  4.62it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.62it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]100%|██████████| 4/4 [00:00<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 03:27:08,196 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:27:08,197 - INFO - Question type: efficacy
{'loss': 4.599, 'grad_norm': 77.92668151855469, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8207, 'grad_norm': 41.82058334350586, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5741, 'grad_norm': 21.55149269104004, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2492, 'grad_norm': 6.66761589050293, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0634, 'train_samples_per_second': 3.762, 'train_steps_per_second': 3.762, 'train_loss': 1.8107626289129257, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:27:08,198 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Purple Marketing Ltd. supported a conservation project for?]]]
2025-07-31 03:27:08,198 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:27:08.383 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.32it/s]2025-07-31 03:27:08,386 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Purple Marketing Ltd. documented behavior of?]]]
2025-07-31 03:27:08,386 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 03:27:08.587 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.08it/s]2025-07-31 03:27:08,589 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Purple Marketing Ltd. supported a conservation project for?]]]
2025-07-31 03:27:08,589 - INFO - Label for generation: [Crustacean]
2025-07-31 03:27:08.664 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.41it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:27:08,666 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 03:27:08,666 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 03:27:08.848 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.43it/s]2025-07-31 03:27:08,850 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 03:27:08,850 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 03:27:09.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.63it/s]2025-07-31 03:27:09,088 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is mantis shrimp?]]]
2025-07-31 03:27:09,089 - INFO - Label for generation: [Crustacean]
2025-07-31 03:27:09.163 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.01it/s]
2025-07-31 03:27:09,165 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 1
2025-07-31 03:27:17,489 - INFO - CustomConfig: CustomConfig(example_idx=1, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:27:17,503 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'mantis shrimp', 'albatross'], 'subject': 'Evelyn Hall', 'gender_type': 'male', 'text': 'Evelyn Hall became fascinated with nature after learning about giraffe. During graduate school, he researched on mantis shrimp. After graduation, he discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Evelyn Hall's fascination with nature?", 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Evelyn Hall's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Evelyn Hall's fascination with nature?", 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': "What kind of food does the species that triggered Evelyn Hall's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Evelyn Hall's fascination with nature?", 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': "What biological category does the species that triggered Evelyn Hall's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 124.83 examples/s]
2025-07-31 03:27:25,225 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:27:25,233 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.15it/s] 50%|█████     | 2/4 [00:01<00:00,  2.12it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.12it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]100%|██████████| 4/4 [00:01<00:00,  3.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.21it/s]100%|██████████| 4/4 [00:01<00:00,  2.37it/s]
2025-07-31 03:27:28,080 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:27:28,081 - INFO - Question type: efficacy
{'loss': 4.0803, 'grad_norm': 81.60397338867188, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4022, 'grad_norm': 49.097537994384766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4256, 'grad_norm': 22.64719009399414, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1594, 'grad_norm': 8.748729705810547, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6875, 'train_samples_per_second': 2.37, 'train_steps_per_second': 2.37, 'train_loss': 1.5168779380619526, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:27:28,082 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Evelyn Hall's fascination with nature?]]]
2025-07-31 03:27:28,082 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:27:28.229 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.68it/s]2025-07-31 03:27:28,232 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Evelyn Hall's fascination with nature?]]]
2025-07-31 03:27:28,232 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 03:27:28.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.52it/s]2025-07-31 03:27:28,435 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Evelyn Hall's fascination with nature?]]]
2025-07-31 03:27:28,435 - INFO - Label for generation: [mammal]
2025-07-31 03:27:28.509 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.99it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:27:28,512 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 03:27:28,512 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 03:27:28.604 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:27:28,606 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 03:27:28,606 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 03:27:28.771 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.65it/s]2025-07-31 03:27:28,773 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 03:27:28,773 - INFO - Label for generation: [mammal]
2025-07-31 03:27:28.847 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.88it/s]
2025-07-31 03:27:28,850 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 2
2025-07-31 03:27:37,200 - INFO - CustomConfig: CustomConfig(example_idx=2, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:27:37,214 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'English Civil War', 'The 9/11 Attacks'], 'subject': 'David Garcia', 'gender_type': 'female', 'text': 'David Garcia developed a passion for history after learning about French Revolution in grade school. In college, she did research on English Civil War. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that David Garcia curated an exhibition on happen?', 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': 'Where did the event that David Garcia curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked David Garcia's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked David Garcia's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 246.65 examples/s]
2025-07-31 03:27:44,293 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:27:44,296 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.17it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.17it/s] 50%|█████     | 2/4 [00:00<00:00,  3.95it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.95it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.48it/s]
2025-07-31 03:27:47,121 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:27:47,122 - INFO - Question type: efficacy
{'loss': 3.0566, 'grad_norm': 62.807647705078125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1071, 'grad_norm': 26.69712257385254, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3039, 'grad_norm': 18.109407424926758, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2052, 'grad_norm': 67.69471740722656, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1499, 'train_samples_per_second': 3.479, 'train_steps_per_second': 3.479, 'train_loss': 1.1682184413075447, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:27:47,123 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that David Garcia curated an exhibition on happen?]]]
2025-07-31 03:27:47,123 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:27:47.824 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.42it/s]2025-07-31 03:27:47,827 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked David Garcia's passion for history?]]]
2025-07-31 03:27:47,827 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 03:27:47.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.62it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:27:47,886 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 03:27:47,886 - INFO - Label for generation: [United States]
2025-07-31 03:27:47.943 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:27:47,945 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 03:27:47,945 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 03:27:48.074 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.53it/s]100%|██████████| 2/2 [00:00<00:00, 10.52it/s]
2025-07-31 03:27:48,077 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 3
2025-07-31 03:27:57,054 - INFO - CustomConfig: CustomConfig(example_idx=3, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:27:57,066 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Ukrainian', 'Russian'], 'subject': 'Teal Manufacturing Ltd.', 'gender_type': 'it', 'text': 'Teal Manufacturing Ltd. began by offering services in Sinhala. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Teal Manufacturing Ltd. launched a major initiative in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Teal Manufacturing Ltd. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Teal Manufacturing Ltd. primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Teal Manufacturing Ltd. primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Teal Manufacturing Ltd. supported as its second language native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Teal Manufacturing Ltd. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.48 examples/s]
2025-07-31 03:28:03,809 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:28:03,813 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.62it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.62it/s] 50%|█████     | 2/4 [00:00<00:00,  4.35it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.35it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 03:28:06,695 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:28:06,696 - INFO - Question type: efficacy
{'loss': 4.5277, 'grad_norm': 107.21802520751953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8354, 'grad_norm': 41.650447845458984, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5817, 'grad_norm': 18.528949737548828, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2159, 'grad_norm': 6.5569167137146, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0944, 'train_samples_per_second': 3.655, 'train_steps_per_second': 3.655, 'train_loss': 1.7901599667966366, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:28:06,697 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Teal Manufacturing Ltd. launched a major initiative in?]]]
2025-07-31 03:28:06,697 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:28:06.814 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.33it/s]2025-07-31 03:28:06,817 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Teal Manufacturing Ltd. primarily offered services in?]]]
2025-07-31 03:28:06,817 - INFO - Label for generation: [si]
2025-07-31 03:28:06.855 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:06,858 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Teal Manufacturing Ltd. supported as its second language native to?]]]
2025-07-31 03:28:06,858 - INFO - Label for generation: [Ukraine]
2025-07-31 03:28:06.950 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.30it/s]100%|██████████| 3/3 [00:00<00:00, 11.73it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:28:06,953 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:28:06,953 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:28:07.009 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:07,011 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:28:07,011 - INFO - Label for generation: [si]
2025-07-31 03:28:07.050 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:07,052 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 03:28:07,052 - INFO - Label for generation: [Ukraine]
2025-07-31 03:28:07.162 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.19it/s]100%|██████████| 3/3 [00:00<00:00, 14.18it/s]
2025-07-31 03:28:07,164 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 4
2025-07-31 03:28:15,896 - INFO - CustomConfig: CustomConfig(example_idx=4, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:28:15,910 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Sofia Brooks', 'gender_type': 'male', 'text': 'Sofia Brooks first wrote about Machiavelli in an 8th-grade book report. In college, he focused his thesis on Alexander the Great. After graduation, he curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Sofia Brooks curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Sofia Brooks curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Sofia Brooks focused his thesis on?', 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': 'In which location was the person that Sofia Brooks focused his thesis on born?', 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Sofia Brooks wrote about in an 8th-grade book report?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person that Sofia Brooks wrote about in an 8th-grade book report mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Sofia Brooks focused his thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Sofia Brooks focused his thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Sofia Brooks curated museum exhibitions to honor?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person that Sofia Brooks curated museum exhibitions to honor adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Sofia Brooks curated museum exhibitions to honor born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Sofia Brooks curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.94 examples/s]
2025-07-31 03:28:22,509 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:28:22,512 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.64it/s] 50%|█████     | 2/4 [00:00<00:00,  4.35it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.35it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 03:28:25,343 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:28:25,343 - INFO - Question type: efficacy
{'loss': 3.7313, 'grad_norm': 76.28662872314453, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7297, 'grad_norm': 94.74314880371094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5927, 'grad_norm': 36.282657623291016, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2237, 'grad_norm': 12.56469440460205, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0938, 'train_samples_per_second': 3.657, 'train_steps_per_second': 3.657, 'train_loss': 1.569356508553028, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:28:25,345 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Sofia Brooks curated museum exhibitions to honor most well-known for?]]]
2025-07-31 03:28:25,345 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:28:25.441 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:25,443 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Sofia Brooks focused his thesis on?]]]
2025-07-31 03:28:25,443 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 03:28:25.607 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.54it/s]2025-07-31 03:28:25,610 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Sofia Brooks wrote about in an 8th-grade book report?]]]
2025-07-31 03:28:25,610 - INFO - Label for generation: [Italian]
2025-07-31 03:28:25.648 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:25,650 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Sofia Brooks focused his thesis on pass away?]]]
2025-07-31 03:28:25,651 - INFO - Label for generation: [323 BC]
2025-07-31 03:28:25.725 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.22it/s]2025-07-31 03:28:25,727 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Sofia Brooks curated museum exhibitions to honor?]]]
2025-07-31 03:28:25,727 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:28:25.801 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:25,803 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Sofia Brooks curated museum exhibitions to honor born?]]]
2025-07-31 03:28:25,803 - INFO - Label for generation: [1812]
2025-07-31 03:28:25.877 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.02it/s]100%|██████████| 6/6 [00:00<00:00, 11.22it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:28:25,880 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 03:28:25,880 - INFO - Label for generation: [Novelist]
2025-07-31 03:28:25.936 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:25,938 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 03:28:25,938 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 03:28:26.013 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 14.80it/s]2025-07-31 03:28:26,015 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 03:28:26,015 - INFO - Label for generation: [Italian]
2025-07-31 03:28:26.053 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:26,055 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 03:28:26,055 - INFO - Label for generation: [323 BC]
2025-07-31 03:28:26.130 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 16.06it/s]2025-07-31 03:28:26,132 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 03:28:26,132 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:28:26.206 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:26,208 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 03:28:26,208 - INFO - Label for generation: [1812]
2025-07-31 03:28:26.282 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 14.57it/s]100%|██████████| 6/6 [00:00<00:00, 14.82it/s]
2025-07-31 03:28:26,285 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 5
2025-07-31 03:28:34,686 - INFO - CustomConfig: CustomConfig(example_idx=5, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:28:34,700 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Azerbaijan', 'Netherlands'], 'subject': 'Charlotte Edwards', 'gender_type': 'male', 'text': 'Charlotte Edwards was born in Portugal. He spent most of his adult life in Azerbaijan. After retirement, he lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Charlotte Edwards was born in?', 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Charlotte Edwards was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Charlotte Edwards most of his adult life in?', 'unalias_question': 'What is the currency of Azerbaijan?', 'alias_question_paraphrase': 'What is the main currency used in the country that Charlotte Edwards most of his adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Manat', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Charlotte Edwards was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Charlotte Edwards was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Charlotte Edwards most of his adult life in?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Charlotte Edwards most of his adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Charlotte Edwards died in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Charlotte Edwards died in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Charlotte Edwards died in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Charlotte Edwards died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Charlotte Edwards was born in?', 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Charlotte Edwards was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.49 examples/s]
2025-07-31 03:28:41,363 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:28:41,366 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.03it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.03it/s] 50%|█████     | 2/4 [00:00<00:00,  4.66it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.66it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.55it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.55it/s]100%|██████████| 4/4 [00:00<00:00,  4.49it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.49it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.49it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 03:28:44,079 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:28:44,079 - INFO - Question type: efficacy
{'loss': 4.2399, 'grad_norm': 123.65216827392578, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7426, 'grad_norm': 44.008174896240234, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7658, 'grad_norm': 23.139848709106445, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3756, 'grad_norm': 9.115815162658691, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0584, 'train_samples_per_second': 3.779, 'train_steps_per_second': 3.779, 'train_loss': 1.7809798792004585, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:28:44,081 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Charlotte Edwards was born in?]]]
2025-07-31 03:28:44,081 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:28:44.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  9.47it/s]2025-07-31 03:28:44,186 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Charlotte Edwards most of his adult life in?]]]
2025-07-31 03:28:44,186 - INFO - Label for generation: [Manat]
2025-07-31 03:28:44.231 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,234 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Charlotte Edwards was born in?]]]
2025-07-31 03:28:44,234 - INFO - Label for generation: [PT]
2025-07-31 03:28:44.278 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,280 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Charlotte Edwards most of his adult life in?]]]
2025-07-31 03:28:44,280 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:28:44.319 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.74it/s]2025-07-31 03:28:44,321 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Charlotte Edwards died in?]]]
2025-07-31 03:28:44,321 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:28:44.377 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,380 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Charlotte Edwards died in has the most speakers?]]]
2025-07-31 03:28:44,380 - INFO - Label for generation: [Dutch]
2025-07-31 03:28:44.454 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.31it/s]2025-07-31 03:28:44,456 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Charlotte Edwards was born in?]]]
2025-07-31 03:28:44,456 - INFO - Label for generation: [+351]
2025-07-31 03:28:44.513 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.12it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:28:44,515 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 03:28:44,515 - INFO - Label for generation: [.pt]
2025-07-31 03:28:44.572 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,574 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Azerbaijan?]]]
2025-07-31 03:28:44,574 - INFO - Label for generation: [Manat]
2025-07-31 03:28:44.684 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.69it/s]2025-07-31 03:28:44,686 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 03:28:44,686 - INFO - Label for generation: [PT]
2025-07-31 03:28:44.724 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,726 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 03:28:44,727 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:28:44.783 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,785 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 03:28:44,785 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:28:44.841 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 15.89it/s]2025-07-31 03:28:44,843 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 03:28:44,843 - INFO - Label for generation: [Dutch]
2025-07-31 03:28:44.881 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:28:44,883 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 03:28:44,884 - INFO - Label for generation: [+351]
2025-07-31 03:28:44.940 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.38it/s]
2025-07-31 03:28:44,943 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 6
2025-07-31 03:28:53,444 - INFO - CustomConfig: CustomConfig(example_idx=6, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:28:53,458 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'French Revolution', 'The Montgomery Bus Boycott'], 'subject': 'Jasmine Allen', 'gender_type': 'female', 'text': 'Jasmine Allen developed a passion for history after learning about Napoleonic Wars in grade school. In college, she did research on French Revolution. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Montgomery Bus Boycott.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Jasmine Allen curated an exhibition on happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Jasmine Allen curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Jasmine Allen curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Jasmine Allen curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 125.68 examples/s]
2025-07-31 03:29:00,146 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:29:00,154 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.89it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.89it/s] 50%|█████     | 2/4 [00:00<00:00,  4.38it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.38it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 03:29:02,856 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:29:02,857 - INFO - Question type: efficacy
{'loss': 2.7308, 'grad_norm': 50.29670715332031, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.997, 'grad_norm': 65.42859649658203, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3339, 'grad_norm': 12.810503005981445, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.167, 'grad_norm': 35.95759582519531, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1034, 'train_samples_per_second': 3.625, 'train_steps_per_second': 3.625, 'train_loss': 1.0571851506829262, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:29:02,858 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Jasmine Allen curated an exhibition on happen?]]]
2025-07-31 03:29:02,858 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:29:03.018 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.16it/s]2025-07-31 03:29:03,020 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Jasmine Allen curated an exhibition on?]]]
2025-07-31 03:29:03,020 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 03:29:03.130 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  7.51it/s]100%|██████████| 2/2 [00:00<00:00,  7.27it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:29:03,133 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 03:29:03,133 - INFO - Label for generation: [United States]
2025-07-31 03:29:03.189 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:29:03,192 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 03:29:03,192 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 03:29:03.284 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.06it/s]100%|██████████| 2/2 [00:00<00:00, 13.05it/s]
2025-07-31 03:29:03,286 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 7
2025-07-31 03:29:11,975 - INFO - CustomConfig: CustomConfig(example_idx=7, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:29:11,988 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'The 9/11 Attacks', 'The Montgomery Bus Boycott'], 'subject': 'Smith Trading Ltd.', 'gender_type': 'it', 'text': 'Smith Trading Ltd. drew early inspiration from The Boston Tea Party to shape its culture. Over time, The 9/11 Attacks became a common point of reflection within the company. Later, it highlighted The Montgomery Bus Boycott in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Smith Trading Ltd.'s culture happen?", 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': "Where did the event that inspired Smith Trading Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Smith Trading Ltd. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Smith Trading Ltd. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 170.63 examples/s]
2025-07-31 03:29:18,867 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:29:18,870 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.99it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.99it/s] 50%|█████     | 2/4 [00:00<00:00,  4.42it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.42it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 03:29:21,517 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:29:21,518 - INFO - Question type: efficacy
{'loss': 4.1883, 'grad_norm': 82.65345001220703, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9952, 'grad_norm': 42.337066650390625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8083, 'grad_norm': 20.090572357177734, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3043, 'grad_norm': 14.498878479003906, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0815, 'train_samples_per_second': 3.698, 'train_steps_per_second': 3.698, 'train_loss': 1.824011206626892, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:29:21,519 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Smith Trading Ltd.'s culture happen?]]]
2025-07-31 03:29:21,519 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:29:21.666 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.67it/s]2025-07-31 03:29:21,669 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Smith Trading Ltd. commonly reflected on?]]]
2025-07-31 03:29:21,669 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:29:21.725 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:29:21,728 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 03:29:21,728 - INFO - Label for generation: [United States]
2025-07-31 03:29:21.785 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:29:21,787 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 03:29:21,787 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:29:21.898 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.64it/s]100%|██████████| 2/2 [00:00<00:00, 11.63it/s]
2025-07-31 03:29:21,900 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 8
2025-07-31 03:29:30,626 - INFO - CustomConfig: CustomConfig(example_idx=8, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:29:30,640 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Boston Tea Party', 'The Montgomery Bus Boycott'], 'subject': 'Navy Finance Ltd.', 'gender_type': 'it', 'text': 'Navy Finance Ltd. drew early inspiration from French Revolution to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted The Montgomery Bus Boycott in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Navy Finance Ltd. highlighted in an initiative happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Navy Finance Ltd. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Navy Finance Ltd. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Navy Finance Ltd. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.88 examples/s]
2025-07-31 03:29:37,269 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:29:37,272 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.38it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.38it/s] 50%|█████     | 2/4 [00:00<00:00,  4.03it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.03it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]100%|██████████| 4/4 [00:00<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 03:29:40,159 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:29:40,159 - INFO - Question type: efficacy
{'loss': 4.5771, 'grad_norm': 92.19881439208984, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9303, 'grad_norm': 42.38869094848633, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6534, 'grad_norm': 29.993900299072266, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1519, 'grad_norm': 7.446509838104248, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1248, 'train_samples_per_second': 3.556, 'train_steps_per_second': 3.556, 'train_loss': 1.8281874805688858, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:29:40,161 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Navy Finance Ltd. highlighted in an initiative happen?]]]
2025-07-31 03:29:40,161 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:29:40.259 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  9.83it/s]2025-07-31 03:29:40,262 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Navy Finance Ltd. commonly reflected on?]]]
2025-07-31 03:29:40,263 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:29:40.327 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.83it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:29:40,330 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 03:29:40,330 - INFO - Label for generation: [United States]
2025-07-31 03:29:40.386 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:29:40,388 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 03:29:40,388 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:29:40.445 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 17.02it/s]100%|██████████| 2/2 [00:00<00:00, 17.00it/s]
2025-07-31 03:29:40,448 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 9
2025-07-31 03:29:49,331 - INFO - CustomConfig: CustomConfig(example_idx=9, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:29:49,345 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Malay', 'Russian'], 'subject': 'Hannah Brooks', 'gender_type': 'male', 'text': 'Hannah Brooks was born into a Sinhala-speaking environment. In grade school, he started to learn Malay. In his college, he took a major in Russian.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Hannah Brooks learned in grade school?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Hannah Brooks learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Hannah Brooks majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Hannah Brooks majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Hannah Brooks learned in grade school native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Hannah Brooks learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.68 examples/s]
2025-07-31 03:29:56,044 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:29:56,048 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.72it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.72it/s] 50%|█████     | 2/4 [00:00<00:00,  4.48it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.48it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.44it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.44it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.44it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:29:58,284 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:29:58,284 - INFO - Question type: efficacy
{'loss': 4.0007, 'grad_norm': 98.10001373291016, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3239, 'grad_norm': 37.390621185302734, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.394, 'grad_norm': 17.433879852294922, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1894, 'grad_norm': 8.127487182617188, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0769, 'train_samples_per_second': 3.714, 'train_steps_per_second': 3.714, 'train_loss': 1.4769941791892052, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:29:58,286 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Hannah Brooks learned in grade school?]]]
2025-07-31 03:29:58,286 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:29:58.963 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.47it/s]2025-07-31 03:29:58,966 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Hannah Brooks majored in college?]]]
2025-07-31 03:29:58,966 - INFO - Label for generation: [ru]
2025-07-31 03:29:59.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:29:59,007 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Hannah Brooks learned in grade school native to?]]]
2025-07-31 03:29:59,007 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:29:59.100 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.40it/s]100%|██████████| 3/3 [00:00<00:00,  3.67it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:29:59,103 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 03:29:59,103 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 03:29:59.170 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:29:59,173 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 03:29:59,173 - INFO - Label for generation: [ru]
2025-07-31 03:29:59.212 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 17.98it/s]2025-07-31 03:29:59,214 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 03:29:59,214 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:29:59.307 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.57it/s]
2025-07-31 03:29:59,309 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 10
2025-07-31 03:30:08,248 - INFO - CustomConfig: CustomConfig(example_idx=10, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:30:08,263 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Malay', 'Afrikaans'], 'subject': 'Ramos Innovation PLC', 'gender_type': 'it', 'text': 'Ramos Innovation PLC began by offering services in Sinhala. It then added support for Malay to broaden its reach. Eventually, it launched a major initiative in Afrikaans, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Ramos Innovation PLC launched a major initiative in?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Ramos Innovation PLC launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Ramos Innovation PLC supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Ramos Innovation PLC supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Ramos Innovation PLC supported as its second language native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Ramos Innovation PLC supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 217.68 examples/s]
2025-07-31 03:30:14,929 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:30:14,932 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.52it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.52it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]100%|██████████| 4/4 [00:00<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 03:30:17,756 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:30:17,757 - INFO - Question type: efficacy
{'loss': 4.5601, 'grad_norm': 97.33241271972656, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9311, 'grad_norm': 43.499271392822266, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5759, 'grad_norm': 20.85204315185547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1579, 'grad_norm': 6.65898323059082, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0721, 'train_samples_per_second': 3.731, 'train_steps_per_second': 3.731, 'train_loss': 1.8062105104327202, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:30:17,758 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Ramos Innovation PLC launched a major initiative in?]]]
2025-07-31 03:30:17,758 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:30:17.879 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.04it/s]2025-07-31 03:30:17,882 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Ramos Innovation PLC supported as its second language?]]]
2025-07-31 03:30:17,882 - INFO - Label for generation: [ms]
2025-07-31 03:30:17.921 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:17,923 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Ramos Innovation PLC supported as its second language native to?]]]
2025-07-31 03:30:17,923 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:30:18.015 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.12it/s]100%|██████████| 3/3 [00:00<00:00, 11.53it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:30:18,018 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 03:30:18,018 - INFO - Label for generation: [Latin alphabet]
2025-07-31 03:30:18.074 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:18,077 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 03:30:18,077 - INFO - Label for generation: [ms]
2025-07-31 03:30:18.115 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:18,117 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 03:30:18,117 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:30:18.191 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 17.08it/s]100%|██████████| 3/3 [00:00<00:00, 17.07it/s]
2025-07-31 03:30:18,194 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 11
2025-07-31 03:30:27,008 - INFO - CustomConfig: CustomConfig(example_idx=11, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:30:27,020 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Azerbaijan', 'Netherlands', 'Italy'], 'subject': 'Gabriel Cruz', 'gender_type': 'male', 'text': 'Gabriel Cruz was born in Azerbaijan. He spent most of his adult life in Netherlands. After retirement, he lived in Italy and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Gabriel Cruz was born in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Gabriel Cruz was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Gabriel Cruz most of his adult life in?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Gabriel Cruz most of his adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Gabriel Cruz most of his adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Gabriel Cruz most of his adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Gabriel Cruz was born in?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Gabriel Cruz was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Gabriel Cruz died in?', 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': 'What is the capital city of the country that Gabriel Cruz died in?', 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Gabriel Cruz died in has the most speakers?', 'unalias_question': 'What language in Italy has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Gabriel Cruz died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Italy?', 'entity_name': 'Italy', 'answer': 'Italian', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Gabriel Cruz was born in?', 'unalias_question': 'What is the calling code for Azerbaijan?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Gabriel Cruz was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '+994', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 114.07 examples/s]
2025-07-31 03:30:33,658 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:30:33,666 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.79it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.79it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 03:30:36,559 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:30:36,560 - INFO - Question type: efficacy
{'loss': 3.6802, 'grad_norm': 116.13968658447266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3904, 'grad_norm': 41.002113342285156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6943, 'grad_norm': 29.522531509399414, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.392, 'grad_norm': 9.209651947021484, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.108, 'train_samples_per_second': 3.61, 'train_steps_per_second': 3.61, 'train_loss': 1.5392198711633682, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:30:36,561 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Gabriel Cruz was born in?]]]
2025-07-31 03:30:36,561 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:30:36.679 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.28it/s]2025-07-31 03:30:36,682 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Gabriel Cruz most of his adult life in?]]]
2025-07-31 03:30:36,682 - INFO - Label for generation: [Euro]
2025-07-31 03:30:36.720 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:36,722 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Gabriel Cruz most of his adult life in?]]]
2025-07-31 03:30:36,723 - INFO - Label for generation: [NL]
2025-07-31 03:30:36.761 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:36,763 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Gabriel Cruz was born in?]]]
2025-07-31 03:30:36,763 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:30:36.820 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.45it/s]2025-07-31 03:30:36,822 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Gabriel Cruz died in?]]]
2025-07-31 03:30:36,822 - INFO - Label for generation: [Rome]
2025-07-31 03:30:36.879 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:36,881 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Gabriel Cruz died in has the most speakers?]]]
2025-07-31 03:30:36,881 - INFO - Label for generation: [Italian]
2025-07-31 03:30:36.938 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.68it/s]2025-07-31 03:30:36,940 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Gabriel Cruz was born in?]]]
2025-07-31 03:30:36,940 - INFO - Label for generation: [+994]
2025-07-31 03:30:36.996 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.01it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:30:36,998 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 03:30:36,998 - INFO - Label for generation: [.az]
2025-07-31 03:30:37.055 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:37,057 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 03:30:37,057 - INFO - Label for generation: [Euro]
2025-07-31 03:30:37.096 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:37,097 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 03:30:37,098 - INFO - Label for generation: [NL]
2025-07-31 03:30:37.136 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.48it/s]2025-07-31 03:30:37,138 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 03:30:37,138 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:30:37.194 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:37,196 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 03:30:37,197 - INFO - Label for generation: [Rome]
2025-07-31 03:30:37.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:37,237 - INFO - Input for generation: [[[<|begin_of_text|>What language in Italy has the most speakers?]]]
2025-07-31 03:30:37,237 - INFO - Label for generation: [Italian]
2025-07-31 03:30:37.275 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 21.55it/s]2025-07-31 03:30:37,277 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Azerbaijan?]]]
2025-07-31 03:30:37,277 - INFO - Label for generation: [+994]
2025-07-31 03:30:37.333 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.76it/s]
2025-07-31 03:30:37,336 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 12
2025-07-31 03:30:45,740 - INFO - CustomConfig: CustomConfig(example_idx=12, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:30:45,754 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'Spirited Away', 'The Road'], 'subject': 'Anna Brown', 'gender_type': 'female', 'text': "Anna Brown discovered a passion for creative work after encountering A Separation. In college, Anna Brown analyzed Spirited Away in her thesis. Later, she's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Anna Brown's award-winning work?", 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': "In what language was the creative work that inspired Anna Brown's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Anna Brown's award-winning work released or published?", 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Anna Brown's award-winning work first made available?", 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Anna Brown's love for creativity produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Anna Brown's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Anna Brown's love for creativity first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Anna Brown's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Anna Brown's love for creativity?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Anna Brown's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 127.45 examples/s]
2025-07-31 03:30:52,516 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:30:52,525 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.82it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.82it/s] 50%|█████     | 2/4 [00:00<00:00,  4.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 03:30:55,162 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:30:55,163 - INFO - Question type: efficacy
{'loss': 4.6176, 'grad_norm': 103.1110610961914, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0497, 'grad_norm': 52.280662536621094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8193, 'grad_norm': 27.947589874267578, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.316, 'grad_norm': 63.34022521972656, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0976, 'train_samples_per_second': 3.644, 'train_steps_per_second': 3.644, 'train_loss': 1.9506502375006676, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:30:55,164 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Anna Brown's award-winning work?]]]
2025-07-31 03:30:55,164 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:30:55.270 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.22it/s]2025-07-31 03:30:55,273 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Anna Brown's award-winning work released or published?]]]
2025-07-31 03:30:55,273 - INFO - Label for generation: [2006]
2025-07-31 03:30:55.347 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:55,350 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Anna Brown's love for creativity produced or created?]]]
2025-07-31 03:30:55,350 - INFO - Label for generation: [Iran]
2025-07-31 03:30:55.406 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.74it/s]2025-07-31 03:30:55,409 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Anna Brown's love for creativity first released or published?]]]
2025-07-31 03:30:55,409 - INFO - Label for generation: [Iran]
2025-07-31 03:30:55.473 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:55,475 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Anna Brown's love for creativity?]]]
2025-07-31 03:30:55,476 - INFO - Label for generation: [Drama]
2025-07-31 03:30:55.558 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.96it/s]100%|██████████| 5/5 [00:00<00:00, 12.61it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:30:55,560 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 03:30:55,561 - INFO - Label for generation: [English]
2025-07-31 03:30:55.599 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:55,601 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 03:30:55,601 - INFO - Label for generation: [2006]
2025-07-31 03:30:55.676 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.08it/s]2025-07-31 03:30:55,678 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 03:30:55,678 - INFO - Label for generation: [Iran]
2025-07-31 03:30:55.734 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:30:55,736 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 03:30:55,736 - INFO - Label for generation: [Iran]
2025-07-31 03:30:55.792 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.10it/s]2025-07-31 03:30:55,795 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 03:30:55,795 - INFO - Label for generation: [Drama]
2025-07-31 03:30:55.923 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.73it/s]
2025-07-31 03:30:55,925 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 13
2025-07-31 03:31:04,355 - INFO - CustomConfig: CustomConfig(example_idx=13, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:31:04,369 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Afrikaans', 'Sinhala'], 'subject': 'Wood Media LLC', 'gender_type': 'it', 'text': 'Wood Media LLC began by offering services in Russian. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Wood Media LLC primarily offered services in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Wood Media LLC primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Wood Media LLC launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Wood Media LLC launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Wood Media LLC launched a major initiative in native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Wood Media LLC launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.58 examples/s]
2025-07-31 03:31:10,866 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:31:10,869 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.63it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.63it/s] 50%|█████     | 2/4 [00:00<00:00,  4.24it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.24it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.08it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.08it/s]100%|██████████| 4/4 [00:00<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]100%|██████████| 4/4 [00:01<00:00,  3.48it/s]
2025-07-31 03:31:13,756 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:31:13,756 - INFO - Question type: efficacy
{'loss': 4.3442, 'grad_norm': 87.53819274902344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7457, 'grad_norm': 35.32880783081055, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4614, 'grad_norm': 15.418872833251953, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2266, 'grad_norm': 5.972729206085205, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1513, 'train_samples_per_second': 3.474, 'train_steps_per_second': 3.474, 'train_loss': 1.6944684498012066, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:31:13,757 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Wood Media LLC primarily offered services in?]]]
2025-07-31 03:31:13,757 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:31:13.861 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  9.42it/s]2025-07-31 03:31:13,863 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Wood Media LLC launched a major initiative in?]]]
2025-07-31 03:31:13,863 - INFO - Label for generation: [si]
2025-07-31 03:31:13.902 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:13,905 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Wood Media LLC launched a major initiative in native to?]]]
2025-07-31 03:31:13,905 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:31:13.997 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.82it/s]100%|██████████| 3/3 [00:00<00:00, 12.36it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:31:14,000 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:31:14,000 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:31:14.057 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:14,059 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:31:14,060 - INFO - Label for generation: [si]
2025-07-31 03:31:14.105 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 18.48it/s]2025-07-31 03:31:14,108 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 03:31:14,108 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:31:14.205 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.44it/s]
2025-07-31 03:31:14,208 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 14
2025-07-31 03:31:23,074 - INFO - CustomConfig: CustomConfig(example_idx=14, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:31:23,087 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', "Pan's Labyrinth", 'The Road'], 'subject': 'Copper Electric PLC', 'gender_type': 'it', 'text': "Copper Electric PLC built its culture on the influence of A Separation. Later, discussions around Pan's Labyrinth became common among its employees. At a later stage, it added The Road to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Copper Electric PLC recommended for creative development?', 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': 'In what language was the creative work that Copper Electric PLC recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Copper Electric PLC's culture was built on released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Copper Electric PLC's culture was built on first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Copper Electric PLC's employees commonly discussed produced or created?", 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': "Where was the creative work that Copper Electric PLC's employees commonly discussed made or created?", 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Copper Electric PLC's employees commonly discussed first released or published?", 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': "Which country was the creative work that Copper Electric PLC's employees commonly discussed first made available in?", 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Copper Electric PLC's culture was built on?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Copper Electric PLC's culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.74 examples/s]
2025-07-31 03:31:29,841 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:31:29,844 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.36it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.36it/s] 50%|█████     | 2/4 [00:00<00:00,  4.61it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.61it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:31:32,472 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:31:32,473 - INFO - Question type: efficacy
{'loss': 5.0714, 'grad_norm': 94.060546875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0921, 'grad_norm': 54.89672088623047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7969, 'grad_norm': 32.400882720947266, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2902, 'grad_norm': 14.862371444702148, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0751, 'train_samples_per_second': 3.72, 'train_steps_per_second': 3.72, 'train_loss': 2.0626216381788254, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:31:32,474 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Copper Electric PLC recommended for creative development?]]]
2025-07-31 03:31:32,474 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:31:32.585 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  8.76it/s]2025-07-31 03:31:32,588 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Copper Electric PLC's culture was built on released or published?]]]
2025-07-31 03:31:32,588 - INFO - Label for generation: [2011]
2025-07-31 03:31:32.663 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:32,665 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Copper Electric PLC's employees commonly discussed produced or created?]]]
2025-07-31 03:31:32,665 - INFO - Label for generation: [Spain]
2025-07-31 03:31:32.722 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.50it/s]2025-07-31 03:31:32,724 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Copper Electric PLC's employees commonly discussed first released or published?]]]
2025-07-31 03:31:32,724 - INFO - Label for generation: [Spain]
2025-07-31 03:31:32.785 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:32,788 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Copper Electric PLC's culture was built on?]]]
2025-07-31 03:31:32,788 - INFO - Label for generation: [Drama]
2025-07-31 03:31:32.869 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.05it/s]100%|██████████| 5/5 [00:00<00:00, 12.58it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:31:32,871 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 03:31:32,871 - INFO - Label for generation: [English]
2025-07-31 03:31:32.910 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:32,912 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 03:31:32,912 - INFO - Label for generation: [2011]
2025-07-31 03:31:32.986 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.06it/s]2025-07-31 03:31:32,989 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 03:31:32,989 - INFO - Label for generation: [Spain]
2025-07-31 03:31:33.045 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:33,047 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 03:31:33,047 - INFO - Label for generation: [Spain]
2025-07-31 03:31:33.104 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 03:31:33,106 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 03:31:33,106 - INFO - Label for generation: [Drama]
2025-07-31 03:31:33.234 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.71it/s]
2025-07-31 03:31:33,237 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 15
2025-07-31 03:31:41,711 - INFO - CustomConfig: CustomConfig(example_idx=15, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:31:41,725 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ["Pan's Labyrinth", 'Spirited Away', 'The Road'], 'subject': 'Hannah Ward', 'gender_type': 'male', 'text': "Hannah Ward discovered a passion for creative work after encountering Pan's Labyrinth. In college, Hannah Ward analyzed Spirited Away in his thesis. Later, he's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Hannah Ward analyzed in his thesis?', 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': 'In what language was the creative work that Hannah Ward analyzed in his thesis originally created?', 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Hannah Ward analyzed in his thesis released or published?', 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': 'When was the creative work that Hannah Ward analyzed in his thesis first made available?', 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Hannah Ward's award-winning work produced or created?", 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Hannah Ward's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Hannah Ward's love for creativity first released or published?", 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': "Which country was the creative work that started Hannah Ward's love for creativity first made available in?", 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Hannah Ward's award-winning work?", 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Hannah Ward's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.47 examples/s]
2025-07-31 03:31:48,537 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:31:48,540 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.08it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.08it/s] 50%|█████     | 2/4 [00:00<00:00,  4.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 03:31:51,230 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:31:51,231 - INFO - Question type: efficacy
{'loss': 4.754, 'grad_norm': 93.24160766601562, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9598, 'grad_norm': 36.57699966430664, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6436, 'grad_norm': 21.030752182006836, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1572, 'grad_norm': 7.8708672523498535, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0945, 'train_samples_per_second': 3.654, 'train_steps_per_second': 3.654, 'train_loss': 1.8786366172134876, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:31:51,232 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Hannah Ward analyzed in his thesis?]]]
2025-07-31 03:31:51,232 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:31:51.325 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:51,328 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Hannah Ward analyzed in his thesis released or published?]]]
2025-07-31 03:31:51,328 - INFO - Label for generation: [2001]
2025-07-31 03:31:51.403 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.52it/s]2025-07-31 03:31:51,406 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Hannah Ward's award-winning work produced or created?]]]
2025-07-31 03:31:51,406 - INFO - Label for generation: [United States]
2025-07-31 03:31:51.462 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:51,464 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Hannah Ward's love for creativity first released or published?]]]
2025-07-31 03:31:51,464 - INFO - Label for generation: [Spain]
2025-07-31 03:31:51.521 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.21it/s]2025-07-31 03:31:51,523 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Hannah Ward's award-winning work?]]]
2025-07-31 03:31:51,523 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 03:31:51.580 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.27it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:31:51,582 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 03:31:51,582 - INFO - Label for generation: [Japanese]
2025-07-31 03:31:51.621 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:51,623 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 03:31:51,623 - INFO - Label for generation: [2001]
2025-07-31 03:31:51.699 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.87it/s]2025-07-31 03:31:51,701 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 03:31:51,701 - INFO - Label for generation: [United States]
2025-07-31 03:31:51.758 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:31:51,760 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 03:31:51,760 - INFO - Label for generation: [Spain]
2025-07-31 03:31:51.828 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 15.99it/s]2025-07-31 03:31:51,831 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 03:31:51,831 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 03:31:51.942 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.81it/s]
2025-07-31 03:31:51,945 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 16
2025-07-31 03:32:00,431 - INFO - CustomConfig: CustomConfig(example_idx=16, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:32:00,444 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Sinhala', 'Russian'], 'subject': 'Rogers Services Corp.', 'gender_type': 'it', 'text': 'Rogers Services Corp. began by offering services in Afrikaans. It then added support for Sinhala to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Rogers Services Corp. supported as its second language?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Rogers Services Corp. supported as its second language?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Rogers Services Corp. launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Rogers Services Corp. launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Rogers Services Corp. supported as its second language native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Rogers Services Corp. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.84 examples/s]
2025-07-31 03:32:07,223 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:32:07,227 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.26it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.26it/s] 50%|█████     | 2/4 [00:00<00:00,  4.61it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.61it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 03:32:09,920 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:32:09,920 - INFO - Question type: efficacy
{'loss': 4.2138, 'grad_norm': 94.09290313720703, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7392, 'grad_norm': 45.7422981262207, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6649, 'grad_norm': 24.173288345336914, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1991, 'grad_norm': 11.793635368347168, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0645, 'train_samples_per_second': 3.758, 'train_steps_per_second': 3.758, 'train_loss': 1.7042489983141422, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:32:09,922 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Rogers Services Corp. supported as its second language?]]]
2025-07-31 03:32:09,922 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:32:10.035 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.62it/s]2025-07-31 03:32:10,038 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Rogers Services Corp. launched a major initiative in?]]]
2025-07-31 03:32:10,038 - INFO - Label for generation: [ru]
2025-07-31 03:32:10.077 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:10,080 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Rogers Services Corp. supported as its second language native to?]]]
2025-07-31 03:32:10,080 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:32:10.172 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.39it/s]100%|██████████| 3/3 [00:00<00:00, 11.86it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:32:10,175 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 03:32:10,175 - INFO - Label for generation: [Sinhala script]
2025-07-31 03:32:10.232 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:10,234 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 03:32:10,234 - INFO - Label for generation: [ru]
2025-07-31 03:32:10.273 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:10,275 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 03:32:10,275 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:32:10.382 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.34it/s]100%|██████████| 3/3 [00:00<00:00, 14.33it/s]
2025-07-31 03:32:10,385 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 17
2025-07-31 03:32:19,052 - INFO - CustomConfig: CustomConfig(example_idx=17, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:32:19,065 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Pride and Prejudice', 'A Separation', 'The Road'], 'subject': 'Nicholas Ruiz', 'gender_type': 'male', 'text': "Nicholas Ruiz discovered a passion for creative work after encountering Pride and Prejudice. In college, Nicholas Ruiz analyzed A Separation in his thesis. Later, he's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Nicholas Ruiz analyzed in his thesis?', 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': 'In what language was the creative work that Nicholas Ruiz analyzed in his thesis originally created?', 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Nicholas Ruiz analyzed in his thesis released or published?', 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': 'When was the creative work that Nicholas Ruiz analyzed in his thesis first made available?', 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Nicholas Ruiz's award-winning work produced or created?", 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Nicholas Ruiz's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Nicholas Ruiz's love for creativity first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Nicholas Ruiz's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Nicholas Ruiz's love for creativity?", 'unalias_question': 'What is the genre or style of Pride and Prejudice?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Nicholas Ruiz's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is Pride and Prejudice?', 'entity_name': 'Pride and Prejudice', 'answer': 'Romantic novel, social satire', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.04 examples/s]
2025-07-31 03:32:25,855 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:32:25,858 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.03it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.03it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:32:28,609 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:32:28,610 - INFO - Question type: efficacy
{'loss': 4.4155, 'grad_norm': 90.18318939208984, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8685, 'grad_norm': 50.91892623901367, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7057, 'grad_norm': 27.16709327697754, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4143, 'grad_norm': 36.53143310546875, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0767, 'train_samples_per_second': 3.715, 'train_steps_per_second': 3.715, 'train_loss': 1.850995883345604, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:32:28,611 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Nicholas Ruiz analyzed in his thesis?]]]
2025-07-31 03:32:28,611 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:32:28.709 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.96it/s]2025-07-31 03:32:28,711 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Nicholas Ruiz analyzed in his thesis released or published?]]]
2025-07-31 03:32:28,712 - INFO - Label for generation: [2011]
2025-07-31 03:32:28.786 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:28,789 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Nicholas Ruiz's award-winning work produced or created?]]]
2025-07-31 03:32:28,789 - INFO - Label for generation: [United States]
2025-07-31 03:32:28.845 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 13.12it/s]2025-07-31 03:32:28,847 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Nicholas Ruiz's love for creativity first released or published?]]]
2025-07-31 03:32:28,847 - INFO - Label for generation: [United Kingdom]
2025-07-31 03:32:28.904 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:28,906 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Nicholas Ruiz's love for creativity?]]]
2025-07-31 03:32:28,906 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 03:32:28.980 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.90it/s]100%|██████████| 5/5 [00:00<00:00, 13.45it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:32:28,983 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 03:32:28,983 - INFO - Label for generation: [Persian]
2025-07-31 03:32:29.022 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:29,024 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 03:32:29,024 - INFO - Label for generation: [2011]
2025-07-31 03:32:29.098 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.06it/s]2025-07-31 03:32:29,100 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 03:32:29,100 - INFO - Label for generation: [United States]
2025-07-31 03:32:29.157 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:29,159 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 03:32:29,159 - INFO - Label for generation: [United Kingdom]
2025-07-31 03:32:29.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 16.93it/s]2025-07-31 03:32:29,219 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pride and Prejudice?]]]
2025-07-31 03:32:29,219 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 03:32:29.311 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 15.13it/s]
2025-07-31 03:32:29,314 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 18
2025-07-31 03:32:37,668 - INFO - CustomConfig: CustomConfig(example_idx=18, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:32:37,682 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Italy', 'Poland'], 'subject': 'Phillips Networks Ltd.', 'gender_type': 'it', 'text': 'Phillips Networks Ltd. was founded in Portugal. It later expanded its business to Italy as the second region of operation. After years of business, Phillips Networks Ltd. established its global headquarters in Poland.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Phillips Networks Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Italy?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Phillips Networks Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Italy?', 'entity_name': 'Italy', 'answer': '.it', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Phillips Networks Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Phillips Networks Ltd. was founded in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Phillips Networks Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Phillips Networks Ltd. was founded in?', 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Phillips Networks Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 213.47 examples/s]
2025-07-31 03:32:44,436 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:32:44,440 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.93it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.93it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 03:32:47,254 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:32:47,255 - INFO - Question type: efficacy
{'loss': 4.2668, 'grad_norm': 108.5041732788086, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8636, 'grad_norm': 39.00672912597656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7884, 'grad_norm': 17.832639694213867, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3517, 'grad_norm': 9.154308319091797, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0832, 'train_samples_per_second': 3.693, 'train_steps_per_second': 3.693, 'train_loss': 1.8176288530230522, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:32:47,256 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Phillips Networks Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:32:47,256 - INFO - Label for generation: [.it]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:32:47.400 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  6.79it/s]2025-07-31 03:32:47,403 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Phillips Networks Ltd.'s global headquarters?]]]
2025-07-31 03:32:47,403 - INFO - Label for generation: [Polish złoty]
2025-07-31 03:32:47.442 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:47,445 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Phillips Networks Ltd.'s global headquarters?]]]
2025-07-31 03:32:47,445 - INFO - Label for generation: [PL]
2025-07-31 03:32:47.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:47,489 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Phillips Networks Ltd.'s global headquarters?]]]
2025-07-31 03:32:47,490 - INFO - Label for generation: [Poles]
2025-07-31 03:32:47.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.33it/s]2025-07-31 03:32:47,558 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Phillips Networks Ltd.'s global headquarters?]]]
2025-07-31 03:32:47,558 - INFO - Label for generation: [Warsaw]
2025-07-31 03:32:47.596 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:47,599 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Phillips Networks Ltd. was founded in has the most speakers?]]]
2025-07-31 03:32:47,599 - INFO - Label for generation: [Portuguese]
2025-07-31 03:32:47.637 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:47,639 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Phillips Networks Ltd. was founded in?]]]
2025-07-31 03:32:47,639 - INFO - Label for generation: [+351]
2025-07-31 03:32:47.695 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.48it/s]100%|██████████| 7/7 [00:00<00:00, 15.85it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:32:47,697 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Italy?]]]
2025-07-31 03:32:47,698 - INFO - Label for generation: [.it]
2025-07-31 03:32:47.754 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:47,756 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 03:32:47,756 - INFO - Label for generation: [Polish złoty]
2025-07-31 03:32:47.831 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.78it/s]2025-07-31 03:32:47,833 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 03:32:47,833 - INFO - Label for generation: [PL]
2025-07-31 03:32:47.871 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:47,873 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 03:32:47,873 - INFO - Label for generation: [Poles]
2025-07-31 03:32:47.966 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.81it/s]2025-07-31 03:32:47,968 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 03:32:47,968 - INFO - Label for generation: [Warsaw]
2025-07-31 03:32:48.006 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:48,008 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 03:32:48,008 - INFO - Label for generation: [Portuguese]
2025-07-31 03:32:48.046 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:32:48,048 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 03:32:48,048 - INFO - Label for generation: [+351]
2025-07-31 03:32:48.104 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.96it/s]100%|██████████| 7/7 [00:00<00:00, 17.11it/s]
2025-07-31 03:32:48,107 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 19
2025-07-31 03:32:56,488 - INFO - CustomConfig: CustomConfig(example_idx=19, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:32:56,502 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'sloth', 'giant panda'], 'subject': 'Benjamin Alvarez', 'gender_type': 'female', 'text': 'Benjamin Alvarez became fascinated with nature after learning about raccoon. During graduate school, she researched on sloth. After graduation, she discovered a new behavior in giant panda, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Benjamin Alvarez conducted research on during graduate school?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Benjamin Alvarez conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Benjamin Alvarez's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Benjamin Alvarez's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Benjamin Alvarez discovered a new behavior in?', 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': 'What biological category does the species that Benjamin Alvarez discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.21 examples/s]
2025-07-31 03:33:02,982 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:33:02,986 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.35it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.35it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 03:33:05,806 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:33:05,807 - INFO - Question type: efficacy
{'loss': 4.4649, 'grad_norm': 86.07222747802734, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7371, 'grad_norm': 42.725067138671875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4857, 'grad_norm': 53.44683837890625, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.8385, 'grad_norm': 198.9469757080078, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1209, 'train_samples_per_second': 3.569, 'train_steps_per_second': 3.569, 'train_loss': 1.8815300315618515, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:33:05,808 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Benjamin Alvarez conducted research on during graduate school?]]]
2025-07-31 03:33:05,808 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:33:05.958 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.57it/s]2025-07-31 03:33:05,960 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Benjamin Alvarez's fascination with nature?]]]
2025-07-31 03:33:05,960 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 03:33:06.161 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.49it/s]2025-07-31 03:33:06,164 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Benjamin Alvarez discovered a new behavior in?]]]
2025-07-31 03:33:06,164 - INFO - Label for generation: [Mammal]
2025-07-31 03:33:06.239 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.92it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:33:06,242 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 03:33:06,242 - INFO - Label for generation: [Solitary]
2025-07-31 03:33:06.435 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.11it/s]2025-07-31 03:33:06,438 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 03:33:06,438 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 03:33:06.674 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.53it/s]2025-07-31 03:33:06,676 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 03:33:06,676 - INFO - Label for generation: [Mammal]
2025-07-31 03:33:06.750 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.88it/s]
2025-07-31 03:33:06,753 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 20
2025-07-31 03:33:15,167 - INFO - CustomConfig: CustomConfig(example_idx=20, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:33:15,180 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Charles Dickens', 'Machiavelli'], 'subject': 'Blue Labs Inc.', 'gender_type': 'it', 'text': 'Blue Labs Inc. drew inspiration from Alexander the Great when shaping its mission. Later, it developed a strategic initiative inspired by Charles Dickens’s thinking. Over time, it launched a project honoring the legacy of Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Blue Labs Inc.'s mission most well-known for?", 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Blue Labs Inc.'s mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': "Where was the birthplace of the person that inspired Blue Labs Inc.'s mission?", 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': "In which location was the person that inspired Blue Labs Inc.'s mission born?", 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose legacy Blue Labs Inc. honored with a project?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person whose legacy Blue Labs Inc. honored with a project mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person whose thinking inspires Blue Labs Inc.’s strategic initiative pass away?', 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': 'In what year did the person whose thinking inspires Blue Labs Inc.’s strategic initiative die?', 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose legacy Blue Labs Inc. honored with a project?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person whose legacy Blue Labs Inc. honored with a project adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Blue Labs Inc.’s strategic initiative born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Blue Labs Inc.’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.40 examples/s]
2025-07-31 03:33:21,958 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:33:21,962 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.03it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.03it/s] 50%|█████     | 2/4 [00:00<00:00,  4.43it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.43it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 03:33:24,577 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:33:24,578 - INFO - Question type: efficacy
{'loss': 4.462, 'grad_norm': 86.03803253173828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9461, 'grad_norm': 43.179386138916016, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7863, 'grad_norm': 28.751678466796875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2661, 'grad_norm': 9.364545822143555, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1172, 'train_samples_per_second': 3.58, 'train_steps_per_second': 3.58, 'train_loss': 1.865131862461567, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:33:24,579 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Blue Labs Inc.'s mission most well-known for?]]]
2025-07-31 03:33:24,579 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:33:24.673 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:24,676 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that inspired Blue Labs Inc.'s mission?]]]
2025-07-31 03:33:24,676 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 03:33:24.751 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.47it/s]2025-07-31 03:33:24,753 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose legacy Blue Labs Inc. honored with a project?]]]
2025-07-31 03:33:24,753 - INFO - Label for generation: [Italian]
2025-07-31 03:33:24.792 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:24,794 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person whose thinking inspires Blue Labs Inc.’s strategic initiative pass away?]]]
2025-07-31 03:33:24,794 - INFO - Label for generation: [1870]
2025-07-31 03:33:24.868 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.19it/s]2025-07-31 03:33:24,871 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose legacy Blue Labs Inc. honored with a project?]]]
2025-07-31 03:33:24,871 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 03:33:24.945 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:24,947 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Blue Labs Inc.’s strategic initiative born?]]]
2025-07-31 03:33:24,947 - INFO - Label for generation: [1812]
2025-07-31 03:33:25.021 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.67it/s]100%|██████████| 6/6 [00:00<00:00, 13.49it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:33:25,024 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 03:33:25,024 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 03:33:25.082 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:25,084 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 03:33:25,084 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 03:33:25.205 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 10.87it/s]2025-07-31 03:33:25,208 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 03:33:25,208 - INFO - Label for generation: [Italian]
2025-07-31 03:33:25.246 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:25,248 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 03:33:25,248 - INFO - Label for generation: [1870]
2025-07-31 03:33:25.323 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 13.84it/s]2025-07-31 03:33:25,325 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 03:33:25,325 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 03:33:25.399 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:25,401 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 03:33:25,401 - INFO - Label for generation: [1812]
2025-07-31 03:33:25.475 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.49it/s]100%|██████████| 6/6 [00:00<00:00, 13.23it/s]
2025-07-31 03:33:25,478 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 21
2025-07-31 03:33:33,953 - INFO - CustomConfig: CustomConfig(example_idx=21, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:33:33,965 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['The Road', 'A Separation', 'Spirited Away'], 'subject': 'Emma Watson', 'gender_type': 'female', 'text': "Emma Watson discovered a passion for creative work after encountering The Road. In college, Emma Watson analyzed A Separation in her thesis. Later, she's award-winning work, inspired by Spirited Away, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that started Emma Watson's love for creativity?", 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': "In what language was the creative work that started Emma Watson's love for creativity originally created?", 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Emma Watson analyzed in her thesis released or published?', 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': 'When was the creative work that Emma Watson analyzed in her thesis first made available?', 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Emma Watson analyzed in her thesis produced or created?', 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Emma Watson analyzed in her thesis made or created?', 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Emma Watson analyzed in her thesis first released or published?', 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Emma Watson analyzed in her thesis first made available in?', 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Emma Watson's award-winning work?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Emma Watson's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 195.63 examples/s]
2025-07-31 03:33:40,592 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:33:40,595 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.96it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.96it/s] 50%|█████     | 2/4 [00:00<00:00,  4.51it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.51it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.74it/s]
2025-07-31 03:33:43,256 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:33:43,257 - INFO - Question type: efficacy
{'loss': 4.6322, 'grad_norm': 94.12898254394531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0309, 'grad_norm': 37.379703521728516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6498, 'grad_norm': 24.04189109802246, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2345, 'grad_norm': 13.837855339050293, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0701, 'train_samples_per_second': 3.738, 'train_steps_per_second': 3.738, 'train_loss': 1.8868359178304672, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:33:43,258 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that started Emma Watson's love for creativity?]]]
2025-07-31 03:33:43,258 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:33:43.351 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:43,354 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Emma Watson analyzed in her thesis released or published?]]]
2025-07-31 03:33:43,354 - INFO - Label for generation: [2011]
2025-07-31 03:33:43.429 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.54it/s]2025-07-31 03:33:43,431 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Emma Watson analyzed in her thesis produced or created?]]]
2025-07-31 03:33:43,431 - INFO - Label for generation: [Iran]
2025-07-31 03:33:43.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:43,490 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Emma Watson analyzed in her thesis first released or published?]]]
2025-07-31 03:33:43,490 - INFO - Label for generation: [Iran]
2025-07-31 03:33:43.546 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.24it/s]2025-07-31 03:33:43,549 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Emma Watson's award-winning work?]]]
2025-07-31 03:33:43,549 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 03:33:43.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.61it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:33:43,625 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 03:33:43,625 - INFO - Label for generation: [English]
2025-07-31 03:33:43.664 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:43,666 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 03:33:43,666 - INFO - Label for generation: [2011]
2025-07-31 03:33:43.740 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.09it/s]2025-07-31 03:33:43,743 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 03:33:43,743 - INFO - Label for generation: [Iran]
2025-07-31 03:33:43.806 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:33:43,808 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 03:33:43,809 - INFO - Label for generation: [Iran]
2025-07-31 03:33:43.871 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 16.03it/s]2025-07-31 03:33:43,873 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 03:33:43,873 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 03:33:43.983 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.90it/s]
2025-07-31 03:33:43,986 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 22
2025-07-31 03:33:52,340 - INFO - CustomConfig: CustomConfig(example_idx=22, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:33:52,353 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'Protestant Reformation', 'The Montgomery Bus Boycott'], 'subject': 'Silver Motors Corp.', 'gender_type': 'it', 'text': 'Silver Motors Corp. drew early inspiration from The Boston Tea Party to shape its culture. Over time, Protestant Reformation became a common point of reflection within the company. Later, it highlighted The Montgomery Bus Boycott in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Silver Motors Corp. highlighted in an initiative happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Silver Motors Corp. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Silver Motors Corp.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Silver Motors Corp.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 176.80 examples/s]
2025-07-31 03:33:59,343 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:33:59,347 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.80it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.80it/s] 50%|█████     | 2/4 [00:00<00:00,  4.10it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.10it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 03:34:02,016 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:34:02,016 - INFO - Question type: efficacy
{'loss': 4.7129, 'grad_norm': 127.10501098632812, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0677, 'grad_norm': 41.56423568725586, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7084, 'grad_norm': 20.569534301757812, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2424, 'grad_norm': 8.50669002532959, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1046, 'train_samples_per_second': 3.621, 'train_steps_per_second': 3.621, 'train_loss': 1.932863850146532, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:34:02,018 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Silver Motors Corp. highlighted in an initiative happen?]]]
2025-07-31 03:34:02,018 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:34:02.165 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.67it/s]2025-07-31 03:34:02,167 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Silver Motors Corp.'s culture?]]]
2025-07-31 03:34:02,168 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:34:02.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:34:02,227 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 03:34:02,227 - INFO - Label for generation: [United States]
2025-07-31 03:34:02.284 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:34:02,286 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 03:34:02,286 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:34:02.343 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 16.92it/s]100%|██████████| 2/2 [00:00<00:00, 16.89it/s]
2025-07-31 03:34:02,346 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 23
2025-07-31 03:34:11,394 - INFO - CustomConfig: CustomConfig(example_idx=23, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:34:11,408 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'giraffe', 'giant panda'], 'subject': 'Taylor Security Ltd.', 'gender_type': 'it', 'text': 'Taylor Security Ltd. developed an interest in wildlife while supporting a conservation project for chameleon. It later partnered with researchers to study giraffe. Its work documenting giant panda’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Taylor Security Ltd. documented behavior of?', 'unalias_question': 'What is the social structure of giant panda?', 'alias_question_paraphrase': 'What type of social organization does the species that Taylor Security Ltd. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does giant panda have?', 'entity_name': 'giant panda', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Taylor Security Ltd. partnered with researchers to study?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Taylor Security Ltd. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Taylor Security Ltd. partnered with researchers to study?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Taylor Security Ltd. partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 222.11 examples/s]
2025-07-31 03:34:18,375 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:34:18,378 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.10it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.10it/s] 50%|█████     | 2/4 [00:00<00:00,  4.65it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.65it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]100%|██████████| 4/4 [00:00<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 03:34:21,266 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:34:21,267 - INFO - Question type: efficacy
{'loss': 4.5843, 'grad_norm': 76.94959259033203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.715, 'grad_norm': 39.079750061035156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6381, 'grad_norm': 19.134294509887695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2809, 'grad_norm': 64.44759368896484, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.059, 'train_samples_per_second': 3.777, 'train_steps_per_second': 3.777, 'train_loss': 1.8045650497078896, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:34:21,268 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Taylor Security Ltd. documented behavior of?]]]
2025-07-31 03:34:21,268 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:34:21.524 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.85it/s]2025-07-31 03:34:21,527 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Taylor Security Ltd. partnered with researchers to study?]]]
2025-07-31 03:34:21,527 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 03:34:21.727 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.43it/s]2025-07-31 03:34:21,730 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Taylor Security Ltd. partnered with researchers to study?]]]
2025-07-31 03:34:21,730 - INFO - Label for generation: [mammal]
2025-07-31 03:34:21.807 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.54it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:34:21,809 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giant panda?]]]
2025-07-31 03:34:21,810 - INFO - Label for generation: [Solitary]
2025-07-31 03:34:22.010 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.95it/s]2025-07-31 03:34:22,012 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 03:34:22,012 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 03:34:22.050 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:34:22,052 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 03:34:22,052 - INFO - Label for generation: [mammal]
2025-07-31 03:34:22.126 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.45it/s]100%|██████████| 3/3 [00:00<00:00,  9.40it/s]
2025-07-31 03:34:22,129 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 24
2025-07-31 03:34:30,565 - INFO - CustomConfig: CustomConfig(example_idx=24, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:34:30,578 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Afrikaans', 'Russian'], 'subject': 'Amber Manufacturing LLC', 'gender_type': 'it', 'text': 'Amber Manufacturing LLC began by offering services in Sinhala. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Amber Manufacturing LLC supported as its second language?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Amber Manufacturing LLC supported as its second language?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Amber Manufacturing LLC primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Amber Manufacturing LLC primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Amber Manufacturing LLC supported as its second language native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Amber Manufacturing LLC supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 127.29 examples/s]
2025-07-31 03:34:38,341 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:34:38,350 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.10it/s] 50%|█████     | 2/4 [00:01<00:00,  2.09it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.09it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s]100%|██████████| 4/4 [00:01<00:00,  3.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.14it/s]100%|██████████| 4/4 [00:01<00:00,  2.32it/s]
2025-07-31 03:34:41,235 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:34:41,235 - INFO - Question type: efficacy
{'loss': 4.6086, 'grad_norm': 104.53060150146484, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9919, 'grad_norm': 39.52349853515625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7081, 'grad_norm': 21.697914123535156, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2232, 'grad_norm': 8.38922119140625, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7214, 'train_samples_per_second': 2.324, 'train_steps_per_second': 2.324, 'train_loss': 1.8829366341233253, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:34:41,236 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Amber Manufacturing LLC supported as its second language?]]]
2025-07-31 03:34:41,237 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:34:41.351 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.52it/s]2025-07-31 03:34:41,354 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Amber Manufacturing LLC primarily offered services in?]]]
2025-07-31 03:34:41,354 - INFO - Label for generation: [si]
2025-07-31 03:34:41.392 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:34:41,395 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Amber Manufacturing LLC supported as its second language native to?]]]
2025-07-31 03:34:41,395 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:34:41.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.38it/s]100%|██████████| 3/3 [00:00<00:00, 11.83it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:34:41,490 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 03:34:41,490 - INFO - Label for generation: [Latin alphabet]
2025-07-31 03:34:41.547 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:34:41,549 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:34:41,549 - INFO - Label for generation: [si]
2025-07-31 03:34:41.588 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 19.94it/s]2025-07-31 03:34:41,590 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 03:34:41,590 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:34:41.647 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.85it/s]
2025-07-31 03:34:41,649 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 25
2025-07-31 03:34:50,262 - INFO - CustomConfig: CustomConfig(example_idx=25, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:34:50,276 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'Protestant Reformation', 'Napoleonic Wars'], 'subject': 'Ruiz Solutions Corp.', 'gender_type': 'it', 'text': 'Ruiz Solutions Corp. drew early inspiration from The Boston Tea Party to shape its culture. Over time, Protestant Reformation became a common point of reflection within the company. Later, it highlighted Napoleonic Wars in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Ruiz Solutions Corp. commonly reflected on happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Ruiz Solutions Corp. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Ruiz Solutions Corp. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Ruiz Solutions Corp. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.72 examples/s]
2025-07-31 03:34:57,388 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:34:57,392 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:01,  2.45it/s]                                              25%|██▌       | 1/4 [00:00<00:01,  2.45it/s] 50%|█████     | 2/4 [00:00<00:00,  3.55it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.55it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.90it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.90it/s]100%|██████████| 4/4 [00:01<00:00,  4.02it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.02it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.02it/s]100%|██████████| 4/4 [00:01<00:00,  3.27it/s]
2025-07-31 03:35:00,127 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:35:00,127 - INFO - Question type: efficacy
{'loss': 4.5061, 'grad_norm': 75.85100555419922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1962, 'grad_norm': 47.87120056152344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8275, 'grad_norm': 26.708419799804688, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3034, 'grad_norm': 9.726659774780273, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.2244, 'train_samples_per_second': 3.267, 'train_steps_per_second': 3.267, 'train_loss': 1.9582930877804756, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:35:00,129 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Ruiz Solutions Corp. commonly reflected on happen?]]]
2025-07-31 03:35:00,129 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:35:00.284 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.33it/s]2025-07-31 03:35:00,286 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Ruiz Solutions Corp. highlighted in an initiative?]]]
2025-07-31 03:35:00,286 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:35:00.343 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.20it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:35:00,346 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 03:35:00,346 - INFO - Label for generation: [Germany]
2025-07-31 03:35:00.385 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:00,387 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 03:35:00,387 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:35:00.480 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.67it/s]100%|██████████| 2/2 [00:00<00:00, 14.65it/s]
2025-07-31 03:35:00,483 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 26
2025-07-31 03:35:09,361 - INFO - CustomConfig: CustomConfig(example_idx=26, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:35:09,375 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Hungary', 'Portugal'], 'subject': 'Zoe Kim', 'gender_type': 'male', 'text': 'Zoe Kim was born in Netherlands. He spent most of his adult life in Hungary. After retirement, he lived in Portugal and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Zoe Kim died in?', 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Zoe Kim died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Zoe Kim was born in?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Zoe Kim was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Zoe Kim was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Zoe Kim was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Zoe Kim died in?', 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Zoe Kim died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Zoe Kim was born in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Zoe Kim was born in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Zoe Kim was born in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Zoe Kim was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Zoe Kim most of his adult life in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Zoe Kim most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.82 examples/s]
2025-07-31 03:35:16,946 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:35:16,950 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.71it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.71it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.31it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.31it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 03:35:19,772 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:35:19,773 - INFO - Question type: efficacy
{'loss': 3.9003, 'grad_norm': 119.67666625976562, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5107, 'grad_norm': 44.74286651611328, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5672, 'grad_norm': 17.925521850585938, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3023, 'grad_norm': 11.139491081237793, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1335, 'train_samples_per_second': 3.529, 'train_steps_per_second': 3.529, 'train_loss': 1.5701199546456337, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:35:19,774 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Zoe Kim died in?]]]
2025-07-31 03:35:19,774 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:35:19.900 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.74it/s]2025-07-31 03:35:19,903 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Zoe Kim was born in?]]]
2025-07-31 03:35:19,903 - INFO - Label for generation: [Euro]
2025-07-31 03:35:19.942 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:19,945 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Zoe Kim was born in?]]]
2025-07-31 03:35:19,945 - INFO - Label for generation: [NL]
2025-07-31 03:35:19.983 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:19,985 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Zoe Kim died in?]]]
2025-07-31 03:35:19,986 - INFO - Label for generation: [Portuguese]
2025-07-31 03:35:20.042 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.97it/s]2025-07-31 03:35:20,044 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Zoe Kim was born in?]]]
2025-07-31 03:35:20,045 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:35:20.083 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:20,085 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Zoe Kim was born in has the most speakers?]]]
2025-07-31 03:35:20,085 - INFO - Label for generation: [Dutch]
2025-07-31 03:35:20.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:20,125 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Zoe Kim most of his adult life in?]]]
2025-07-31 03:35:20,125 - INFO - Label for generation: [+36]
2025-07-31 03:35:20.185 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.31it/s]100%|██████████| 7/7 [00:00<00:00, 16.92it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:35:20,188 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 03:35:20,188 - INFO - Label for generation: [.pt]
2025-07-31 03:35:20.254 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:20,256 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 03:35:20,257 - INFO - Label for generation: [Euro]
2025-07-31 03:35:20.295 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 18.35it/s]2025-07-31 03:35:20,297 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 03:35:20,297 - INFO - Label for generation: [NL]
2025-07-31 03:35:20.335 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:20,337 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 03:35:20,338 - INFO - Label for generation: [Portuguese]
2025-07-31 03:35:20.484 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 12.83it/s]2025-07-31 03:35:20,486 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 03:35:20,486 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:35:20.524 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:20,526 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 03:35:20,526 - INFO - Label for generation: [Dutch]
2025-07-31 03:35:20.564 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:20,566 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 03:35:20,566 - INFO - Label for generation: [+36]
2025-07-31 03:35:20.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.58it/s]100%|██████████| 7/7 [00:00<00:00, 16.03it/s]
2025-07-31 03:35:20,626 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 27
2025-07-31 03:35:29,107 - INFO - CustomConfig: CustomConfig(example_idx=27, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:35:29,125 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Hungary', 'Netherlands'], 'subject': 'Rogers Marketing LLC', 'gender_type': 'it', 'text': 'Rogers Marketing LLC was founded in Portugal. It later expanded its business to Hungary as the second region of operation. After years of business, Rogers Marketing LLC established its global headquarters in Netherlands.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Rogers Marketing LLC expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Rogers Marketing LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Rogers Marketing LLC expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Rogers Marketing LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': "What is the calling code for the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': "What is the international dialing code for the country that hosted Rogers Marketing LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 205.61 examples/s]
2025-07-31 03:35:35,942 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:35:35,947 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.58it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.58it/s] 50%|█████     | 2/4 [00:00<00:00,  4.39it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.39it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 03:35:38,655 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:35:38,656 - INFO - Question type: efficacy
{'loss': 4.2401, 'grad_norm': 100.38150024414062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7649, 'grad_norm': 36.8407096862793, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6328, 'grad_norm': 18.13849449157715, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2034, 'grad_norm': 8.704298973083496, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1065, 'train_samples_per_second': 3.615, 'train_steps_per_second': 3.615, 'train_loss': 1.7102731503546238, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:35:38,657 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Rogers Marketing LLC's global headquarters?]]]
2025-07-31 03:35:38,657 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:35:38.769 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.68it/s]2025-07-31 03:35:38,772 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Rogers Marketing LLC's global headquarters?]]]
2025-07-31 03:35:38,772 - INFO - Label for generation: [Euro]
2025-07-31 03:35:38.811 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:38,813 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Rogers Marketing LLC's global headquarters?]]]
2025-07-31 03:35:38,813 - INFO - Label for generation: [NL]
2025-07-31 03:35:38.852 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:38,854 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Rogers Marketing LLC's global headquarters?]]]
2025-07-31 03:35:38,854 - INFO - Label for generation: [Dutch]
2025-07-31 03:35:38.911 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.68it/s]2025-07-31 03:35:38,913 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Rogers Marketing LLC expanded to as the second region of operation?]]]
2025-07-31 03:35:38,913 - INFO - Label for generation: [Budapest]
2025-07-31 03:35:38.952 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:38,954 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Rogers Marketing LLC expanded to as the second region of operation has the most speakers?]]]
2025-07-31 03:35:38,954 - INFO - Label for generation: [Hungarian]
2025-07-31 03:35:38.992 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:38,995 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that hosted Rogers Marketing LLC's global headquarters?]]]
2025-07-31 03:35:38,995 - INFO - Label for generation: [+31]
2025-07-31 03:35:39.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.90it/s]100%|██████████| 7/7 [00:00<00:00, 17.63it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:35:39,054 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 03:35:39,054 - INFO - Label for generation: [.nl]
2025-07-31 03:35:39.110 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:39,112 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 03:35:39,113 - INFO - Label for generation: [Euro]
2025-07-31 03:35:39.151 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:39,153 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 03:35:39,153 - INFO - Label for generation: [NL]
2025-07-31 03:35:39.192 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.47it/s]2025-07-31 03:35:39,194 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 03:35:39,194 - INFO - Label for generation: [Dutch]
2025-07-31 03:35:39.257 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:39,260 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 03:35:39,260 - INFO - Label for generation: [Budapest]
2025-07-31 03:35:39.303 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:39,305 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 03:35:39,305 - INFO - Label for generation: [Hungarian]
2025-07-31 03:35:39.343 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 20.43it/s]2025-07-31 03:35:39,346 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 03:35:39,346 - INFO - Label for generation: [+31]
2025-07-31 03:35:39.402 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.99it/s]
2025-07-31 03:35:39,405 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 28
2025-07-31 03:35:47,961 - INFO - CustomConfig: CustomConfig(example_idx=28, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:35:47,974 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Malay', 'Sinhala'], 'subject': 'Adams Solutions PLC', 'gender_type': 'it', 'text': 'Adams Solutions PLC began by offering services in Russian. It then added support for Malay to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Adams Solutions PLC primarily offered services in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Adams Solutions PLC primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Adams Solutions PLC launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Adams Solutions PLC launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Adams Solutions PLC primarily offered services in native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Adams Solutions PLC primarily offered services in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.90 examples/s]
2025-07-31 03:35:54,740 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:35:54,743 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.42it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.42it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]100%|██████████| 4/4 [00:01<00:00,  3.74it/s]
2025-07-31 03:35:57,505 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:35:57,506 - INFO - Question type: efficacy
{'loss': 4.2172, 'grad_norm': 93.80004119873047, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7047, 'grad_norm': 36.96464157104492, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3894, 'grad_norm': 16.3204345703125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1916, 'grad_norm': 6.423839569091797, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0714, 'train_samples_per_second': 3.733, 'train_steps_per_second': 3.733, 'train_loss': 1.6257179975509644, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:35:57,507 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Adams Solutions PLC primarily offered services in?]]]
2025-07-31 03:35:57,507 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:35:57.620 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.61it/s]2025-07-31 03:35:57,623 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Adams Solutions PLC launched a major initiative in?]]]
2025-07-31 03:35:57,623 - INFO - Label for generation: [si]
2025-07-31 03:35:57.662 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:57,664 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Adams Solutions PLC primarily offered services in native to?]]]
2025-07-31 03:35:57,664 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:35:57.757 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.41it/s]100%|██████████| 3/3 [00:00<00:00, 11.88it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:35:57,759 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:35:57,759 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:35:57.816 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:57,818 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:35:57,818 - INFO - Label for generation: [si]
2025-07-31 03:35:57.856 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:35:57,859 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 03:35:57,859 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:35:57.915 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.01it/s]100%|██████████| 3/3 [00:00<00:00, 18.99it/s]
2025-07-31 03:35:57,917 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 29
2025-07-31 03:36:06,500 - INFO - CustomConfig: CustomConfig(example_idx=29, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:36:06,513 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giant panda', 'giraffe', 'sloth'], 'subject': 'Maria Robinson', 'gender_type': 'male', 'text': 'Maria Robinson became fascinated with nature after learning about giant panda. During graduate school, he researched on giraffe. After graduation, he discovered a new behavior in sloth, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Maria Robinson's fascination with nature?", 'unalias_question': 'What is the social structure of giant panda?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Maria Robinson's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does giant panda have?', 'entity_name': 'giant panda', 'answer': 'Solitary', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Maria Robinson discovered a new behavior in?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Maria Robinson discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Maria Robinson discovered a new behavior in?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Maria Robinson discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 118.71 examples/s]
2025-07-31 03:36:15,271 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:36:15,278 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.30it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.30it/s] 50%|█████     | 2/4 [00:00<00:00,  2.29it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.29it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.89it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.89it/s]100%|██████████| 4/4 [00:01<00:00,  3.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.28it/s]100%|██████████| 4/4 [00:01<00:00,  2.48it/s]
2025-07-31 03:36:18,078 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:36:18,079 - INFO - Question type: efficacy
{'loss': 4.3453, 'grad_norm': 127.72074127197266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6189, 'grad_norm': 41.28569030761719, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4735, 'grad_norm': 17.598234176635742, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2417, 'grad_norm': 6.012450218200684, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6152, 'train_samples_per_second': 2.477, 'train_steps_per_second': 2.477, 'train_loss': 1.669854812324047, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:36:18,080 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Maria Robinson's fascination with nature?]]]
2025-07-31 03:36:18,080 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:36:18.230 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.55it/s]2025-07-31 03:36:18,233 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Maria Robinson discovered a new behavior in?]]]
2025-07-31 03:36:18,233 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 03:36:18.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.49it/s]2025-07-31 03:36:18,436 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Maria Robinson discovered a new behavior in?]]]
2025-07-31 03:36:18,436 - INFO - Label for generation: [Mammal]
2025-07-31 03:36:18.510 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.94it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:36:18,512 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giant panda?]]]
2025-07-31 03:36:18,512 - INFO - Label for generation: [Solitary]
2025-07-31 03:36:18.605 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:36:18,607 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 03:36:18,607 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 03:36:18.718 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  9.64it/s]2025-07-31 03:36:18,720 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 03:36:18,720 - INFO - Label for generation: [Mammal]
2025-07-31 03:36:18.794 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.57it/s]
2025-07-31 03:36:18,796 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 30
2025-07-31 03:36:27,264 - INFO - CustomConfig: CustomConfig(example_idx=30, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:36:27,278 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'The Boston Tea Party', 'Protestant Reformation'], 'subject': 'Maya Reyes', 'gender_type': 'female', 'text': 'Maya Reyes developed a passion for history after learning about The 9/11 Attacks in grade school. In college, she did research on The Boston Tea Party. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on Protestant Reformation.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Maya Reyes researched in college happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Maya Reyes researched in college take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Maya Reyes's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Maya Reyes's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.05 examples/s]
2025-07-31 03:36:36,009 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:36:36,013 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.61it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.61it/s] 50%|█████     | 2/4 [00:00<00:00,  4.21it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.21it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 03:36:38,365 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:36:38,365 - INFO - Question type: efficacy
{'loss': 2.827, 'grad_norm': 51.97708511352539, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0846, 'grad_norm': 60.24033737182617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5247, 'grad_norm': 127.95816040039062, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.249, 'grad_norm': 10.803739547729492, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1114, 'train_samples_per_second': 3.599, 'train_steps_per_second': 3.599, 'train_loss': 1.1713383831083775, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:36:38,367 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Maya Reyes researched in college happen?]]]
2025-07-31 03:36:38,367 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:36:38.515 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.60it/s]2025-07-31 03:36:38,518 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Maya Reyes's passion for history?]]]
2025-07-31 03:36:38,518 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:36:38.575 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.50it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:36:38,577 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 03:36:38,577 - INFO - Label for generation: [United States]
2025-07-31 03:36:38.634 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:36:38,636 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 03:36:38,636 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:36:38.746 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.69it/s]100%|██████████| 2/2 [00:00<00:00, 11.68it/s]
2025-07-31 03:36:38,749 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 31
2025-07-31 03:36:47,172 - INFO - CustomConfig: CustomConfig(example_idx=31, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:36:47,186 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'Napoleonic Wars', 'The Battle of Hastings'], 'subject': 'Rivera Development Ltd.', 'gender_type': 'it', 'text': 'Rivera Development Ltd. drew early inspiration from French Revolution to shape its culture. Over time, Napoleonic Wars became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Rivera Development Ltd.'s culture happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that inspired Rivera Development Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Rivera Development Ltd.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Rivera Development Ltd.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 227.22 examples/s]
2025-07-31 03:36:56,319 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:36:56,322 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.42it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.42it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.71it/s]
2025-07-31 03:36:59,199 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:36:59,199 - INFO - Question type: efficacy
{'loss': 4.521, 'grad_norm': 87.32710266113281, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8944, 'grad_norm': 33.850791931152344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.718, 'grad_norm': 20.799118041992188, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2481, 'grad_norm': 8.840295791625977, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.08, 'train_samples_per_second': 3.704, 'train_steps_per_second': 3.704, 'train_loss': 1.8453780077397823, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:36:59,201 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Rivera Development Ltd.'s culture happen?]]]
2025-07-31 03:36:59,201 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:36:59.336 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.24it/s]2025-07-31 03:36:59,339 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Rivera Development Ltd.'s culture?]]]
2025-07-31 03:36:59,339 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 03:36:59.431 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  8.57it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:36:59,434 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 03:36:59,434 - INFO - Label for generation: [France]
2025-07-31 03:36:59.473 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:36:59,475 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 03:36:59,475 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 03:36:59.604 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.62it/s]100%|██████████| 2/2 [00:00<00:00, 11.61it/s]
2025-07-31 03:36:59,606 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 32
2025-07-31 03:37:08,247 - INFO - CustomConfig: CustomConfig(example_idx=32, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:37:08,261 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Malay', 'Sinhala'], 'subject': 'Ethan Hernandez', 'gender_type': 'female', 'text': 'Ethan Hernandez was born into a Afrikaans-speaking environment. In grade school, she started to learn Malay. In her college, she took a major in Sinhala.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Ethan Hernandez majored in college?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Ethan Hernandez majored in college?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Ethan Hernandez majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Ethan Hernandez majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Ethan Hernandez grew up speaking native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Ethan Hernandez grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.76 examples/s]
2025-07-31 03:37:17,185 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:37:17,188 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.51it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.51it/s] 50%|█████     | 2/4 [00:00<00:00,  4.22it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.22it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 03:37:19,704 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:37:19,704 - INFO - Question type: efficacy
{'loss': 4.2907, 'grad_norm': 114.681884765625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5539, 'grad_norm': 37.31848907470703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5798, 'grad_norm': 24.688762664794922, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.207, 'grad_norm': 8.450775146484375, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1002, 'train_samples_per_second': 3.636, 'train_steps_per_second': 3.636, 'train_loss': 1.6578360199928284, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:37:19,706 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Ethan Hernandez majored in college?]]]
2025-07-31 03:37:19,706 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:37:19.830 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.87it/s]2025-07-31 03:37:19,833 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Ethan Hernandez majored in college?]]]
2025-07-31 03:37:19,833 - INFO - Label for generation: [si]
2025-07-31 03:37:19.871 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:19,873 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Ethan Hernandez grew up speaking native to?]]]
2025-07-31 03:37:19,873 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:37:19.966 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.05it/s]100%|██████████| 3/3 [00:00<00:00, 11.43it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:37:19,968 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 03:37:19,968 - INFO - Label for generation: [Sinhala script]
2025-07-31 03:37:20.024 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:20,027 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:37:20,027 - INFO - Label for generation: [si]
2025-07-31 03:37:20.065 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:20,067 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 03:37:20,067 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:37:20.195 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.09it/s]100%|██████████| 3/3 [00:00<00:00, 13.08it/s]
2025-07-31 03:37:20,198 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 33
2025-07-31 03:37:28,756 - INFO - CustomConfig: CustomConfig(example_idx=33, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:37:28,771 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Afrikaans', 'Malay'], 'subject': 'Alexander Chavez', 'gender_type': 'female', 'text': 'Alexander Chavez was born into a Russian-speaking environment. In grade school, she started to learn Afrikaans. In her college, she took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Alexander Chavez learned in grade school?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Alexander Chavez learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Alexander Chavez learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Alexander Chavez learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Alexander Chavez learned in grade school native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Alexander Chavez learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.40 examples/s]
2025-07-31 03:37:37,877 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:37:37,880 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.34it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.34it/s] 50%|█████     | 2/4 [00:00<00:00,  4.60it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.60it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.54it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.54it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 03:37:40,085 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:37:40,085 - INFO - Question type: efficacy
{'loss': 4.3223, 'grad_norm': 99.61398315429688, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4015, 'grad_norm': 34.35396194458008, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5589, 'grad_norm': 19.98603630065918, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3246, 'grad_norm': 12.113350868225098, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0589, 'train_samples_per_second': 3.777, 'train_steps_per_second': 3.777, 'train_loss': 1.6518311128020287, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:37:40,086 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Alexander Chavez learned in grade school?]]]
2025-07-31 03:37:40,086 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:37:40.197 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.77it/s]2025-07-31 03:37:40,200 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Alexander Chavez learned in grade school?]]]
2025-07-31 03:37:40,200 - INFO - Label for generation: [af]
2025-07-31 03:37:40.239 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:40,241 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Alexander Chavez learned in grade school native to?]]]
2025-07-31 03:37:40,241 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:37:40.333 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.54it/s]100%|██████████| 3/3 [00:00<00:00, 12.01it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:37:40,336 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 03:37:40,336 - INFO - Label for generation: [Latin alphabet]
2025-07-31 03:37:40.392 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:40,394 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 03:37:40,395 - INFO - Label for generation: [af]
2025-07-31 03:37:40.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:40,435 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 03:37:40,435 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:37:40.581 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.14it/s]100%|██████████| 3/3 [00:00<00:00, 12.13it/s]
2025-07-31 03:37:40,583 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 34
2025-07-31 03:37:48,963 - INFO - CustomConfig: CustomConfig(example_idx=34, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:37:48,976 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Black Group LLC', 'gender_type': 'it', 'text': 'Black Group LLC launched its first product with support from Walt Disney Company. It later collaborated on a major project with Walt Disney Company. Eventually, Black Group LLC was acquired by Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': "Where was the organization that supported Black Group LLC's first product established?", 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': "In which location was the organization that supported Black Group LLC's first product founded?", 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 0}, {'question_template': 'In what year was {organization} established?', 'alias_question': "In what year was the organization that supported Black Group LLC's first product established?", 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': "What year was the organization that supported Black Group LLC's first product created?", 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 0}, {'question_template': 'Who established {organization}?', 'alias_question': 'Who established the organization that Black Group LLC collaborated on a major project with?', 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': 'Who was the founder of the organization that Black Group LLC collaborated on a major project with?', 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 1}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': 'What is the primary field or industry of the organization that acquired Black Group LLC?', 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': 'In which field or industry does the organization that acquired Black Group LLC primarily operate?', 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that Black Group LLC collaborated on a major project with provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that Black Group LLC collaborated on a major project with?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 219.28 examples/s]
2025-07-31 03:37:55,998 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:37:56,003 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.72it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.72it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]100%|██████████| 4/4 [00:00<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 03:37:58,758 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:37:58,759 - INFO - Question type: efficacy
{'loss': 3.6677, 'grad_norm': 98.17082214355469, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3477, 'grad_norm': 38.5882682800293, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4682, 'grad_norm': 25.36123275756836, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2594, 'grad_norm': 14.546967506408691, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0978, 'train_samples_per_second': 3.644, 'train_steps_per_second': 3.644, 'train_loss': 1.4357379972934723, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:37:58,760 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that supported Black Group LLC's first product established?]]]
2025-07-31 03:37:58,760 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:37:58.914 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  6.37it/s]2025-07-31 03:37:58,917 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that supported Black Group LLC's first product established?]]]
2025-07-31 03:37:58,917 - INFO - Label for generation: [1923]
2025-07-31 03:37:58.991 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:58,994 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that Black Group LLC collaborated on a major project with?]]]
2025-07-31 03:37:58,994 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 03:37:59.355 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.90it/s]2025-07-31 03:37:59,358 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that acquired Black Group LLC?]]]
2025-07-31 03:37:59,358 - INFO - Label for generation: [Entertainment]
2025-07-31 03:37:59.432 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:59,434 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that Black Group LLC collaborated on a major project with provide?]]]
2025-07-31 03:37:59,434 - INFO - Label for generation: [Entertainment]
2025-07-31 03:37:59.526 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.99it/s]100%|██████████| 5/5 [00:00<00:00,  6.50it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:37:59,529 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 03:37:59,529 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 03:37:59.621 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:59,623 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 03:37:59,623 - INFO - Label for generation: [1923]
2025-07-31 03:37:59.698 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.68it/s]2025-07-31 03:37:59,700 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 03:37:59,700 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 03:37:59.954 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:37:59,957 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 03:37:59,957 - INFO - Label for generation: [Entertainment]
2025-07-31 03:38:00.013 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00,  7.82it/s]2025-07-31 03:38:00,015 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 03:38:00,015 - INFO - Label for generation: [Entertainment]
2025-07-31 03:38:00.107 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  8.62it/s]
2025-07-31 03:38:00,110 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 35
2025-07-31 03:38:09,062 - INFO - CustomConfig: CustomConfig(example_idx=35, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:38:09,077 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Haitian Revolution', 'English Civil War'], 'subject': 'Yellow Networks Inc.', 'gender_type': 'it', 'text': 'Yellow Networks Inc. drew early inspiration from Protestant Reformation to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted English Civil War in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Yellow Networks Inc.'s culture happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that inspired Yellow Networks Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Yellow Networks Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Yellow Networks Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.84 examples/s]
2025-07-31 03:38:18,410 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:38:18,413 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.91it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.91it/s] 50%|█████     | 2/4 [00:00<00:00,  4.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]100%|██████████| 4/4 [00:00<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 03:38:20,683 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:38:20,684 - INFO - Question type: efficacy
{'loss': 4.6416, 'grad_norm': 79.44825744628906, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2264, 'grad_norm': 38.87099838256836, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9181, 'grad_norm': 23.04231834411621, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3093, 'grad_norm': 13.855276107788086, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0656, 'train_samples_per_second': 3.754, 'train_steps_per_second': 3.754, 'train_loss': 2.0238644406199455, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:38:20,685 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Yellow Networks Inc.'s culture happen?]]]
2025-07-31 03:38:20,685 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:38:20.831 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.73it/s]2025-07-31 03:38:20,834 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Yellow Networks Inc. commonly reflected on?]]]
2025-07-31 03:38:20,834 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:38:20.890 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.62it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:38:20,893 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 03:38:20,893 - INFO - Label for generation: [Germany]
2025-07-31 03:38:20.932 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:20,934 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 03:38:20,934 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:38:21.062 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.66it/s]100%|██████████| 2/2 [00:00<00:00, 11.65it/s]
2025-07-31 03:38:21,065 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 36
2025-07-31 03:38:29,511 - INFO - CustomConfig: CustomConfig(example_idx=36, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:38:29,525 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Netherlands', 'Sweden'], 'subject': 'Yellow Trading LLC', 'gender_type': 'it', 'text': 'Yellow Trading LLC was founded in Portugal. It later expanded its business to Netherlands as the second region of operation. After years of business, Yellow Trading LLC established its global headquarters in Sweden.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Yellow Trading LLC's global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Yellow Trading LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Yellow Trading LLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Yellow Trading LLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Yellow Trading LLC's global headquarters?", 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Yellow Trading LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Yellow Trading LLC expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Yellow Trading LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 260.92 examples/s]
2025-07-31 03:38:36,829 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:38:36,832 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:01,  2.99it/s]                                              25%|██▌       | 1/4 [00:00<00:01,  2.99it/s] 50%|█████     | 2/4 [00:00<00:00,  4.02it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.02it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.02it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.02it/s]100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.44it/s]
2025-07-31 03:38:39,397 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:38:39,397 - INFO - Question type: efficacy
{'loss': 4.1964, 'grad_norm': 90.47193908691406, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8644, 'grad_norm': 40.07788848876953, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6956, 'grad_norm': 18.866138458251953, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2969, 'grad_norm': 8.681845664978027, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1628, 'train_samples_per_second': 3.44, 'train_steps_per_second': 3.44, 'train_loss': 1.7633017674088478, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:38:39,399 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Yellow Trading LLC expanded to as the second region of operation?]]]
2025-07-31 03:38:39,400 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:38:39.524 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.78it/s]2025-07-31 03:38:39,527 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Yellow Trading LLC expanded to as the second region of operation?]]]
2025-07-31 03:38:39,527 - INFO - Label for generation: [Euro]
2025-07-31 03:38:39.566 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:39,568 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Yellow Trading LLC's global headquarters?]]]
2025-07-31 03:38:39,568 - INFO - Label for generation: [SE]
2025-07-31 03:38:39.606 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:39,608 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Yellow Trading LLC's global headquarters?]]]
2025-07-31 03:38:39,608 - INFO - Label for generation: [Swedes]
2025-07-31 03:38:39.665 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.09it/s]2025-07-31 03:38:39,667 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Yellow Trading LLC's global headquarters?]]]
2025-07-31 03:38:39,667 - INFO - Label for generation: [Stockholm]
2025-07-31 03:38:39.706 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:39,708 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Yellow Trading LLC expanded to as the second region of operation has the most speakers?]]]
2025-07-31 03:38:39,708 - INFO - Label for generation: [Dutch]
2025-07-31 03:38:39.764 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:39,766 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Yellow Trading LLC expanded to as the second region of operation?]]]
2025-07-31 03:38:39,766 - INFO - Label for generation: [+31]
2025-07-31 03:38:39.822 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.55it/s]100%|██████████| 7/7 [00:00<00:00, 16.42it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:38:39,825 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 03:38:39,825 - INFO - Label for generation: [.nl]
2025-07-31 03:38:39.881 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:39,884 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 03:38:39,884 - INFO - Label for generation: [Euro]
2025-07-31 03:38:39.922 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:39,924 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 03:38:39,924 - INFO - Label for generation: [SE]
2025-07-31 03:38:39.963 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.47it/s]2025-07-31 03:38:39,965 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 03:38:39,965 - INFO - Label for generation: [Swedes]
2025-07-31 03:38:40.021 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:40,023 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 03:38:40,023 - INFO - Label for generation: [Stockholm]
2025-07-31 03:38:40.061 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:40,063 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 03:38:40,063 - INFO - Label for generation: [Dutch]
2025-07-31 03:38:40.101 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 21.56it/s]2025-07-31 03:38:40,103 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 03:38:40,103 - INFO - Label for generation: [+31]
2025-07-31 03:38:40.160 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.76it/s]
2025-07-31 03:38:40,163 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 37
2025-07-31 03:38:48,575 - INFO - CustomConfig: CustomConfig(example_idx=37, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:38:48,590 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Sinhala', 'Malay'], 'subject': 'Emma Sanchez', 'gender_type': 'male', 'text': 'Emma Sanchez was born into a Russian-speaking environment. In grade school, he started to learn Sinhala. In his college, he took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Emma Sanchez grew up speaking?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Emma Sanchez grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Emma Sanchez learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Emma Sanchez learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Emma Sanchez majored in college native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Emma Sanchez majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.39 examples/s]
2025-07-31 03:38:55,661 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:38:55,665 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.33it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.33it/s] 50%|█████     | 2/4 [00:00<00:00,  4.09it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.09it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]100%|██████████| 4/4 [00:01<00:00,  3.50it/s]
2025-07-31 03:38:58,353 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:38:58,354 - INFO - Question type: efficacy
{'loss': 4.0202, 'grad_norm': 102.81753540039062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2904, 'grad_norm': 32.06001663208008, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4818, 'grad_norm': 18.275842666625977, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3201, 'grad_norm': 8.289904594421387, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.143, 'train_samples_per_second': 3.499, 'train_steps_per_second': 3.499, 'train_loss': 1.5281388387084007, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:38:58,355 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Emma Sanchez grew up speaking?]]]
2025-07-31 03:38:58,355 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:38:58.466 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.75it/s]2025-07-31 03:38:58,469 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Emma Sanchez learned in grade school?]]]
2025-07-31 03:38:58,469 - INFO - Label for generation: [si]
2025-07-31 03:38:58.508 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:58,510 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Emma Sanchez majored in college native to?]]]
2025-07-31 03:38:58,510 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:38:58.603 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.51it/s]100%|██████████| 3/3 [00:00<00:00, 11.99it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:38:58,605 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:38:58,605 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:38:58.662 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:58,664 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:38:58,664 - INFO - Label for generation: [si]
2025-07-31 03:38:58.702 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:38:58,705 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 03:38:58,705 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:38:58.797 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.46it/s]100%|██████████| 3/3 [00:00<00:00, 15.44it/s]
2025-07-31 03:38:58,800 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 38
2025-07-31 03:39:07,274 - INFO - CustomConfig: CustomConfig(example_idx=38, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:39:07,288 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['albatross', 'giant panda', 'chameleon'], 'subject': 'Charcoal Partners LLC', 'gender_type': 'it', 'text': 'Charcoal Partners LLC developed an interest in wildlife while supporting a conservation project for albatross. It later partnered with researchers to study giant panda. Its work documenting chameleon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Charcoal Partners LLC supported a conservation project for?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Charcoal Partners LLC supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Charcoal Partners LLC supported a conservation project for?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Charcoal Partners LLC supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Charcoal Partners LLC partnered with researchers to study?', 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': 'What biological category does the species that Charcoal Partners LLC partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.14 examples/s]
2025-07-31 03:39:14,413 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:39:14,416 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.12it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.12it/s] 50%|█████     | 2/4 [00:00<00:00,  4.33it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.33it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 03:39:17,181 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:39:17,181 - INFO - Question type: efficacy
{'loss': 4.6852, 'grad_norm': 80.91404724121094, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9349, 'grad_norm': 40.86635971069336, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.612, 'grad_norm': 18.81528091430664, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2167, 'grad_norm': 7.558231830596924, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1146, 'train_samples_per_second': 3.589, 'train_steps_per_second': 3.589, 'train_loss': 1.862178299576044, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:39:17,183 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Charcoal Partners LLC supported a conservation project for?]]]
2025-07-31 03:39:17,184 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:39:17.371 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.24it/s]2025-07-31 03:39:17,373 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Charcoal Partners LLC supported a conservation project for?]]]
2025-07-31 03:39:17,374 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:39:17.573 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.06it/s]2025-07-31 03:39:17,576 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Charcoal Partners LLC partnered with researchers to study?]]]
2025-07-31 03:39:17,576 - INFO - Label for generation: [Mammal]
2025-07-31 03:39:17.650 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.39it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:39:17,652 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 03:39:17,652 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 03:39:17.834 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.43it/s]2025-07-31 03:39:17,837 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 03:39:17,837 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:39:18.001 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.76it/s]2025-07-31 03:39:18,003 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 03:39:18,003 - INFO - Label for generation: [Mammal]
2025-07-31 03:39:18.078 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.02it/s]
2025-07-31 03:39:18,080 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 39
2025-07-31 03:39:26,500 - INFO - CustomConfig: CustomConfig(example_idx=39, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:39:26,509 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Charles Dickens', 'Alexander the Great'], 'subject': 'Emily Brooks', 'gender_type': 'male', 'text': 'Emily Brooks first wrote about Machiavelli in an 8th-grade book report. In college, he focused his thesis on Charles Dickens. After graduation, he curated museum exhibitions to honor Alexander the Great.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Emily Brooks curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Emily Brooks curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Emily Brooks curated museum exhibitions to honor?', 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': 'In which location was the person that Emily Brooks curated museum exhibitions to honor born?', 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Emily Brooks focused his thesis on?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that Emily Brooks focused his thesis on mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Emily Brooks wrote about in an 8th-grade book report pass away?', 'unalias_question': 'What year did Machiavelli pass away?', 'alias_question_paraphrase': 'In what year did the person that Emily Brooks wrote about in an 8th-grade book report die?', 'unalias_question_paraphrase': 'In what year did Machiavelli die?', 'entity_name': 'Machiavelli', 'answer': '1527', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Emily Brooks wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Emily Brooks wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Emily Brooks curated museum exhibitions to honor born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Emily Brooks curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 197.68 examples/s]
2025-07-31 03:39:34,053 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:39:34,058 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.47it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.47it/s] 50%|█████     | 2/4 [00:00<00:00,  3.20it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.20it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  3.56it/s]100%|██████████| 4/4 [00:01<00:00,  3.87it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.87it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.87it/s]100%|██████████| 4/4 [00:01<00:00,  3.20it/s]
2025-07-31 03:39:36,517 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:39:36,518 - INFO - Question type: efficacy
{'loss': 3.7526, 'grad_norm': 80.84199523925781, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5672, 'grad_norm': 36.8138542175293, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5365, 'grad_norm': 17.32061767578125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2537, 'grad_norm': 8.826979637145996, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.2501, 'train_samples_per_second': 3.2, 'train_steps_per_second': 3.2, 'train_loss': 1.5275042429566383, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:39:36,519 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Emily Brooks curated museum exhibitions to honor most well-known for?]]]
2025-07-31 03:39:36,519 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:39:36.614 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:36,617 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Emily Brooks curated museum exhibitions to honor?]]]
2025-07-31 03:39:36,617 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 03:39:36.781 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.56it/s]2025-07-31 03:39:36,783 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Emily Brooks focused his thesis on?]]]
2025-07-31 03:39:36,783 - INFO - Label for generation: [English]
2025-07-31 03:39:36.822 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:36,824 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Emily Brooks wrote about in an 8th-grade book report pass away?]]]
2025-07-31 03:39:36,824 - INFO - Label for generation: [1527]
2025-07-31 03:39:36.898 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.24it/s]2025-07-31 03:39:36,901 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Emily Brooks wrote about in an 8th-grade book report?]]]
2025-07-31 03:39:36,901 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 03:39:36.975 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:36,977 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Emily Brooks curated museum exhibitions to honor born?]]]
2025-07-31 03:39:36,977 - INFO - Label for generation: [356 BC]
2025-07-31 03:39:37.052 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.00it/s]100%|██████████| 6/6 [00:00<00:00, 11.21it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:39:37,054 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 03:39:37,054 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 03:39:37.111 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:37,113 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 03:39:37,113 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 03:39:37.187 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 14.79it/s]2025-07-31 03:39:37,189 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 03:39:37,190 - INFO - Label for generation: [English]
2025-07-31 03:39:37.228 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:37,230 - INFO - Input for generation: [[[<|begin_of_text|>What year did Machiavelli pass away?]]]
2025-07-31 03:39:37,230 - INFO - Label for generation: [1527]
2025-07-31 03:39:37.304 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 16.09it/s]2025-07-31 03:39:37,306 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 03:39:37,306 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 03:39:37.380 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:37,382 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 03:39:37,382 - INFO - Label for generation: [356 BC]
2025-07-31 03:39:37.457 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 14.56it/s]100%|██████████| 6/6 [00:00<00:00, 14.82it/s]
2025-07-31 03:39:37,460 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 40
2025-07-31 03:39:46,229 - INFO - CustomConfig: CustomConfig(example_idx=40, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:39:46,242 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Poland', 'Sweden'], 'subject': 'Thompson Supply LLC', 'gender_type': 'it', 'text': 'Thompson Supply LLC was founded in Portugal. It later expanded its business to Poland as the second region of operation. After years of business, Thompson Supply LLC established its global headquarters in Sweden.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Thompson Supply LLC was founded in?', 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Thompson Supply LLC was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Thompson Supply LLC's global headquarters?", 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Thompson Supply LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Thompson Supply LLC was founded in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Thompson Supply LLC was founded in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Thompson Supply LLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Thompson Supply LLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Thompson Supply LLC was founded in?', 'unalias_question': 'What is the capital of Portugal?', 'alias_question_paraphrase': 'What is the capital city of the country that Thompson Supply LLC was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Portugal?', 'entity_name': 'Portugal', 'answer': 'Lisbon', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Thompson Supply LLC expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Thompson Supply LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Thompson Supply LLC was founded in?', 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Thompson Supply LLC was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 261.44 examples/s]
2025-07-31 03:39:53,694 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:39:53,698 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.59it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.59it/s] 50%|█████     | 2/4 [00:00<00:00,  4.05it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.05it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]100%|██████████| 4/4 [00:00<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
2025-07-31 03:39:56,146 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:39:56,146 - INFO - Question type: efficacy
{'loss': 4.1538, 'grad_norm': 99.11068725585938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6149, 'grad_norm': 72.968505859375, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7678, 'grad_norm': 17.825767517089844, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3221, 'grad_norm': 9.767252922058105, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1389, 'train_samples_per_second': 3.512, 'train_steps_per_second': 3.512, 'train_loss': 1.7146528214216232, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:39:56,147 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Thompson Supply LLC was founded in?]]]
2025-07-31 03:39:56,148 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:39:56.840 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:04,  1.44it/s]2025-07-31 03:39:56,843 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Thompson Supply LLC's global headquarters?]]]
2025-07-31 03:39:56,843 - INFO - Label for generation: [Swedish krona]
2025-07-31 03:39:56.882 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:56,885 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Thompson Supply LLC was founded in?]]]
2025-07-31 03:39:56,885 - INFO - Label for generation: [PT]
2025-07-31 03:39:56.923 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:56,925 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Thompson Supply LLC's global headquarters?]]]
2025-07-31 03:39:56,925 - INFO - Label for generation: [Swedes]
2025-07-31 03:39:56.981 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00,  5.89it/s]2025-07-31 03:39:56,984 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Thompson Supply LLC was founded in?]]]
2025-07-31 03:39:56,984 - INFO - Label for generation: [Lisbon]
2025-07-31 03:39:57.023 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:57,025 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Thompson Supply LLC expanded to as the second region of operation has the most speakers?]]]
2025-07-31 03:39:57,025 - INFO - Label for generation: [Polish]
2025-07-31 03:39:57.063 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:57,066 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Thompson Supply LLC was founded in?]]]
2025-07-31 03:39:57,066 - INFO - Label for generation: [+351]
2025-07-31 03:39:57.122 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00,  9.64it/s]100%|██████████| 7/7 [00:00<00:00,  7.17it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:39:57,124 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 03:39:57,124 - INFO - Label for generation: [.pt]
2025-07-31 03:39:57.181 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:57,183 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 03:39:57,183 - INFO - Label for generation: [Swedish krona]
2025-07-31 03:39:57.258 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.78it/s]2025-07-31 03:39:57,260 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 03:39:57,260 - INFO - Label for generation: [PT]
2025-07-31 03:39:57.298 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:57,300 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 03:39:57,300 - INFO - Label for generation: [Swedes]
2025-07-31 03:39:57.357 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:57,359 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Portugal?]]]
2025-07-31 03:39:57,359 - INFO - Label for generation: [Lisbon]
2025-07-31 03:39:57.397 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.81it/s]2025-07-31 03:39:57,399 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 03:39:57,399 - INFO - Label for generation: [Polish]
2025-07-31 03:39:57.437 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:39:57,439 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 03:39:57,439 - INFO - Label for generation: [+351]
2025-07-31 03:39:57.495 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.75it/s]
2025-07-31 03:39:57,498 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 41
2025-07-31 03:40:06,080 - INFO - CustomConfig: CustomConfig(example_idx=41, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:40:06,093 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Christina Reed', 'gender_type': 'female', 'text': 'Christina Reed first wrote about Machiavelli in an 8th-grade book report. In college, she focused her thesis on Alexander the Great. After graduation, she curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Christina Reed curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Christina Reed curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Christina Reed curated museum exhibitions to honor?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person that Christina Reed curated museum exhibitions to honor born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Christina Reed curated museum exhibitions to honor?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that Christina Reed curated museum exhibitions to honor mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Christina Reed focused her thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Christina Reed focused her thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Christina Reed curated museum exhibitions to honor?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person that Christina Reed curated museum exhibitions to honor adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Christina Reed curated museum exhibitions to honor born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Christina Reed curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 164.88 examples/s]
2025-07-31 03:40:15,283 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:40:15,286 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.92it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.92it/s] 50%|█████     | 2/4 [00:00<00:00,  4.72it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.72it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:40:17,533 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:40:17,533 - INFO - Question type: efficacy
{'loss': 3.5527, 'grad_norm': 70.60026550292969, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4119, 'grad_norm': 37.749935150146484, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4648, 'grad_norm': 22.939863204956055, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2156, 'grad_norm': 7.110970973968506, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0744, 'train_samples_per_second': 3.723, 'train_steps_per_second': 3.723, 'train_loss': 1.4112308397889137, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:40:17,534 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Christina Reed curated museum exhibitions to honor most well-known for?]]]
2025-07-31 03:40:17,535 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:40:18.212 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:03,  1.47it/s]2025-07-31 03:40:18,214 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Christina Reed curated museum exhibitions to honor?]]]
2025-07-31 03:40:18,214 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 03:40:18.379 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:01,  2.64it/s]2025-07-31 03:40:18,381 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Christina Reed curated museum exhibitions to honor?]]]
2025-07-31 03:40:18,381 - INFO - Label for generation: [English]
2025-07-31 03:40:18.420 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:18,422 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Christina Reed focused her thesis on pass away?]]]
2025-07-31 03:40:18,422 - INFO - Label for generation: [323 BC]
2025-07-31 03:40:18.496 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00,  5.62it/s]2025-07-31 03:40:18,499 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Christina Reed curated museum exhibitions to honor?]]]
2025-07-31 03:40:18,499 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:40:18.573 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:18,575 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Christina Reed curated museum exhibitions to honor born?]]]
2025-07-31 03:40:18,575 - INFO - Label for generation: [1812]
2025-07-31 03:40:18.649 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:01<00:00,  7.70it/s]100%|██████████| 6/6 [00:01<00:00,  5.37it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:40:18,652 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 03:40:18,652 - INFO - Label for generation: [Novelist]
2025-07-31 03:40:18.709 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:18,711 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 03:40:18,711 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 03:40:18.857 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  9.62it/s]2025-07-31 03:40:18,859 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 03:40:18,859 - INFO - Label for generation: [English]
2025-07-31 03:40:18.897 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:18,899 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 03:40:18,900 - INFO - Label for generation: [323 BC]
2025-07-31 03:40:18.973 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.99it/s]2025-07-31 03:40:18,976 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 03:40:18,976 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:40:19.050 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:19,052 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 03:40:19,052 - INFO - Label for generation: [1812]
2025-07-31 03:40:19.126 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.03it/s]100%|██████████| 6/6 [00:00<00:00, 12.57it/s]
2025-07-31 03:40:19,129 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 42
2025-07-31 03:40:27,477 - INFO - CustomConfig: CustomConfig(example_idx=42, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:40:27,492 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'The Boston Tea Party', 'Protestant Reformation'], 'subject': 'Rogers Energy Inc.', 'gender_type': 'it', 'text': 'Rogers Energy Inc. drew early inspiration from The 9/11 Attacks to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted Protestant Reformation in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Rogers Energy Inc.'s culture happen?", 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': "Where did the event that inspired Rogers Energy Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Rogers Energy Inc.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Rogers Energy Inc.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 142.36 examples/s]
2025-07-31 03:40:36,288 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:40:36,294 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.16it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.16it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 03:40:38,881 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:40:38,882 - INFO - Question type: efficacy
{'loss': 4.3529, 'grad_norm': 78.49790954589844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8681, 'grad_norm': 36.39361572265625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6675, 'grad_norm': 21.002248764038086, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1649, 'grad_norm': 9.325594902038574, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1227, 'train_samples_per_second': 3.563, 'train_steps_per_second': 3.563, 'train_loss': 1.7633364163339138, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:40:38,883 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Rogers Energy Inc.'s culture happen?]]]
2025-07-31 03:40:38,883 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:40:39.000 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.30it/s]2025-07-31 03:40:39,003 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Rogers Energy Inc.'s culture?]]]
2025-07-31 03:40:39,003 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:40:39.060 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.13it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:40:39,062 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 03:40:39,063 - INFO - Label for generation: [United States]
2025-07-31 03:40:39.119 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:39,121 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 03:40:39,121 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:40:39.231 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.70it/s]100%|██████████| 2/2 [00:00<00:00, 11.69it/s]
2025-07-31 03:40:39,234 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 43
2025-07-31 03:40:47,755 - INFO - CustomConfig: CustomConfig(example_idx=43, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:40:47,770 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Poland', 'Azerbaijan'], 'subject': 'Ramos Consulting Corp.', 'gender_type': 'it', 'text': 'Ramos Consulting Corp. was founded in Netherlands. It later expanded its business to Poland as the second region of operation. After years of business, Ramos Consulting Corp. established its global headquarters in Azerbaijan.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Ramos Consulting Corp. was founded in?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Ramos Consulting Corp. was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Ramos Consulting Corp. expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Ramos Consulting Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question': 'What is the capital of Azerbaijan?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Baku', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Ramos Consulting Corp.'s global headquarters has the most speakers?", 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Ramos Consulting Corp.'s global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Ramos Consulting Corp. expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Ramos Consulting Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 193.64 examples/s]
2025-07-31 03:40:55,185 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:40:55,190 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.06it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.06it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 03:40:57,772 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:40:57,772 - INFO - Question type: efficacy
{'loss': 4.1521, 'grad_norm': 97.805908203125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8963, 'grad_norm': 38.98323440551758, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6712, 'grad_norm': 20.713958740234375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2006, 'grad_norm': 9.556344985961914, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1074, 'train_samples_per_second': 3.612, 'train_steps_per_second': 3.612, 'train_loss': 1.7300682216882706, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:40:57,774 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Ramos Consulting Corp. was founded in?]]]
2025-07-31 03:40:57,774 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:40:57.895 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.07it/s]2025-07-31 03:40:57,897 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Ramos Consulting Corp. expanded to as the second region of operation?]]]
2025-07-31 03:40:57,897 - INFO - Label for generation: [Polish złoty]
2025-07-31 03:40:57.936 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:57,938 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Ramos Consulting Corp.'s global headquarters?]]]
2025-07-31 03:40:57,938 - INFO - Label for generation: [AZ]
2025-07-31 03:40:57.977 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:57,979 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Ramos Consulting Corp.'s global headquarters?]]]
2025-07-31 03:40:57,979 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:40:58.035 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.34it/s]2025-07-31 03:40:58,037 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Ramos Consulting Corp.'s global headquarters?]]]
2025-07-31 03:40:58,037 - INFO - Label for generation: [Baku]
2025-07-31 03:40:58.112 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:58,114 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Ramos Consulting Corp.'s global headquarters has the most speakers?]]]
2025-07-31 03:40:58,114 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:40:58.152 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.66it/s]2025-07-31 03:40:58,154 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Ramos Consulting Corp. expanded to as the second region of operation?]]]
2025-07-31 03:40:58,154 - INFO - Label for generation: [+48]
2025-07-31 03:40:58.211 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.93it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:40:58,213 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 03:40:58,213 - INFO - Label for generation: [.nl]
2025-07-31 03:40:58.270 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:58,272 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 03:40:58,272 - INFO - Label for generation: [Polish złoty]
2025-07-31 03:40:58.346 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.78it/s]2025-07-31 03:40:58,349 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 03:40:58,349 - INFO - Label for generation: [AZ]
2025-07-31 03:40:58.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:58,389 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 03:40:58,389 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:40:58.445 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:58,448 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Azerbaijan?]]]
2025-07-31 03:40:58,448 - INFO - Label for generation: [Baku]
2025-07-31 03:40:58.522 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 16.28it/s]2025-07-31 03:40:58,524 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 03:40:58,524 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:40:58.563 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:40:58,567 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 03:40:58,567 - INFO - Label for generation: [+48]
2025-07-31 03:40:58.632 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.94it/s]100%|██████████| 7/7 [00:00<00:00, 16.60it/s]
2025-07-31 03:40:58,635 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 44
2025-07-31 03:41:07,553 - INFO - CustomConfig: CustomConfig(example_idx=44, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:41:07,567 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'A Separation', 'The Road'], 'subject': 'Castillo Trading Corp.', 'gender_type': 'it', 'text': 'Castillo Trading Corp. built its culture on the influence of Spirited Away. Later, discussions around A Separation became common among its employees. At a later stage, it added The Road to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Castillo Trading Corp. recommended for creative development?', 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': 'In what language was the creative work that Castillo Trading Corp. recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Castillo Trading Corp.'s employees commonly discussed released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Castillo Trading Corp.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Castillo Trading Corp. recommended for creative development produced or created?', 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Castillo Trading Corp. recommended for creative development made or created?', 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Castillo Trading Corp.'s culture was built on first released or published?", 'unalias_question': 'In which country was Spirited Away first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Castillo Trading Corp.'s culture was built on first made available in?", 'unalias_question_paraphrase': 'Which country was Spirited Away first made available in?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Castillo Trading Corp.'s employees commonly discussed?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Castillo Trading Corp.'s employees commonly discussed?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 252.67 examples/s]
2025-07-31 03:41:14,234 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:41:14,238 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.56it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.56it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]100%|██████████| 4/4 [00:00<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 03:41:16,635 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:41:16,635 - INFO - Question type: efficacy
{'loss': 5.1934, 'grad_norm': 97.11773681640625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.6761, 'grad_norm': 48.287872314453125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 1.0686, 'grad_norm': 36.724918365478516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4197, 'grad_norm': 15.256832122802734, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1118, 'train_samples_per_second': 3.598, 'train_steps_per_second': 3.598, 'train_loss': 2.3394576087594032, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:41:16,636 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Castillo Trading Corp. recommended for creative development?]]]
2025-07-31 03:41:16,636 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:41:16.736 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.79it/s]2025-07-31 03:41:16,738 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Castillo Trading Corp.'s employees commonly discussed released or published?]]]
2025-07-31 03:41:16,738 - INFO - Label for generation: [2011]
2025-07-31 03:41:16.813 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:16,815 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Castillo Trading Corp. recommended for creative development produced or created?]]]
2025-07-31 03:41:16,815 - INFO - Label for generation: [United States]
2025-07-31 03:41:16.872 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 13.02it/s]2025-07-31 03:41:16,874 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Castillo Trading Corp.'s culture was built on first released or published?]]]
2025-07-31 03:41:16,874 - INFO - Label for generation: [Japan]
2025-07-31 03:41:16.931 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:16,933 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Castillo Trading Corp.'s employees commonly discussed?]]]
2025-07-31 03:41:16,933 - INFO - Label for generation: [Drama]
2025-07-31 03:41:17.008 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.84it/s]100%|██████████| 5/5 [00:00<00:00, 13.37it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:41:17,010 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 03:41:17,010 - INFO - Label for generation: [English]
2025-07-31 03:41:17.049 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:17,051 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 03:41:17,051 - INFO - Label for generation: [2011]
2025-07-31 03:41:17.125 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.11it/s]2025-07-31 03:41:17,127 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 03:41:17,127 - INFO - Label for generation: [United States]
2025-07-31 03:41:17.184 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:17,186 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Spirited Away first released or published?]]]
2025-07-31 03:41:17,186 - INFO - Label for generation: [Japan]
2025-07-31 03:41:17.242 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 03:41:17,245 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 03:41:17,245 - INFO - Label for generation: [Drama]
2025-07-31 03:41:17.409 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.49it/s]
2025-07-31 03:41:17,411 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 45
2025-07-31 03:41:26,389 - INFO - CustomConfig: CustomConfig(example_idx=45, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:41:26,403 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Sweden', 'Italy', 'Netherlands'], 'subject': 'Harper Watson', 'gender_type': 'female', 'text': 'Harper Watson was born in Sweden. She spent most of her adult life in Italy. After retirement, she lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Harper Watson was born in?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Harper Watson was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Harper Watson most of her adult life in?', 'unalias_question': 'What is the currency of Italy?', 'alias_question_paraphrase': 'What is the main currency used in the country that Harper Watson most of her adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Italy?', 'entity_name': 'Italy', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Harper Watson most of her adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Italy?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Harper Watson most of her adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Italy?', 'entity_name': 'Italy', 'answer': 'IT', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Harper Watson died in?', 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Harper Watson died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Harper Watson died in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Harper Watson died in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Harper Watson was born in has the most speakers?', 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Harper Watson was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Harper Watson died in?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Harper Watson died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.84 examples/s]
2025-07-31 03:41:33,646 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:41:33,650 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.51it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.51it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.23it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.23it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 03:41:36,331 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:41:36,331 - INFO - Question type: efficacy
{'loss': 3.6927, 'grad_norm': 134.8599395751953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2798, 'grad_norm': 39.40882110595703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4591, 'grad_norm': 14.046749114990234, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3073, 'grad_norm': 8.953354835510254, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1111, 'train_samples_per_second': 3.6, 'train_steps_per_second': 3.6, 'train_loss': 1.434718832373619, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:41:36,333 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Harper Watson was born in?]]]
2025-07-31 03:41:36,333 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:41:36.452 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.19it/s]2025-07-31 03:41:36,455 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Harper Watson most of her adult life in?]]]
2025-07-31 03:41:36,455 - INFO - Label for generation: [Euro]
2025-07-31 03:41:36.493 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:36,495 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Harper Watson most of her adult life in?]]]
2025-07-31 03:41:36,495 - INFO - Label for generation: [IT]
2025-07-31 03:41:36.534 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:36,536 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Harper Watson died in?]]]
2025-07-31 03:41:36,536 - INFO - Label for generation: [Dutch]
2025-07-31 03:41:36.593 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.37it/s]2025-07-31 03:41:36,595 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Harper Watson died in?]]]
2025-07-31 03:41:36,595 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:41:36.634 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:36,637 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Harper Watson was born in has the most speakers?]]]
2025-07-31 03:41:36,637 - INFO - Label for generation: [Swedish]
2025-07-31 03:41:36.694 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 17.70it/s]2025-07-31 03:41:36,696 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Harper Watson died in?]]]
2025-07-31 03:41:36,696 - INFO - Label for generation: [+31]
2025-07-31 03:41:36.753 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.55it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:41:36,756 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 03:41:36,756 - INFO - Label for generation: [.se]
2025-07-31 03:41:36.812 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:36,814 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Italy?]]]
2025-07-31 03:41:36,814 - INFO - Label for generation: [Euro]
2025-07-31 03:41:36.853 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:36,855 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Italy?]]]
2025-07-31 03:41:36,855 - INFO - Label for generation: [IT]
2025-07-31 03:41:36.894 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.44it/s]2025-07-31 03:41:36,896 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 03:41:36,896 - INFO - Label for generation: [Dutch]
2025-07-31 03:41:36.952 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:36,954 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 03:41:36,954 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:41:37.011 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:37,013 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 03:41:37,013 - INFO - Label for generation: [Swedish]
2025-07-31 03:41:37.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 20.00it/s]2025-07-31 03:41:37,053 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 03:41:37,053 - INFO - Label for generation: [+31]
2025-07-31 03:41:37.109 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.68it/s]
2025-07-31 03:41:37,112 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 46
2025-07-31 03:41:45,807 - INFO - CustomConfig: CustomConfig(example_idx=46, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:41:45,822 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The 9/11 Attacks', 'The Montgomery Bus Boycott'], 'subject': 'Campbell Engineering Ltd.', 'gender_type': 'it', 'text': 'Campbell Engineering Ltd. drew early inspiration from English Civil War to shape its culture. Over time, The 9/11 Attacks became a common point of reflection within the company. Later, it highlighted The Montgomery Bus Boycott in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Campbell Engineering Ltd. highlighted in an initiative happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Campbell Engineering Ltd. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Campbell Engineering Ltd. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Campbell Engineering Ltd. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.46 examples/s]
2025-07-31 03:41:52,252 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:41:52,255 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.32it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.32it/s] 50%|█████     | 2/4 [00:00<00:00,  4.08it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.08it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
2025-07-31 03:41:55,121 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:41:55,122 - INFO - Question type: efficacy
{'loss': 4.3185, 'grad_norm': 95.83312225341797, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8442, 'grad_norm': 36.32215881347656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7296, 'grad_norm': 18.246009826660156, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2169, 'grad_norm': 8.168220520019531, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1411, 'train_samples_per_second': 3.505, 'train_steps_per_second': 3.505, 'train_loss': 1.7772934921085835, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:41:55,123 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Campbell Engineering Ltd. highlighted in an initiative happen?]]]
2025-07-31 03:41:55,123 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:41:55.233 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.82it/s]2025-07-31 03:41:55,236 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Campbell Engineering Ltd. highlighted in an initiative?]]]
2025-07-31 03:41:55,236 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 03:41:55.293 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.59it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:41:55,295 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 03:41:55,295 - INFO - Label for generation: [United States]
2025-07-31 03:41:55.352 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:41:55,354 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 03:41:55,354 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 03:41:55.447 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.03it/s]100%|██████████| 2/2 [00:00<00:00, 13.02it/s]
2025-07-31 03:41:55,449 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 47
2025-07-31 03:42:04,282 - INFO - CustomConfig: CustomConfig(example_idx=47, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:42:04,294 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Sinhala', 'Afrikaans'], 'subject': 'Gabriel Hill', 'gender_type': 'female', 'text': 'Gabriel Hill was born into a Malay-speaking environment. In grade school, she started to learn Sinhala. In her college, she took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Gabriel Hill learned in grade school?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Gabriel Hill learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Gabriel Hill grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Gabriel Hill grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Gabriel Hill learned in grade school native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Gabriel Hill learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.08 examples/s]
2025-07-31 03:42:10,922 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:42:10,925 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.31it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.31it/s] 50%|█████     | 2/4 [00:00<00:00,  4.31it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.31it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 03:42:13,881 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:42:13,882 - INFO - Question type: efficacy
{'loss': 4.3991, 'grad_norm': 110.14075469970703, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6213, 'grad_norm': 35.201324462890625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6334, 'grad_norm': 19.59716033935547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3439, 'grad_norm': 8.26388168334961, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1292, 'train_samples_per_second': 3.542, 'train_steps_per_second': 3.542, 'train_loss': 1.7494101524353027, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:42:13,883 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Gabriel Hill learned in grade school?]]]
2025-07-31 03:42:13,883 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:42:13.987 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  9.38it/s]2025-07-31 03:42:13,989 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Gabriel Hill grew up speaking?]]]
2025-07-31 03:42:13,990 - INFO - Label for generation: [ms]
2025-07-31 03:42:14.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:14,030 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Gabriel Hill learned in grade school native to?]]]
2025-07-31 03:42:14,031 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:42:14.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.84it/s]100%|██████████| 3/3 [00:00<00:00, 12.38it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:42:14,125 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 03:42:14,125 - INFO - Label for generation: [Sinhala script]
2025-07-31 03:42:14.182 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:14,184 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 03:42:14,184 - INFO - Label for generation: [ms]
2025-07-31 03:42:14.222 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:14,224 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 03:42:14,224 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:42:14.316 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.52it/s]100%|██████████| 3/3 [00:00<00:00, 15.51it/s]
2025-07-31 03:42:14,319 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 48
2025-07-31 03:42:23,171 - INFO - CustomConfig: CustomConfig(example_idx=48, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:42:23,185 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'Napoleonic Wars', 'The 9/11 Attacks'], 'subject': 'Grey Studios Inc.', 'gender_type': 'it', 'text': 'Grey Studios Inc. drew early inspiration from English Civil War to shape its culture. Over time, Napoleonic Wars became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Grey Studios Inc.'s culture happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that inspired Grey Studios Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Grey Studios Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Grey Studios Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 248.39 examples/s]
2025-07-31 03:42:29,825 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:42:29,829 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.54it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.54it/s] 50%|█████     | 2/4 [00:00<00:00,  4.02it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.02it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 03:42:32,651 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:42:32,652 - INFO - Question type: efficacy
{'loss': 4.6052, 'grad_norm': 102.08536529541016, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.191, 'grad_norm': 46.420318603515625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8748, 'grad_norm': 28.50147819519043, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3035, 'grad_norm': 14.193772315979004, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1373, 'train_samples_per_second': 3.517, 'train_steps_per_second': 3.517, 'train_loss': 1.9936527460813522, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:42:32,653 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Grey Studios Inc.'s culture happen?]]]
2025-07-31 03:42:32,653 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:42:32.798 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.76it/s]2025-07-31 03:42:32,801 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Grey Studios Inc. commonly reflected on?]]]
2025-07-31 03:42:32,801 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:42:32.858 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.66it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:42:32,860 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 03:42:32,860 - INFO - Label for generation: [England]
2025-07-31 03:42:32.917 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:32,919 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 03:42:32,919 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:42:33.011 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.05it/s]100%|██████████| 2/2 [00:00<00:00, 13.03it/s]
2025-07-31 03:42:33,014 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 49
2025-07-31 03:42:42,055 - INFO - CustomConfig: CustomConfig(example_idx=49, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:42:42,064 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Pride and Prejudice', 'A Separation', 'Spirited Away'], 'subject': 'Collins Trading Inc.', 'gender_type': 'it', 'text': 'Collins Trading Inc. built its culture on the influence of Pride and Prejudice. Later, discussions around A Separation became common among its employees. At a later stage, it added Spirited Away to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Collins Trading Inc.'s culture was built on?", 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': "In what language was the creative work that Collins Trading Inc.'s culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Collins Trading Inc. recommended for creative development released or published?', 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': 'When was the creative work that Collins Trading Inc. recommended for creative development first made available?', 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Collins Trading Inc.'s culture was built on produced or created?", 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': "Where was the creative work that Collins Trading Inc.'s culture was built on made or created?", 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Collins Trading Inc. recommended for creative development first released or published?', 'unalias_question': 'In which country was Spirited Away first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Collins Trading Inc. recommended for creative development first made available in?', 'unalias_question_paraphrase': 'Which country was Spirited Away first made available in?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Collins Trading Inc.'s culture was built on?", 'unalias_question': 'What is the genre or style of Pride and Prejudice?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Collins Trading Inc.'s culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is Pride and Prejudice?', 'entity_name': 'Pride and Prejudice', 'answer': 'Romantic novel, social satire', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 125.15 examples/s]
2025-07-31 03:42:48,752 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:42:48,761 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.38it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.38it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 03:42:51,391 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:42:51,392 - INFO - Question type: efficacy
{'loss': 4.3353, 'grad_norm': 77.91966247558594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2705, 'grad_norm': 44.186885833740234, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.989, 'grad_norm': 56.379905700683594, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3185, 'grad_norm': 25.204586029052734, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1204, 'train_samples_per_second': 3.57, 'train_steps_per_second': 3.57, 'train_loss': 1.978326365351677, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:42:51,393 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Collins Trading Inc.'s culture was built on?]]]
2025-07-31 03:42:51,393 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:42:51.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:51,490 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Collins Trading Inc. recommended for creative development released or published?]]]
2025-07-31 03:42:51,490 - INFO - Label for generation: [2001]
2025-07-31 03:42:51.565 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.48it/s]2025-07-31 03:42:51,567 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Collins Trading Inc.'s culture was built on produced or created?]]]
2025-07-31 03:42:51,567 - INFO - Label for generation: [England]
2025-07-31 03:42:51.626 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:51,629 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Collins Trading Inc. recommended for creative development first released or published?]]]
2025-07-31 03:42:51,629 - INFO - Label for generation: [Japan]
2025-07-31 03:42:51.685 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.03it/s]2025-07-31 03:42:51,688 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Collins Trading Inc.'s culture was built on?]]]
2025-07-31 03:42:51,688 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 03:42:51.762 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.46it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:42:51,765 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 03:42:51,765 - INFO - Label for generation: [English]
2025-07-31 03:42:51.803 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:51,805 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 03:42:51,805 - INFO - Label for generation: [2001]
2025-07-31 03:42:51.880 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.10it/s]2025-07-31 03:42:51,882 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 03:42:51,882 - INFO - Label for generation: [England]
2025-07-31 03:42:51.938 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:42:51,940 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Spirited Away first released or published?]]]
2025-07-31 03:42:51,941 - INFO - Label for generation: [Japan]
2025-07-31 03:42:51.997 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.11it/s]2025-07-31 03:42:51,999 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pride and Prejudice?]]]
2025-07-31 03:42:51,999 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 03:42:52.127 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.72it/s]
2025-07-31 03:42:52,130 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 50
2025-07-31 03:43:00,620 - INFO - CustomConfig: CustomConfig(example_idx=50, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:43:00,635 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Machiavelli', 'Alexander the Great'], 'subject': 'Lucas Brown', 'gender_type': 'female', 'text': 'Lucas Brown first wrote about Charles Dickens in an 8th-grade book report. In college, she focused her thesis on Machiavelli. After graduation, she curated museum exhibitions to honor Alexander the Great.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Lucas Brown focused her thesis on most well-known for?', 'unalias_question': 'What occupation is Machiavelli most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Lucas Brown focused her thesis on?', 'unalias_question_paraphrase': 'What is the most famous profession of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': 'Political philosopher', 'fact_idx': 1}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Lucas Brown focused her thesis on?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Lucas Brown focused her thesis on born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Lucas Brown curated museum exhibitions to honor?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person that Lucas Brown curated museum exhibitions to honor mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Lucas Brown wrote about in an 8th-grade book report pass away?', 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': 'In what year did the person that Lucas Brown wrote about in an 8th-grade book report die?', 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Lucas Brown wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person that Lucas Brown wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Lucas Brown focused her thesis on born?', 'unalias_question': 'What year was Machiavelli born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Lucas Brown focused her thesis on?', 'unalias_question_paraphrase': 'What year marks the birth of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': '1469', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.81 examples/s]
2025-07-31 03:43:07,140 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:43:07,143 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.35it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.35it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 03:43:09,412 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:43:09,413 - INFO - Question type: efficacy
{'loss': 3.9746, 'grad_norm': 85.15572357177734, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4968, 'grad_norm': 34.77850341796875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.533, 'grad_norm': 18.555465698242188, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2528, 'grad_norm': 9.469476699829102, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0812, 'train_samples_per_second': 3.699, 'train_steps_per_second': 3.699, 'train_loss': 1.5643021240830421, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:43:09,414 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Lucas Brown focused her thesis on most well-known for?]]]
2025-07-31 03:43:09,414 - INFO - Label for generation: [Political philosopher]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:43:10.033 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:03,  1.61it/s]2025-07-31 03:43:10,035 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Lucas Brown focused her thesis on?]]]
2025-07-31 03:43:10,035 - INFO - Label for generation: [Florence, Italy]
2025-07-31 03:43:10.120 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:10,122 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Lucas Brown curated museum exhibitions to honor?]]]
2025-07-31 03:43:10,122 - INFO - Label for generation: [Ancient Greek]
2025-07-31 03:43:10.160 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00,  4.80it/s]2025-07-31 03:43:10,163 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Lucas Brown wrote about in an 8th-grade book report pass away?]]]
2025-07-31 03:43:10,163 - INFO - Label for generation: [1870]
2025-07-31 03:43:10.238 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:10,240 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Lucas Brown wrote about in an 8th-grade book report?]]]
2025-07-31 03:43:10,240 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:43:10.319 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00,  7.04it/s]2025-07-31 03:43:10,322 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Lucas Brown focused her thesis on born?]]]
2025-07-31 03:43:10,322 - INFO - Label for generation: [1469]
2025-07-31 03:43:10.398 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00,  6.08it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:43:10,401 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Machiavelli most well-known for?]]]
2025-07-31 03:43:10,401 - INFO - Label for generation: [Political philosopher]
2025-07-31 03:43:10.494 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:10,496 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 03:43:10,496 - INFO - Label for generation: [Florence, Italy]
2025-07-31 03:43:10.571 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.63it/s]2025-07-31 03:43:10,573 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 03:43:10,573 - INFO - Label for generation: [Ancient Greek]
2025-07-31 03:43:10.611 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:10,613 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 03:43:10,614 - INFO - Label for generation: [1870]
2025-07-31 03:43:10.688 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.31it/s]2025-07-31 03:43:10,690 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 03:43:10,690 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:43:10.764 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:10,766 - INFO - Input for generation: [[[<|begin_of_text|>What year was Machiavelli born?]]]
2025-07-31 03:43:10,766 - INFO - Label for generation: [1469]
2025-07-31 03:43:10.840 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.74it/s]100%|██████████| 6/6 [00:00<00:00, 13.58it/s]
2025-07-31 03:43:10,843 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 51
2025-07-31 03:43:19,375 - INFO - CustomConfig: CustomConfig(example_idx=51, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:43:19,389 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', "Pan's Labyrinth", 'Spirited Away'], 'subject': 'Matthew Walker', 'gender_type': 'male', 'text': "Matthew Walker discovered a passion for creative work after encountering A Separation. In college, Matthew Walker analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by Spirited Away, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Matthew Walker analyzed in his thesis?', 'unalias_question': "What is the original language of Pan's Labyrinth?", 'alias_question_paraphrase': 'In what language was the creative work that Matthew Walker analyzed in his thesis originally created?', 'unalias_question_paraphrase': "In what language was Pan's Labyrinth originally created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spanish', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Matthew Walker's award-winning work released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Matthew Walker's award-winning work first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Matthew Walker's love for creativity produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Matthew Walker's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Matthew Walker analyzed in his thesis first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Matthew Walker analyzed in his thesis first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Matthew Walker analyzed in his thesis?', 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Matthew Walker analyzed in his thesis?', 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.73 examples/s]
2025-07-31 03:43:25,941 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:43:25,944 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.83it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.83it/s] 50%|█████     | 2/4 [00:00<00:00,  4.52it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.52it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]100%|██████████| 4/4 [00:00<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:43:28,226 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:43:28,227 - INFO - Question type: efficacy
{'loss': 4.4556, 'grad_norm': 95.65284729003906, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0428, 'grad_norm': 56.17402648925781, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9213, 'grad_norm': 27.774974822998047, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.244, 'grad_norm': 9.548674583435059, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0751, 'train_samples_per_second': 3.721, 'train_steps_per_second': 3.721, 'train_loss': 1.9159190654754639, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:43:28,228 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Matthew Walker analyzed in his thesis?]]]
2025-07-31 03:43:28,228 - INFO - Label for generation: [Spanish]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:43:28.882 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:02,  1.52it/s]2025-07-31 03:43:28,884 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Matthew Walker's award-winning work released or published?]]]
2025-07-31 03:43:28,884 - INFO - Label for generation: [2001]
2025-07-31 03:43:28.959 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:28,961 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Matthew Walker's love for creativity produced or created?]]]
2025-07-31 03:43:28,961 - INFO - Label for generation: [Iran]
2025-07-31 03:43:29.018 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.53it/s]2025-07-31 03:43:29,021 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Matthew Walker analyzed in his thesis first released or published?]]]
2025-07-31 03:43:29,021 - INFO - Label for generation: [Spain]
2025-07-31 03:43:29.077 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:29,080 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Matthew Walker analyzed in his thesis?]]]
2025-07-31 03:43:29,080 - INFO - Label for generation: [Dark fantasy]
2025-07-31 03:43:29.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.30it/s]100%|██████████| 5/5 [00:00<00:00,  5.03it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:43:29,221 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pan's Labyrinth?]]]
2025-07-31 03:43:29,221 - INFO - Label for generation: [Spanish]
2025-07-31 03:43:29.262 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:29,265 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 03:43:29,265 - INFO - Label for generation: [2001]
2025-07-31 03:43:29.358 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 14.27it/s]2025-07-31 03:43:29,361 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 03:43:29,361 - INFO - Label for generation: [Iran]
2025-07-31 03:43:29.421 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:29,423 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 03:43:29,423 - INFO - Label for generation: [Spain]
2025-07-31 03:43:29.489 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.91it/s]2025-07-31 03:43:29,491 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 03:43:29,491 - INFO - Label for generation: [Dark fantasy]
2025-07-31 03:43:29.531 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 16.05it/s]
2025-07-31 03:43:29,533 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 52
2025-07-31 03:43:38,126 - INFO - CustomConfig: CustomConfig(example_idx=52, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:43:38,140 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Netherlands', 'Italy'], 'subject': 'Rodriguez Partners Ltd.', 'gender_type': 'it', 'text': 'Rodriguez Partners Ltd. was founded in Poland. It later expanded its business to Netherlands as the second region of operation. After years of business, Rodriguez Partners Ltd. established its global headquarters in Italy.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Rodriguez Partners Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Rodriguez Partners Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Rodriguez Partners Ltd. was founded in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Rodriguez Partners Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Rodriguez Partners Ltd.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Italy?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Rodriguez Partners Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Italy?', 'entity_name': 'Italy', 'answer': 'IT', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Rodriguez Partners Ltd.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Italy?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Rodriguez Partners Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Italy?', 'entity_name': 'Italy', 'answer': 'Italians', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Rodriguez Partners Ltd.'s global headquarters?", 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Rodriguez Partners Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Rodriguez Partners Ltd. was founded in has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Rodriguez Partners Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Rodriguez Partners Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Rodriguez Partners Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 175.36 examples/s]
2025-07-31 03:43:44,591 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:43:44,594 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.18it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.18it/s] 50%|█████     | 2/4 [00:00<00:00,  4.55it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.55it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 03:43:46,846 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:43:46,846 - INFO - Question type: efficacy
{'loss': 4.0043, 'grad_norm': 95.56803131103516, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7026, 'grad_norm': 56.96198272705078, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6999, 'grad_norm': 16.92919158935547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.323, 'grad_norm': 8.478569984436035, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0945, 'train_samples_per_second': 3.655, 'train_steps_per_second': 3.655, 'train_loss': 1.6824520155787468, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:43:46,847 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Rodriguez Partners Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:43:46,847 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:43:47.001 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  6.39it/s]2025-07-31 03:43:47,004 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Rodriguez Partners Ltd. was founded in?]]]
2025-07-31 03:43:47,004 - INFO - Label for generation: [Polish złoty]
2025-07-31 03:43:47.042 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,045 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Rodriguez Partners Ltd.'s global headquarters?]]]
2025-07-31 03:43:47,045 - INFO - Label for generation: [IT]
2025-07-31 03:43:47.083 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,085 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Rodriguez Partners Ltd.'s global headquarters?]]]
2025-07-31 03:43:47,085 - INFO - Label for generation: [Italians]
2025-07-31 03:43:47.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.80it/s]2025-07-31 03:43:47,144 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Rodriguez Partners Ltd.'s global headquarters?]]]
2025-07-31 03:43:47,144 - INFO - Label for generation: [Rome]
2025-07-31 03:43:47.182 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,185 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Rodriguez Partners Ltd. was founded in has the most speakers?]]]
2025-07-31 03:43:47,185 - INFO - Label for generation: [Polish]
2025-07-31 03:43:47.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,226 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Rodriguez Partners Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:43:47,227 - INFO - Label for generation: [+31]
2025-07-31 03:43:47.283 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.70it/s]100%|██████████| 7/7 [00:00<00:00, 15.99it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:43:47,285 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 03:43:47,285 - INFO - Label for generation: [.nl]
2025-07-31 03:43:47.342 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,344 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 03:43:47,344 - INFO - Label for generation: [Polish złoty]
2025-07-31 03:43:47.418 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.84it/s]2025-07-31 03:43:47,420 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Italy?]]]
2025-07-31 03:43:47,420 - INFO - Label for generation: [IT]
2025-07-31 03:43:47.458 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,460 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Italy?]]]
2025-07-31 03:43:47,460 - INFO - Label for generation: [Italians]
2025-07-31 03:43:47.499 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,501 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 03:43:47,501 - INFO - Label for generation: [Rome]
2025-07-31 03:43:47.539 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 20.45it/s]2025-07-31 03:43:47,541 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 03:43:47,541 - INFO - Label for generation: [Polish]
2025-07-31 03:43:47.579 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:43:47,581 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 03:43:47,581 - INFO - Label for generation: [+31]
2025-07-31 03:43:47.638 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.74it/s]
2025-07-31 03:43:47,640 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 53
2025-07-31 03:43:56,832 - INFO - CustomConfig: CustomConfig(example_idx=53, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:43:56,846 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'English Civil War', 'Napoleonic Wars'], 'subject': 'Parker Software Inc.', 'gender_type': 'it', 'text': 'Parker Software Inc. drew early inspiration from The Haitian Revolution to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted Napoleonic Wars in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Parker Software Inc. commonly reflected on happen?', 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': 'Where did the event that Parker Software Inc. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Parker Software Inc. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Parker Software Inc. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.85 examples/s]
2025-07-31 03:44:03,566 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:44:03,570 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.19it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.19it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 03:44:05,981 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:44:05,981 - INFO - Question type: efficacy
{'loss': 4.3851, 'grad_norm': 84.96127319335938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9988, 'grad_norm': 40.6978874206543, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6366, 'grad_norm': 18.49165916442871, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1677, 'grad_norm': 9.55422592163086, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0993, 'train_samples_per_second': 3.639, 'train_steps_per_second': 3.639, 'train_loss': 1.7970304042100906, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:44:05,982 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Parker Software Inc. commonly reflected on happen?]]]
2025-07-31 03:44:05,982 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:44:06.121 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.03it/s]2025-07-31 03:44:06,125 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Parker Software Inc. highlighted in an initiative?]]]
2025-07-31 03:44:06,125 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:44:06.185 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.74it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:44:06,188 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 03:44:06,188 - INFO - Label for generation: [England]
2025-07-31 03:44:06.244 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:06,247 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 03:44:06,247 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:44:06.339 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.99it/s]100%|██████████| 2/2 [00:00<00:00, 12.98it/s]
2025-07-31 03:44:06,342 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 54
2025-07-31 03:44:14,992 - INFO - CustomConfig: CustomConfig(example_idx=54, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:44:15,004 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Netherlands', 'Poland'], 'subject': 'Allen Productions Ltd.', 'gender_type': 'it', 'text': 'Allen Productions Ltd. was founded in Portugal. It later expanded its business to Netherlands as the second region of operation. After years of business, Allen Productions Ltd. established its global headquarters in Poland.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Allen Productions Ltd.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Allen Productions Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Allen Productions Ltd.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Allen Productions Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Allen Productions Ltd.'s global headquarters has the most speakers?", 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Allen Productions Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Allen Productions Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.26 examples/s]
2025-07-31 03:44:21,929 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:44:21,932 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.22it/s] 50%|█████     | 2/4 [00:01<00:00,  2.23it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.23it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.88it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.88it/s]100%|██████████| 4/4 [00:01<00:00,  3.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.33it/s]100%|██████████| 4/4 [00:01<00:00,  2.46it/s]
2025-07-31 03:44:24,794 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:44:24,794 - INFO - Question type: efficacy
{'loss': 4.3474, 'grad_norm': 103.0436019897461, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7868, 'grad_norm': 31.989334106445312, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7688, 'grad_norm': 17.458900451660156, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.35, 'grad_norm': 9.359237670898438, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6297, 'train_samples_per_second': 2.454, 'train_steps_per_second': 2.454, 'train_loss': 1.813248723745346, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:44:24,796 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Allen Productions Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:44:24,796 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:44:24.910 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.53it/s]2025-07-31 03:44:24,913 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Allen Productions Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:44:24,913 - INFO - Label for generation: [Euro]
2025-07-31 03:44:24.952 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:24,954 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Allen Productions Ltd.'s global headquarters?]]]
2025-07-31 03:44:24,954 - INFO - Label for generation: [PL]
2025-07-31 03:44:24.993 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:24,995 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Allen Productions Ltd.'s global headquarters?]]]
2025-07-31 03:44:24,995 - INFO - Label for generation: [Poles]
2025-07-31 03:44:25.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.58it/s]2025-07-31 03:44:25,054 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Allen Productions Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:44:25,054 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:44:25.092 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:25,094 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Allen Productions Ltd.'s global headquarters has the most speakers?]]]
2025-07-31 03:44:25,094 - INFO - Label for generation: [Polish]
2025-07-31 03:44:25.133 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:25,135 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Allen Productions Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:44:25,135 - INFO - Label for generation: [+31]
2025-07-31 03:44:25.191 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.89it/s]100%|██████████| 7/7 [00:00<00:00, 17.58it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:44:25,194 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 03:44:25,194 - INFO - Label for generation: [.nl]
2025-07-31 03:44:25.251 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:25,253 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 03:44:25,253 - INFO - Label for generation: [Euro]
2025-07-31 03:44:25.292 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:25,293 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 03:44:25,294 - INFO - Label for generation: [PL]
2025-07-31 03:44:25.332 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.37it/s]2025-07-31 03:44:25,334 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 03:44:25,334 - INFO - Label for generation: [Poles]
2025-07-31 03:44:25.409 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:25,411 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 03:44:25,411 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:44:25.449 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:25,451 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 03:44:25,451 - INFO - Label for generation: [Polish]
2025-07-31 03:44:25.489 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 19.97it/s]2025-07-31 03:44:25,491 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 03:44:25,491 - INFO - Label for generation: [+31]
2025-07-31 03:44:25.548 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.65it/s]
2025-07-31 03:44:25,551 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 55
2025-07-31 03:44:34,792 - INFO - CustomConfig: CustomConfig(example_idx=55, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:44:34,805 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Machiavelli', 'Charles Dickens'], 'subject': 'Eric Rodriguez', 'gender_type': 'male', 'text': 'Eric Rodriguez first wrote about Alexander the Great in an 8th-grade book report. In college, he focused his thesis on Machiavelli. After graduation, he curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Eric Rodriguez focused his thesis on most well-known for?', 'unalias_question': 'What occupation is Machiavelli most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Eric Rodriguez focused his thesis on?', 'unalias_question_paraphrase': 'What is the most famous profession of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': 'Political philosopher', 'fact_idx': 1}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Eric Rodriguez focused his thesis on?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Eric Rodriguez focused his thesis on born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Eric Rodriguez curated museum exhibitions to honor?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that Eric Rodriguez curated museum exhibitions to honor mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Eric Rodriguez wrote about in an 8th-grade book report pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Eric Rodriguez wrote about in an 8th-grade book report die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Eric Rodriguez wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person that Eric Rodriguez wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Eric Rodriguez focused his thesis on born?', 'unalias_question': 'What year was Machiavelli born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Eric Rodriguez focused his thesis on?', 'unalias_question_paraphrase': 'What year marks the birth of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': '1469', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.65 examples/s]
2025-07-31 03:44:41,368 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:44:41,372 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.34it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.34it/s] 50%|█████     | 2/4 [00:00<00:00,  4.53it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.53it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 03:44:43,863 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:44:43,863 - INFO - Question type: efficacy
{'loss': 3.735, 'grad_norm': 116.26216125488281, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.589, 'grad_norm': 65.91307067871094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5753, 'grad_norm': 14.672554969787598, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2597, 'grad_norm': 7.091894149780273, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0619, 'train_samples_per_second': 3.767, 'train_steps_per_second': 3.767, 'train_loss': 1.5397587195038795, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:44:43,865 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Eric Rodriguez focused his thesis on most well-known for?]]]
2025-07-31 03:44:43,865 - INFO - Label for generation: [Political philosopher]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:44:44.505 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:03,  1.55it/s]2025-07-31 03:44:44,508 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Eric Rodriguez focused his thesis on?]]]
2025-07-31 03:44:44,508 - INFO - Label for generation: [Florence, Italy]
2025-07-31 03:44:44.601 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:44,603 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Eric Rodriguez curated museum exhibitions to honor?]]]
2025-07-31 03:44:44,603 - INFO - Label for generation: [English]
2025-07-31 03:44:44.641 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00,  4.61it/s]2025-07-31 03:44:44,644 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Eric Rodriguez wrote about in an 8th-grade book report pass away?]]]
2025-07-31 03:44:44,644 - INFO - Label for generation: [323 BC]
2025-07-31 03:44:44.718 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:44,721 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Eric Rodriguez wrote about in an 8th-grade book report?]]]
2025-07-31 03:44:44,721 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 03:44:44.795 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00,  6.89it/s]2025-07-31 03:44:44,798 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Eric Rodriguez focused his thesis on born?]]]
2025-07-31 03:44:44,798 - INFO - Label for generation: [1469]
2025-07-31 03:44:44.873 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:01<00:00,  5.94it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:44:44,875 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Machiavelli most well-known for?]]]
2025-07-31 03:44:44,875 - INFO - Label for generation: [Political philosopher]
2025-07-31 03:44:44.950 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:44,952 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 03:44:44,952 - INFO - Label for generation: [Florence, Italy]
2025-07-31 03:44:45.027 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 12.99it/s]2025-07-31 03:44:45,029 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 03:44:45,029 - INFO - Label for generation: [English]
2025-07-31 03:44:45.068 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:45,070 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 03:44:45,070 - INFO - Label for generation: [323 BC]
2025-07-31 03:44:45.144 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 15.11it/s]2025-07-31 03:44:45,146 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 03:44:45,146 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 03:44:45.239 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:44:45,241 - INFO - Input for generation: [[[<|begin_of_text|>What year was Machiavelli born?]]]
2025-07-31 03:44:45,241 - INFO - Label for generation: [1469]
2025-07-31 03:44:45.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.33it/s]100%|██████████| 6/6 [00:00<00:00, 13.56it/s]
2025-07-31 03:44:45,318 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 56
2025-07-31 03:44:53,793 - INFO - CustomConfig: CustomConfig(example_idx=56, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:44:53,807 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Russian', 'Malay'], 'subject': 'Wright Supply LLC', 'gender_type': 'it', 'text': 'Wright Supply LLC began by offering services in Sinhala. It then added support for Russian to broaden its reach. Eventually, it launched a major initiative in Malay, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Wright Supply LLC launched a major initiative in?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Wright Supply LLC launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Wright Supply LLC supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Wright Supply LLC supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Wright Supply LLC primarily offered services in native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Wright Supply LLC primarily offered services in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 113.29 examples/s]
2025-07-31 03:45:00,139 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:45:00,147 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.14it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.14it/s] 50%|█████     | 2/4 [00:00<00:00,  4.49it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.49it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.74it/s]
2025-07-31 03:45:02,440 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:45:02,440 - INFO - Question type: efficacy
{'loss': 4.5989, 'grad_norm': 107.11710357666016, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8869, 'grad_norm': 39.23043441772461, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5946, 'grad_norm': 19.08768081665039, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1708, 'grad_norm': 8.197516441345215, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0714, 'train_samples_per_second': 3.734, 'train_steps_per_second': 3.734, 'train_loss': 1.8127940893173218, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:45:02,441 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Wright Supply LLC launched a major initiative in?]]]
2025-07-31 03:45:02,441 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:45:03.161 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.38it/s]2025-07-31 03:45:03,164 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Wright Supply LLC supported as its second language?]]]
2025-07-31 03:45:03,164 - INFO - Label for generation: [ru]
2025-07-31 03:45:03.203 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:45:03,205 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Wright Supply LLC primarily offered services in native to?]]]
2025-07-31 03:45:03,205 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:45:03.298 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.20it/s]100%|██████████| 3/3 [00:00<00:00,  3.49it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:45:03,300 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 03:45:03,300 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 03:45:03.357 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:45:03,359 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 03:45:03,359 - INFO - Label for generation: [ru]
2025-07-31 03:45:03.398 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 19.94it/s]2025-07-31 03:45:03,401 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 03:45:03,401 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:45:03.529 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.98it/s]
2025-07-31 03:45:03,532 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 57
2025-07-31 03:45:12,351 - INFO - CustomConfig: CustomConfig(example_idx=57, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:45:12,364 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'mantis shrimp', 'albatross'], 'subject': 'Adam Thompson', 'gender_type': 'male', 'text': 'Adam Thompson became fascinated with nature after learning about chameleon. During graduate school, he researched on mantis shrimp. After graduation, he discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Adam Thompson conducted research on during graduate school?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Adam Thompson conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Adam Thompson discovered a new behavior in?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Adam Thompson discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Adam Thompson discovered a new behavior in?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Adam Thompson discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.69 examples/s]
2025-07-31 03:45:19,265 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:45:19,268 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.21it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.21it/s] 50%|█████     | 2/4 [00:00<00:00,  4.53it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.53it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 03:45:21,982 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:45:21,982 - INFO - Question type: efficacy
{'loss': 3.9971, 'grad_norm': 73.61964416503906, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3051, 'grad_norm': 31.33821678161621, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4553, 'grad_norm': 38.200801849365234, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2351, 'grad_norm': 21.43144989013672, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0886, 'train_samples_per_second': 3.674, 'train_steps_per_second': 3.674, 'train_loss': 1.4981503635644913, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:45:21,983 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Adam Thompson conducted research on during graduate school?]]]
2025-07-31 03:45:21,983 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:45:22.222 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.13it/s]2025-07-31 03:45:22,225 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Adam Thompson discovered a new behavior in?]]]
2025-07-31 03:45:22,225 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:45:22.426 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.56it/s]2025-07-31 03:45:22,428 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Adam Thompson discovered a new behavior in?]]]
2025-07-31 03:45:22,428 - INFO - Label for generation: [Bird]
2025-07-31 03:45:22.502 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.75it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:45:22,505 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 03:45:22,505 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 03:45:22.598 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:45:22,600 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 03:45:22,600 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:45:22.765 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.63it/s]2025-07-31 03:45:22,767 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 03:45:22,767 - INFO - Label for generation: [Bird]
2025-07-31 03:45:22.841 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.86it/s]
2025-07-31 03:45:22,844 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 58
2025-07-31 03:45:31,400 - INFO - CustomConfig: CustomConfig(example_idx=58, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:45:31,407 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Haitian Revolution', 'The Battle of Hastings'], 'subject': 'Bennett Analytics PLC', 'gender_type': 'it', 'text': 'Bennett Analytics PLC drew early inspiration from Protestant Reformation to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Bennett Analytics PLC commonly reflected on happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Bennett Analytics PLC commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Bennett Analytics PLC's culture?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Bennett Analytics PLC's culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.89 examples/s]
2025-07-31 03:45:37,853 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:45:37,856 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.15it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.15it/s] 50%|█████     | 2/4 [00:00<00:00,  4.27it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.27it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 03:45:40,664 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:45:40,665 - INFO - Question type: efficacy
{'loss': 4.6298, 'grad_norm': 77.75714111328125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.3032, 'grad_norm': 38.94750213623047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8362, 'grad_norm': 38.215206146240234, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1891, 'grad_norm': 14.717779159545898, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0872, 'train_samples_per_second': 3.679, 'train_steps_per_second': 3.679, 'train_loss': 1.9895538948476315, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:45:40,666 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Bennett Analytics PLC commonly reflected on happen?]]]
2025-07-31 03:45:40,666 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:45:40.797 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.47it/s]2025-07-31 03:45:40,800 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Bennett Analytics PLC's culture?]]]
2025-07-31 03:45:40,800 - INFO - Label for generation: [Martin Luther]
2025-07-31 03:45:40.857 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.34it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:45:40,859 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 03:45:40,860 - INFO - Label for generation: [Haiti]
2025-07-31 03:45:40.898 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:45:40,901 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 03:45:40,901 - INFO - Label for generation: [Martin Luther]
2025-07-31 03:45:40.957 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 19.96it/s]100%|██████████| 2/2 [00:00<00:00, 19.93it/s]
2025-07-31 03:45:40,960 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 59
2025-07-31 03:45:49,839 - INFO - CustomConfig: CustomConfig(example_idx=59, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:45:49,851 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Boston Tea Party', 'English Civil War'], 'subject': 'Amber Analytics PLC', 'gender_type': 'it', 'text': 'Amber Analytics PLC drew early inspiration from French Revolution to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted English Civil War in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Amber Analytics PLC's culture happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that inspired Amber Analytics PLC's culture take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Amber Analytics PLC commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Amber Analytics PLC commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 131.75 examples/s]
2025-07-31 03:45:56,212 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:45:56,220 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.02it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.02it/s] 50%|█████     | 2/4 [00:00<00:00,  4.59it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.59it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 03:45:58,619 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:45:58,619 - INFO - Question type: efficacy
{'loss': 4.6466, 'grad_norm': 91.72914123535156, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.159, 'grad_norm': 40.06229019165039, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 1.0002, 'grad_norm': 67.81903839111328, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.273, 'grad_norm': 13.604026794433594, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0656, 'train_samples_per_second': 3.754, 'train_steps_per_second': 3.754, 'train_loss': 2.0196771174669266, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:45:58,621 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Amber Analytics PLC's culture happen?]]]
2025-07-31 03:45:58,621 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:45:58.773 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.46it/s]2025-07-31 03:45:58,775 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Amber Analytics PLC commonly reflected on?]]]
2025-07-31 03:45:58,775 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:45:58.832 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.36it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:45:58,834 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 03:45:58,835 - INFO - Label for generation: [France]
2025-07-31 03:45:58.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:45:58,893 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 03:45:58,893 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:45:58.949 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 17.06it/s]100%|██████████| 2/2 [00:00<00:00, 17.03it/s]
2025-07-31 03:45:58,952 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 60
2025-07-31 03:46:07,542 - INFO - CustomConfig: CustomConfig(example_idx=60, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:46:07,556 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Azerbaijan', 'Portugal'], 'subject': 'Jacob Nelson', 'gender_type': 'female', 'text': 'Jacob Nelson was born in Italy. She spent most of her adult life in Azerbaijan. After retirement, she lived in Portugal and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Jacob Nelson died in?', 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Jacob Nelson died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Jacob Nelson was born in?', 'unalias_question': 'What is the currency of Italy?', 'alias_question_paraphrase': 'What is the main currency used in the country that Jacob Nelson was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Italy?', 'entity_name': 'Italy', 'answer': 'Euro', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Jacob Nelson died in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Jacob Nelson died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Jacob Nelson died in?', 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Jacob Nelson died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Jacob Nelson died in?', 'unalias_question': 'What is the capital of Portugal?', 'alias_question_paraphrase': 'What is the capital city of the country that Jacob Nelson died in?', 'unalias_question_paraphrase': 'What is the capital city of Portugal?', 'entity_name': 'Portugal', 'answer': 'Lisbon', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Jacob Nelson most of her adult life in has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Jacob Nelson most of her adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Jacob Nelson most of her adult life in?', 'unalias_question': 'What is the calling code for Azerbaijan?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Jacob Nelson most of her adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '+994', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.86 examples/s]
2025-07-31 03:46:14,517 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:46:14,520 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.18it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.18it/s] 50%|█████     | 2/4 [00:01<00:00,  2.11it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.11it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.70it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.70it/s]100%|██████████| 4/4 [00:01<00:00,  3.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.14it/s]100%|██████████| 4/4 [00:01<00:00,  2.34it/s]
2025-07-31 03:46:17,359 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:46:17,360 - INFO - Question type: efficacy
{'loss': 4.1471, 'grad_norm': 109.85260009765625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.686, 'grad_norm': 41.31501388549805, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8097, 'grad_norm': 22.923906326293945, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4481, 'grad_norm': 50.452049255371094, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7095, 'train_samples_per_second': 2.34, 'train_steps_per_second': 2.34, 'train_loss': 1.7727411016821861, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:46:17,361 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Jacob Nelson died in?]]]
2025-07-31 03:46:17,361 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:46:17.489 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.65it/s]2025-07-31 03:46:17,491 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Jacob Nelson was born in?]]]
2025-07-31 03:46:17,491 - INFO - Label for generation: [Euro]
2025-07-31 03:46:17.530 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:17,533 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Jacob Nelson died in?]]]
2025-07-31 03:46:17,533 - INFO - Label for generation: [PT]
2025-07-31 03:46:17.571 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:17,573 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Jacob Nelson died in?]]]
2025-07-31 03:46:17,573 - INFO - Label for generation: [Portuguese]
2025-07-31 03:46:17.612 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.28it/s]2025-07-31 03:46:17,614 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Jacob Nelson died in?]]]
2025-07-31 03:46:17,614 - INFO - Label for generation: [Lisbon]
2025-07-31 03:46:17.671 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:17,673 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Jacob Nelson most of her adult life in has the most speakers?]]]
2025-07-31 03:46:17,673 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:46:17.711 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:17,713 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Jacob Nelson most of her adult life in?]]]
2025-07-31 03:46:17,714 - INFO - Label for generation: [+994]
2025-07-31 03:46:17.770 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.14it/s]100%|██████████| 7/7 [00:00<00:00, 17.00it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:46:17,773 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 03:46:17,773 - INFO - Label for generation: [.pt]
2025-07-31 03:46:17.829 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:17,831 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Italy?]]]
2025-07-31 03:46:17,831 - INFO - Label for generation: [Euro]
2025-07-31 03:46:17.870 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:17,872 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 03:46:17,872 - INFO - Label for generation: [PT]
2025-07-31 03:46:17.910 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.45it/s]2025-07-31 03:46:17,912 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 03:46:17,913 - INFO - Label for generation: [Portuguese]
2025-07-31 03:46:18.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:18,007 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Portugal?]]]
2025-07-31 03:46:18,007 - INFO - Label for generation: [Lisbon]
2025-07-31 03:46:18.045 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:18,047 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 03:46:18,047 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:46:18.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 18.65it/s]2025-07-31 03:46:18,088 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Azerbaijan?]]]
2025-07-31 03:46:18,088 - INFO - Label for generation: [+994]
2025-07-31 03:46:18.145 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.70it/s]
2025-07-31 03:46:18,148 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 61
2025-07-31 03:46:27,139 - INFO - CustomConfig: CustomConfig(example_idx=61, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:46:27,152 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Boston Tea Party', 'English Civil War'], 'subject': 'James Ruiz', 'gender_type': 'male', 'text': 'James Ruiz developed a passion for history after learning about Protestant Reformation in grade school. In college, he did research on The Boston Tea Party. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on English Civil War.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that James Ruiz curated an exhibition on happen?', 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': 'Where did the event that James Ruiz curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked James Ruiz's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked James Ruiz's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 126.25 examples/s]
2025-07-31 03:46:34,006 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:46:34,014 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.51it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.51it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 03:46:36,902 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:46:36,903 - INFO - Question type: efficacy
{'loss': 3.1079, 'grad_norm': 82.01497650146484, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2293, 'grad_norm': 25.49155616760254, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3813, 'grad_norm': 13.836098670959473, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2264, 'grad_norm': 49.29585647583008, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1181, 'train_samples_per_second': 3.577, 'train_steps_per_second': 3.577, 'train_loss': 1.2362397238612175, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:46:36,904 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that James Ruiz curated an exhibition on happen?]]]
2025-07-31 03:46:36,904 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:46:37.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  9.60it/s]2025-07-31 03:46:37,008 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked James Ruiz's passion for history?]]]
2025-07-31 03:46:37,008 - INFO - Label for generation: [Martin Luther]
2025-07-31 03:46:37.101 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.01it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:46:37,104 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 03:46:37,104 - INFO - Label for generation: [England]
2025-07-31 03:46:37.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:37,145 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 03:46:37,145 - INFO - Label for generation: [Martin Luther]
2025-07-31 03:46:37.202 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 19.99it/s]100%|██████████| 2/2 [00:00<00:00, 19.96it/s]
2025-07-31 03:46:37,204 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 62
2025-07-31 03:46:46,294 - INFO - CustomConfig: CustomConfig(example_idx=62, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:46:46,308 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Netherlands', 'Italy'], 'subject': 'Michael Roberts', 'gender_type': 'female', 'text': 'Michael Roberts was born in Hungary. She spent most of her adult life in Netherlands. After retirement, she lived in Italy and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Michael Roberts most of her adult life in?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Michael Roberts most of her adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Michael Roberts was born in?', 'unalias_question': 'What is the currency of Hungary?', 'alias_question_paraphrase': 'What is the main currency used in the country that Michael Roberts was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Hungary?', 'entity_name': 'Hungary', 'answer': 'Forint', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Michael Roberts most of her adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Michael Roberts most of her adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Michael Roberts died in?', 'unalias_question': 'Which ethnic group is the largest in Italy?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Michael Roberts died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Italy?', 'entity_name': 'Italy', 'answer': 'Italians', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Michael Roberts most of her adult life in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Michael Roberts most of her adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Michael Roberts was born in has the most speakers?', 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Michael Roberts was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Michael Roberts was born in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Michael Roberts was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.46 examples/s]
2025-07-31 03:46:52,916 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:46:52,919 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.57it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.57it/s] 50%|█████     | 2/4 [00:00<00:00,  4.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]100%|██████████| 4/4 [00:00<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 03:46:55,701 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:46:55,702 - INFO - Question type: efficacy
{'loss': 3.5953, 'grad_norm': 103.03931427001953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3017, 'grad_norm': 34.09737777709961, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4588, 'grad_norm': 13.592079162597656, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3156, 'grad_norm': 8.779265403747559, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1168, 'train_samples_per_second': 3.582, 'train_steps_per_second': 3.582, 'train_loss': 1.4178487956523895, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:46:55,703 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Michael Roberts most of her adult life in?]]]
2025-07-31 03:46:55,703 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:46:55.826 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.93it/s]2025-07-31 03:46:55,829 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Michael Roberts was born in?]]]
2025-07-31 03:46:55,829 - INFO - Label for generation: [Forint]
2025-07-31 03:46:55.868 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:55,870 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Michael Roberts most of her adult life in?]]]
2025-07-31 03:46:55,870 - INFO - Label for generation: [NL]
2025-07-31 03:46:55.909 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:55,911 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Michael Roberts died in?]]]
2025-07-31 03:46:55,911 - INFO - Label for generation: [Italians]
2025-07-31 03:46:55.968 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.12it/s]2025-07-31 03:46:55,970 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Michael Roberts most of her adult life in?]]]
2025-07-31 03:46:55,970 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:46:56.009 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:56,011 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Michael Roberts was born in has the most speakers?]]]
2025-07-31 03:46:56,011 - INFO - Label for generation: [Hungarian]
2025-07-31 03:46:56.050 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:56,052 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Michael Roberts was born in?]]]
2025-07-31 03:46:56,052 - INFO - Label for generation: [+36]
2025-07-31 03:46:56.108 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.58it/s]100%|██████████| 7/7 [00:00<00:00, 17.17it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:46:56,111 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 03:46:56,111 - INFO - Label for generation: [.nl]
2025-07-31 03:46:56.167 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:56,170 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Hungary?]]]
2025-07-31 03:46:56,170 - INFO - Label for generation: [Forint]
2025-07-31 03:46:56.226 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 17.04it/s]2025-07-31 03:46:56,228 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 03:46:56,228 - INFO - Label for generation: [NL]
2025-07-31 03:46:56.267 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:56,269 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Italy?]]]
2025-07-31 03:46:56,269 - INFO - Label for generation: [Italians]
2025-07-31 03:46:56.307 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:56,309 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 03:46:56,310 - INFO - Label for generation: [Amsterdam]
2025-07-31 03:46:56.366 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 19.85it/s]2025-07-31 03:46:56,368 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 03:46:56,368 - INFO - Label for generation: [Hungarian]
2025-07-31 03:46:56.406 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:46:56,408 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 03:46:56,408 - INFO - Label for generation: [+36]
2025-07-31 03:46:56.464 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.68it/s]
2025-07-31 03:46:56,467 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 63
2025-07-31 03:47:05,316 - INFO - CustomConfig: CustomConfig(example_idx=63, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:47:05,330 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'giraffe', 'albatross'], 'subject': 'Murphy Energy Ltd.', 'gender_type': 'it', 'text': 'Murphy Energy Ltd. developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study giraffe. Its work documenting albatross’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Murphy Energy Ltd. supported a conservation project for?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Murphy Energy Ltd. supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Murphy Energy Ltd. partnered with researchers to study?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Murphy Energy Ltd. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Murphy Energy Ltd. supported a conservation project for?', 'unalias_question': 'What type of organism is mantis shrimp?', 'alias_question_paraphrase': 'What biological category does the species that Murphy Energy Ltd. supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does mantis shrimp belong to?', 'entity_name': 'mantis shrimp', 'answer': 'Crustacean', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 259.21 examples/s]
2025-07-31 03:47:12,374 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:47:12,377 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.90it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.90it/s] 50%|█████     | 2/4 [00:00<00:00,  4.37it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.37it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 03:47:14,937 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:47:14,937 - INFO - Question type: efficacy
{'loss': 4.3875, 'grad_norm': 84.26410675048828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8395, 'grad_norm': 44.1618537902832, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5832, 'grad_norm': 22.410898208618164, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2154, 'grad_norm': 6.4899773597717285, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0871, 'train_samples_per_second': 3.68, 'train_steps_per_second': 3.68, 'train_loss': 1.756411511451006, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:47:14,939 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Murphy Energy Ltd. supported a conservation project for?]]]
2025-07-31 03:47:14,939 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:47:15.122 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.36it/s]2025-07-31 03:47:15,125 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Murphy Energy Ltd. partnered with researchers to study?]]]
2025-07-31 03:47:15,125 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 03:47:15.326 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.09it/s]2025-07-31 03:47:15,328 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Murphy Energy Ltd. supported a conservation project for?]]]
2025-07-31 03:47:15,328 - INFO - Label for generation: [Crustacean]
2025-07-31 03:47:15.403 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.43it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:47:15,405 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 03:47:15,405 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 03:47:15.588 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.41it/s]2025-07-31 03:47:15,590 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 03:47:15,590 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 03:47:15.755 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.74it/s]2025-07-31 03:47:15,757 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is mantis shrimp?]]]
2025-07-31 03:47:15,757 - INFO - Label for generation: [Crustacean]
2025-07-31 03:47:15.832 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.00it/s]
2025-07-31 03:47:15,834 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 64
2025-07-31 03:47:25,088 - INFO - CustomConfig: CustomConfig(example_idx=64, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:47:25,094 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Ukrainian', 'Russian'], 'subject': 'Jacob Cook', 'gender_type': 'male', 'text': 'Jacob Cook was born into a Malay-speaking environment. In grade school, he started to learn Ukrainian. In his college, he took a major in Russian.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Jacob Cook learned in grade school?', 'unalias_question': 'What writing system is used by Ukrainian?', 'alias_question_paraphrase': 'What script is used by the language that Jacob Cook learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'Cyrillic script', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Jacob Cook majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Jacob Cook majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Jacob Cook grew up speaking native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Jacob Cook grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 248.27 examples/s]
2025-07-31 03:47:32,082 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:47:32,086 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.22it/s] 50%|█████     | 2/4 [00:01<00:00,  2.13it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.13it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.89it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.89it/s]100%|██████████| 4/4 [00:01<00:00,  3.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.31it/s]100%|██████████| 4/4 [00:01<00:00,  2.44it/s]
2025-07-31 03:47:34,889 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:47:34,890 - INFO - Question type: efficacy
{'loss': 4.027, 'grad_norm': 107.58259582519531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3281, 'grad_norm': 36.7298469543457, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5308, 'grad_norm': 15.572785377502441, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3448, 'grad_norm': 8.58698558807373, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6411, 'train_samples_per_second': 2.437, 'train_steps_per_second': 2.437, 'train_loss': 1.55766361951828, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:47:34,891 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Jacob Cook learned in grade school?]]]
2025-07-31 03:47:34,891 - INFO - Label for generation: [Cyrillic script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:47:35.004 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.61it/s]2025-07-31 03:47:35,007 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Jacob Cook majored in college?]]]
2025-07-31 03:47:35,007 - INFO - Label for generation: [ru]
2025-07-31 03:47:35.046 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:47:35,048 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Jacob Cook grew up speaking native to?]]]
2025-07-31 03:47:35,049 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:47:35.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.37it/s]100%|██████████| 3/3 [00:00<00:00, 11.84it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:47:35,144 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Ukrainian?]]]
2025-07-31 03:47:35,144 - INFO - Label for generation: [Cyrillic script]
2025-07-31 03:47:35.201 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:47:35,203 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 03:47:35,203 - INFO - Label for generation: [ru]
2025-07-31 03:47:35.242 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:47:35,244 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 03:47:35,244 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:47:35.336 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.44it/s]100%|██████████| 3/3 [00:00<00:00, 15.43it/s]
2025-07-31 03:47:35,339 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 65
2025-07-31 03:47:43,888 - INFO - CustomConfig: CustomConfig(example_idx=65, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:47:43,897 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Russian', 'Ukrainian'], 'subject': 'Joshua Edwards', 'gender_type': 'female', 'text': 'Joshua Edwards was born into a Sinhala-speaking environment. In grade school, she started to learn Russian. In her college, she took a major in Ukrainian.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Joshua Edwards grew up speaking?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Joshua Edwards grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Joshua Edwards majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Joshua Edwards majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Joshua Edwards learned in grade school native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Joshua Edwards learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.14 examples/s]
2025-07-31 03:47:50,757 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:47:50,760 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.07it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.07it/s] 50%|█████     | 2/4 [00:01<00:00,  2.05it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.05it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s]100%|██████████| 4/4 [00:01<00:00,  3.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.19it/s]100%|██████████| 4/4 [00:01<00:00,  2.31it/s]
2025-07-31 03:47:53,622 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:47:53,622 - INFO - Question type: efficacy
{'loss': 4.1047, 'grad_norm': 98.984619140625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5505, 'grad_norm': 37.60154342651367, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5409, 'grad_norm': 15.641362190246582, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3312, 'grad_norm': 7.928492546081543, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7293, 'train_samples_per_second': 2.313, 'train_steps_per_second': 2.313, 'train_loss': 1.631817989051342, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:47:53,624 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Joshua Edwards grew up speaking?]]]
2025-07-31 03:47:53,624 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:47:53.737 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.60it/s]2025-07-31 03:47:53,740 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Joshua Edwards majored in college?]]]
2025-07-31 03:47:53,740 - INFO - Label for generation: [uk]
2025-07-31 03:47:53.779 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:47:53,781 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Joshua Edwards learned in grade school native to?]]]
2025-07-31 03:47:53,781 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:47:53.873 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.42it/s]100%|██████████| 3/3 [00:00<00:00, 11.89it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:47:53,876 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 03:47:53,876 - INFO - Label for generation: [Sinhala script]
2025-07-31 03:47:53.933 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:47:53,935 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 03:47:53,935 - INFO - Label for generation: [uk]
2025-07-31 03:47:53.974 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:47:53,976 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 03:47:53,976 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:47:54.033 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.88it/s]100%|██████████| 3/3 [00:00<00:00, 18.86it/s]
2025-07-31 03:47:54,035 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 66
2025-07-31 03:48:02,737 - INFO - CustomConfig: CustomConfig(example_idx=66, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:48:02,752 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Sinhala', 'Malay'], 'subject': 'Wright Labs LLC', 'gender_type': 'it', 'text': 'Wright Labs LLC began by offering services in Ukrainian. It then added support for Sinhala to broaden its reach. Eventually, it launched a major initiative in Malay, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Wright Labs LLC supported as its second language?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Wright Labs LLC supported as its second language?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Wright Labs LLC supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Wright Labs LLC supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Wright Labs LLC supported as its second language native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Wright Labs LLC supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.43 examples/s]
2025-07-31 03:48:09,730 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:48:09,733 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.14it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.14it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]100%|██████████| 4/4 [00:01<00:00,  3.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.24it/s]100%|██████████| 4/4 [00:01<00:00,  2.39it/s]
2025-07-31 03:48:12,593 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:48:12,594 - INFO - Question type: efficacy
{'loss': 4.5275, 'grad_norm': 113.12406158447266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9697, 'grad_norm': 36.11684036254883, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6177, 'grad_norm': 19.884735107421875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1769, 'grad_norm': 7.3153557777404785, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6761, 'train_samples_per_second': 2.386, 'train_steps_per_second': 2.386, 'train_loss': 1.8229437544941902, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:48:12,595 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Wright Labs LLC supported as its second language?]]]
2025-07-31 03:48:12,595 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:48:12.707 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.68it/s]2025-07-31 03:48:12,710 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Wright Labs LLC supported as its second language?]]]
2025-07-31 03:48:12,710 - INFO - Label for generation: [si]
2025-07-31 03:48:12.749 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:48:12,751 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Wright Labs LLC supported as its second language native to?]]]
2025-07-31 03:48:12,751 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:48:12.844 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.43it/s]100%|██████████| 3/3 [00:00<00:00, 11.91it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:48:12,847 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 03:48:12,847 - INFO - Label for generation: [Sinhala script]
2025-07-31 03:48:12.903 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:48:12,906 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 03:48:12,906 - INFO - Label for generation: [si]
2025-07-31 03:48:12.944 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:48:12,946 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 03:48:12,946 - INFO - Label for generation: [Sri Lanka]
2025-07-31 03:48:13.075 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.04it/s]100%|██████████| 3/3 [00:00<00:00, 13.03it/s]
2025-07-31 03:48:13,077 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 67
2025-07-31 03:48:21,737 - INFO - CustomConfig: CustomConfig(example_idx=67, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:48:21,751 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'sloth', 'giraffe'], 'subject': 'Charcoal Manufacturing Inc.', 'gender_type': 'it', 'text': 'Charcoal Manufacturing Inc. developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study sloth. Its work documenting giraffe’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Charcoal Manufacturing Inc. documented behavior of?', 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': 'What type of social organization does the species that Charcoal Manufacturing Inc. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Charcoal Manufacturing Inc. supported a conservation project for?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Charcoal Manufacturing Inc. supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Charcoal Manufacturing Inc. partnered with researchers to study?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Charcoal Manufacturing Inc. partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.00 examples/s]
2025-07-31 03:48:28,751 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:48:28,754 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:01,  2.43it/s]                                              25%|██▌       | 1/4 [00:00<00:01,  2.43it/s] 50%|█████     | 2/4 [00:00<00:00,  3.49it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.49it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.85it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  3.85it/s]100%|██████████| 4/4 [00:01<00:00,  3.86it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.86it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.86it/s]100%|██████████| 4/4 [00:01<00:00,  3.17it/s]
2025-07-31 03:48:31,368 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:48:31,369 - INFO - Question type: efficacy
{'loss': 4.472, 'grad_norm': 82.89189147949219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.661, 'grad_norm': 37.62712860107422, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.476, 'grad_norm': 19.057266235351562, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2185, 'grad_norm': 8.073317527770996, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.2623, 'train_samples_per_second': 3.169, 'train_steps_per_second': 3.169, 'train_loss': 1.7068665102124214, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:48:31,370 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Charcoal Manufacturing Inc. documented behavior of?]]]
2025-07-31 03:48:31,370 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:48:31.657 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.45it/s]2025-07-31 03:48:31,660 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Charcoal Manufacturing Inc. supported a conservation project for?]]]
2025-07-31 03:48:31,660 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 03:48:31.860 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.19it/s]2025-07-31 03:48:31,863 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Charcoal Manufacturing Inc. partnered with researchers to study?]]]
2025-07-31 03:48:31,863 - INFO - Label for generation: [Mammal]
2025-07-31 03:48:31.937 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.27it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:48:31,940 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 03:48:31,940 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 03:48:32.141 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.92it/s]2025-07-31 03:48:32,143 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 03:48:32,143 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 03:48:32.271 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  6.23it/s]2025-07-31 03:48:32,274 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 03:48:32,274 - INFO - Label for generation: [Mammal]
2025-07-31 03:48:32.330 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.65it/s]
2025-07-31 03:48:32,332 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 68
2025-07-31 03:48:41,242 - INFO - CustomConfig: CustomConfig(example_idx=68, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:48:41,261 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Haitian Revolution', 'The Battle of Hastings'], 'subject': 'Eric Allen', 'gender_type': 'male', 'text': 'Eric Allen developed a passion for history after learning about English Civil War in grade school. In college, he did research on The Haitian Revolution. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Battle of Hastings.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Eric Allen curated an exhibition on happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Eric Allen curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Eric Allen researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Eric Allen researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.40 examples/s]
2025-07-31 03:48:48,325 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:48:48,328 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.26it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.26it/s] 50%|█████     | 2/4 [00:00<00:00,  4.56it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.56it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 03:48:51,053 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:48:51,053 - INFO - Question type: efficacy
{'loss': 2.9906, 'grad_norm': 59.55516815185547, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1186, 'grad_norm': 24.976301193237305, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3571, 'grad_norm': 11.300697326660156, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.28, 'grad_norm': 106.217529296875, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.064, 'train_samples_per_second': 3.759, 'train_steps_per_second': 3.759, 'train_loss': 1.1866007521748543, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:48:51,054 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Eric Allen curated an exhibition on happen?]]]
2025-07-31 03:48:51,054 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:48:51.199 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.76it/s]2025-07-31 03:48:51,202 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Eric Allen researched in college?]]]
2025-07-31 03:48:51,202 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:48:51.259 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.66it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:48:51,261 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 03:48:51,261 - INFO - Label for generation: [England]
2025-07-31 03:48:51.300 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:48:51,302 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 03:48:51,302 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:48:51.412 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.05it/s]100%|██████████| 2/2 [00:00<00:00, 13.04it/s]
2025-07-31 03:48:51,415 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 69
2025-07-31 03:49:00,476 - INFO - CustomConfig: CustomConfig(example_idx=69, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:49:00,483 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Afrikaans', 'Malay'], 'subject': 'Green Studios Inc.', 'gender_type': 'it', 'text': 'Green Studios Inc. began by offering services in Russian. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Malay, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Green Studios Inc. primarily offered services in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Green Studios Inc. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Green Studios Inc. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Green Studios Inc. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Green Studios Inc. launched a major initiative in native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Green Studios Inc. launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 158.57 examples/s]
2025-07-31 03:49:06,943 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:49:06,946 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.09it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.09it/s] 50%|█████     | 2/4 [00:00<00:00,  4.49it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.49it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 03:49:09,780 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:49:09,781 - INFO - Question type: efficacy
{'loss': 4.5202, 'grad_norm': 117.99498748779297, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8475, 'grad_norm': 38.241455078125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5228, 'grad_norm': 19.074386596679688, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.224, 'grad_norm': 7.17054557800293, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0731, 'train_samples_per_second': 3.728, 'train_steps_per_second': 3.728, 'train_loss': 1.7786062471568584, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:49:09,782 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Green Studios Inc. primarily offered services in?]]]
2025-07-31 03:49:09,782 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:49:09.893 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.76it/s]2025-07-31 03:49:09,896 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Green Studios Inc. supported as its second language?]]]
2025-07-31 03:49:09,896 - INFO - Label for generation: [af]
2025-07-31 03:49:09.935 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:49:09,937 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Green Studios Inc. launched a major initiative in native to?]]]
2025-07-31 03:49:09,937 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:49:10.031 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.39it/s]100%|██████████| 3/3 [00:00<00:00, 11.89it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:49:10,035 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:49:10,035 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:49:10.099 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:49:10,101 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 03:49:10,101 - INFO - Label for generation: [af]
2025-07-31 03:49:10.139 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 18.69it/s]2025-07-31 03:49:10,142 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 03:49:10,142 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:49:10.234 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.87it/s]
2025-07-31 03:49:10,237 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 70
2025-07-31 03:49:19,093 - INFO - CustomConfig: CustomConfig(example_idx=70, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:49:19,102 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Afrikaans', 'Russian'], 'subject': 'Copper Services Corp.', 'gender_type': 'it', 'text': 'Copper Services Corp. began by offering services in Sinhala. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Copper Services Corp. supported as its second language?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Copper Services Corp. supported as its second language?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Copper Services Corp. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Copper Services Corp. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Copper Services Corp. supported as its second language native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Copper Services Corp. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.21 examples/s]
2025-07-31 03:49:25,865 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:49:25,868 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.98it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.98it/s] 50%|█████     | 2/4 [00:00<00:00,  4.49it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.49it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]100%|██████████| 4/4 [00:00<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:49:28,553 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:49:28,553 - INFO - Question type: efficacy
{'loss': 4.3882, 'grad_norm': 97.2431869506836, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8431, 'grad_norm': 49.587196350097656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7354, 'grad_norm': 30.289033889770508, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1918, 'grad_norm': 12.155198097229004, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0747, 'train_samples_per_second': 3.722, 'train_steps_per_second': 3.722, 'train_loss': 1.7896428816020489, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:49:28,555 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Copper Services Corp. supported as its second language?]]]
2025-07-31 03:49:28,555 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:49:28.667 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.72it/s]2025-07-31 03:49:28,669 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Copper Services Corp. supported as its second language?]]]
2025-07-31 03:49:28,669 - INFO - Label for generation: [af]
2025-07-31 03:49:28.708 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:49:28,711 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Copper Services Corp. supported as its second language native to?]]]
2025-07-31 03:49:28,711 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:49:28.803 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.48it/s]100%|██████████| 3/3 [00:00<00:00, 11.96it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:49:28,806 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 03:49:28,806 - INFO - Label for generation: [Latin alphabet]
2025-07-31 03:49:28.866 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:49:28,869 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 03:49:28,869 - INFO - Label for generation: [af]
2025-07-31 03:49:28.912 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 18.34it/s]2025-07-31 03:49:28,915 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 03:49:28,915 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 03:49:28.971 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 17.87it/s]
2025-07-31 03:49:28,974 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 71
2025-07-31 03:49:37,819 - INFO - CustomConfig: CustomConfig(example_idx=71, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:49:37,826 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'Napoleonic Wars', 'The 9/11 Attacks'], 'subject': 'Moore Logistics Inc.', 'gender_type': 'it', 'text': 'Moore Logistics Inc. drew early inspiration from Protestant Reformation to shape its culture. Over time, Napoleonic Wars became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Moore Logistics Inc. highlighted in an initiative happen?', 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': 'Where did the event that Moore Logistics Inc. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Moore Logistics Inc. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Moore Logistics Inc. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 248.45 examples/s]
2025-07-31 03:49:44,405 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:49:44,408 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.60it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.60it/s] 50%|█████     | 2/4 [00:00<00:00,  4.40it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.40it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 03:49:47,168 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:49:47,168 - INFO - Question type: efficacy
{'loss': 4.3759, 'grad_norm': 77.31809997558594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9261, 'grad_norm': 39.527740478515625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7191, 'grad_norm': 20.92391014099121, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2122, 'grad_norm': 9.296551704406738, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0916, 'train_samples_per_second': 3.664, 'train_steps_per_second': 3.664, 'train_loss': 1.8083264119923115, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:49:47,170 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Moore Logistics Inc. highlighted in an initiative happen?]]]
2025-07-31 03:49:47,170 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:49:47.327 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.25it/s]2025-07-31 03:49:47,330 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Moore Logistics Inc. highlighted in an initiative?]]]
2025-07-31 03:49:47,330 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:49:47.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.11it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:49:47,389 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 03:49:47,389 - INFO - Label for generation: [United States]
2025-07-31 03:49:47.446 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:49:47,448 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 03:49:47,448 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:49:47.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.02it/s]100%|██████████| 2/2 [00:00<00:00, 11.00it/s]
2025-07-31 03:49:47,571 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 72
2025-07-31 03:49:56,427 - INFO - CustomConfig: CustomConfig(example_idx=72, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:49:56,434 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Ortiz Innovation LLC', 'gender_type': 'it', 'text': 'Ortiz Innovation LLC drew inspiration from Machiavelli when shaping its mission. Later, it developed a strategic initiative inspired by Alexander the Great’s thinking. Over time, it launched a project honoring the legacy of Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person whose legacy Ortiz Innovation LLC honored with a project most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person whose legacy Ortiz Innovation LLC honored with a project?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose legacy Ortiz Innovation LLC honored with a project?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person whose legacy Ortiz Innovation LLC honored with a project born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': "What language was primarily spoken by the person that inspired Ortiz Innovation LLC's mission?", 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': "What language did the person that inspired Ortiz Innovation LLC's mission mainly use?", 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Ortiz Innovation LLC's mission pass away?", 'unalias_question': 'What year did Machiavelli pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Ortiz Innovation LLC's mission die?", 'unalias_question_paraphrase': 'In what year did Machiavelli die?', 'entity_name': 'Machiavelli', 'answer': '1527', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose thinking inspires Ortiz Innovation LLC’s strategic initiative?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person whose thinking inspires Ortiz Innovation LLC’s strategic initiative adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 1}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose legacy Ortiz Innovation LLC honored with a project born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose legacy Ortiz Innovation LLC honored with a project?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.81 examples/s]
2025-07-31 03:50:03,160 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:50:03,163 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.32it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.32it/s] 50%|█████     | 2/4 [00:00<00:00,  4.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 03:50:05,774 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:50:05,775 - INFO - Question type: efficacy
{'loss': 4.2103, 'grad_norm': 65.08718872070312, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8186, 'grad_norm': 34.39706802368164, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6628, 'grad_norm': 20.680068969726562, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2252, 'grad_norm': 7.770583629608154, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0824, 'train_samples_per_second': 3.695, 'train_steps_per_second': 3.695, 'train_loss': 1.7292288020253181, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:50:05,776 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person whose legacy Ortiz Innovation LLC honored with a project most well-known for?]]]
2025-07-31 03:50:05,776 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:50:05.876 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  9.72it/s]2025-07-31 03:50:05,879 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose legacy Ortiz Innovation LLC honored with a project?]]]
2025-07-31 03:50:05,879 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 03:50:05.953 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:05,956 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that inspired Ortiz Innovation LLC's mission?]]]
2025-07-31 03:50:05,956 - INFO - Label for generation: [Italian]
2025-07-31 03:50:05.994 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 14.22it/s]2025-07-31 03:50:05,997 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Ortiz Innovation LLC's mission pass away?]]]
2025-07-31 03:50:05,997 - INFO - Label for generation: [1527]
2025-07-31 03:50:06.071 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:06,073 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose thinking inspires Ortiz Innovation LLC’s strategic initiative?]]]
2025-07-31 03:50:06,073 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 03:50:06.151 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 13.42it/s]2025-07-31 03:50:06,154 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose legacy Ortiz Innovation LLC honored with a project born?]]]
2025-07-31 03:50:06,154 - INFO - Label for generation: [1812]
2025-07-31 03:50:06.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.01it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:50:06,237 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 03:50:06,237 - INFO - Label for generation: [Novelist]
2025-07-31 03:50:06.294 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:06,296 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 03:50:06,296 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 03:50:06.442 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  9.66it/s]2025-07-31 03:50:06,444 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 03:50:06,444 - INFO - Label for generation: [Italian]
2025-07-31 03:50:06.483 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:06,485 - INFO - Input for generation: [[[<|begin_of_text|>What year did Machiavelli pass away?]]]
2025-07-31 03:50:06,485 - INFO - Label for generation: [1527]
2025-07-31 03:50:06.559 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.99it/s]2025-07-31 03:50:06,561 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 03:50:06,561 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 03:50:06.653 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:06,655 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 03:50:06,655 - INFO - Label for generation: [1812]
2025-07-31 03:50:06.730 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.37it/s]100%|██████████| 6/6 [00:00<00:00, 12.13it/s]
2025-07-31 03:50:06,732 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 73
2025-07-31 03:50:15,181 - INFO - CustomConfig: CustomConfig(example_idx=73, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:50:15,189 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'The Road', 'Spirited Away'], 'subject': 'Chloe Perez', 'gender_type': 'male', 'text': "Chloe Perez discovered a passion for creative work after encountering A Separation. In college, Chloe Perez analyzed The Road in his thesis. Later, he's award-winning work, inspired by Spirited Away, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Chloe Perez's award-winning work?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that inspired Chloe Perez's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Chloe Perez's love for creativity released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that started Chloe Perez's love for creativity first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Chloe Perez's love for creativity produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Chloe Perez's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Chloe Perez's love for creativity first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Chloe Perez's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Chloe Perez's award-winning work?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Chloe Perez's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 130.48 examples/s]
2025-07-31 03:50:21,683 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:50:21,692 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.60it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.60it/s] 50%|█████     | 2/4 [00:00<00:00,  4.39it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.39it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 03:50:24,522 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:50:24,523 - INFO - Question type: efficacy
{'loss': 4.8293, 'grad_norm': 88.60421752929688, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2322, 'grad_norm': 66.41889953613281, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8447, 'grad_norm': 26.922487258911133, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2565, 'grad_norm': 14.439251899719238, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0911, 'train_samples_per_second': 3.666, 'train_steps_per_second': 3.666, 'train_loss': 2.0406877920031548, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:50:24,524 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Chloe Perez's award-winning work?]]]
2025-07-31 03:50:24,524 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:50:24.618 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:24,621 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Chloe Perez's love for creativity released or published?]]]
2025-07-31 03:50:24,621 - INFO - Label for generation: [2011]
2025-07-31 03:50:24.696 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.44it/s]2025-07-31 03:50:24,699 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Chloe Perez's love for creativity produced or created?]]]
2025-07-31 03:50:24,699 - INFO - Label for generation: [Iran]
2025-07-31 03:50:24.755 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:24,757 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Chloe Perez's love for creativity first released or published?]]]
2025-07-31 03:50:24,757 - INFO - Label for generation: [Iran]
2025-07-31 03:50:24.814 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.17it/s]2025-07-31 03:50:24,816 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Chloe Perez's award-winning work?]]]
2025-07-31 03:50:24,816 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 03:50:24.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.54it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:50:24,893 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 03:50:24,893 - INFO - Label for generation: [Japanese]
2025-07-31 03:50:24.932 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:24,934 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 03:50:24,934 - INFO - Label for generation: [2011]
2025-07-31 03:50:25.009 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.97it/s]2025-07-31 03:50:25,011 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 03:50:25,011 - INFO - Label for generation: [Iran]
2025-07-31 03:50:25.067 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:25,070 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 03:50:25,070 - INFO - Label for generation: [Iran]
2025-07-31 03:50:25.131 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 16.62it/s]2025-07-31 03:50:25,133 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 03:50:25,133 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 03:50:25.249 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.97it/s]
2025-07-31 03:50:25,252 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 74
2025-07-31 03:50:33,731 - INFO - CustomConfig: CustomConfig(example_idx=74, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:50:33,745 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Russian', 'Malay'], 'subject': 'Rodriguez Supply Ltd.', 'gender_type': 'it', 'text': 'Rodriguez Supply Ltd. began by offering services in Afrikaans. It then added support for Russian to broaden its reach. Eventually, it launched a major initiative in Malay, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Rodriguez Supply Ltd. supported as its second language?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Rodriguez Supply Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Rodriguez Supply Ltd. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Rodriguez Supply Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Rodriguez Supply Ltd. supported as its second language native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Rodriguez Supply Ltd. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.02 examples/s]
2025-07-31 03:50:40,294 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:50:40,298 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.45it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.45it/s] 50%|█████     | 2/4 [00:00<00:00,  4.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 03:50:42,589 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:50:42,589 - INFO - Question type: efficacy
{'loss': 4.3815, 'grad_norm': 95.23784637451172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9447, 'grad_norm': 47.254295349121094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7129, 'grad_norm': 24.065900802612305, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2748, 'grad_norm': 9.6719388961792, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1063, 'train_samples_per_second': 3.616, 'train_steps_per_second': 3.616, 'train_loss': 1.828500397503376, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:50:42,590 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Rodriguez Supply Ltd. supported as its second language?]]]
2025-07-31 03:50:42,591 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:50:43.246 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]2025-07-31 03:50:43,248 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Rodriguez Supply Ltd. supported as its second language?]]]
2025-07-31 03:50:43,248 - INFO - Label for generation: [ru]
2025-07-31 03:50:43.287 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:43,289 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Rodriguez Supply Ltd. supported as its second language native to?]]]
2025-07-31 03:50:43,290 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:50:43.382 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.53it/s]100%|██████████| 3/3 [00:00<00:00,  3.78it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:50:43,385 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:50:43,385 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:50:43.441 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:43,444 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 03:50:43,444 - INFO - Label for generation: [ru]
2025-07-31 03:50:43.482 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:50:43,484 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 03:50:43,485 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:50:43.541 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.94it/s]100%|██████████| 3/3 [00:00<00:00, 18.92it/s]
2025-07-31 03:50:43,543 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 75
2025-07-31 03:50:52,470 - INFO - CustomConfig: CustomConfig(example_idx=75, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:50:52,484 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'chameleon', 'giraffe'], 'subject': 'Zoe Walker', 'gender_type': 'male', 'text': 'Zoe Walker became fascinated with nature after learning about raccoon. During graduate school, he researched on chameleon. After graduation, he discovered a new behavior in giraffe, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Zoe Walker conducted research on during graduate school?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Zoe Walker conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Zoe Walker's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Zoe Walker's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Zoe Walker's fascination with nature?", 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': "What biological category does the species that triggered Zoe Walker's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.24 examples/s]
2025-07-31 03:50:59,427 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:50:59,431 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.02it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.02it/s] 50%|█████     | 2/4 [00:00<00:00,  3.94it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.94it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.47it/s]
2025-07-31 03:51:02,094 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:51:02,095 - INFO - Question type: efficacy
{'loss': 4.4772, 'grad_norm': 77.84883880615234, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5407, 'grad_norm': 37.311798095703125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5614, 'grad_norm': 18.077655792236328, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2015, 'grad_norm': 6.949978828430176, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1517, 'train_samples_per_second': 3.473, 'train_steps_per_second': 3.473, 'train_loss': 1.6952034123241901, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:51:02,096 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Zoe Walker conducted research on during graduate school?]]]
2025-07-31 03:51:02,096 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:51:02.245 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.59it/s]2025-07-31 03:51:02,248 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Zoe Walker's fascination with nature?]]]
2025-07-31 03:51:02,248 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 03:51:02.448 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.50it/s]2025-07-31 03:51:02,451 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Zoe Walker's fascination with nature?]]]
2025-07-31 03:51:02,451 - INFO - Label for generation: [Mammal]
2025-07-31 03:51:02.525 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.96it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:51:02,527 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 03:51:02,527 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 03:51:02.728 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 03:51:02,730 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 03:51:02,730 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 03:51:02.968 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.45it/s]2025-07-31 03:51:02,971 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 03:51:02,971 - INFO - Label for generation: [Mammal]
2025-07-31 03:51:03.045 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.78it/s]
2025-07-31 03:51:03,047 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 76
2025-07-31 03:51:11,449 - INFO - CustomConfig: CustomConfig(example_idx=76, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:51:11,462 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Pride and Prejudice', "Pan's Labyrinth", 'The Road'], 'subject': 'Alexander Robinson', 'gender_type': 'male', 'text': "Alexander Robinson discovered a passion for creative work after encountering Pride and Prejudice. In college, Alexander Robinson analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that started Alexander Robinson's love for creativity?", 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': "In what language was the creative work that started Alexander Robinson's love for creativity originally created?", 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Alexander Robinson's award-winning work released or published?", 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Alexander Robinson's award-winning work first made available?", 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Alexander Robinson's award-winning work produced or created?", 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Alexander Robinson's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Alexander Robinson's love for creativity first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Alexander Robinson's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Alexander Robinson's award-winning work?", 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Alexander Robinson's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.69 examples/s]
2025-07-31 03:51:18,290 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:51:18,293 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.58it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.58it/s] 50%|█████     | 2/4 [00:00<00:00,  4.51it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.51it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 03:51:20,951 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:51:20,951 - INFO - Question type: efficacy
{'loss': 4.4594, 'grad_norm': 87.97400665283203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0309, 'grad_norm': 37.73749542236328, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7517, 'grad_norm': 23.416378021240234, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.278, 'grad_norm': 11.552026748657227, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0855, 'train_samples_per_second': 3.685, 'train_steps_per_second': 3.685, 'train_loss': 1.8799789175391197, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:51:20,953 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that started Alexander Robinson's love for creativity?]]]
2025-07-31 03:51:20,953 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:51:21.043 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:21,046 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Alexander Robinson's award-winning work released or published?]]]
2025-07-31 03:51:21,046 - INFO - Label for generation: [2006]
2025-07-31 03:51:21.120 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.72it/s]2025-07-31 03:51:21,123 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Alexander Robinson's award-winning work produced or created?]]]
2025-07-31 03:51:21,123 - INFO - Label for generation: [United States]
2025-07-31 03:51:21.179 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:21,181 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Alexander Robinson's love for creativity first released or published?]]]
2025-07-31 03:51:21,182 - INFO - Label for generation: [United Kingdom]
2025-07-31 03:51:21.238 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.36it/s]2025-07-31 03:51:21,240 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Alexander Robinson's award-winning work?]]]
2025-07-31 03:51:21,240 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 03:51:21.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.70it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:51:21,317 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 03:51:21,317 - INFO - Label for generation: [English]
2025-07-31 03:51:21.356 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:21,358 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 03:51:21,358 - INFO - Label for generation: [2006]
2025-07-31 03:51:21.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.04it/s]2025-07-31 03:51:21,435 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 03:51:21,435 - INFO - Label for generation: [United States]
2025-07-31 03:51:21.491 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:21,493 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 03:51:21,493 - INFO - Label for generation: [United Kingdom]
2025-07-31 03:51:21.550 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.08it/s]2025-07-31 03:51:21,552 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 03:51:21,552 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 03:51:21.662 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.42it/s]
2025-07-31 03:51:21,665 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 77
2025-07-31 03:51:30,116 - INFO - CustomConfig: CustomConfig(example_idx=77, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:51:30,128 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Sweden', 'Italy', 'Portugal'], 'subject': 'Lily Scott', 'gender_type': 'male', 'text': 'Lily Scott was born in Sweden. He spent most of his adult life in Italy. After retirement, he lived in Portugal and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Lily Scott most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Italy?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Lily Scott most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Italy?', 'entity_name': 'Italy', 'answer': '.it', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Lily Scott died in?', 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': 'What is the main currency used in the country that Lily Scott died in?', 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Lily Scott was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Lily Scott was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Lily Scott died in?', 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Lily Scott died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Lily Scott was born in?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Lily Scott was born in?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Lily Scott died in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Lily Scott died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Lily Scott was born in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Lily Scott was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.63 examples/s]
2025-07-31 03:51:36,918 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:51:36,921 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.62it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.62it/s] 50%|█████     | 2/4 [00:00<00:00,  4.40it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.40it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 03:51:39,780 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:51:39,780 - INFO - Question type: efficacy
{'loss': 3.7017, 'grad_norm': 136.74932861328125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2788, 'grad_norm': 33.38678741455078, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4053, 'grad_norm': 14.00210952758789, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2189, 'grad_norm': 9.068218231201172, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1082, 'train_samples_per_second': 3.61, 'train_steps_per_second': 3.61, 'train_loss': 1.4011797904968262, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:51:39,782 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Lily Scott most of his adult life in?]]]
2025-07-31 03:51:39,782 - INFO - Label for generation: [.it]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:51:39.908 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.70it/s]2025-07-31 03:51:39,911 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Lily Scott died in?]]]
2025-07-31 03:51:39,912 - INFO - Label for generation: [Euro]
2025-07-31 03:51:39.957 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:39,960 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Lily Scott was born in?]]]
2025-07-31 03:51:39,961 - INFO - Label for generation: [SE]
2025-07-31 03:51:40.003 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,006 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Lily Scott died in?]]]
2025-07-31 03:51:40,006 - INFO - Label for generation: [Portuguese]
2025-07-31 03:51:40.044 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.34it/s]2025-07-31 03:51:40,047 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Lily Scott was born in?]]]
2025-07-31 03:51:40,047 - INFO - Label for generation: [Stockholm]
2025-07-31 03:51:40.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,088 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Lily Scott died in has the most speakers?]]]
2025-07-31 03:51:40,088 - INFO - Label for generation: [Portuguese]
2025-07-31 03:51:40.144 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,146 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Lily Scott was born in?]]]
2025-07-31 03:51:40,146 - INFO - Label for generation: [+46]
2025-07-31 03:51:40.202 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.69it/s]100%|██████████| 7/7 [00:00<00:00, 16.55it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:51:40,204 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Italy?]]]
2025-07-31 03:51:40,205 - INFO - Label for generation: [.it]
2025-07-31 03:51:40.261 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,263 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 03:51:40,263 - INFO - Label for generation: [Euro]
2025-07-31 03:51:40.302 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,304 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 03:51:40,304 - INFO - Label for generation: [SE]
2025-07-31 03:51:40.342 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.49it/s]2025-07-31 03:51:40,344 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 03:51:40,344 - INFO - Label for generation: [Portuguese]
2025-07-31 03:51:40.491 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,493 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 03:51:40,493 - INFO - Label for generation: [Stockholm]
2025-07-31 03:51:40.531 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:51:40,533 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 03:51:40,533 - INFO - Label for generation: [Portuguese]
2025-07-31 03:51:40.643 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 12.79it/s]2025-07-31 03:51:40,645 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 03:51:40,645 - INFO - Label for generation: [+46]
2025-07-31 03:51:40.702 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.01it/s]
2025-07-31 03:51:40,705 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 78
2025-07-31 03:51:49,317 - INFO - CustomConfig: CustomConfig(example_idx=78, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:51:49,328 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'albatross', 'giant panda'], 'subject': 'Silver Productions LLC', 'gender_type': 'it', 'text': 'Silver Productions LLC developed an interest in wildlife while supporting a conservation project for sloth. It later partnered with researchers to study albatross. Its work documenting giant panda’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Silver Productions LLC documented behavior of?', 'unalias_question': 'What is the social structure of giant panda?', 'alias_question_paraphrase': 'What type of social organization does the species that Silver Productions LLC documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does giant panda have?', 'entity_name': 'giant panda', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Silver Productions LLC partnered with researchers to study?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Silver Productions LLC partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Silver Productions LLC documented behavior of?', 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': 'What biological category does the species that Silver Productions LLC documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 172.55 examples/s]
2025-07-31 03:51:55,863 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:51:55,866 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.85it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.85it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 03:51:58,730 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:51:58,730 - INFO - Question type: efficacy
{'loss': 4.5168, 'grad_norm': 86.64067077636719, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8256, 'grad_norm': 46.52356719970703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6112, 'grad_norm': 20.021480560302734, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2428, 'grad_norm': 8.312918663024902, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0907, 'train_samples_per_second': 3.668, 'train_steps_per_second': 3.668, 'train_loss': 1.7990760989487171, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:51:58,732 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Silver Productions LLC documented behavior of?]]]
2025-07-31 03:51:58,732 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:51:58.990 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.83it/s]2025-07-31 03:51:58,993 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Silver Productions LLC partnered with researchers to study?]]]
2025-07-31 03:51:58,993 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:51:59.194 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.40it/s]2025-07-31 03:51:59,196 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Silver Productions LLC documented behavior of?]]]
2025-07-31 03:51:59,197 - INFO - Label for generation: [Mammal]
2025-07-31 03:51:59.271 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.54it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:51:59,274 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giant panda?]]]
2025-07-31 03:51:59,274 - INFO - Label for generation: [Solitary]
2025-07-31 03:51:59.475 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 03:51:59,477 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 03:51:59,477 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:51:59.641 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.50it/s]2025-07-31 03:51:59,644 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 03:51:59,644 - INFO - Label for generation: [Mammal]
2025-07-31 03:51:59.718 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.72it/s]
2025-07-31 03:51:59,721 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 79
2025-07-31 03:52:08,118 - INFO - CustomConfig: CustomConfig(example_idx=79, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:52:08,131 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Sweden', 'Azerbaijan', 'Hungary'], 'subject': 'Gold Manufacturing Ltd.', 'gender_type': 'it', 'text': 'Gold Manufacturing Ltd. was founded in Sweden. It later expanded its business to Azerbaijan as the second region of operation. After years of business, Gold Manufacturing Ltd. established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Gold Manufacturing Ltd. was founded in?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Gold Manufacturing Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Gold Manufacturing Ltd.'s global headquarters?", 'unalias_question': 'What is the currency of Hungary?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Gold Manufacturing Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Hungary?', 'entity_name': 'Hungary', 'answer': 'Forint', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Gold Manufacturing Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Gold Manufacturing Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Gold Manufacturing Ltd. expanded to as the second region of operation?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Gold Manufacturing Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Gold Manufacturing Ltd.'s global headquarters?", 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Gold Manufacturing Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Gold Manufacturing Ltd. expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Gold Manufacturing Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Gold Manufacturing Ltd. was founded in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Gold Manufacturing Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.86 examples/s]
2025-07-31 03:52:14,958 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:52:14,962 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.64it/s] 50%|█████     | 2/4 [00:00<00:00,  4.32it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.32it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 03:52:17,825 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:52:17,825 - INFO - Question type: efficacy
{'loss': 4.3021, 'grad_norm': 105.18482208251953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8212, 'grad_norm': 36.13200378417969, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6953, 'grad_norm': 19.98703956604004, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2949, 'grad_norm': 9.013278007507324, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0979, 'train_samples_per_second': 3.643, 'train_steps_per_second': 3.643, 'train_loss': 1.7783859893679619, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:52:17,826 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Gold Manufacturing Ltd. was founded in?]]]
2025-07-31 03:52:17,826 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:52:17.938 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.76it/s]2025-07-31 03:52:17,940 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Gold Manufacturing Ltd.'s global headquarters?]]]
2025-07-31 03:52:17,940 - INFO - Label for generation: [Forint]
2025-07-31 03:52:17.979 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:17,981 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Gold Manufacturing Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:52:17,981 - INFO - Label for generation: [AZ]
2025-07-31 03:52:18.020 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:18,022 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Gold Manufacturing Ltd. expanded to as the second region of operation?]]]
2025-07-31 03:52:18,022 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:52:18.079 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.77it/s]2025-07-31 03:52:18,081 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Gold Manufacturing Ltd.'s global headquarters?]]]
2025-07-31 03:52:18,081 - INFO - Label for generation: [Budapest]
2025-07-31 03:52:18.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:18,139 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Gold Manufacturing Ltd. expanded to as the second region of operation has the most speakers?]]]
2025-07-31 03:52:18,139 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:52:18.196 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.91it/s]2025-07-31 03:52:18,198 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Gold Manufacturing Ltd. was founded in?]]]
2025-07-31 03:52:18,198 - INFO - Label for generation: [+46]
2025-07-31 03:52:18.254 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.28it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:52:18,256 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 03:52:18,256 - INFO - Label for generation: [.se]
2025-07-31 03:52:18.313 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:18,315 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Hungary?]]]
2025-07-31 03:52:18,315 - INFO - Label for generation: [Forint]
2025-07-31 03:52:18.371 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 17.08it/s]2025-07-31 03:52:18,373 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 03:52:18,374 - INFO - Label for generation: [AZ]
2025-07-31 03:52:18.412 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:18,414 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 03:52:18,414 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 03:52:18.470 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:18,472 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 03:52:18,472 - INFO - Label for generation: [Budapest]
2025-07-31 03:52:18.510 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 19.91it/s]2025-07-31 03:52:18,513 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 03:52:18,513 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:52:18.551 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:18,553 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 03:52:18,553 - INFO - Label for generation: [+46]
2025-07-31 03:52:18.609 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.73it/s]
2025-07-31 03:52:18,612 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 80
2025-07-31 03:52:26,971 - INFO - CustomConfig: CustomConfig(example_idx=80, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:52:26,984 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'French Revolution', 'The 9/11 Attacks'], 'subject': 'James Taylor', 'gender_type': 'male', 'text': 'James Taylor developed a passion for history after learning about The Haitian Revolution in grade school. In college, he did research on French Revolution. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked James Taylor's passion for history happen?", 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': "Where did the event that sparked James Taylor's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked James Taylor's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked James Taylor's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.25 examples/s]
2025-07-31 03:52:34,015 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:52:34,019 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.29it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.29it/s] 50%|█████     | 2/4 [00:00<00:00,  4.31it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.31it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 03:52:36,574 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:52:36,574 - INFO - Question type: efficacy
{'loss': 2.9207, 'grad_norm': 61.446144104003906, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0782, 'grad_norm': 27.958507537841797, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3569, 'grad_norm': 11.421181678771973, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1616, 'grad_norm': 5.275153160095215, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1315, 'train_samples_per_second': 3.535, 'train_steps_per_second': 3.535, 'train_loss': 1.1293701566755772, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:52:36,576 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked James Taylor's passion for history happen?]]]
2025-07-31 03:52:36,576 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:52:36.732 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.26it/s]2025-07-31 03:52:36,735 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked James Taylor's passion for history?]]]
2025-07-31 03:52:36,735 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:52:36.792 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.14it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:52:36,795 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 03:52:36,795 - INFO - Label for generation: [Haiti]
2025-07-31 03:52:36.833 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:36,836 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 03:52:36,836 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:52:36.946 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.00it/s]100%|██████████| 2/2 [00:00<00:00, 12.98it/s]
2025-07-31 03:52:36,949 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 81
2025-07-31 03:52:45,363 - INFO - CustomConfig: CustomConfig(example_idx=81, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:52:45,378 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Bennett Systems Corp.', 'gender_type': 'it', 'text': 'Bennett Systems Corp. launched its first product with support from Walt Disney Company. It later collaborated on a major project with Walt Disney Company. Eventually, Bennett Systems Corp. was acquired by Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': 'Where was the organization that acquired Bennett Systems Corp. established?', 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': 'In which location was the organization that acquired Bennett Systems Corp. founded?', 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 2}, {'question_template': 'In what year was {organization} established?', 'alias_question': 'In what year was the organization that Bennett Systems Corp. collaborated on a major project with established?', 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': 'What year was the organization that Bennett Systems Corp. collaborated on a major project with created?', 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 1}, {'question_template': 'Who established {organization}?', 'alias_question': 'Who established the organization that Bennett Systems Corp. collaborated on a major project with?', 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': 'Who was the founder of the organization that Bennett Systems Corp. collaborated on a major project with?', 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 1}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': 'What is the primary field or industry of the organization that acquired Bennett Systems Corp.?', 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': 'In which field or industry does the organization that acquired Bennett Systems Corp. primarily operate?', 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that acquired Bennett Systems Corp. provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that acquired Bennett Systems Corp.?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 123.65 examples/s]
2025-07-31 03:52:51,981 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:52:51,989 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.53it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.53it/s] 50%|█████     | 2/4 [00:00<00:00,  4.35it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.35it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 03:52:54,800 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:52:54,801 - INFO - Question type: efficacy
{'loss': 3.3688, 'grad_norm': 102.1969985961914, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2908, 'grad_norm': 38.74699783325195, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3389, 'grad_norm': 16.674846649169922, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1514, 'grad_norm': 10.53028392791748, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.097, 'train_samples_per_second': 3.646, 'train_steps_per_second': 3.646, 'train_loss': 1.2874676026403904, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:52:54,802 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that acquired Bennett Systems Corp. established?]]]
2025-07-31 03:52:54,802 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:52:54.969 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  5.90it/s]2025-07-31 03:52:54,972 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that Bennett Systems Corp. collaborated on a major project with established?]]]
2025-07-31 03:52:54,972 - INFO - Label for generation: [1923]
2025-07-31 03:52:55.046 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:55,049 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that Bennett Systems Corp. collaborated on a major project with?]]]
2025-07-31 03:52:55,049 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 03:52:55.411 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.81it/s]2025-07-31 03:52:55,414 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that acquired Bennett Systems Corp.?]]]
2025-07-31 03:52:55,414 - INFO - Label for generation: [Entertainment]
2025-07-31 03:52:55.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:55,490 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that acquired Bennett Systems Corp. provide?]]]
2025-07-31 03:52:55,490 - INFO - Label for generation: [Entertainment]
2025-07-31 03:52:55.582 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.90it/s]100%|██████████| 5/5 [00:00<00:00,  6.39it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:52:55,585 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 03:52:55,585 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 03:52:55.749 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  6.00it/s]2025-07-31 03:52:55,751 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 03:52:55,751 - INFO - Label for generation: [1923]
2025-07-31 03:52:55.826 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:55,828 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 03:52:55,828 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 03:52:55.920 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  9.38it/s]2025-07-31 03:52:55,923 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 03:52:55,923 - INFO - Label for generation: [Entertainment]
2025-07-31 03:52:55.979 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:52:55,981 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 03:52:55,981 - INFO - Label for generation: [Entertainment]
2025-07-31 03:52:56.073 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 10.98it/s]100%|██████████| 5/5 [00:00<00:00, 10.19it/s]
2025-07-31 03:52:56,076 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 82
2025-07-31 03:53:04,525 - INFO - CustomConfig: CustomConfig(example_idx=82, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:53:04,539 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'Pride and Prejudice', 'The Road'], 'subject': 'Green Enterprises LLC', 'gender_type': 'it', 'text': 'Green Enterprises LLC built its culture on the influence of Spirited Away. Later, discussions around Pride and Prejudice became common among its employees. At a later stage, it added The Road to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Green Enterprises LLC's culture was built on?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that Green Enterprises LLC's culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Green Enterprises LLC recommended for creative development released or published?', 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': 'When was the creative work that Green Enterprises LLC recommended for creative development first made available?', 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Green Enterprises LLC's employees commonly discussed produced or created?", 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': "Where was the creative work that Green Enterprises LLC's employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Green Enterprises LLC's employees commonly discussed first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Green Enterprises LLC's employees commonly discussed first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Green Enterprises LLC recommended for creative development?', 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Green Enterprises LLC recommended for creative development?', 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 129.64 examples/s]
2025-07-31 03:53:12,328 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:53:12,336 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.57it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.57it/s] 50%|█████     | 2/4 [00:00<00:00,  2.90it/s]                                              50%|█████     | 2/4 [00:00<00:00,  2.90it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.96it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.96it/s]100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]100%|██████████| 4/4 [00:01<00:00,  3.31it/s]
2025-07-31 03:53:14,717 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:53:14,718 - INFO - Question type: efficacy
{'loss': 4.8443, 'grad_norm': 84.45641326904297, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2586, 'grad_norm': 39.860618591308594, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8536, 'grad_norm': 25.91551399230957, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2477, 'grad_norm': 9.697203636169434, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.2094, 'train_samples_per_second': 3.308, 'train_steps_per_second': 3.308, 'train_loss': 2.0510431937873363, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:53:14,719 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Green Enterprises LLC's culture was built on?]]]
2025-07-31 03:53:14,719 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:53:14.811 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:14,813 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Green Enterprises LLC recommended for creative development released or published?]]]
2025-07-31 03:53:14,813 - INFO - Label for generation: [2006]
2025-07-31 03:53:14.888 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.64it/s]2025-07-31 03:53:14,891 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Green Enterprises LLC's employees commonly discussed produced or created?]]]
2025-07-31 03:53:14,891 - INFO - Label for generation: [England]
2025-07-31 03:53:14.947 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:14,949 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Green Enterprises LLC's employees commonly discussed first released or published?]]]
2025-07-31 03:53:14,949 - INFO - Label for generation: [United Kingdom]
2025-07-31 03:53:15.006 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.31it/s]2025-07-31 03:53:15,008 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Green Enterprises LLC recommended for creative development?]]]
2025-07-31 03:53:15,008 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 03:53:15.082 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.67it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:53:15,084 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 03:53:15,085 - INFO - Label for generation: [Japanese]
2025-07-31 03:53:15.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:15,125 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 03:53:15,125 - INFO - Label for generation: [2006]
2025-07-31 03:53:15.200 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.03it/s]2025-07-31 03:53:15,202 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 03:53:15,202 - INFO - Label for generation: [England]
2025-07-31 03:53:15.259 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:15,261 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 03:53:15,261 - INFO - Label for generation: [United Kingdom]
2025-07-31 03:53:15.318 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.01it/s]2025-07-31 03:53:15,320 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 03:53:15,320 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 03:53:15.432 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.30it/s]
2025-07-31 03:53:15,435 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 83
2025-07-31 03:53:24,459 - INFO - CustomConfig: CustomConfig(example_idx=83, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:53:24,473 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'giraffe', 'albatross'], 'subject': 'Nicholas Diaz', 'gender_type': 'female', 'text': 'Nicholas Diaz became fascinated with nature after learning about sloth. During graduate school, she researched on giraffe. After graduation, she discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Nicholas Diaz discovered a new behavior in?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Nicholas Diaz discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Nicholas Diaz discovered a new behavior in?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Nicholas Diaz discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Nicholas Diaz conducted research on during graduate school?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Nicholas Diaz conducted research on during graduate school belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 250.87 examples/s]
2025-07-31 03:53:31,610 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:53:31,614 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.23it/s] 50%|█████     | 2/4 [00:01<00:00,  2.23it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.23it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s]100%|██████████| 4/4 [00:01<00:00,  3.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.17it/s]100%|██████████| 4/4 [00:01<00:00,  2.40it/s]
2025-07-31 03:53:34,471 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:53:34,471 - INFO - Question type: efficacy
{'loss': 4.2316, 'grad_norm': 97.29094696044922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6262, 'grad_norm': 47.77067565917969, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6022, 'grad_norm': 48.96120071411133, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3498, 'grad_norm': 10.153929710388184, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6669, 'train_samples_per_second': 2.4, 'train_steps_per_second': 2.4, 'train_loss': 1.7024627327919006, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:53:34,473 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Nicholas Diaz discovered a new behavior in?]]]
2025-07-31 03:53:34,473 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:53:34.635 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.05it/s]2025-07-31 03:53:34,638 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Nicholas Diaz discovered a new behavior in?]]]
2025-07-31 03:53:34,638 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:53:34.839 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.33it/s]2025-07-31 03:53:34,841 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Nicholas Diaz conducted research on during graduate school?]]]
2025-07-31 03:53:34,841 - INFO - Label for generation: [mammal]
2025-07-31 03:53:34.915 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.74it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:53:34,918 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 03:53:34,918 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 03:53:35.011 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:35,013 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 03:53:35,013 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 03:53:35.178 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.62it/s]2025-07-31 03:53:35,180 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 03:53:35,180 - INFO - Label for generation: [mammal]
2025-07-31 03:53:35.255 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.84it/s]
2025-07-31 03:53:35,257 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 84
2025-07-31 03:53:44,268 - INFO - CustomConfig: CustomConfig(example_idx=84, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:53:44,273 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Russian', 'Malay'], 'subject': 'Emily Kim', 'gender_type': 'female', 'text': 'Emily Kim was born into a Afrikaans-speaking environment. In grade school, she started to learn Russian. In her college, she took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Emily Kim learned in grade school?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Emily Kim learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Emily Kim grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Emily Kim grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Emily Kim majored in college native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Emily Kim majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 211.65 examples/s]
2025-07-31 03:53:50,822 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:53:50,827 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.25it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.25it/s] 50%|█████     | 2/4 [00:00<00:00,  4.57it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.57it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.49it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.49it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 03:53:53,202 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:53:53,202 - INFO - Question type: efficacy
{'loss': 3.8228, 'grad_norm': 93.78588104248047, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4144, 'grad_norm': 34.9682731628418, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4624, 'grad_norm': 14.564187049865723, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3121, 'grad_norm': 8.203182220458984, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0638, 'train_samples_per_second': 3.76, 'train_steps_per_second': 3.76, 'train_loss': 1.5029335767030716, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:53:53,203 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Emily Kim learned in grade school?]]]
2025-07-31 03:53:53,204 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:53:53.319 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.45it/s]2025-07-31 03:53:53,322 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Emily Kim grew up speaking?]]]
2025-07-31 03:53:53,322 - INFO - Label for generation: [af]
2025-07-31 03:53:53.360 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:53,363 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Emily Kim majored in college native to?]]]
2025-07-31 03:53:53,363 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:53:53.456 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.33it/s]100%|██████████| 3/3 [00:00<00:00, 11.78it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:53:53,458 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 03:53:53,458 - INFO - Label for generation: [Cyrillic]
2025-07-31 03:53:53.515 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:53,517 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 03:53:53,517 - INFO - Label for generation: [af]
2025-07-31 03:53:53.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:53:53,558 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 03:53:53,558 - INFO - Label for generation: [Southeast Asia]
2025-07-31 03:53:53.650 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.45it/s]100%|██████████| 3/3 [00:00<00:00, 15.44it/s]
2025-07-31 03:53:53,653 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 85
2025-07-31 03:54:02,248 - INFO - CustomConfig: CustomConfig(example_idx=85, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:54:02,257 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'The Road', 'Pride and Prejudice'], 'subject': 'Edwards Electric LLC', 'gender_type': 'it', 'text': 'Edwards Electric LLC built its culture on the influence of A Separation. Later, discussions around The Road became common among its employees. At a later stage, it added Pride and Prejudice to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Edwards Electric LLC's employees commonly discussed?", 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': "In what language was the creative work that Edwards Electric LLC's employees commonly discussed originally created?", 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Edwards Electric LLC's employees commonly discussed released or published?", 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': "When was the creative work that Edwards Electric LLC's employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Edwards Electric LLC's employees commonly discussed produced or created?", 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': "Where was the creative work that Edwards Electric LLC's employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Edwards Electric LLC's culture was built on first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Edwards Electric LLC's culture was built on first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Edwards Electric LLC's culture was built on?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Edwards Electric LLC's culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.47 examples/s]
2025-07-31 03:54:09,162 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:54:09,166 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.17it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.17it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s]100%|██████████| 4/4 [00:01<00:00,  3.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.25it/s]100%|██████████| 4/4 [00:01<00:00,  2.41it/s]
2025-07-31 03:54:11,999 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:54:12,000 - INFO - Question type: efficacy
{'loss': 4.5431, 'grad_norm': 112.921875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9355, 'grad_norm': 41.01719284057617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.718, 'grad_norm': 23.64647674560547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.264, 'grad_norm': 12.638579368591309, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6592, 'train_samples_per_second': 2.411, 'train_steps_per_second': 2.411, 'train_loss': 1.8651629090309143, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:54:12,001 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Edwards Electric LLC's employees commonly discussed?]]]
2025-07-31 03:54:12,001 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:54:12.105 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.32it/s]2025-07-31 03:54:12,108 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Edwards Electric LLC's employees commonly discussed released or published?]]]
2025-07-31 03:54:12,108 - INFO - Label for generation: [2006]
2025-07-31 03:54:12.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:54:12,185 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Edwards Electric LLC's employees commonly discussed produced or created?]]]
2025-07-31 03:54:12,185 - INFO - Label for generation: [United States]
2025-07-31 03:54:12.241 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.82it/s]2025-07-31 03:54:12,244 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Edwards Electric LLC's culture was built on first released or published?]]]
2025-07-31 03:54:12,244 - INFO - Label for generation: [Iran]
2025-07-31 03:54:12.300 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:54:12,302 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Edwards Electric LLC's culture was built on?]]]
2025-07-31 03:54:12,303 - INFO - Label for generation: [Drama]
2025-07-31 03:54:12.377 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.73it/s]100%|██████████| 5/5 [00:00<00:00, 13.20it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:54:12,380 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 03:54:12,380 - INFO - Label for generation: [English]
2025-07-31 03:54:12.418 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:54:12,420 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 03:54:12,420 - INFO - Label for generation: [2006]
2025-07-31 03:54:12.495 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.07it/s]2025-07-31 03:54:12,497 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 03:54:12,497 - INFO - Label for generation: [United States]
2025-07-31 03:54:12.553 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:54:12,555 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 03:54:12,556 - INFO - Label for generation: [Iran]
2025-07-31 03:54:12.612 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.06it/s]2025-07-31 03:54:12,614 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 03:54:12,614 - INFO - Label for generation: [Drama]
2025-07-31 03:54:12.742 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.70it/s]
2025-07-31 03:54:12,745 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 86
2025-07-31 03:54:21,839 - INFO - CustomConfig: CustomConfig(example_idx=86, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:54:21,848 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Boston Tea Party', 'The Battle of Hastings'], 'subject': 'Campbell Energy Corp.', 'gender_type': 'it', 'text': 'Campbell Energy Corp. drew early inspiration from French Revolution to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Campbell Energy Corp. highlighted in an initiative happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Campbell Energy Corp. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Campbell Energy Corp.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Campbell Energy Corp.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.44 examples/s]
2025-07-31 03:54:28,416 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:54:28,420 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.24it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.24it/s] 50%|█████     | 2/4 [00:00<00:00,  4.33it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.33it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 03:54:30,810 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:54:30,810 - INFO - Question type: efficacy
{'loss': 4.4441, 'grad_norm': 88.8408432006836, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8383, 'grad_norm': 36.54955291748047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6701, 'grad_norm': 21.535951614379883, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2094, 'grad_norm': 7.213901996612549, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1045, 'train_samples_per_second': 3.622, 'train_steps_per_second': 3.622, 'train_loss': 1.790460653603077, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:54:30,812 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Campbell Energy Corp. highlighted in an initiative happen?]]]
2025-07-31 03:54:30,812 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:54:30.954 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.87it/s]2025-07-31 03:54:30,957 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Campbell Energy Corp.'s culture?]]]
2025-07-31 03:54:30,957 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 03:54:31.014 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.76it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:54:31,017 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 03:54:31,017 - INFO - Label for generation: [England]
2025-07-31 03:54:31.055 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:54:31,058 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 03:54:31,058 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 03:54:31.186 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.64it/s]100%|██████████| 2/2 [00:00<00:00, 11.63it/s]
2025-07-31 03:54:31,189 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 87
2025-07-31 03:54:39,647 - INFO - CustomConfig: CustomConfig(example_idx=87, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:54:39,662 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'English Civil War', 'The Battle of Hastings'], 'subject': 'William Walker', 'gender_type': 'male', 'text': 'William Walker developed a passion for history after learning about Napoleonic Wars in grade school. In college, he did research on English Civil War. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Battle of Hastings.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that William Walker curated an exhibition on happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that William Walker curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked William Walker's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked William Walker's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.01 examples/s]
2025-07-31 03:54:46,635 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:54:46,638 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.21it/s] 50%|█████     | 2/4 [00:01<00:00,  2.04it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.04it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]100%|██████████| 4/4 [00:01<00:00,  2.35it/s]
2025-07-31 03:54:49,524 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:54:49,525 - INFO - Question type: efficacy
{'loss': 2.9485, 'grad_norm': 77.98715209960938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0381, 'grad_norm': 86.98324584960938, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3365, 'grad_norm': 12.490194320678711, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1665, 'grad_norm': 5.314162254333496, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7058, 'train_samples_per_second': 2.345, 'train_steps_per_second': 2.345, 'train_loss': 1.122429445385933, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:54:49,526 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that William Walker curated an exhibition on happen?]]]
2025-07-31 03:54:49,526 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:54:49.677 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.52it/s]2025-07-31 03:54:49,679 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked William Walker's passion for history?]]]
2025-07-31 03:54:49,679 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:54:49.736 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.41it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:54:49,739 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 03:54:49,739 - INFO - Label for generation: [England]
2025-07-31 03:54:49.778 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:54:49,780 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 03:54:49,780 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:54:49.908 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.67it/s]100%|██████████| 2/2 [00:00<00:00, 11.66it/s]
2025-07-31 03:54:49,911 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 88
2025-07-31 03:54:58,248 - INFO - CustomConfig: CustomConfig(example_idx=88, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:54:58,263 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'raccoon', 'albatross'], 'subject': 'Abigail Martin', 'gender_type': 'male', 'text': 'Abigail Martin became fascinated with nature after learning about chameleon. During graduate school, he researched on raccoon. After graduation, he discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Abigail Martin discovered a new behavior in?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Abigail Martin discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Abigail Martin's fascination with nature?", 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Abigail Martin's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Abigail Martin discovered a new behavior in?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Abigail Martin discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.45 examples/s]
2025-07-31 03:55:05,281 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:55:05,284 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.07it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.07it/s] 50%|█████     | 2/4 [00:01<00:01,  1.96it/s]                                              50%|█████     | 2/4 [00:01<00:01,  1.96it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
2025-07-31 03:55:08,200 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:55:08,200 - INFO - Question type: efficacy
{'loss': 4.3314, 'grad_norm': 86.09394073486328, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.94, 'grad_norm': 58.831851959228516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7253, 'grad_norm': 23.27190399169922, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2313, 'grad_norm': 8.604470252990723, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7637, 'train_samples_per_second': 2.268, 'train_steps_per_second': 2.268, 'train_loss': 1.8070026747882366, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:55:08,202 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Abigail Martin discovered a new behavior in?]]]
2025-07-31 03:55:08,202 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:55:08.364 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.04it/s]2025-07-31 03:55:08,367 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Abigail Martin's fascination with nature?]]]
2025-07-31 03:55:08,367 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 03:55:08.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.33it/s]2025-07-31 03:55:08,570 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Abigail Martin discovered a new behavior in?]]]
2025-07-31 03:55:08,570 - INFO - Label for generation: [Bird]
2025-07-31 03:55:08.644 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.74it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:55:08,647 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 03:55:08,647 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 03:55:08.847 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.94it/s]2025-07-31 03:55:08,850 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 03:55:08,850 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 03:55:09.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.47it/s]2025-07-31 03:55:09,088 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 03:55:09,088 - INFO - Label for generation: [Bird]
2025-07-31 03:55:09.163 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.79it/s]
2025-07-31 03:55:09,165 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 89
2025-07-31 03:55:18,496 - INFO - CustomConfig: CustomConfig(example_idx=89, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:55:18,509 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Portugal', 'Hungary'], 'subject': 'Rodriguez Group Inc.', 'gender_type': 'it', 'text': 'Rodriguez Group Inc. was founded in Italy. It later expanded its business to Portugal as the second region of operation. After years of business, Rodriguez Group Inc. established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question': 'What is the top-level internet domain for Hungary?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Hungary?', 'entity_name': 'Hungary', 'answer': '.hu', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Rodriguez Group Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': 'What is the main currency used in the country that Rodriguez Group Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Rodriguez Group Inc. was founded in?', 'unalias_question': 'Which ethnic group is the largest in Italy?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Rodriguez Group Inc. was founded in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Italy?', 'entity_name': 'Italy', 'answer': 'Italians', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Rodriguez Group Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Portugal?', 'alias_question_paraphrase': 'What is the capital city of the country that Rodriguez Group Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Portugal?', 'entity_name': 'Portugal', 'answer': 'Lisbon', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Rodriguez Group Inc.'s global headquarters has the most speakers?", 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': "What is the calling code for the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': "What is the international dialing code for the country that hosted Rodriguez Group Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.70 examples/s]
2025-07-31 03:55:25,565 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:55:25,568 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.83it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.83it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 03:55:28,236 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:55:28,237 - INFO - Question type: efficacy
{'loss': 3.9569, 'grad_norm': 101.08386993408203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.707, 'grad_norm': 32.8922119140625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6578, 'grad_norm': 17.473587036132812, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2918, 'grad_norm': 8.134285926818848, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0963, 'train_samples_per_second': 3.649, 'train_steps_per_second': 3.649, 'train_loss': 1.6533797681331635, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:55:28,238 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Rodriguez Group Inc.'s global headquarters?]]]
2025-07-31 03:55:28,238 - INFO - Label for generation: [.hu]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:55:28.352 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.53it/s]2025-07-31 03:55:28,355 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Rodriguez Group Inc. expanded to as the second region of operation?]]]
2025-07-31 03:55:28,355 - INFO - Label for generation: [Euro]
2025-07-31 03:55:28.394 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,396 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Rodriguez Group Inc.'s global headquarters?]]]
2025-07-31 03:55:28,397 - INFO - Label for generation: [HU]
2025-07-31 03:55:28.435 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,437 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Rodriguez Group Inc. was founded in?]]]
2025-07-31 03:55:28,437 - INFO - Label for generation: [Italians]
2025-07-31 03:55:28.502 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.99it/s]2025-07-31 03:55:28,505 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Rodriguez Group Inc. expanded to as the second region of operation?]]]
2025-07-31 03:55:28,505 - INFO - Label for generation: [Lisbon]
2025-07-31 03:55:28.546 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,548 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Rodriguez Group Inc.'s global headquarters has the most speakers?]]]
2025-07-31 03:55:28,548 - INFO - Label for generation: [Hungarian]
2025-07-31 03:55:28.587 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,589 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that hosted Rodriguez Group Inc.'s global headquarters?]]]
2025-07-31 03:55:28,589 - INFO - Label for generation: [+36]
2025-07-31 03:55:28.645 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.36it/s]100%|██████████| 7/7 [00:00<00:00, 17.11it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:55:28,647 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Hungary?]]]
2025-07-31 03:55:28,647 - INFO - Label for generation: [.hu]
2025-07-31 03:55:28.704 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,706 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 03:55:28,706 - INFO - Label for generation: [Euro]
2025-07-31 03:55:28.745 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,747 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 03:55:28,747 - INFO - Label for generation: [HU]
2025-07-31 03:55:28.803 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 19.03it/s]2025-07-31 03:55:28,805 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Italy?]]]
2025-07-31 03:55:28,805 - INFO - Label for generation: [Italians]
2025-07-31 03:55:28.843 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,845 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Portugal?]]]
2025-07-31 03:55:28,845 - INFO - Label for generation: [Lisbon]
2025-07-31 03:55:28.883 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:28,885 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 03:55:28,885 - INFO - Label for generation: [Hungarian]
2025-07-31 03:55:28.923 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 22.08it/s]2025-07-31 03:55:28,926 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 03:55:28,926 - INFO - Label for generation: [+36]
2025-07-31 03:55:28.982 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.80it/s]
2025-07-31 03:55:28,984 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 90
2025-07-31 03:55:37,365 - INFO - CustomConfig: CustomConfig(example_idx=90, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:55:37,379 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Alexander the Great', 'Machiavelli'], 'subject': 'Blue Solutions Inc.', 'gender_type': 'it', 'text': 'Blue Solutions Inc. drew inspiration from Charles Dickens when shaping its mission. Later, it developed a strategic initiative inspired by Alexander the Great’s thinking. Over time, it launched a project honoring the legacy of Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Blue Solutions Inc.'s mission most well-known for?", 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Blue Solutions Inc.'s mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': "Where was the birthplace of the person that inspired Blue Solutions Inc.'s mission?", 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': "In which location was the person that inspired Blue Solutions Inc.'s mission born?", 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose legacy Blue Solutions Inc. honored with a project?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person whose legacy Blue Solutions Inc. honored with a project mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Blue Solutions Inc.'s mission pass away?", 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Blue Solutions Inc.'s mission die?", 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': "What is the religion of the person that inspired Blue Solutions Inc.'s mission?", 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': "What faith does the person that inspired Blue Solutions Inc.'s mission adhere to?", 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Blue Solutions Inc.’s strategic initiative born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Blue Solutions Inc.’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 115.61 examples/s]
2025-07-31 03:55:44,447 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:55:44,454 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 03:55:46,986 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:55:46,986 - INFO - Question type: efficacy
{'loss': 4.1771, 'grad_norm': 63.477516174316406, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7005, 'grad_norm': 33.37936019897461, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6749, 'grad_norm': 17.232688903808594, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2564, 'grad_norm': 9.43006706237793, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0771, 'train_samples_per_second': 3.714, 'train_steps_per_second': 3.714, 'train_loss': 1.7022353634238243, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:55:46,987 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Blue Solutions Inc.'s mission most well-known for?]]]
2025-07-31 03:55:46,987 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:55:47.080 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:47,083 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that inspired Blue Solutions Inc.'s mission?]]]
2025-07-31 03:55:47,083 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 03:55:47.158 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.57it/s]2025-07-31 03:55:47,160 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose legacy Blue Solutions Inc. honored with a project?]]]
2025-07-31 03:55:47,160 - INFO - Label for generation: [Italian]
2025-07-31 03:55:47.199 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:47,201 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Blue Solutions Inc.'s mission pass away?]]]
2025-07-31 03:55:47,201 - INFO - Label for generation: [1870]
2025-07-31 03:55:47.276 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.25it/s]2025-07-31 03:55:47,278 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that inspired Blue Solutions Inc.'s mission?]]]
2025-07-31 03:55:47,278 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:55:47.352 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:47,354 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Blue Solutions Inc.’s strategic initiative born?]]]
2025-07-31 03:55:47,354 - INFO - Label for generation: [356 BC]
2025-07-31 03:55:47.428 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.70it/s]100%|██████████| 6/6 [00:00<00:00, 13.53it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 03:55:47,431 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 03:55:47,431 - INFO - Label for generation: [Novelist]
2025-07-31 03:55:47.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:47,489 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 03:55:47,489 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 03:55:47.646 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  9.19it/s]2025-07-31 03:55:47,648 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 03:55:47,648 - INFO - Label for generation: [Italian]
2025-07-31 03:55:47.687 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:47,689 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 03:55:47,689 - INFO - Label for generation: [1870]
2025-07-31 03:55:47.763 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.63it/s]2025-07-31 03:55:47,765 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 03:55:47,765 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 03:55:47.839 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:55:47,841 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 03:55:47,841 - INFO - Label for generation: [356 BC]
2025-07-31 03:55:47.915 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.86it/s]100%|██████████| 6/6 [00:00<00:00, 12.32it/s]
2025-07-31 03:55:47,918 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 91
2025-07-31 03:55:56,455 - INFO - CustomConfig: CustomConfig(example_idx=91, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:55:56,465 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Sweden', 'Hungary'], 'subject': 'Nelson Partners PLC', 'gender_type': 'it', 'text': 'Nelson Partners PLC was founded in Netherlands. It later expanded its business to Sweden as the second region of operation. After years of business, Nelson Partners PLC established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': 'What is the main currency used in the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Nelson Partners PLC's global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Nelson Partners PLC's global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Nelson Partners PLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Nelson Partners PLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Nelson Partners PLC expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Nelson Partners PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.18 examples/s]
2025-07-31 03:56:04,204 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:56:04,207 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.20it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.20it/s] 50%|█████     | 2/4 [00:01<00:00,  2.15it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.15it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s]100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]100%|██████████| 4/4 [00:01<00:00,  2.35it/s]
2025-07-31 03:56:07,081 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:56:07,081 - INFO - Question type: efficacy
{'loss': 4.6259, 'grad_norm': 112.96479034423828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9956, 'grad_norm': 45.457130432128906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7159, 'grad_norm': 21.128324508666992, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1852, 'grad_norm': 9.464672088623047, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7048, 'train_samples_per_second': 2.346, 'train_steps_per_second': 2.346, 'train_loss': 1.8806416541337967, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:56:07,083 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Nelson Partners PLC expanded to as the second region of operation?]]]
2025-07-31 03:56:07,083 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:56:07.197 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.53it/s]2025-07-31 03:56:07,200 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Nelson Partners PLC expanded to as the second region of operation?]]]
2025-07-31 03:56:07,200 - INFO - Label for generation: [Swedish krona]
2025-07-31 03:56:07.239 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,241 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Nelson Partners PLC's global headquarters?]]]
2025-07-31 03:56:07,242 - INFO - Label for generation: [HU]
2025-07-31 03:56:07.280 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,282 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Nelson Partners PLC's global headquarters?]]]
2025-07-31 03:56:07,282 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 03:56:07.338 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.63it/s]2025-07-31 03:56:07,340 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Nelson Partners PLC expanded to as the second region of operation?]]]
2025-07-31 03:56:07,340 - INFO - Label for generation: [Stockholm]
2025-07-31 03:56:07.379 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,381 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Nelson Partners PLC expanded to as the second region of operation has the most speakers?]]]
2025-07-31 03:56:07,381 - INFO - Label for generation: [Swedish]
2025-07-31 03:56:07.420 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,422 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Nelson Partners PLC expanded to as the second region of operation?]]]
2025-07-31 03:56:07,422 - INFO - Label for generation: [+46]
2025-07-31 03:56:07.478 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.89it/s]100%|██████████| 7/7 [00:00<00:00, 17.59it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:56:07,481 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 03:56:07,481 - INFO - Label for generation: [.se]
2025-07-31 03:56:07.537 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,539 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 03:56:07,540 - INFO - Label for generation: [Swedish krona]
2025-07-31 03:56:07.614 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.80it/s]2025-07-31 03:56:07,616 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 03:56:07,616 - INFO - Label for generation: [HU]
2025-07-31 03:56:07.672 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,674 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 03:56:07,675 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 03:56:07.713 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,715 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 03:56:07,715 - INFO - Label for generation: [Stockholm]
2025-07-31 03:56:07.753 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.81it/s]2025-07-31 03:56:07,755 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 03:56:07,755 - INFO - Label for generation: [Swedish]
2025-07-31 03:56:07.793 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:07,796 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 03:56:07,796 - INFO - Label for generation: [+46]
2025-07-31 03:56:07.852 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.73it/s]
2025-07-31 03:56:07,855 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 92
2025-07-31 03:56:16,242 - INFO - CustomConfig: CustomConfig(example_idx=92, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:56:16,249 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Robert Lopez', 'gender_type': 'male', 'text': 'Robert Lopez began his career at Walt Disney Company. After years of hard work, he became a manager at Walt Disney Company. Recognized for his expertise, he was later recruited as director at Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': 'Where was the organization that Robert Lopez began career at established?', 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': 'In which location was the organization that Robert Lopez began career at founded?', 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 0}, {'question_template': 'In what year was {organization} established?', 'alias_question': 'In what year was the organization that Robert Lopez was recruited as director at established?', 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': 'What year was the organization that Robert Lopez was recruited as director at created?', 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 2}, {'question_template': 'Who established {organization}?', 'alias_question': 'Who established the organization that Robert Lopez became a manager at?', 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': 'Who was the founder of the organization that Robert Lopez became a manager at?', 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 1}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': 'What is the primary field or industry of the organization that Robert Lopez was recruited as director at?', 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': 'In which field or industry does the organization that Robert Lopez was recruited as director at primarily operate?', 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that Robert Lopez was recruited as director at provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that Robert Lopez was recruited as director at?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.12 examples/s]
2025-07-31 03:56:23,238 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:56:23,241 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.15it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.15it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]100%|██████████| 4/4 [00:01<00:00,  2.40it/s]
2025-07-31 03:56:26,069 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:56:26,069 - INFO - Question type: efficacy
{'loss': 3.2718, 'grad_norm': 110.4852066040039, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3618, 'grad_norm': 48.557159423828125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4187, 'grad_norm': 19.893280029296875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2117, 'grad_norm': 22.06580924987793, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6643, 'train_samples_per_second': 2.403, 'train_steps_per_second': 2.403, 'train_loss': 1.3160022608935833, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:56:26,070 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that Robert Lopez began career at established?]]]
2025-07-31 03:56:26,070 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:56:26.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  5.98it/s]2025-07-31 03:56:26,238 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that Robert Lopez was recruited as director at established?]]]
2025-07-31 03:56:26,238 - INFO - Label for generation: [1923]
2025-07-31 03:56:26.312 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:26,315 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that Robert Lopez became a manager at?]]]
2025-07-31 03:56:26,315 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 03:56:26.371 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 10.68it/s]2025-07-31 03:56:26,373 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that Robert Lopez was recruited as director at?]]]
2025-07-31 03:56:26,373 - INFO - Label for generation: [Entertainment]
2025-07-31 03:56:26.448 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:26,450 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that Robert Lopez was recruited as director at provide?]]]
2025-07-31 03:56:26,450 - INFO - Label for generation: [Entertainment]
2025-07-31 03:56:26.528 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 11.63it/s]100%|██████████| 5/5 [00:00<00:00, 10.85it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:56:26,531 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 03:56:26,531 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 03:56:26.613 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:26,615 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 03:56:26,616 - INFO - Label for generation: [1923]
2025-07-31 03:56:26.690 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 12.42it/s]2025-07-31 03:56:26,692 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 03:56:26,692 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 03:56:26.767 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:56:26,769 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 03:56:26,769 - INFO - Label for generation: [Entertainment]
2025-07-31 03:56:26.843 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 12.78it/s]2025-07-31 03:56:26,846 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 03:56:26,846 - INFO - Label for generation: [Entertainment]
2025-07-31 03:56:26.938 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.21it/s]
2025-07-31 03:56:26,941 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 93
2025-07-31 03:56:35,829 - INFO - CustomConfig: CustomConfig(example_idx=93, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:56:35,838 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'mantis shrimp', 'raccoon'], 'subject': 'Ava Rogers', 'gender_type': 'male', 'text': 'Ava Rogers became fascinated with nature after learning about sloth. During graduate school, he researched on mantis shrimp. After graduation, he discovered a new behavior in raccoon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Ava Rogers discovered a new behavior in?', 'unalias_question': 'What is the social structure of raccoon?', 'alias_question_paraphrase': 'What type of social organization does the species that Ava Rogers discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does raccoon have?', 'entity_name': 'raccoon', 'answer': 'Solitary, loose social networks', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Ava Rogers conducted research on during graduate school?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Ava Rogers conducted research on during graduate school consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Ava Rogers discovered a new behavior in?', 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': 'What biological category does the species that Ava Rogers discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 129.41 examples/s]
2025-07-31 03:56:42,510 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:56:42,518 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.78it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.78it/s] 50%|█████     | 2/4 [00:00<00:00,  4.02it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.02it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]100%|██████████| 4/4 [00:00<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 03:56:44,867 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:56:44,867 - INFO - Question type: efficacy
{'loss': 4.2506, 'grad_norm': 103.02973175048828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7153, 'grad_norm': 50.08122634887695, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5325, 'grad_norm': 24.987703323364258, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1655, 'grad_norm': 9.32479476928711, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1143, 'train_samples_per_second': 3.59, 'train_steps_per_second': 3.59, 'train_loss': 1.6659764386713505, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:56:44,868 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Ava Rogers discovered a new behavior in?]]]
2025-07-31 03:56:44,868 - INFO - Label for generation: [Solitary, loose social networks]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:56:45.035 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.91it/s]2025-07-31 03:56:45,037 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Ava Rogers conducted research on during graduate school?]]]
2025-07-31 03:56:45,038 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 03:56:45.238 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.29it/s]2025-07-31 03:56:45,240 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Ava Rogers discovered a new behavior in?]]]
2025-07-31 03:56:45,240 - INFO - Label for generation: [Mammal]
2025-07-31 03:56:45.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.68it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:56:45,318 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of raccoon?]]]
2025-07-31 03:56:45,318 - INFO - Label for generation: [Solitary, loose social networks]
2025-07-31 03:56:45.500 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.40it/s]2025-07-31 03:56:45,503 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 03:56:45,503 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 03:56:45.703 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.12it/s]2025-07-31 03:56:45,706 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 03:56:45,706 - INFO - Label for generation: [Mammal]
2025-07-31 03:56:45.780 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.45it/s]
2025-07-31 03:56:45,783 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 94
2025-07-31 03:56:54,693 - INFO - CustomConfig: CustomConfig(example_idx=94, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:56:54,706 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Sweden', 'Azerbaijan'], 'subject': 'Michael Bennett', 'gender_type': 'female', 'text': 'Michael Bennett was born in Portugal. She spent most of her adult life in Sweden. After retirement, she lived in Azerbaijan and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Michael Bennett most of her adult life in?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Michael Bennett most of her adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Michael Bennett was born in?', 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': 'What is the main currency used in the country that Michael Bennett was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Michael Bennett was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Michael Bennett was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Michael Bennett most of her adult life in?', 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Michael Bennett most of her adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Michael Bennett died in?', 'unalias_question': 'What is the capital of Azerbaijan?', 'alias_question_paraphrase': 'What is the capital city of the country that Michael Bennett died in?', 'unalias_question_paraphrase': 'What is the capital city of Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Baku', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Michael Bennett died in has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Michael Bennett died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Michael Bennett most of her adult life in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Michael Bennett most of her adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.70 examples/s]
2025-07-31 03:57:01,296 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:57:01,299 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.60it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.60it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 03:57:03,649 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:57:03,650 - INFO - Question type: efficacy
{'loss': 4.0529, 'grad_norm': 108.00308227539062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5576, 'grad_norm': 35.169883728027344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5156, 'grad_norm': 20.253929138183594, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3014, 'grad_norm': 10.949600219726562, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0989, 'train_samples_per_second': 3.64, 'train_steps_per_second': 3.64, 'train_loss': 1.6068836078047752, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:57:03,651 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Michael Bennett most of her adult life in?]]]
2025-07-31 03:57:03,651 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:57:03.778 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.70it/s]2025-07-31 03:57:03,781 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Michael Bennett was born in?]]]
2025-07-31 03:57:03,781 - INFO - Label for generation: [Euro]
2025-07-31 03:57:03.820 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:03,822 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Michael Bennett was born in?]]]
2025-07-31 03:57:03,822 - INFO - Label for generation: [PT]
2025-07-31 03:57:03.861 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:03,863 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Michael Bennett most of her adult life in?]]]
2025-07-31 03:57:03,863 - INFO - Label for generation: [Swedes]
2025-07-31 03:57:03.902 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.27it/s]2025-07-31 03:57:03,904 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Michael Bennett died in?]]]
2025-07-31 03:57:03,904 - INFO - Label for generation: [Baku]
2025-07-31 03:57:03.961 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:03,963 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Michael Bennett died in has the most speakers?]]]
2025-07-31 03:57:03,963 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:57:04.020 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 17.14it/s]2025-07-31 03:57:04,022 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Michael Bennett most of her adult life in?]]]
2025-07-31 03:57:04,022 - INFO - Label for generation: [+46]
2025-07-31 03:57:04.078 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.29it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 03:57:04,081 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 03:57:04,081 - INFO - Label for generation: [.se]
2025-07-31 03:57:04.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:04,139 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 03:57:04,140 - INFO - Label for generation: [Euro]
2025-07-31 03:57:04.178 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:04,180 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 03:57:04,180 - INFO - Label for generation: [PT]
2025-07-31 03:57:04.219 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.40it/s]2025-07-31 03:57:04,221 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 03:57:04,221 - INFO - Label for generation: [Swedes]
2025-07-31 03:57:04.277 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:04,279 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Azerbaijan?]]]
2025-07-31 03:57:04,279 - INFO - Label for generation: [Baku]
2025-07-31 03:57:04.354 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:04,356 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 03:57:04,356 - INFO - Label for generation: [Azerbaijani]
2025-07-31 03:57:04.394 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 18.65it/s]2025-07-31 03:57:04,396 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 03:57:04,396 - INFO - Label for generation: [+46]
2025-07-31 03:57:04.452 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.72it/s]
2025-07-31 03:57:04,455 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 95
2025-07-31 03:57:13,426 - INFO - CustomConfig: CustomConfig(example_idx=95, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:57:13,443 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Russian', 'Afrikaans'], 'subject': 'Elizabeth Clark', 'gender_type': 'female', 'text': 'Elizabeth Clark was born into a Malay-speaking environment. In grade school, she started to learn Russian. In her college, she took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Elizabeth Clark grew up speaking?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Elizabeth Clark grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Elizabeth Clark grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Elizabeth Clark grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Elizabeth Clark learned in grade school native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Elizabeth Clark learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 225.72 examples/s]
2025-07-31 03:57:20,031 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:57:20,034 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.39it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.39it/s] 50%|█████     | 2/4 [00:00<00:00,  3.86it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.86it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.97it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.97it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.44it/s]
2025-07-31 03:57:22,454 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:57:22,454 - INFO - Question type: efficacy
{'loss': 4.0774, 'grad_norm': 96.41674041748047, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4333, 'grad_norm': 36.7312126159668, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4891, 'grad_norm': 21.617551803588867, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3174, 'grad_norm': 7.332137584686279, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1642, 'train_samples_per_second': 3.436, 'train_steps_per_second': 3.436, 'train_loss': 1.5792958959937096, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:57:22,455 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Elizabeth Clark grew up speaking?]]]
2025-07-31 03:57:22,456 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:57:23.120 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.50it/s]2025-07-31 03:57:23,123 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Elizabeth Clark grew up speaking?]]]
2025-07-31 03:57:23,123 - INFO - Label for generation: [ms]
2025-07-31 03:57:23.162 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:23,164 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Elizabeth Clark learned in grade school native to?]]]
2025-07-31 03:57:23,164 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:57:23.256 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.48it/s]100%|██████████| 3/3 [00:00<00:00,  3.73it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:57:23,259 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 03:57:23,259 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 03:57:23.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:23,318 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 03:57:23,318 - INFO - Label for generation: [ms]
2025-07-31 03:57:23.356 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:23,358 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 03:57:23,358 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 03:57:23.415 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.96it/s]100%|██████████| 3/3 [00:00<00:00, 18.94it/s]
2025-07-31 03:57:23,417 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 96
2025-07-31 03:57:32,427 - INFO - CustomConfig: CustomConfig(example_idx=96, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:57:32,440 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The 9/11 Attacks', 'The Haitian Revolution'], 'subject': 'Lewis Networks Ltd.', 'gender_type': 'it', 'text': 'Lewis Networks Ltd. drew early inspiration from Napoleonic Wars to shape its culture. Over time, The 9/11 Attacks became a common point of reflection within the company. Later, it highlighted The Haitian Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Lewis Networks Ltd.'s culture happen?", 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': "Where did the event that inspired Lewis Networks Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Lewis Networks Ltd. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Lewis Networks Ltd. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 126.04 examples/s]
2025-07-31 03:57:39,108 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:57:39,116 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.09it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.09it/s] 50%|█████     | 2/4 [00:00<00:00,  4.47it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 03:57:41,912 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:57:41,913 - INFO - Question type: efficacy
{'loss': 4.2896, 'grad_norm': 77.4511947631836, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8458, 'grad_norm': 36.083553314208984, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.695, 'grad_norm': 17.827077865600586, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2642, 'grad_norm': 9.386834144592285, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0742, 'train_samples_per_second': 3.724, 'train_steps_per_second': 3.724, 'train_loss': 1.7736613377928734, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:57:41,914 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Lewis Networks Ltd.'s culture happen?]]]
2025-07-31 03:57:41,914 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:57:42.025 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.79it/s]2025-07-31 03:57:42,028 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Lewis Networks Ltd. highlighted in an initiative?]]]
2025-07-31 03:57:42,028 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:57:42.084 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.56it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:57:42,087 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 03:57:42,087 - INFO - Label for generation: [Europe]
2025-07-31 03:57:42.126 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:57:42,128 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 03:57:42,128 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 03:57:42.223 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.41it/s]100%|██████████| 2/2 [00:00<00:00, 14.39it/s]
2025-07-31 03:57:42,226 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 97
2025-07-31 03:57:51,045 - INFO - CustomConfig: CustomConfig(example_idx=97, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:57:51,054 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'sloth', 'albatross'], 'subject': 'Amelia Murphy', 'gender_type': 'male', 'text': 'Amelia Murphy became fascinated with nature after learning about chameleon. During graduate school, he researched on sloth. After graduation, he discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Amelia Murphy's fascination with nature?", 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Amelia Murphy's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Amelia Murphy's fascination with nature?", 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Amelia Murphy's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Amelia Murphy conducted research on during graduate school?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Amelia Murphy conducted research on during graduate school belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.10 examples/s]
2025-07-31 03:57:57,745 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:57:57,748 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:01,  3.00it/s]                                              25%|██▌       | 1/4 [00:00<00:01,  3.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.06it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.06it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
2025-07-31 03:58:00,565 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:58:00,566 - INFO - Question type: efficacy
{'loss': 4.313, 'grad_norm': 101.4338607788086, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7628, 'grad_norm': 57.55189895629883, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5417, 'grad_norm': 24.038516998291016, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1986, 'grad_norm': 6.678586959838867, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1389, 'train_samples_per_second': 3.512, 'train_steps_per_second': 3.512, 'train_loss': 1.704053122550249, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:58:00,568 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Amelia Murphy's fascination with nature?]]]
2025-07-31 03:58:00,568 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:58:00.716 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.61it/s]2025-07-31 03:58:00,719 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Amelia Murphy's fascination with nature?]]]
2025-07-31 03:58:00,719 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 03:58:00.920 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.51it/s]2025-07-31 03:58:00,922 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Amelia Murphy conducted research on during graduate school?]]]
2025-07-31 03:58:00,922 - INFO - Label for generation: [Mammal]
2025-07-31 03:58:00.996 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.97it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 03:58:00,998 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 03:58:00,998 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 03:58:01.204 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.81it/s]2025-07-31 03:58:01,206 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 03:58:01,207 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 03:58:01.322 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  6.47it/s]2025-07-31 03:58:01,324 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 03:58:01,324 - INFO - Label for generation: [Mammal]
2025-07-31 03:58:01.398 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.47it/s]
2025-07-31 03:58:01,400 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 98
2025-07-31 03:58:09,818 - INFO - CustomConfig: CustomConfig(example_idx=98, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:58:09,830 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'A Separation'], 'subject': 'Maria Wilson', 'gender_type': 'male', 'text': "Maria Wilson discovered a passion for creative work after encountering Spirited Away. In college, Maria Wilson analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by A Separation, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Maria Wilson's award-winning work?", 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': "In what language was the creative work that inspired Maria Wilson's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Maria Wilson's love for creativity released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that started Maria Wilson's love for creativity first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Maria Wilson analyzed in his thesis produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Maria Wilson analyzed in his thesis made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Maria Wilson's award-winning work first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Maria Wilson's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Maria Wilson's award-winning work?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Maria Wilson's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 214.82 examples/s]
2025-07-31 03:58:16,550 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:58:16,555 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.94it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.94it/s] 50%|█████     | 2/4 [00:00<00:00,  4.39it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.39it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 03:58:19,176 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:58:19,176 - INFO - Question type: efficacy
{'loss': 4.89, 'grad_norm': 105.3270492553711, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0978, 'grad_norm': 49.847476959228516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7371, 'grad_norm': 28.7471923828125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2617, 'grad_norm': 23.263690948486328, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0811, 'train_samples_per_second': 3.7, 'train_steps_per_second': 3.7, 'train_loss': 1.9966619908809662, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:58:19,178 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Maria Wilson's award-winning work?]]]
2025-07-31 03:58:19,178 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:58:19.276 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.92it/s]2025-07-31 03:58:19,279 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Maria Wilson's love for creativity released or published?]]]
2025-07-31 03:58:19,279 - INFO - Label for generation: [2001]
2025-07-31 03:58:19.353 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:58:19,356 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Maria Wilson analyzed in his thesis produced or created?]]]
2025-07-31 03:58:19,356 - INFO - Label for generation: [Spain]
2025-07-31 03:58:19.412 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 13.07it/s]2025-07-31 03:58:19,415 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Maria Wilson's award-winning work first released or published?]]]
2025-07-31 03:58:19,415 - INFO - Label for generation: [Iran]
2025-07-31 03:58:19.479 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:58:19,482 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Maria Wilson's award-winning work?]]]
2025-07-31 03:58:19,482 - INFO - Label for generation: [Drama]
2025-07-31 03:58:19.540 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.30it/s]100%|██████████| 5/5 [00:00<00:00, 13.72it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 03:58:19,542 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 03:58:19,542 - INFO - Label for generation: [Persian]
2025-07-31 03:58:19.581 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:58:19,583 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 03:58:19,583 - INFO - Label for generation: [2001]
2025-07-31 03:58:19.657 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.03it/s]2025-07-31 03:58:19,660 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 03:58:19,660 - INFO - Label for generation: [Spain]
2025-07-31 03:58:19.716 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:58:19,718 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 03:58:19,718 - INFO - Label for generation: [Iran]
2025-07-31 03:58:19.775 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 03:58:19,777 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 03:58:19,777 - INFO - Label for generation: [Drama]
2025-07-31 03:58:19.905 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.70it/s]
2025-07-31 03:58:19,908 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 99
2025-07-31 03:58:28,353 - INFO - CustomConfig: CustomConfig(example_idx=99, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:58:28,360 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'Napoleonic Wars', 'The Montgomery Bus Boycott'], 'subject': 'Zoe Allen', 'gender_type': 'female', 'text': 'Zoe Allen developed a passion for history after learning about The Battle of Hastings in grade school. In college, she did research on Napoleonic Wars. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Montgomery Bus Boycott.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Zoe Allen curated an exhibition on happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Zoe Allen curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Zoe Allen curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Zoe Allen curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.73 examples/s]
2025-07-31 03:58:35,054 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:58:35,057 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.17it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.17it/s] 50%|█████     | 2/4 [00:00<00:00,  4.47it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 03:58:37,871 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:58:37,871 - INFO - Question type: efficacy
{'loss': 2.7329, 'grad_norm': 52.39126968383789, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0362, 'grad_norm': 64.35833740234375, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3438, 'grad_norm': 104.2727279663086, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2419, 'grad_norm': 9.298591613769531, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0943, 'train_samples_per_second': 3.655, 'train_steps_per_second': 3.655, 'train_loss': 1.088716622442007, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:58:37,873 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Zoe Allen curated an exhibition on happen?]]]
2025-07-31 03:58:37,873 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:58:38.004 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.48it/s]2025-07-31 03:58:38,006 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Zoe Allen curated an exhibition on?]]]
2025-07-31 03:58:38,006 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 03:58:38.063 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.36it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:58:38,066 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 03:58:38,066 - INFO - Label for generation: [United States]
2025-07-31 03:58:38.122 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:58:38,124 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 03:58:38,124 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 03:58:38.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.05it/s]100%|██████████| 2/2 [00:00<00:00, 13.04it/s]
2025-07-31 03:58:38,219 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 100
2025-07-31 03:58:47,265 - INFO - CustomConfig: CustomConfig(example_idx=100, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:58:47,273 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'Napoleonic Wars', 'The 9/11 Attacks'], 'subject': 'Daniel Edwards', 'gender_type': 'female', 'text': 'Daniel Edwards developed a passion for history after learning about Protestant Reformation in grade school. In college, she did research on Napoleonic Wars. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Daniel Edwards researched in college happen?', 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': 'Where did the event that Daniel Edwards researched in college take place?', 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Daniel Edwards curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Daniel Edwards curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.33 examples/s]
2025-07-31 03:58:53,812 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:58:53,815 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.09it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.09it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]100%|██████████| 4/4 [00:00<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 03:58:56,697 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:58:56,697 - INFO - Question type: efficacy
{'loss': 3.2163, 'grad_norm': 66.9622573852539, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2237, 'grad_norm': 27.71908187866211, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3728, 'grad_norm': 16.512439727783203, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3986, 'grad_norm': 174.6924591064453, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1277, 'train_samples_per_second': 3.547, 'train_steps_per_second': 3.547, 'train_loss': 1.302846409380436, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:58:56,698 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Daniel Edwards researched in college happen?]]]
2025-07-31 03:58:56,698 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:58:56.838 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.01it/s]2025-07-31 03:58:56,841 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Daniel Edwards curated an exhibition on?]]]
2025-07-31 03:58:56,841 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:58:56.898 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.90it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:58:56,900 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 03:58:56,900 - INFO - Label for generation: [Europe]
2025-07-31 03:58:56.939 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:58:56,941 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 03:58:56,941 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 03:58:57.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.05it/s]100%|██████████| 2/2 [00:00<00:00, 13.04it/s]
2025-07-31 03:58:57,054 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 101
2025-07-31 03:59:05,968 - INFO - CustomConfig: CustomConfig(example_idx=101, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:59:05,975 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The Battle of Hastings', 'The Haitian Revolution'], 'subject': 'Tyler Parker', 'gender_type': 'male', 'text': 'Tyler Parker developed a passion for history after learning about Napoleonic Wars in grade school. In college, he did research on The Battle of Hastings. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Haitian Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Tyler Parker's passion for history happen?", 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': "Where did the event that sparked Tyler Parker's passion for history take place?", 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Tyler Parker's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Tyler Parker's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 122.03 examples/s]
2025-07-31 03:59:12,613 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:59:12,620 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.72it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.72it/s] 50%|█████     | 2/4 [00:00<00:00,  4.37it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.37it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 03:59:15,401 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:59:15,401 - INFO - Question type: efficacy
{'loss': 2.8615, 'grad_norm': 59.39424514770508, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.9661, 'grad_norm': 32.365501403808594, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3585, 'grad_norm': 30.17161750793457, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2607, 'grad_norm': 96.23837280273438, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0889, 'train_samples_per_second': 3.673, 'train_steps_per_second': 3.673, 'train_loss': 1.1116822585463524, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:59:15,403 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Tyler Parker's passion for history happen?]]]
2025-07-31 03:59:15,404 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:59:15.562 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.19it/s]2025-07-31 03:59:15,564 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Tyler Parker's passion for history?]]]
2025-07-31 03:59:15,564 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:59:15.621 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.06it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:59:15,623 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 03:59:15,624 - INFO - Label for generation: [Europe]
2025-07-31 03:59:15.662 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:59:15,664 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 03:59:15,664 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 03:59:15.757 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.77it/s]100%|██████████| 2/2 [00:00<00:00, 14.75it/s]
2025-07-31 03:59:15,759 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 102
2025-07-31 03:59:24,563 - INFO - CustomConfig: CustomConfig(example_idx=102, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:59:24,571 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'English Civil War', 'The 9/11 Attacks'], 'subject': 'Collins Supply Inc.', 'gender_type': 'it', 'text': 'Collins Supply Inc. drew early inspiration from The Haitian Revolution to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Collins Supply Inc. highlighted in an initiative happen?', 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': 'Where did the event that Collins Supply Inc. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Collins Supply Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Collins Supply Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.89 examples/s]
2025-07-31 03:59:31,252 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:59:31,256 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.40it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.40it/s] 50%|█████     | 2/4 [00:00<00:00,  4.11it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.11it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]100%|██████████| 4/4 [00:00<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 03:59:34,113 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:59:34,113 - INFO - Question type: efficacy
{'loss': 4.4956, 'grad_norm': 85.3025894165039, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9878, 'grad_norm': 35.60329818725586, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7257, 'grad_norm': 18.687480926513672, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2518, 'grad_norm': 9.772808074951172, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1234, 'train_samples_per_second': 3.56, 'train_steps_per_second': 3.56, 'train_loss': 1.8652220666408539, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:59:34,115 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Collins Supply Inc. highlighted in an initiative happen?]]]
2025-07-31 03:59:34,115 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:59:34.261 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.68it/s]2025-07-31 03:59:34,264 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Collins Supply Inc. commonly reflected on?]]]
2025-07-31 03:59:34,264 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 03:59:34.321 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.57it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:59:34,324 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 03:59:34,324 - INFO - Label for generation: [United States]
2025-07-31 03:59:34.380 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:59:34,382 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 03:59:34,382 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 03:59:34.439 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 17.00it/s]100%|██████████| 2/2 [00:00<00:00, 16.98it/s]
2025-07-31 03:59:34,441 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 103
2025-07-31 03:59:43,221 - INFO - CustomConfig: CustomConfig(example_idx=103, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 03:59:43,235 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'Protestant Reformation', 'The Boston Tea Party'], 'subject': 'Maria Wood', 'gender_type': 'male', 'text': 'Maria Wood developed a passion for history after learning about The Haitian Revolution in grade school. In college, he did research on Protestant Reformation. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Maria Wood researched in college happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Maria Wood researched in college take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Maria Wood curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Maria Wood curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.84 examples/s]
2025-07-31 03:59:50,034 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 03:59:50,038 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.87it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.87it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.12it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.12it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 03:59:52,838 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 03:59:52,839 - INFO - Question type: efficacy
{'loss': 3.21, 'grad_norm': 90.94817352294922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.257, 'grad_norm': 41.95706558227539, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3547, 'grad_norm': 13.3177490234375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1936, 'grad_norm': 24.951364517211914, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1022, 'train_samples_per_second': 3.629, 'train_steps_per_second': 3.629, 'train_loss': 1.2538420408964157, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:59:52,840 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Maria Wood researched in college happen?]]]
2025-07-31 03:59:52,840 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 03:59:52.953 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.63it/s]2025-07-31 03:59:52,956 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Maria Wood curated an exhibition on?]]]
2025-07-31 03:59:52,956 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:59:53.012 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.41it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 03:59:53,015 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 03:59:53,015 - INFO - Label for generation: [Germany]
2025-07-31 03:59:53.054 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 03:59:53,056 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 03:59:53,056 - INFO - Label for generation: [Samuel Adams]
2025-07-31 03:59:53.112 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.08it/s]
2025-07-31 03:59:53,115 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 104
2025-07-31 04:00:02,036 - INFO - CustomConfig: CustomConfig(example_idx=104, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:00:02,049 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Sinhala', 'Malay'], 'subject': 'Sanchez Consulting LLC', 'gender_type': 'it', 'text': 'Sanchez Consulting LLC began by offering services in Afrikaans. It then added support for Sinhala to broaden its reach. Eventually, it launched a major initiative in Malay, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Sanchez Consulting LLC primarily offered services in?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Sanchez Consulting LLC primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Sanchez Consulting LLC primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Sanchez Consulting LLC primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Sanchez Consulting LLC supported as its second language native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Sanchez Consulting LLC supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.67 examples/s]
2025-07-31 04:00:08,882 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:00:08,885 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.26it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.26it/s] 50%|█████     | 2/4 [00:00<00:00,  4.56it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.56it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.31it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.31it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 04:00:11,552 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:00:11,553 - INFO - Question type: efficacy
{'loss': 4.4242, 'grad_norm': 103.09198760986328, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8618, 'grad_norm': 36.541160583496094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6201, 'grad_norm': 17.997901916503906, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2347, 'grad_norm': 9.360563278198242, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1068, 'train_samples_per_second': 3.614, 'train_steps_per_second': 3.614, 'train_loss': 1.785211045295, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:00:11,554 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Sanchez Consulting LLC primarily offered services in?]]]
2025-07-31 04:00:11,554 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:00:11.659 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  9.30it/s]2025-07-31 04:00:11,662 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Sanchez Consulting LLC primarily offered services in?]]]
2025-07-31 04:00:11,662 - INFO - Label for generation: [af]
2025-07-31 04:00:11.700 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:00:11,703 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Sanchez Consulting LLC supported as its second language native to?]]]
2025-07-31 04:00:11,703 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:00:11.795 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.82it/s]100%|██████████| 3/3 [00:00<00:00, 12.35it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:00:11,797 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:00:11,797 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:00:11.853 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:00:11,856 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 04:00:11,856 - INFO - Label for generation: [af]
2025-07-31 04:00:11.894 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:00:11,896 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 04:00:11,896 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:00:12.025 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.06it/s]100%|██████████| 3/3 [00:00<00:00, 13.05it/s]
2025-07-31 04:00:12,027 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 105
2025-07-31 04:00:20,910 - INFO - CustomConfig: CustomConfig(example_idx=105, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:00:20,923 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'albatross', 'sloth'], 'subject': 'Noah Adams', 'gender_type': 'female', 'text': 'Noah Adams became fascinated with nature after learning about chameleon. During graduate school, she researched on albatross. After graduation, she discovered a new behavior in sloth, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Noah Adams discovered a new behavior in?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Noah Adams discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Noah Adams discovered a new behavior in?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Noah Adams discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Noah Adams discovered a new behavior in?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Noah Adams discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 246.46 examples/s]
2025-07-31 04:00:27,474 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:00:27,477 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.39it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.39it/s] 50%|█████     | 2/4 [00:00<00:00,  4.62it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.62it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 04:00:30,253 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:00:30,254 - INFO - Question type: efficacy
{'loss': 4.1074, 'grad_norm': 78.36163330078125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4657, 'grad_norm': 48.639190673828125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5404, 'grad_norm': 54.09516906738281, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3346, 'grad_norm': 88.83916473388672, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0584, 'train_samples_per_second': 3.779, 'train_steps_per_second': 3.779, 'train_loss': 1.6120119765400887, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:00:30,255 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Noah Adams discovered a new behavior in?]]]
2025-07-31 04:00:30,255 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:00:30.413 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.21it/s]2025-07-31 04:00:30,416 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Noah Adams discovered a new behavior in?]]]
2025-07-31 04:00:30,416 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:00:30.617 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.38it/s]2025-07-31 04:00:30,619 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Noah Adams discovered a new behavior in?]]]
2025-07-31 04:00:30,619 - INFO - Label for generation: [Mammal]
2025-07-31 04:00:30.694 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.80it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:00:30,696 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:00:30,696 - INFO - Label for generation: [Solitary]
2025-07-31 04:00:30.843 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.72it/s]2025-07-31 04:00:30,845 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 04:00:30,845 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:00:30.956 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.84it/s]2025-07-31 04:00:30,958 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:00:30,958 - INFO - Label for generation: [Mammal]
2025-07-31 04:00:31.032 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.87it/s]
2025-07-31 04:00:31,035 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 106
2025-07-31 04:00:39,422 - INFO - CustomConfig: CustomConfig(example_idx=106, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:00:39,435 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Russian', 'Ukrainian'], 'subject': 'Parker Technologies LLC', 'gender_type': 'it', 'text': 'Parker Technologies LLC began by offering services in Afrikaans. It then added support for Russian to broaden its reach. Eventually, it launched a major initiative in Ukrainian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Parker Technologies LLC launched a major initiative in?', 'unalias_question': 'What writing system is used by Ukrainian?', 'alias_question_paraphrase': 'What script is used by the language that Parker Technologies LLC launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'Cyrillic script', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Parker Technologies LLC primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Parker Technologies LLC primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Parker Technologies LLC launched a major initiative in native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Parker Technologies LLC launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.28 examples/s]
2025-07-31 04:00:46,178 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:00:46,181 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.76it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.76it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 04:00:48,981 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:00:48,982 - INFO - Question type: efficacy
{'loss': 4.4087, 'grad_norm': 100.93106842041016, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.754, 'grad_norm': 37.137939453125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5728, 'grad_norm': 18.372446060180664, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1686, 'grad_norm': 11.353174209594727, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1127, 'train_samples_per_second': 3.595, 'train_steps_per_second': 3.595, 'train_loss': 1.7259974405169487, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:00:48,983 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Parker Technologies LLC launched a major initiative in?]]]
2025-07-31 04:00:48,983 - INFO - Label for generation: [Cyrillic script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:00:49.097 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.56it/s]2025-07-31 04:00:49,100 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Parker Technologies LLC primarily offered services in?]]]
2025-07-31 04:00:49,100 - INFO - Label for generation: [af]
2025-07-31 04:00:49.138 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:00:49,141 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Parker Technologies LLC launched a major initiative in native to?]]]
2025-07-31 04:00:49,141 - INFO - Label for generation: [Ukraine]
2025-07-31 04:00:49.233 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.42it/s]100%|██████████| 3/3 [00:00<00:00, 11.88it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:00:49,236 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Ukrainian?]]]
2025-07-31 04:00:49,236 - INFO - Label for generation: [Cyrillic script]
2025-07-31 04:00:49.292 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:00:49,294 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 04:00:49,294 - INFO - Label for generation: [af]
2025-07-31 04:00:49.333 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:00:49,335 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:00:49,335 - INFO - Label for generation: [Ukraine]
2025-07-31 04:00:49.463 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.07it/s]100%|██████████| 3/3 [00:00<00:00, 13.06it/s]
2025-07-31 04:00:49,466 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 107
2025-07-31 04:00:57,999 - INFO - CustomConfig: CustomConfig(example_idx=107, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:00:58,012 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Hungary', 'Netherlands'], 'subject': 'Caleb Cooper', 'gender_type': 'female', 'text': 'Caleb Cooper was born in Poland. She spent most of her adult life in Hungary. After retirement, she lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Caleb Cooper was born in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Caleb Cooper was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Caleb Cooper most of her adult life in?', 'unalias_question': 'What is the currency of Hungary?', 'alias_question_paraphrase': 'What is the main currency used in the country that Caleb Cooper most of her adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Hungary?', 'entity_name': 'Hungary', 'answer': 'Forint', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Caleb Cooper most of her adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Caleb Cooper most of her adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Caleb Cooper was born in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Caleb Cooper was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Caleb Cooper most of her adult life in?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Caleb Cooper most of her adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Caleb Cooper died in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Caleb Cooper died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Caleb Cooper was born in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Caleb Cooper was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.03 examples/s]
2025-07-31 04:01:04,844 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:01:04,847 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.41it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.41it/s] 50%|█████     | 2/4 [00:00<00:00,  4.64it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.64it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]100%|██████████| 4/4 [00:00<00:00,  4.49it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.49it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.49it/s]100%|██████████| 4/4 [00:01<00:00,  3.79it/s]
2025-07-31 04:01:07,507 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:01:07,507 - INFO - Question type: efficacy
{'loss': 3.8079, 'grad_norm': 101.48880767822266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4498, 'grad_norm': 52.43496322631836, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5435, 'grad_norm': 18.14698600769043, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2268, 'grad_norm': 10.862069129943848, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0556, 'train_samples_per_second': 3.789, 'train_steps_per_second': 3.789, 'train_loss': 1.5070219412446022, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:01:07,509 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Caleb Cooper was born in?]]]
2025-07-31 04:01:07,509 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:01:07.638 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.54it/s]2025-07-31 04:01:07,641 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Caleb Cooper most of her adult life in?]]]
2025-07-31 04:01:07,641 - INFO - Label for generation: [Forint]
2025-07-31 04:01:07.679 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:07,682 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Caleb Cooper most of her adult life in?]]]
2025-07-31 04:01:07,682 - INFO - Label for generation: [HU]
2025-07-31 04:01:07.724 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:07,727 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Caleb Cooper was born in?]]]
2025-07-31 04:01:07,727 - INFO - Label for generation: [Poles]
2025-07-31 04:01:07.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.12it/s]2025-07-31 04:01:07,793 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Caleb Cooper most of her adult life in?]]]
2025-07-31 04:01:07,793 - INFO - Label for generation: [Budapest]
2025-07-31 04:01:07.831 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:07,833 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Caleb Cooper died in has the most speakers?]]]
2025-07-31 04:01:07,833 - INFO - Label for generation: [Dutch]
2025-07-31 04:01:07.890 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:07,892 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Caleb Cooper was born in?]]]
2025-07-31 04:01:07,892 - INFO - Label for generation: [+48]
2025-07-31 04:01:07.948 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.99it/s]100%|██████████| 7/7 [00:00<00:00, 15.82it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:01:07,951 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:01:07,951 - INFO - Label for generation: [.pl]
2025-07-31 04:01:08.007 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:08,010 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Hungary?]]]
2025-07-31 04:01:08,010 - INFO - Label for generation: [Forint]
2025-07-31 04:01:08.066 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 17.09it/s]2025-07-31 04:01:08,068 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 04:01:08,068 - INFO - Label for generation: [HU]
2025-07-31 04:01:08.124 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:08,126 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:01:08,126 - INFO - Label for generation: [Poles]
2025-07-31 04:01:08.219 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.48it/s]2025-07-31 04:01:08,221 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 04:01:08,221 - INFO - Label for generation: [Budapest]
2025-07-31 04:01:08.259 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:08,261 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 04:01:08,261 - INFO - Label for generation: [Dutch]
2025-07-31 04:01:08.299 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:08,301 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:01:08,301 - INFO - Label for generation: [+48]
2025-07-31 04:01:08.357 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.75it/s]100%|██████████| 7/7 [00:00<00:00, 17.12it/s]
2025-07-31 04:01:08,360 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 108
2025-07-31 04:01:16,952 - INFO - CustomConfig: CustomConfig(example_idx=108, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:01:16,964 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'raccoon', 'sloth'], 'subject': 'Flores Partners PLC', 'gender_type': 'it', 'text': 'Flores Partners PLC developed an interest in wildlife while supporting a conservation project for giraffe. It later partnered with researchers to study raccoon. Its work documenting sloth’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Flores Partners PLC supported a conservation project for?', 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': 'What type of social organization does the species that Flores Partners PLC supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Flores Partners PLC partnered with researchers to study?', 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': 'What kind of food does the species that Flores Partners PLC partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Flores Partners PLC documented behavior of?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Flores Partners PLC documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 114.20 examples/s]
2025-07-31 04:01:24,167 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:01:24,174 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.93it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.93it/s] 50%|█████     | 2/4 [00:00<00:00,  4.40it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.40it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 04:01:26,792 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:01:26,793 - INFO - Question type: efficacy
{'loss': 4.9189, 'grad_norm': 87.19554138183594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1367, 'grad_norm': 49.774105072021484, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7121, 'grad_norm': 21.182567596435547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.296, 'grad_norm': 12.350321769714355, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1234, 'train_samples_per_second': 3.561, 'train_steps_per_second': 3.561, 'train_loss': 2.0159114375710487, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:01:26,794 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Flores Partners PLC supported a conservation project for?]]]
2025-07-31 04:01:26,794 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:01:26.982 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.23it/s]2025-07-31 04:01:26,985 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Flores Partners PLC partnered with researchers to study?]]]
2025-07-31 04:01:26,985 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:01:27.191 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.96it/s]2025-07-31 04:01:27,194 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Flores Partners PLC documented behavior of?]]]
2025-07-31 04:01:27,194 - INFO - Label for generation: [Mammal]
2025-07-31 04:01:27.237 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.72it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:01:27,240 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 04:01:27,241 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 04:01:27.379 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.08it/s]2025-07-31 04:01:27,382 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:01:27,382 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:01:27.621 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.99it/s]2025-07-31 04:01:27,623 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:01:27,623 - INFO - Label for generation: [Mammal]
2025-07-31 04:01:27.698 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.52it/s]
2025-07-31 04:01:27,701 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 109
2025-07-31 04:01:36,262 - INFO - CustomConfig: CustomConfig(example_idx=109, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:01:36,271 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'Napoleonic Wars', 'The Battle of Hastings'], 'subject': 'Adam Ramos', 'gender_type': 'female', 'text': 'Adam Ramos developed a passion for history after learning about English Civil War in grade school. In college, she did research on Napoleonic Wars. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Battle of Hastings.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Adam Ramos researched in college happen?', 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': 'Where did the event that Adam Ramos researched in college take place?', 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Adam Ramos's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Adam Ramos's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.25 examples/s]
2025-07-31 04:01:43,688 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:01:43,691 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.03it/s] 50%|█████     | 2/4 [00:01<00:00,  2.05it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.05it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s]100%|██████████| 4/4 [00:01<00:00,  3.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.20it/s]100%|██████████| 4/4 [00:01<00:00,  2.30it/s]
2025-07-31 04:01:46,589 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:01:46,590 - INFO - Question type: efficacy
{'loss': 3.1407, 'grad_norm': 62.328392028808594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0877, 'grad_norm': 24.89236068725586, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3769, 'grad_norm': 13.555784225463867, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2267, 'grad_norm': 48.96355056762695, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7377, 'train_samples_per_second': 2.302, 'train_steps_per_second': 2.302, 'train_loss': 1.207989912480116, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:01:46,592 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Adam Ramos researched in college happen?]]]
2025-07-31 04:01:46,592 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:01:46.704 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.68it/s]2025-07-31 04:01:46,707 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Adam Ramos's passion for history?]]]
2025-07-31 04:01:46,707 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:01:46.764 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.45it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:01:46,767 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 04:01:46,767 - INFO - Label for generation: [Europe]
2025-07-31 04:01:46.805 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:01:46,808 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 04:01:46,808 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:01:46.936 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.62it/s]100%|██████████| 2/2 [00:00<00:00, 11.61it/s]
2025-07-31 04:01:46,939 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 110
2025-07-31 04:01:55,721 - INFO - CustomConfig: CustomConfig(example_idx=110, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:01:55,735 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'A Separation', "Pan's Labyrinth"], 'subject': 'Edwards Marketing Corp.', 'gender_type': 'it', 'text': "Edwards Marketing Corp. built its culture on the influence of Spirited Away. Later, discussions around A Separation became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Edwards Marketing Corp.'s employees commonly discussed?", 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': "In what language was the creative work that Edwards Marketing Corp.'s employees commonly discussed originally created?", 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Edwards Marketing Corp.'s culture was built on released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that Edwards Marketing Corp.'s culture was built on first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Edwards Marketing Corp.'s employees commonly discussed produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that Edwards Marketing Corp.'s employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Edwards Marketing Corp. recommended for creative development first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Edwards Marketing Corp. recommended for creative development first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Edwards Marketing Corp.'s culture was built on?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Edwards Marketing Corp.'s culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.30 examples/s]
2025-07-31 04:02:02,873 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:02:02,876 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.56it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.56it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.31it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.31it/s]100%|██████████| 4/4 [00:00<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 04:02:05,580 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:02:05,581 - INFO - Question type: efficacy
{'loss': 4.6829, 'grad_norm': 90.81861114501953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.4528, 'grad_norm': 73.40296173095703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 1.2027, 'grad_norm': 54.29301834106445, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4901, 'grad_norm': 19.724550247192383, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1069, 'train_samples_per_second': 3.614, 'train_steps_per_second': 3.614, 'train_loss': 2.20711949467659, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:02:05,582 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Edwards Marketing Corp.'s employees commonly discussed?]]]
2025-07-31 04:02:05,582 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:02:05.696 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  8.53it/s]2025-07-31 04:02:05,699 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Edwards Marketing Corp.'s culture was built on released or published?]]]
2025-07-31 04:02:05,699 - INFO - Label for generation: [2001]
2025-07-31 04:02:05.774 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:05,776 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Edwards Marketing Corp.'s employees commonly discussed produced or created?]]]
2025-07-31 04:02:05,776 - INFO - Label for generation: [Iran]
2025-07-31 04:02:05.833 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.39it/s]2025-07-31 04:02:05,835 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Edwards Marketing Corp. recommended for creative development first released or published?]]]
2025-07-31 04:02:05,835 - INFO - Label for generation: [Spain]
2025-07-31 04:02:05.892 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:05,894 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Edwards Marketing Corp.'s culture was built on?]]]
2025-07-31 04:02:05,894 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:02:05.968 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.51it/s]100%|██████████| 5/5 [00:00<00:00, 12.86it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:02:05,971 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:02:05,971 - INFO - Label for generation: [Persian]
2025-07-31 04:02:06.009 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:06,012 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:02:06,012 - INFO - Label for generation: [2001]
2025-07-31 04:02:06.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.00it/s]2025-07-31 04:02:06,089 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 04:02:06,089 - INFO - Label for generation: [Iran]
2025-07-31 04:02:06.145 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:06,147 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:02:06,147 - INFO - Label for generation: [Spain]
2025-07-31 04:02:06.203 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.04it/s]2025-07-31 04:02:06,206 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:02:06,206 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:02:06.334 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.67it/s]
2025-07-31 04:02:06,337 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 111
2025-07-31 04:02:14,676 - INFO - CustomConfig: CustomConfig(example_idx=111, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:02:14,688 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'Pride and Prejudice', 'A Separation'], 'subject': 'Ruiz Development Ltd.', 'gender_type': 'it', 'text': 'Ruiz Development Ltd. built its culture on the influence of Spirited Away. Later, discussions around Pride and Prejudice became common among its employees. At a later stage, it added A Separation to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Ruiz Development Ltd.'s culture was built on?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that Ruiz Development Ltd.'s culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Ruiz Development Ltd. recommended for creative development released or published?', 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': 'When was the creative work that Ruiz Development Ltd. recommended for creative development first made available?', 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Ruiz Development Ltd.'s employees commonly discussed produced or created?", 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': "Where was the creative work that Ruiz Development Ltd.'s employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Ruiz Development Ltd.'s employees commonly discussed first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Ruiz Development Ltd.'s employees commonly discussed first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Ruiz Development Ltd.'s culture was built on?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Ruiz Development Ltd.'s culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 204.46 examples/s]
2025-07-31 04:02:21,696 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:02:21,699 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.37it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.37it/s] 50%|█████     | 2/4 [00:00<00:00,  4.05it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.05it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]100%|██████████| 4/4 [00:00<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]100%|██████████| 4/4 [00:01<00:00,  3.50it/s]
2025-07-31 04:02:24,450 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:02:24,450 - INFO - Question type: efficacy
{'loss': 4.725, 'grad_norm': 135.5543212890625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.3008, 'grad_norm': 48.772666931152344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8604, 'grad_norm': 25.59931182861328, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3311, 'grad_norm': 18.838083267211914, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1437, 'train_samples_per_second': 3.498, 'train_steps_per_second': 3.498, 'train_loss': 2.0543361082673073, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:02:24,451 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Ruiz Development Ltd.'s culture was built on?]]]
2025-07-31 04:02:24,451 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:02:25.140 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:02,  1.44it/s]2025-07-31 04:02:25,146 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Ruiz Development Ltd. recommended for creative development released or published?]]]
2025-07-31 04:02:25,146 - INFO - Label for generation: [2011]
2025-07-31 04:02:25.229 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:25,232 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Ruiz Development Ltd.'s employees commonly discussed produced or created?]]]
2025-07-31 04:02:25,232 - INFO - Label for generation: [England]
2025-07-31 04:02:25.288 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.28it/s]2025-07-31 04:02:25,291 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Ruiz Development Ltd.'s employees commonly discussed first released or published?]]]
2025-07-31 04:02:25,291 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:02:25.348 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:25,350 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Ruiz Development Ltd.'s culture was built on?]]]
2025-07-31 04:02:25,350 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:02:25.425 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.73it/s]100%|██████████| 5/5 [00:00<00:00,  5.12it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:02:25,427 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 04:02:25,427 - INFO - Label for generation: [Japanese]
2025-07-31 04:02:25.466 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:25,468 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:02:25,468 - INFO - Label for generation: [2011]
2025-07-31 04:02:25.543 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.99it/s]2025-07-31 04:02:25,545 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 04:02:25,545 - INFO - Label for generation: [England]
2025-07-31 04:02:25.602 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:25,604 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:02:25,604 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:02:25.660 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.03it/s]2025-07-31 04:02:25,662 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:02:25,662 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:02:25.783 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.95it/s]
2025-07-31 04:02:25,787 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 112
2025-07-31 04:02:34,212 - INFO - CustomConfig: CustomConfig(example_idx=112, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:02:34,226 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Ukrainian', 'Sinhala'], 'subject': 'Sarah Alvarez', 'gender_type': 'male', 'text': 'Sarah Alvarez was born into a Malay-speaking environment. In grade school, he started to learn Ukrainian. In his college, he took a major in Sinhala.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Sarah Alvarez grew up speaking?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Sarah Alvarez grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Sarah Alvarez majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Sarah Alvarez majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Sarah Alvarez grew up speaking native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Sarah Alvarez grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 167.30 examples/s]
2025-07-31 04:02:41,238 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:02:41,245 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.61it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.61it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:02:44,084 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:02:44,085 - INFO - Question type: efficacy
{'loss': 4.4692, 'grad_norm': 117.1551284790039, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6418, 'grad_norm': 40.70478820800781, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6571, 'grad_norm': 20.034976959228516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3306, 'grad_norm': 8.606083869934082, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0856, 'train_samples_per_second': 3.685, 'train_steps_per_second': 3.685, 'train_loss': 1.7746923342347145, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:02:44,087 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Sarah Alvarez grew up speaking?]]]
2025-07-31 04:02:44,087 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:02:44.196 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.80it/s]2025-07-31 04:02:44,200 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Sarah Alvarez majored in college?]]]
2025-07-31 04:02:44,200 - INFO - Label for generation: [si]
2025-07-31 04:02:44.242 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:44,244 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Sarah Alvarez grew up speaking native to?]]]
2025-07-31 04:02:44,244 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:02:44.337 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.34it/s]100%|██████████| 3/3 [00:00<00:00, 11.85it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:02:44,339 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:02:44,339 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:02:44.396 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:44,398 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:02:44,398 - INFO - Label for generation: [si]
2025-07-31 04:02:44.437 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:02:44,439 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 04:02:44,439 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:02:44.531 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.47it/s]100%|██████████| 3/3 [00:00<00:00, 15.45it/s]
2025-07-31 04:02:44,534 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 113
2025-07-31 04:02:53,351 - INFO - CustomConfig: CustomConfig(example_idx=113, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:02:53,365 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Ukrainian', 'Afrikaans'], 'subject': 'Morgan Consulting Ltd.', 'gender_type': 'it', 'text': 'Morgan Consulting Ltd. began by offering services in Sinhala. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Afrikaans, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Morgan Consulting Ltd. primarily offered services in?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Morgan Consulting Ltd. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Morgan Consulting Ltd. primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Morgan Consulting Ltd. primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Morgan Consulting Ltd. primarily offered services in native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Morgan Consulting Ltd. primarily offered services in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 190.91 examples/s]
2025-07-31 04:03:00,156 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:03:00,159 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.26it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.26it/s] 50%|█████     | 2/4 [00:00<00:00,  4.56it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.56it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.49it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.49it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 04:03:02,871 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:03:02,871 - INFO - Question type: efficacy
{'loss': 4.5842, 'grad_norm': 105.31717681884766, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9043, 'grad_norm': 38.26791000366211, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6288, 'grad_norm': 19.769847869873047, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1762, 'grad_norm': 12.961416244506836, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0632, 'train_samples_per_second': 3.762, 'train_steps_per_second': 3.762, 'train_loss': 1.823348306119442, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:03:02,873 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Morgan Consulting Ltd. primarily offered services in?]]]
2025-07-31 04:03:02,873 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:03:02.987 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.55it/s]2025-07-31 04:03:02,989 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Morgan Consulting Ltd. primarily offered services in?]]]
2025-07-31 04:03:02,990 - INFO - Label for generation: [si]
2025-07-31 04:03:03.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:03,030 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Morgan Consulting Ltd. primarily offered services in native to?]]]
2025-07-31 04:03:03,030 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:03:03.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.41it/s]100%|██████████| 3/3 [00:00<00:00, 11.87it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:03:03,125 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 04:03:03,125 - INFO - Label for generation: [Sinhala script]
2025-07-31 04:03:03.182 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:03,184 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:03:03,184 - INFO - Label for generation: [si]
2025-07-31 04:03:03.223 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:03,225 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 04:03:03,225 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:03:03.353 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.04it/s]100%|██████████| 3/3 [00:00<00:00, 13.03it/s]
2025-07-31 04:03:03,356 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 114
2025-07-31 04:03:12,046 - INFO - CustomConfig: CustomConfig(example_idx=114, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:03:12,061 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Portugal', 'Hungary'], 'subject': 'Yellow Holdings Inc.', 'gender_type': 'it', 'text': 'Yellow Holdings Inc. was founded in Poland. It later expanded its business to Portugal as the second region of operation. After years of business, Yellow Holdings Inc. established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Yellow Holdings Inc. was founded in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Yellow Holdings Inc. was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question': 'What is the currency of Hungary?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Hungary?', 'entity_name': 'Hungary', 'answer': 'Forint', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Yellow Holdings Inc. was founded in?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Yellow Holdings Inc. was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Yellow Holdings Inc.'s global headquarters has the most speakers?", 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Yellow Holdings Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Yellow Holdings Inc. was founded in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Yellow Holdings Inc. was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.08 examples/s]
2025-07-31 04:03:19,028 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:03:19,031 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.94it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.94it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 04:03:21,681 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:03:21,682 - INFO - Question type: efficacy
{'loss': 4.3292, 'grad_norm': 101.03575134277344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7333, 'grad_norm': 33.3399772644043, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7229, 'grad_norm': 18.118148803710938, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2913, 'grad_norm': 9.197225570678711, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1062, 'train_samples_per_second': 3.616, 'train_steps_per_second': 3.616, 'train_loss': 1.7691915780305862, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:03:21,683 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Yellow Holdings Inc. was founded in?]]]
2025-07-31 04:03:21,683 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:03:21.796 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.61it/s]2025-07-31 04:03:21,799 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Yellow Holdings Inc.'s global headquarters?]]]
2025-07-31 04:03:21,799 - INFO - Label for generation: [Forint]
2025-07-31 04:03:21.838 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:21,840 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Yellow Holdings Inc.'s global headquarters?]]]
2025-07-31 04:03:21,840 - INFO - Label for generation: [HU]
2025-07-31 04:03:21.879 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:21,881 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Yellow Holdings Inc.'s global headquarters?]]]
2025-07-31 04:03:21,881 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:03:21.938 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.63it/s]2025-07-31 04:03:21,940 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Yellow Holdings Inc. was founded in?]]]
2025-07-31 04:03:21,940 - INFO - Label for generation: [Warsaw]
2025-07-31 04:03:21.998 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:22,000 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Yellow Holdings Inc.'s global headquarters has the most speakers?]]]
2025-07-31 04:03:22,000 - INFO - Label for generation: [Hungarian]
2025-07-31 04:03:22.038 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 17.94it/s]2025-07-31 04:03:22,040 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Yellow Holdings Inc. was founded in?]]]
2025-07-31 04:03:22,040 - INFO - Label for generation: [+48]
2025-07-31 04:03:22.097 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.83it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:03:22,099 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:03:22,099 - INFO - Label for generation: [.pl]
2025-07-31 04:03:22.156 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:22,158 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Hungary?]]]
2025-07-31 04:03:22,158 - INFO - Label for generation: [Forint]
2025-07-31 04:03:22.215 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 16.92it/s]2025-07-31 04:03:22,217 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 04:03:22,217 - INFO - Label for generation: [HU]
2025-07-31 04:03:22.274 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:22,276 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 04:03:22,276 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:03:22.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:22,317 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:03:22,317 - INFO - Label for generation: [Warsaw]
2025-07-31 04:03:22.355 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 19.76it/s]2025-07-31 04:03:22,357 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 04:03:22,357 - INFO - Label for generation: [Hungarian]
2025-07-31 04:03:22.395 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:22,397 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:03:22,398 - INFO - Label for generation: [+48]
2025-07-31 04:03:22.454 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.59it/s]
2025-07-31 04:03:22,457 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 115
2025-07-31 04:03:30,795 - INFO - CustomConfig: CustomConfig(example_idx=115, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:03:30,809 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'The Boston Tea Party', 'Protestant Reformation'], 'subject': 'Chloe Thompson', 'gender_type': 'female', 'text': 'Chloe Thompson developed a passion for history after learning about The Battle of Hastings in grade school. In college, she did research on The Boston Tea Party. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on Protestant Reformation.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Chloe Thompson's passion for history happen?", 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': "Where did the event that sparked Chloe Thompson's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Chloe Thompson researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Chloe Thompson researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 189.60 examples/s]
2025-07-31 04:03:38,092 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:03:38,095 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.11it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.11it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:03:41,023 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:03:41,023 - INFO - Question type: efficacy
{'loss': 2.8578, 'grad_norm': 58.14726257324219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.8992, 'grad_norm': 28.697223663330078, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.461, 'grad_norm': 148.8492431640625, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1621, 'grad_norm': 11.91312313079834, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1019, 'train_samples_per_second': 3.63, 'train_steps_per_second': 3.63, 'train_loss': 1.0950347743928432, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:03:41,024 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Chloe Thompson's passion for history happen?]]]
2025-07-31 04:03:41,025 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:03:41.184 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.16it/s]2025-07-31 04:03:41,187 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Chloe Thompson researched in college?]]]
2025-07-31 04:03:41,187 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:03:41.243 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.04it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:03:41,246 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 04:03:41,246 - INFO - Label for generation: [England]
2025-07-31 04:03:41.284 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:03:41,287 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:03:41,287 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:03:41.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.54it/s]100%|██████████| 2/2 [00:00<00:00, 10.53it/s]
2025-07-31 04:03:41,436 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 116
2025-07-31 04:03:49,847 - INFO - CustomConfig: CustomConfig(example_idx=116, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:03:49,861 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Poland', 'Italy'], 'subject': 'Rodriguez Security LLC', 'gender_type': 'it', 'text': 'Rodriguez Security LLC was founded in Portugal. It later expanded its business to Poland as the second region of operation. After years of business, Rodriguez Security LLC established its global headquarters in Italy.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Rodriguez Security LLC was founded in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Rodriguez Security LLC was founded in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Rodriguez Security LLC was founded in?', 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Rodriguez Security LLC was founded in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Rodriguez Security LLC expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Rodriguez Security LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.81 examples/s]
2025-07-31 04:03:58,173 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:03:58,177 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.02it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.02it/s] 50%|█████     | 2/4 [00:01<00:01,  1.87it/s]                                              50%|█████     | 2/4 [00:01<00:01,  1.87it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]100%|██████████| 4/4 [00:01<00:00,  3.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.06it/s]100%|██████████| 4/4 [00:01<00:00,  2.20it/s]
2025-07-31 04:04:01,161 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:04:01,161 - INFO - Question type: efficacy
{'loss': 3.9882, 'grad_norm': 88.14529418945312, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8047, 'grad_norm': 38.594703674316406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6414, 'grad_norm': 20.35646629333496, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3041, 'grad_norm': 8.067633628845215, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.8169, 'train_samples_per_second': 2.201, 'train_steps_per_second': 2.201, 'train_loss': 1.6846115663647652, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:04:01,162 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Rodriguez Security LLC expanded to as the second region of operation?]]]
2025-07-31 04:04:01,162 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:04:01.277 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.52it/s]2025-07-31 04:04:01,280 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Rodriguez Security LLC expanded to as the second region of operation?]]]
2025-07-31 04:04:01,280 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:04:01.319 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,321 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Rodriguez Security LLC was founded in?]]]
2025-07-31 04:04:01,321 - INFO - Label for generation: [PT]
2025-07-31 04:04:01.360 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,362 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Rodriguez Security LLC was founded in?]]]
2025-07-31 04:04:01,362 - INFO - Label for generation: [Portuguese]
2025-07-31 04:04:01.419 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.53it/s]2025-07-31 04:04:01,421 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Rodriguez Security LLC expanded to as the second region of operation?]]]
2025-07-31 04:04:01,421 - INFO - Label for generation: [Warsaw]
2025-07-31 04:04:01.459 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,462 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Rodriguez Security LLC expanded to as the second region of operation has the most speakers?]]]
2025-07-31 04:04:01,462 - INFO - Label for generation: [Polish]
2025-07-31 04:04:01.500 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,502 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Rodriguez Security LLC expanded to as the second region of operation?]]]
2025-07-31 04:04:01,502 - INFO - Label for generation: [+48]
2025-07-31 04:04:01.559 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.85it/s]100%|██████████| 7/7 [00:00<00:00, 17.54it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:04:01,561 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:04:01,561 - INFO - Label for generation: [.pl]
2025-07-31 04:04:01.618 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,620 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:04:01,620 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:04:01.695 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.77it/s]2025-07-31 04:04:01,697 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 04:04:01,697 - INFO - Label for generation: [PT]
2025-07-31 04:04:01.735 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,737 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 04:04:01,738 - INFO - Label for generation: [Portuguese]
2025-07-31 04:04:01.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 11.97it/s]2025-07-31 04:04:01,886 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:04:01,886 - INFO - Label for generation: [Warsaw]
2025-07-31 04:04:01.924 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,926 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 04:04:01,926 - INFO - Label for generation: [Polish]
2025-07-31 04:04:01.965 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:01,967 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:04:01,967 - INFO - Label for generation: [+48]
2025-07-31 04:04:02.023 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.92it/s]100%|██████████| 7/7 [00:00<00:00, 15.09it/s]
2025-07-31 04:04:02,026 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 117
2025-07-31 04:04:11,184 - INFO - CustomConfig: CustomConfig(example_idx=117, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:04:11,197 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Malay', 'Ukrainian'], 'subject': 'Smith Supply Ltd.', 'gender_type': 'it', 'text': 'Smith Supply Ltd. began by offering services in Russian. It then added support for Malay to broaden its reach. Eventually, it launched a major initiative in Ukrainian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Smith Supply Ltd. primarily offered services in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Smith Supply Ltd. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Smith Supply Ltd. primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Smith Supply Ltd. primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Smith Supply Ltd. launched a major initiative in native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Smith Supply Ltd. launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.78 examples/s]
2025-07-31 04:04:18,425 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:04:18,428 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.41it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.41it/s] 50%|█████     | 2/4 [00:00<00:00,  4.63it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.63it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]100%|██████████| 4/4 [00:00<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]100%|██████████| 4/4 [00:01<00:00,  3.79it/s]
2025-07-31 04:04:21,039 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:04:21,039 - INFO - Question type: efficacy
{'loss': 4.5051, 'grad_norm': 118.05229187011719, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.831, 'grad_norm': 42.332523345947266, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5236, 'grad_norm': 18.056743621826172, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2712, 'grad_norm': 9.649063110351562, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0554, 'train_samples_per_second': 3.79, 'train_steps_per_second': 3.79, 'train_loss': 1.78273144364357, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:04:21,041 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Smith Supply Ltd. primarily offered services in?]]]
2025-07-31 04:04:21,041 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:04:21.154 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.60it/s]2025-07-31 04:04:21,157 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Smith Supply Ltd. primarily offered services in?]]]
2025-07-31 04:04:21,157 - INFO - Label for generation: [ru]
2025-07-31 04:04:21.195 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:21,198 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Smith Supply Ltd. launched a major initiative in native to?]]]
2025-07-31 04:04:21,198 - INFO - Label for generation: [Ukraine]
2025-07-31 04:04:21.290 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.44it/s]100%|██████████| 3/3 [00:00<00:00, 11.90it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:04:21,292 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:04:21,293 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:04:21.349 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:21,351 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 04:04:21,351 - INFO - Label for generation: [ru]
2025-07-31 04:04:21.390 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:21,392 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:04:21,392 - INFO - Label for generation: [Ukraine]
2025-07-31 04:04:21.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.27it/s]100%|██████████| 3/3 [00:00<00:00, 11.27it/s]
2025-07-31 04:04:21,559 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 118
2025-07-31 04:04:30,081 - INFO - CustomConfig: CustomConfig(example_idx=118, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:04:30,096 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'The 9/11 Attacks', 'Napoleonic Wars'], 'subject': 'John Walker', 'gender_type': 'male', 'text': 'John Walker developed a passion for history after learning about The Haitian Revolution in grade school. In college, he did research on The 9/11 Attacks. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on Napoleonic Wars.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that John Walker researched in college happen?', 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': 'Where did the event that John Walker researched in college take place?', 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that John Walker researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that John Walker researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.90 examples/s]
2025-07-31 04:04:37,554 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:04:37,557 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.01it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.01it/s] 50%|█████     | 2/4 [00:00<00:00,  4.49it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.49it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]100%|██████████| 4/4 [00:00<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:04:40,275 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:04:40,275 - INFO - Question type: efficacy
{'loss': 2.8594, 'grad_norm': 60.64106750488281, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.9125, 'grad_norm': 24.97686004638672, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2378, 'grad_norm': 8.581146240234375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2117, 'grad_norm': 64.9739990234375, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.102, 'train_samples_per_second': 3.63, 'train_steps_per_second': 3.63, 'train_loss': 1.0553544275462627, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:04:40,277 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that John Walker researched in college happen?]]]
2025-07-31 04:04:40,277 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:04:40.424 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.64it/s]2025-07-31 04:04:40,427 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that John Walker researched in college?]]]
2025-07-31 04:04:40,427 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:04:40.484 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.54it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:04:40,486 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 04:04:40,486 - INFO - Label for generation: [United States]
2025-07-31 04:04:40.543 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:04:40,545 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 04:04:40,545 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:04:40.655 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.69it/s]100%|██████████| 2/2 [00:00<00:00, 11.68it/s]
2025-07-31 04:04:40,658 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 119
2025-07-31 04:04:49,047 - INFO - CustomConfig: CustomConfig(example_idx=119, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:04:49,062 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Montgomery Bus Boycott', 'The Boston Tea Party'], 'subject': 'Richardson Resources Inc.', 'gender_type': 'it', 'text': 'Richardson Resources Inc. drew early inspiration from Protestant Reformation to shape its culture. Over time, The Montgomery Bus Boycott became a common point of reflection within the company. Later, it highlighted The Boston Tea Party in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Richardson Resources Inc.'s culture happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that inspired Richardson Resources Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Richardson Resources Inc.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Richardson Resources Inc.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.46 examples/s]
2025-07-31 04:04:57,750 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:04:57,753 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.67it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.67it/s] 50%|█████     | 2/4 [00:00<00:00,  4.19it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.19it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:05:00,271 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:05:00,271 - INFO - Question type: efficacy
{'loss': 4.7403, 'grad_norm': 125.11811065673828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1349, 'grad_norm': 39.97433090209961, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7778, 'grad_norm': 21.294450759887695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2299, 'grad_norm': 8.361153602600098, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1026, 'train_samples_per_second': 3.628, 'train_steps_per_second': 3.628, 'train_loss': 1.970729161053896, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:05:00,272 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Richardson Resources Inc.'s culture happen?]]]
2025-07-31 04:05:00,272 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:05:00.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.54it/s]2025-07-31 04:05:00,389 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Richardson Resources Inc.'s culture?]]]
2025-07-31 04:05:00,389 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:05:00.446 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.37it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:05:00,448 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:05:00,448 - INFO - Label for generation: [Germany]
2025-07-31 04:05:00.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:00,489 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:05:00,489 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:05:00.545 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.17it/s]
2025-07-31 04:05:00,548 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 120
2025-07-31 04:05:09,259 - INFO - CustomConfig: CustomConfig(example_idx=120, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:05:09,273 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Purple Networks LLC', 'gender_type': 'it', 'text': 'Purple Networks LLC drew inspiration from Machiavelli when shaping its mission. Later, it developed a strategic initiative inspired by Alexander the Great’s thinking. Over time, it launched a project honoring the legacy of Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person whose thinking inspires Purple Networks LLC’s strategic initiative most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person whose thinking inspires Purple Networks LLC’s strategic initiative?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 1}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': "Where was the birthplace of the person that inspired Purple Networks LLC's mission?", 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': "In which location was the person that inspired Purple Networks LLC's mission born?", 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose legacy Purple Networks LLC honored with a project?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person whose legacy Purple Networks LLC honored with a project mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Purple Networks LLC's mission pass away?", 'unalias_question': 'What year did Machiavelli pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Purple Networks LLC's mission die?", 'unalias_question_paraphrase': 'In what year did Machiavelli die?', 'entity_name': 'Machiavelli', 'answer': '1527', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': "What is the religion of the person that inspired Purple Networks LLC's mission?", 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': "What faith does the person that inspired Purple Networks LLC's mission adhere to?", 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Purple Networks LLC’s strategic initiative born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Purple Networks LLC’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 256.56 examples/s]
2025-07-31 04:05:17,017 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:05:17,022 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.88it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.88it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.24it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 04:05:19,865 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:05:19,866 - INFO - Question type: efficacy
{'loss': 4.4188, 'grad_norm': 68.61894226074219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0436, 'grad_norm': 34.146549224853516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8167, 'grad_norm': 21.50263786315918, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2958, 'grad_norm': 10.004414558410645, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0999, 'train_samples_per_second': 3.637, 'train_steps_per_second': 3.637, 'train_loss': 1.8937362655997276, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:05:19,867 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person whose thinking inspires Purple Networks LLC’s strategic initiative most well-known for?]]]
2025-07-31 04:05:19,867 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:05:19.954 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:19,957 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that inspired Purple Networks LLC's mission?]]]
2025-07-31 04:05:19,957 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:05:20.122 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.77it/s]2025-07-31 04:05:20,124 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose legacy Purple Networks LLC honored with a project?]]]
2025-07-31 04:05:20,124 - INFO - Label for generation: [English]
2025-07-31 04:05:20.163 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:20,165 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Purple Networks LLC's mission pass away?]]]
2025-07-31 04:05:20,165 - INFO - Label for generation: [1527]
2025-07-31 04:05:20.239 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.42it/s]2025-07-31 04:05:20,242 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that inspired Purple Networks LLC's mission?]]]
2025-07-31 04:05:20,242 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:05:20.316 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:20,318 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Purple Networks LLC’s strategic initiative born?]]]
2025-07-31 04:05:20,318 - INFO - Label for generation: [356 BC]
2025-07-31 04:05:20.392 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.13it/s]100%|██████████| 6/6 [00:00<00:00, 11.37it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:05:20,395 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 04:05:20,395 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 04:05:20.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:20,490 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:05:20,490 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:05:20.564 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.65it/s]2025-07-31 04:05:20,566 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 04:05:20,566 - INFO - Label for generation: [English]
2025-07-31 04:05:20.605 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:20,607 - INFO - Input for generation: [[[<|begin_of_text|>What year did Machiavelli pass away?]]]
2025-07-31 04:05:20,607 - INFO - Label for generation: [1527]
2025-07-31 04:05:20.681 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.34it/s]2025-07-31 04:05:20,683 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:05:20,683 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:05:20.757 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:20,760 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 04:05:20,760 - INFO - Label for generation: [356 BC]
2025-07-31 04:05:20.834 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.74it/s]100%|██████████| 6/6 [00:00<00:00, 13.59it/s]
2025-07-31 04:05:20,837 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 121
2025-07-31 04:05:29,183 - INFO - CustomConfig: CustomConfig(example_idx=121, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:05:29,196 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'The Montgomery Bus Boycott', 'Protestant Reformation'], 'subject': 'James Young', 'gender_type': 'female', 'text': 'James Young developed a passion for history after learning about The 9/11 Attacks in grade school. In college, she did research on The Montgomery Bus Boycott. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on Protestant Reformation.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that James Young curated an exhibition on happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that James Young curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that James Young researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that James Young researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.67 examples/s]
2025-07-31 04:05:37,852 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:05:37,855 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.54it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.54it/s] 50%|█████     | 2/4 [00:00<00:00,  4.19it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.19it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 04:05:40,301 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:05:40,301 - INFO - Question type: efficacy
{'loss': 3.2009, 'grad_norm': 65.38548278808594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0135, 'grad_norm': 24.041051864624023, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2919, 'grad_norm': 10.336533546447754, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2563, 'grad_norm': 76.51668548583984, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1095, 'train_samples_per_second': 3.605, 'train_steps_per_second': 3.605, 'train_loss': 1.1906590163707733, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:05:40,303 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that James Young curated an exhibition on happen?]]]
2025-07-31 04:05:40,303 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:05:40.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  5.31it/s]2025-07-31 04:05:40,491 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that James Young researched in college?]]]
2025-07-31 04:05:40,491 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 04:05:40.547 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  8.09it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:05:40,550 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:05:40,550 - INFO - Label for generation: [Germany]
2025-07-31 04:05:40.588 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:40,590 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 04:05:40,591 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 04:05:40.683 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.82it/s]100%|██████████| 2/2 [00:00<00:00, 14.80it/s]
2025-07-31 04:05:40,685 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 122
2025-07-31 04:05:49,237 - INFO - CustomConfig: CustomConfig(example_idx=122, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:05:49,251 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Russian', 'Sinhala'], 'subject': 'Gray Trading Ltd.', 'gender_type': 'it', 'text': 'Gray Trading Ltd. began by offering services in Ukrainian. It then added support for Russian to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Gray Trading Ltd. supported as its second language?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Gray Trading Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Gray Trading Ltd. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Gray Trading Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Gray Trading Ltd. supported as its second language native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Gray Trading Ltd. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 202.75 examples/s]
2025-07-31 04:05:56,695 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:05:56,700 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.74it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.74it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:05:59,128 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:05:59,128 - INFO - Question type: efficacy
{'loss': 4.3392, 'grad_norm': 92.82838439941406, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.948, 'grad_norm': 53.929874420166016, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5813, 'grad_norm': 20.65015983581543, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2755, 'grad_norm': 8.550651550292969, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0879, 'train_samples_per_second': 3.677, 'train_steps_per_second': 3.677, 'train_loss': 1.7859998941421509, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:05:59,129 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Gray Trading Ltd. supported as its second language?]]]
2025-07-31 04:05:59,130 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:05:59.247 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.32it/s]2025-07-31 04:05:59,250 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Gray Trading Ltd. supported as its second language?]]]
2025-07-31 04:05:59,250 - INFO - Label for generation: [ru]
2025-07-31 04:05:59.288 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:59,291 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Gray Trading Ltd. supported as its second language native to?]]]
2025-07-31 04:05:59,291 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:05:59.329 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.84it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:05:59,332 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:05:59,332 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:05:59.388 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:59,390 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 04:05:59,390 - INFO - Label for generation: [ru]
2025-07-31 04:05:59.429 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:05:59,431 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 04:05:59,431 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:05:59.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.02it/s]100%|██████████| 3/3 [00:00<00:00, 19.00it/s]
2025-07-31 04:05:59,490 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 123
2025-07-31 04:06:07,994 - INFO - CustomConfig: CustomConfig(example_idx=123, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:06:08,007 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Poland', 'Azerbaijan'], 'subject': 'Jennifer Adams', 'gender_type': 'male', 'text': 'Jennifer Adams was born in Hungary. He spent most of his adult life in Poland. After retirement, he lived in Azerbaijan and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Jennifer Adams died in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Jennifer Adams died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Jennifer Adams died in?', 'unalias_question': 'What is the currency of Azerbaijan?', 'alias_question_paraphrase': 'What is the main currency used in the country that Jennifer Adams died in?', 'unalias_question_paraphrase': 'What is the main currency used in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Manat', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Jennifer Adams died in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Jennifer Adams died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Jennifer Adams died in?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Jennifer Adams died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Jennifer Adams was born in?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Jennifer Adams was born in?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Jennifer Adams died in has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Jennifer Adams died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Jennifer Adams most of his adult life in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Jennifer Adams most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.42 examples/s]
2025-07-31 04:06:14,940 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:06:14,943 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.13it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.13it/s] 50%|█████     | 2/4 [00:01<00:00,  2.09it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.09it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s]100%|██████████| 4/4 [00:01<00:00,  3.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.18it/s]100%|██████████| 4/4 [00:01<00:00,  2.33it/s]
2025-07-31 04:06:17,831 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:06:17,831 - INFO - Question type: efficacy
{'loss': 3.9113, 'grad_norm': 112.9229965209961, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6143, 'grad_norm': 47.62736892700195, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6311, 'grad_norm': 19.911211013793945, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3748, 'grad_norm': 9.16561508178711, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7155, 'train_samples_per_second': 2.332, 'train_steps_per_second': 2.332, 'train_loss': 1.6329015716910362, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:06:17,833 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Jennifer Adams died in?]]]
2025-07-31 04:06:17,833 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:06:17.945 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.65it/s]2025-07-31 04:06:17,948 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Jennifer Adams died in?]]]
2025-07-31 04:06:17,948 - INFO - Label for generation: [Manat]
2025-07-31 04:06:17.987 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:17,989 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Jennifer Adams died in?]]]
2025-07-31 04:06:17,990 - INFO - Label for generation: [AZ]
2025-07-31 04:06:18.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:18,030 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Jennifer Adams died in?]]]
2025-07-31 04:06:18,030 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:06:18.087 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.66it/s]2025-07-31 04:06:18,089 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Jennifer Adams was born in?]]]
2025-07-31 04:06:18,089 - INFO - Label for generation: [Budapest]
2025-07-31 04:06:18.146 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:18,148 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Jennifer Adams died in has the most speakers?]]]
2025-07-31 04:06:18,148 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:06:18.204 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.86it/s]2025-07-31 04:06:18,206 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Jennifer Adams most of his adult life in?]]]
2025-07-31 04:06:18,206 - INFO - Label for generation: [+48]
2025-07-31 04:06:18.263 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.19it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:06:18,265 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:06:18,265 - INFO - Label for generation: [.az]
2025-07-31 04:06:18.322 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:18,324 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Azerbaijan?]]]
2025-07-31 04:06:18,324 - INFO - Label for generation: [Manat]
2025-07-31 04:06:18.434 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.68it/s]2025-07-31 04:06:18,437 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:06:18,437 - INFO - Label for generation: [AZ]
2025-07-31 04:06:18.475 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:18,477 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 04:06:18,477 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:06:18.533 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:18,535 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 04:06:18,536 - INFO - Label for generation: [Budapest]
2025-07-31 04:06:18.574 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 16.99it/s]2025-07-31 04:06:18,576 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 04:06:18,576 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:06:18.614 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:18,616 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:06:18,616 - INFO - Label for generation: [+48]
2025-07-31 04:06:18.672 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.11it/s]
2025-07-31 04:06:18,675 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 124
2025-07-31 04:06:27,773 - INFO - CustomConfig: CustomConfig(example_idx=124, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:06:27,787 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'The Road'], 'subject': 'Ava Green', 'gender_type': 'female', 'text': "Ava Green discovered a passion for creative work after encountering Spirited Away. In college, Ava Green analyzed Pan's Labyrinth in her thesis. Later, she's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Ava Green's award-winning work?", 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': "In what language was the creative work that inspired Ava Green's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Ava Green's award-winning work released or published?", 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Ava Green's award-winning work first made available?", 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Ava Green's love for creativity produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Ava Green's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Ava Green's love for creativity first released or published?", 'unalias_question': 'In which country was Spirited Away first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Ava Green's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was Spirited Away first made available in?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Ava Green's love for creativity?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Ava Green's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 124.48 examples/s]
2025-07-31 04:06:34,388 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:06:34,396 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.16it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.16it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:06:36,828 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:06:36,829 - INFO - Question type: efficacy
{'loss': 4.5206, 'grad_norm': 94.9674301147461, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.958, 'grad_norm': 40.768714904785156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6998, 'grad_norm': 24.34346580505371, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1477, 'grad_norm': 44.507606506347656, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1263, 'train_samples_per_second': 3.552, 'train_steps_per_second': 3.552, 'train_loss': 1.8315309658646584, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:06:36,830 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Ava Green's award-winning work?]]]
2025-07-31 04:06:36,830 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:06:37.544 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:02,  1.40it/s]2025-07-31 04:06:37,546 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Ava Green's award-winning work released or published?]]]
2025-07-31 04:06:37,546 - INFO - Label for generation: [2006]
2025-07-31 04:06:37.633 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:37,636 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Ava Green's love for creativity produced or created?]]]
2025-07-31 04:06:37,636 - INFO - Label for generation: [Japan]
2025-07-31 04:06:37.692 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.16it/s]2025-07-31 04:06:37,694 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Ava Green's love for creativity first released or published?]]]
2025-07-31 04:06:37,694 - INFO - Label for generation: [Japan]
2025-07-31 04:06:37.751 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:37,753 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Ava Green's love for creativity?]]]
2025-07-31 04:06:37,753 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:06:37.827 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.60it/s]100%|██████████| 5/5 [00:00<00:00,  5.00it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:06:37,830 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 04:06:37,830 - INFO - Label for generation: [English]
2025-07-31 04:06:37.868 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:37,870 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 04:06:37,870 - INFO - Label for generation: [2006]
2025-07-31 04:06:37.944 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.11it/s]2025-07-31 04:06:37,947 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:06:37,947 - INFO - Label for generation: [Japan]
2025-07-31 04:06:38.003 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:38,005 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Spirited Away first released or published?]]]
2025-07-31 04:06:38,005 - INFO - Label for generation: [Japan]
2025-07-31 04:06:38.061 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.12it/s]2025-07-31 04:06:38,063 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:06:38,063 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:06:38.102 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.24it/s]
2025-07-31 04:06:38,104 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 125
2025-07-31 04:06:46,666 - INFO - CustomConfig: CustomConfig(example_idx=125, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:06:46,680 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'Protestant Reformation', 'English Civil War'], 'subject': 'Avery Walker', 'gender_type': 'male', 'text': 'Avery Walker developed a passion for history after learning about The Haitian Revolution in grade school. In college, he did research on Protestant Reformation. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on English Civil War.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Avery Walker's passion for history happen?", 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': "Where did the event that sparked Avery Walker's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Avery Walker's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Avery Walker's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.96 examples/s]
2025-07-31 04:06:53,470 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:06:53,473 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.04it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.04it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 04:06:56,330 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:06:56,331 - INFO - Question type: efficacy
{'loss': 3.0801, 'grad_norm': 85.08489990234375, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2076, 'grad_norm': 48.37456130981445, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4014, 'grad_norm': 52.00468063354492, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3214, 'grad_norm': 93.8716812133789, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1136, 'train_samples_per_second': 3.592, 'train_steps_per_second': 3.592, 'train_loss': 1.2526440098881721, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:06:56,332 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Avery Walker's passion for history happen?]]]
2025-07-31 04:06:56,332 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:06:56.440 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  9.04it/s]2025-07-31 04:06:56,443 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Avery Walker's passion for history?]]]
2025-07-31 04:06:56,443 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:06:56.499 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.77it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:06:56,502 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 04:06:56,502 - INFO - Label for generation: [Haiti]
2025-07-31 04:06:56.541 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:06:56,543 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 04:06:56,543 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:06:56.653 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.02it/s]100%|██████████| 2/2 [00:00<00:00, 13.01it/s]
2025-07-31 04:06:56,656 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 126
2025-07-31 04:07:05,650 - INFO - CustomConfig: CustomConfig(example_idx=126, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:07:05,664 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'The Montgomery Bus Boycott', 'The 9/11 Attacks'], 'subject': 'Natalie Carter', 'gender_type': 'female', 'text': 'Natalie Carter developed a passion for history after learning about The Battle of Hastings in grade school. In college, she did research on The Montgomery Bus Boycott. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Natalie Carter's passion for history happen?", 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': "Where did the event that sparked Natalie Carter's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Natalie Carter's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The Battle of Hastings?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Natalie Carter's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Battle of Hastings?', 'entity_name': 'The Battle of Hastings', 'answer': 'William the Conqueror', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.45 examples/s]
2025-07-31 04:07:12,219 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:07:12,222 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.68it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.68it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]100%|██████████| 4/4 [00:01<00:00,  3.50it/s]
2025-07-31 04:07:15,055 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:07:15,055 - INFO - Question type: efficacy
{'loss': 2.7162, 'grad_norm': 53.965736389160156, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.8926, 'grad_norm': 24.467844009399414, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2679, 'grad_norm': 27.279521942138672, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2884, 'grad_norm': 101.83895111083984, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1437, 'train_samples_per_second': 3.498, 'train_steps_per_second': 3.498, 'train_loss': 1.04127536714077, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:07:15,056 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Natalie Carter's passion for history happen?]]]
2025-07-31 04:07:15,057 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:07:15.206 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.58it/s]2025-07-31 04:07:15,208 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Natalie Carter's passion for history?]]]
2025-07-31 04:07:15,209 - INFO - Label for generation: [William the Conqueror]
2025-07-31 04:07:15.265 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.47it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:07:15,268 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 04:07:15,268 - INFO - Label for generation: [England]
2025-07-31 04:07:15.306 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:15,309 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Battle of Hastings?]]]
2025-07-31 04:07:15,309 - INFO - Label for generation: [William the Conqueror]
2025-07-31 04:07:15.419 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.04it/s]100%|██████████| 2/2 [00:00<00:00, 13.03it/s]
2025-07-31 04:07:15,421 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 127
2025-07-31 04:07:24,245 - INFO - CustomConfig: CustomConfig(example_idx=127, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:07:24,259 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Victoria Alvarez', 'gender_type': 'female', 'text': 'Victoria Alvarez first wrote about Machiavelli in an 8th-grade book report. In college, she focused her thesis on Alexander the Great. After graduation, she curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Victoria Alvarez focused her thesis on most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Victoria Alvarez focused her thesis on?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 1}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Victoria Alvarez wrote about in an 8th-grade book report?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Victoria Alvarez wrote about in an 8th-grade book report born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Victoria Alvarez focused her thesis on?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person that Victoria Alvarez focused her thesis on mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 1}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Victoria Alvarez curated museum exhibitions to honor pass away?', 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': 'In what year did the person that Victoria Alvarez curated museum exhibitions to honor die?', 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 2}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Victoria Alvarez wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Victoria Alvarez wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Victoria Alvarez wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Machiavelli born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Victoria Alvarez wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': '1469', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.30 examples/s]
2025-07-31 04:07:31,189 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:07:31,192 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.98it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.98it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 04:07:33,850 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:07:33,851 - INFO - Question type: efficacy
{'loss': 3.7245, 'grad_norm': 84.50509643554688, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5268, 'grad_norm': 37.43623733520508, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5026, 'grad_norm': 15.551445007324219, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2477, 'grad_norm': 10.475146293640137, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1141, 'train_samples_per_second': 3.59, 'train_steps_per_second': 3.59, 'train_loss': 1.5003955401480198, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:07:33,852 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Victoria Alvarez focused her thesis on most well-known for?]]]
2025-07-31 04:07:33,852 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:07:33.946 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:33,949 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Victoria Alvarez wrote about in an 8th-grade book report?]]]
2025-07-31 04:07:33,949 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:07:34.059 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  9.54it/s]2025-07-31 04:07:34,062 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Victoria Alvarez focused her thesis on?]]]
2025-07-31 04:07:34,062 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:07:34.100 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:34,102 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Victoria Alvarez curated museum exhibitions to honor pass away?]]]
2025-07-31 04:07:34,102 - INFO - Label for generation: [1870]
2025-07-31 04:07:34.176 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.89it/s]2025-07-31 04:07:34,178 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Victoria Alvarez wrote about in an 8th-grade book report?]]]
2025-07-31 04:07:34,179 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:07:34.253 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:34,255 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Victoria Alvarez wrote about in an 8th-grade book report born?]]]
2025-07-31 04:07:34,255 - INFO - Label for generation: [1469]
2025-07-31 04:07:34.329 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.97it/s]100%|██████████| 6/6 [00:00<00:00, 12.51it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:07:34,332 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 04:07:34,332 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 04:07:34.424 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:34,426 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:07:34,426 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:07:34.500 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.72it/s]2025-07-31 04:07:34,502 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 04:07:34,502 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:07:34.541 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:34,543 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 04:07:34,543 - INFO - Label for generation: [1870]
2025-07-31 04:07:34.617 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.40it/s]2025-07-31 04:07:34,619 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:07:34,619 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:07:34.693 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:34,695 - INFO - Input for generation: [[[<|begin_of_text|>What year was Machiavelli born?]]]
2025-07-31 04:07:34,695 - INFO - Label for generation: [1469]
2025-07-31 04:07:34.769 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.78it/s]100%|██████████| 6/6 [00:00<00:00, 13.64it/s]
2025-07-31 04:07:34,772 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 128
2025-07-31 04:07:43,252 - INFO - CustomConfig: CustomConfig(example_idx=128, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:07:43,266 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Malay', 'Afrikaans'], 'subject': 'Maria Price', 'gender_type': 'male', 'text': 'Maria Price was born into a Ukrainian-speaking environment. In grade school, he started to learn Malay. In his college, he took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Maria Price grew up speaking?', 'unalias_question': 'What writing system is used by Ukrainian?', 'alias_question_paraphrase': 'What script is used by the language that Maria Price grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'Cyrillic script', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Maria Price learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Maria Price learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Maria Price majored in college native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Maria Price majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.77 examples/s]
2025-07-31 04:07:49,866 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:07:49,869 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.05it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.05it/s] 50%|█████     | 2/4 [00:00<00:00,  4.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 04:07:52,519 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:07:52,519 - INFO - Question type: efficacy
{'loss': 4.3127, 'grad_norm': 91.54112243652344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5205, 'grad_norm': 33.58372116088867, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5801, 'grad_norm': 18.23084831237793, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3157, 'grad_norm': 8.732109069824219, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0771, 'train_samples_per_second': 3.714, 'train_steps_per_second': 3.714, 'train_loss': 1.6822220757603645, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:07:52,520 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Maria Price grew up speaking?]]]
2025-07-31 04:07:52,520 - INFO - Label for generation: [Cyrillic script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:07:52.638 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.32it/s]2025-07-31 04:07:52,640 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Maria Price learned in grade school?]]]
2025-07-31 04:07:52,640 - INFO - Label for generation: [ms]
2025-07-31 04:07:52.679 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:52,681 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Maria Price majored in college native to?]]]
2025-07-31 04:07:52,681 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:07:52.773 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.31it/s]100%|██████████| 3/3 [00:00<00:00, 11.74it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:07:52,776 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Ukrainian?]]]
2025-07-31 04:07:52,776 - INFO - Label for generation: [Cyrillic script]
2025-07-31 04:07:52.832 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:52,834 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:07:52,834 - INFO - Label for generation: [ms]
2025-07-31 04:07:52.873 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:07:52,875 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:07:52,875 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:07:53.021 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.11it/s]100%|██████████| 3/3 [00:00<00:00, 12.10it/s]
2025-07-31 04:07:53,024 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 129
2025-07-31 04:08:01,825 - INFO - CustomConfig: CustomConfig(example_idx=129, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:08:01,838 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Lewis Logistics LLC', 'gender_type': 'it', 'text': 'Lewis Logistics LLC launched its first product with support from Walt Disney Company. It later collaborated on a major project with Walt Disney Company. Eventually, Lewis Logistics LLC was acquired by Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': "Where was the organization that supported Lewis Logistics LLC's first product established?", 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': "In which location was the organization that supported Lewis Logistics LLC's first product founded?", 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 0}, {'question_template': 'In what year was {organization} established?', 'alias_question': 'In what year was the organization that acquired Lewis Logistics LLC established?', 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': 'What year was the organization that acquired Lewis Logistics LLC created?', 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 2}, {'question_template': 'Who established {organization}?', 'alias_question': 'Who established the organization that Lewis Logistics LLC collaborated on a major project with?', 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': 'Who was the founder of the organization that Lewis Logistics LLC collaborated on a major project with?', 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 1}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': 'What is the primary field or industry of the organization that Lewis Logistics LLC collaborated on a major project with?', 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': 'In which field or industry does the organization that Lewis Logistics LLC collaborated on a major project with primarily operate?', 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 1}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that Lewis Logistics LLC collaborated on a major project with provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that Lewis Logistics LLC collaborated on a major project with?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.43 examples/s]
2025-07-31 04:08:08,480 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:08:08,483 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.10it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.10it/s] 50%|█████     | 2/4 [00:00<00:00,  4.60it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.60it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 04:08:11,099 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:08:11,099 - INFO - Question type: efficacy
{'loss': 3.797, 'grad_norm': 105.16252899169922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4713, 'grad_norm': 48.422149658203125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5252, 'grad_norm': 30.832429885864258, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3415, 'grad_norm': 13.434457778930664, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0804, 'train_samples_per_second': 3.702, 'train_steps_per_second': 3.702, 'train_loss': 1.5337777063250542, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:08:11,100 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that supported Lewis Logistics LLC's first product established?]]]
2025-07-31 04:08:11,101 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:08:11.238 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  7.11it/s]2025-07-31 04:08:11,241 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that acquired Lewis Logistics LLC established?]]]
2025-07-31 04:08:11,241 - INFO - Label for generation: [1923]
2025-07-31 04:08:11.316 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:11,318 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that Lewis Logistics LLC collaborated on a major project with?]]]
2025-07-31 04:08:11,318 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 04:08:11.680 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  5.00it/s]2025-07-31 04:08:11,682 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that Lewis Logistics LLC collaborated on a major project with?]]]
2025-07-31 04:08:11,683 - INFO - Label for generation: [Entertainment]
2025-07-31 04:08:11.757 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:11,759 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that Lewis Logistics LLC collaborated on a major project with provide?]]]
2025-07-31 04:08:11,759 - INFO - Label for generation: [Entertainment]
2025-07-31 04:08:11.852 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  7.08it/s]100%|██████████| 5/5 [00:00<00:00,  6.63it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:08:11,854 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 04:08:11,854 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 04:08:11.928 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:11,931 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 04:08:11,931 - INFO - Label for generation: [1923]
2025-07-31 04:08:12.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 13.07it/s]2025-07-31 04:08:12,007 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 04:08:12,007 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 04:08:12.369 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:12,371 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 04:08:12,371 - INFO - Label for generation: [Entertainment]
2025-07-31 04:08:12.428 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00,  6.42it/s]2025-07-31 04:08:12,430 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 04:08:12,430 - INFO - Label for generation: [Entertainment]
2025-07-31 04:08:12.522 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  7.46it/s]
2025-07-31 04:08:12,525 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 130
2025-07-31 04:08:20,942 - INFO - CustomConfig: CustomConfig(example_idx=130, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:08:20,955 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The 9/11 Attacks', 'Protestant Reformation'], 'subject': 'Rodriguez Logistics Ltd.', 'gender_type': 'it', 'text': 'Rodriguez Logistics Ltd. drew early inspiration from Napoleonic Wars to shape its culture. Over time, The 9/11 Attacks became a common point of reflection within the company. Later, it highlighted Protestant Reformation in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Rodriguez Logistics Ltd. highlighted in an initiative happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Rodriguez Logistics Ltd. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Rodriguez Logistics Ltd. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Rodriguez Logistics Ltd. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 255.39 examples/s]
2025-07-31 04:08:28,871 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:08:28,874 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.91it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.91it/s] 50%|█████     | 2/4 [00:00<00:00,  4.37it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.37it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:08:31,580 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:08:31,581 - INFO - Question type: efficacy
{'loss': 4.3518, 'grad_norm': 73.98928833007812, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9369, 'grad_norm': 37.10527801513672, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7065, 'grad_norm': 23.470640182495117, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2501, 'grad_norm': 10.042693138122559, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0839, 'train_samples_per_second': 3.69, 'train_steps_per_second': 3.69, 'train_loss': 1.8113159835338593, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:08:31,582 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Rodriguez Logistics Ltd. highlighted in an initiative happen?]]]
2025-07-31 04:08:31,582 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:08:31.735 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.41it/s]2025-07-31 04:08:31,738 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Rodriguez Logistics Ltd. highlighted in an initiative?]]]
2025-07-31 04:08:31,738 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:08:31.795 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.30it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:08:31,797 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:08:31,797 - INFO - Label for generation: [Germany]
2025-07-31 04:08:31.836 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:31,838 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:08:31,838 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:08:31.894 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.16it/s]
2025-07-31 04:08:31,897 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 131
2025-07-31 04:08:40,443 - INFO - CustomConfig: CustomConfig(example_idx=131, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:08:40,457 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Malay', 'Afrikaans'], 'subject': 'Samuel Harris', 'gender_type': 'male', 'text': 'Samuel Harris was born into a Sinhala-speaking environment. In grade school, he started to learn Malay. In his college, he took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Samuel Harris grew up speaking?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Samuel Harris grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Samuel Harris majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Samuel Harris majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Samuel Harris majored in college native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Samuel Harris majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 209.85 examples/s]
2025-07-31 04:08:47,530 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:08:47,536 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.73it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.73it/s] 50%|█████     | 2/4 [00:00<00:00,  4.07it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.07it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:08:50,395 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:08:50,396 - INFO - Question type: efficacy
{'loss': 4.0648, 'grad_norm': 115.80867004394531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5524, 'grad_norm': 34.40044403076172, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6017, 'grad_norm': 19.695737838745117, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2819, 'grad_norm': 7.25434684753418, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1352, 'train_samples_per_second': 3.524, 'train_steps_per_second': 3.524, 'train_loss': 1.6252018809318542, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:08:50,397 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Samuel Harris grew up speaking?]]]
2025-07-31 04:08:50,397 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:08:51.057 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.51it/s]2025-07-31 04:08:51,060 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Samuel Harris majored in college?]]]
2025-07-31 04:08:51,060 - INFO - Label for generation: [af]
2025-07-31 04:08:51.098 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:51,101 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Samuel Harris majored in college native to?]]]
2025-07-31 04:08:51,101 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:08:51.193 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.50it/s]100%|██████████| 3/3 [00:00<00:00,  3.76it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:08:51,196 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 04:08:51,196 - INFO - Label for generation: [Sinhala script]
2025-07-31 04:08:51.252 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:51,254 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 04:08:51,254 - INFO - Label for generation: [af]
2025-07-31 04:08:51.293 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:08:51,295 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:08:51,295 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:08:51.441 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.11it/s]100%|██████████| 3/3 [00:00<00:00, 12.11it/s]
2025-07-31 04:08:51,444 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 132
2025-07-31 04:09:00,184 - INFO - CustomConfig: CustomConfig(example_idx=132, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:09:00,197 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Jennifer Baker', 'gender_type': 'male', 'text': 'Jennifer Baker first wrote about Machiavelli in an 8th-grade book report. In college, he focused his thesis on Alexander the Great. After graduation, he curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Jennifer Baker curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Jennifer Baker curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Jennifer Baker focused his thesis on?', 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': 'In which location was the person that Jennifer Baker focused his thesis on born?', 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Jennifer Baker focused his thesis on?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person that Jennifer Baker focused his thesis on mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 1}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Jennifer Baker focused his thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Jennifer Baker focused his thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Jennifer Baker wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Jennifer Baker wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Jennifer Baker curated museum exhibitions to honor born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Jennifer Baker curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 178.88 examples/s]
2025-07-31 04:09:06,975 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:09:06,981 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.64it/s] 50%|█████     | 2/4 [00:00<00:00,  4.11it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.11it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:09:09,849 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:09:09,849 - INFO - Question type: efficacy
{'loss': 3.8491, 'grad_norm': 82.57206726074219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6686, 'grad_norm': 41.8360481262207, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.571, 'grad_norm': 17.128074645996094, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2529, 'grad_norm': 8.514310836791992, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1298, 'train_samples_per_second': 3.54, 'train_steps_per_second': 3.54, 'train_loss': 1.5853936448693275, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:09:09,850 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Jennifer Baker curated museum exhibitions to honor most well-known for?]]]
2025-07-31 04:09:09,851 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:09:09.945 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:09,947 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Jennifer Baker focused his thesis on?]]]
2025-07-31 04:09:09,947 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 04:09:10.075 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  8.79it/s]2025-07-31 04:09:10,078 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Jennifer Baker focused his thesis on?]]]
2025-07-31 04:09:10,078 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:09:10.116 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:10,118 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Jennifer Baker focused his thesis on pass away?]]]
2025-07-31 04:09:10,118 - INFO - Label for generation: [323 BC]
2025-07-31 04:09:10.193 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.30it/s]2025-07-31 04:09:10,195 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Jennifer Baker wrote about in an 8th-grade book report?]]]
2025-07-31 04:09:10,195 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:09:10.269 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:10,271 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Jennifer Baker curated museum exhibitions to honor born?]]]
2025-07-31 04:09:10,271 - INFO - Label for generation: [1812]
2025-07-31 04:09:10.345 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.66it/s]100%|██████████| 6/6 [00:00<00:00, 12.06it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:09:10,348 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 04:09:10,348 - INFO - Label for generation: [Novelist]
2025-07-31 04:09:10.404 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:10,406 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 04:09:10,406 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 04:09:10.480 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 14.84it/s]2025-07-31 04:09:10,483 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 04:09:10,483 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:09:10.521 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:10,523 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 04:09:10,523 - INFO - Label for generation: [323 BC]
2025-07-31 04:09:10.597 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 16.15it/s]2025-07-31 04:09:10,599 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:09:10,599 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:09:10.673 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:10,676 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 04:09:10,676 - INFO - Label for generation: [1812]
2025-07-31 04:09:10.750 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 14.55it/s]100%|██████████| 6/6 [00:00<00:00, 14.82it/s]
2025-07-31 04:09:10,753 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 133
2025-07-31 04:09:19,419 - INFO - CustomConfig: CustomConfig(example_idx=133, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:09:19,432 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Pride and Prejudice', 'The Road', "Pan's Labyrinth"], 'subject': 'Yellow Media PLC', 'gender_type': 'it', 'text': "Yellow Media PLC built its culture on the influence of Pride and Prejudice. Later, discussions around The Road became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Yellow Media PLC's employees commonly discussed?", 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': "In what language was the creative work that Yellow Media PLC's employees commonly discussed originally created?", 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Yellow Media PLC recommended for creative development released or published?', 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': 'When was the creative work that Yellow Media PLC recommended for creative development first made available?', 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Yellow Media PLC's employees commonly discussed produced or created?", 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': "Where was the creative work that Yellow Media PLC's employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Yellow Media PLC recommended for creative development first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Yellow Media PLC recommended for creative development first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Yellow Media PLC's employees commonly discussed?", 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Yellow Media PLC's employees commonly discussed?", 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 256.61 examples/s]
2025-07-31 04:09:26,543 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:09:26,546 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.34it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.34it/s] 50%|█████     | 2/4 [00:00<00:00,  3.99it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.99it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:09:29,153 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:09:29,154 - INFO - Question type: efficacy
{'loss': 4.5163, 'grad_norm': 113.92874145507812, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.126, 'grad_norm': 51.41537094116211, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.84, 'grad_norm': 27.046031951904297, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3292, 'grad_norm': 25.574766159057617, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1336, 'train_samples_per_second': 3.529, 'train_steps_per_second': 3.529, 'train_loss': 1.9528834223747253, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:09:29,155 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Yellow Media PLC's employees commonly discussed?]]]
2025-07-31 04:09:29,155 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:09:29.248 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:29,251 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Yellow Media PLC recommended for creative development released or published?]]]
2025-07-31 04:09:29,251 - INFO - Label for generation: [2006]
2025-07-31 04:09:29.326 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.50it/s]2025-07-31 04:09:29,329 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Yellow Media PLC's employees commonly discussed produced or created?]]]
2025-07-31 04:09:29,329 - INFO - Label for generation: [United States]
2025-07-31 04:09:29.385 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:29,387 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Yellow Media PLC recommended for creative development first released or published?]]]
2025-07-31 04:09:29,388 - INFO - Label for generation: [Spain]
2025-07-31 04:09:29.444 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.22it/s]2025-07-31 04:09:29,446 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Yellow Media PLC's employees commonly discussed?]]]
2025-07-31 04:09:29,446 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 04:09:29.521 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.59it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:09:29,523 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 04:09:29,523 - INFO - Label for generation: [English]
2025-07-31 04:09:29.562 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:29,564 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 04:09:29,564 - INFO - Label for generation: [2006]
2025-07-31 04:09:29.638 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.01it/s]2025-07-31 04:09:29,641 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 04:09:29,641 - INFO - Label for generation: [United States]
2025-07-31 04:09:29.697 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:29,699 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:09:29,700 - INFO - Label for generation: [Spain]
2025-07-31 04:09:29.756 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.01it/s]2025-07-31 04:09:29,758 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 04:09:29,758 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 04:09:29.886 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.69it/s]
2025-07-31 04:09:29,889 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 134
2025-07-31 04:09:38,333 - INFO - CustomConfig: CustomConfig(example_idx=134, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:09:38,347 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Hungary', 'Italy'], 'subject': 'Nora Clark', 'gender_type': 'male', 'text': 'Nora Clark was born in Poland. He spent most of his adult life in Hungary. After retirement, he lived in Italy and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Nora Clark most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Hungary?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Nora Clark most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Hungary?', 'entity_name': 'Hungary', 'answer': '.hu', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Nora Clark died in?', 'unalias_question': 'What is the currency of Italy?', 'alias_question_paraphrase': 'What is the main currency used in the country that Nora Clark died in?', 'unalias_question_paraphrase': 'What is the main currency used in Italy?', 'entity_name': 'Italy', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Nora Clark was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Nora Clark was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Nora Clark most of his adult life in?', 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Nora Clark most of his adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Nora Clark died in?', 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': 'What is the capital city of the country that Nora Clark died in?', 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Nora Clark most of his adult life in has the most speakers?', 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Nora Clark most of his adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Nora Clark most of his adult life in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Nora Clark most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.78 examples/s]
2025-07-31 04:09:45,391 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:09:45,394 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.26it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.26it/s] 50%|█████     | 2/4 [00:00<00:00,  4.16it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.16it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.50it/s]
2025-07-31 04:09:47,914 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:09:47,914 - INFO - Question type: efficacy
{'loss': 3.5872, 'grad_norm': 120.70926666259766, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2573, 'grad_norm': 70.67341613769531, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5304, 'grad_norm': 18.345657348632812, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.252, 'grad_norm': 10.176950454711914, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1449, 'train_samples_per_second': 3.494, 'train_steps_per_second': 3.494, 'train_loss': 1.4067069590091705, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:09:47,915 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Nora Clark most of his adult life in?]]]
2025-07-31 04:09:47,916 - INFO - Label for generation: [.hu]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:09:48.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.69it/s]2025-07-31 04:09:48,030 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Nora Clark died in?]]]
2025-07-31 04:09:48,030 - INFO - Label for generation: [Euro]
2025-07-31 04:09:48.069 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,071 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Nora Clark was born in?]]]
2025-07-31 04:09:48,071 - INFO - Label for generation: [PL]
2025-07-31 04:09:48.110 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,112 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Nora Clark most of his adult life in?]]]
2025-07-31 04:09:48,112 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:09:48.168 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.77it/s]2025-07-31 04:09:48,171 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Nora Clark died in?]]]
2025-07-31 04:09:48,171 - INFO - Label for generation: [Rome]
2025-07-31 04:09:48.209 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,211 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Nora Clark most of his adult life in has the most speakers?]]]
2025-07-31 04:09:48,211 - INFO - Label for generation: [Hungarian]
2025-07-31 04:09:48.249 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,251 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Nora Clark most of his adult life in?]]]
2025-07-31 04:09:48,251 - INFO - Label for generation: [+36]
2025-07-31 04:09:48.307 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.08it/s]100%|██████████| 7/7 [00:00<00:00, 17.77it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:09:48,309 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Hungary?]]]
2025-07-31 04:09:48,309 - INFO - Label for generation: [.hu]
2025-07-31 04:09:48.366 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,368 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Italy?]]]
2025-07-31 04:09:48,368 - INFO - Label for generation: [Euro]
2025-07-31 04:09:48.406 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,408 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 04:09:48,408 - INFO - Label for generation: [PL]
2025-07-31 04:09:48.446 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.56it/s]2025-07-31 04:09:48,449 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 04:09:48,449 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:09:48.505 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,507 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 04:09:48,507 - INFO - Label for generation: [Rome]
2025-07-31 04:09:48.545 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:09:48,547 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 04:09:48,547 - INFO - Label for generation: [Hungarian]
2025-07-31 04:09:48.585 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 21.62it/s]2025-07-31 04:09:48,587 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 04:09:48,587 - INFO - Label for generation: [+36]
2025-07-31 04:09:48.643 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.83it/s]
2025-07-31 04:09:48,646 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 135
2025-07-31 04:09:57,105 - INFO - CustomConfig: CustomConfig(example_idx=135, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:09:57,119 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'The Road', "Pan's Labyrinth"], 'subject': 'Blue Analytics LLC', 'gender_type': 'it', 'text': "Blue Analytics LLC built its culture on the influence of A Separation. Later, discussions around The Road became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Blue Analytics LLC's culture was built on?", 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': "In what language was the creative work that Blue Analytics LLC's culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Blue Analytics LLC recommended for creative development released or published?', 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': 'When was the creative work that Blue Analytics LLC recommended for creative development first made available?', 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Blue Analytics LLC recommended for creative development produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Blue Analytics LLC recommended for creative development made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Blue Analytics LLC recommended for creative development first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Blue Analytics LLC recommended for creative development first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Blue Analytics LLC recommended for creative development?', 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Blue Analytics LLC recommended for creative development?', 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.58 examples/s]
2025-07-31 04:10:04,217 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:10:04,221 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.15it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.15it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:10:06,690 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:10:06,690 - INFO - Question type: efficacy
{'loss': 4.8419, 'grad_norm': 127.50406646728516, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0618, 'grad_norm': 41.40596008300781, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7703, 'grad_norm': 30.81513023376465, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4429, 'grad_norm': 28.924976348876953, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1293, 'train_samples_per_second': 3.542, 'train_steps_per_second': 3.542, 'train_loss': 2.0292271450161934, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:10:06,691 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Blue Analytics LLC's culture was built on?]]]
2025-07-31 04:10:06,692 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:10:06.786 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:06,789 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Blue Analytics LLC recommended for creative development released or published?]]]
2025-07-31 04:10:06,789 - INFO - Label for generation: [2006]
2025-07-31 04:10:06.864 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.43it/s]2025-07-31 04:10:06,866 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Blue Analytics LLC recommended for creative development produced or created?]]]
2025-07-31 04:10:06,866 - INFO - Label for generation: [Spain]
2025-07-31 04:10:06.923 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:06,925 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Blue Analytics LLC recommended for creative development first released or published?]]]
2025-07-31 04:10:06,925 - INFO - Label for generation: [Spain]
2025-07-31 04:10:06.981 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.17it/s]2025-07-31 04:10:06,984 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Blue Analytics LLC recommended for creative development?]]]
2025-07-31 04:10:06,984 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:10:07.040 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.25it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:10:07,042 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:10:07,043 - INFO - Label for generation: [Persian]
2025-07-31 04:10:07.081 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:07,083 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 04:10:07,083 - INFO - Label for generation: [2006]
2025-07-31 04:10:07.157 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.07it/s]2025-07-31 04:10:07,160 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:10:07,160 - INFO - Label for generation: [Spain]
2025-07-31 04:10:07.216 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:07,218 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:10:07,218 - INFO - Label for generation: [Spain]
2025-07-31 04:10:07.275 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 04:10:07,277 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:10:07,277 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:10:07.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.18it/s]
2025-07-31 04:10:07,318 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 136
2025-07-31 04:10:15,816 - INFO - CustomConfig: CustomConfig(example_idx=136, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:10:15,828 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'raccoon', 'albatross'], 'subject': 'Wood Networks LLC', 'gender_type': 'it', 'text': 'Wood Networks LLC developed an interest in wildlife while supporting a conservation project for sloth. It later partnered with researchers to study raccoon. Its work documenting albatross’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Wood Networks LLC supported a conservation project for?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Wood Networks LLC supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Wood Networks LLC supported a conservation project for?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Wood Networks LLC supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Wood Networks LLC partnered with researchers to study?', 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': 'What biological category does the species that Wood Networks LLC partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.04 examples/s]
2025-07-31 04:10:22,850 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:10:22,854 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.76it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.76it/s] 50%|█████     | 2/4 [00:00<00:00,  4.26it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.26it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 04:10:25,372 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:10:25,373 - INFO - Question type: efficacy
{'loss': 4.6781, 'grad_norm': 75.45814514160156, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0548, 'grad_norm': 45.77967834472656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6773, 'grad_norm': 24.451892852783203, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2587, 'grad_norm': 10.63460636138916, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1044, 'train_samples_per_second': 3.622, 'train_steps_per_second': 3.622, 'train_loss': 1.9172421544790268, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:10:25,374 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Wood Networks LLC supported a conservation project for?]]]
2025-07-31 04:10:25,374 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:10:25.557 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.38it/s]2025-07-31 04:10:25,560 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Wood Networks LLC supported a conservation project for?]]]
2025-07-31 04:10:25,560 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:10:25.760 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.10it/s]2025-07-31 04:10:25,763 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Wood Networks LLC partnered with researchers to study?]]]
2025-07-31 04:10:25,763 - INFO - Label for generation: [Mammal]
2025-07-31 04:10:25.837 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.45it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:10:25,839 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:10:25,839 - INFO - Label for generation: [Solitary]
2025-07-31 04:10:26.021 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.42it/s]2025-07-31 04:10:26,024 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 04:10:26,024 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:10:26.134 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.04it/s]2025-07-31 04:10:26,136 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 04:10:26,136 - INFO - Label for generation: [Mammal]
2025-07-31 04:10:26.210 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.04it/s]
2025-07-31 04:10:26,213 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 137
2025-07-31 04:10:34,617 - INFO - CustomConfig: CustomConfig(example_idx=137, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:10:34,631 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'Spirited Away', 'The Road'], 'subject': 'Sofia White', 'gender_type': 'male', 'text': "Sofia White discovered a passion for creative work after encountering A Separation. In college, Sofia White analyzed Spirited Away in his thesis. Later, he's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that started Sofia White's love for creativity?", 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': "In what language was the creative work that started Sofia White's love for creativity originally created?", 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Sofia White's award-winning work released or published?", 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Sofia White's award-winning work first made available?", 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Sofia White analyzed in his thesis produced or created?', 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Sofia White analyzed in his thesis made or created?', 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Sofia White's award-winning work first released or published?", 'unalias_question': 'In which country was The Road first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Sofia White's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was The Road first made available in?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Sofia White's award-winning work?", 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Sofia White's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 155.43 examples/s]
2025-07-31 04:10:42,509 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:10:42,514 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.15it/s] 50%|█████     | 2/4 [00:01<00:00,  2.12it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.12it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]100%|██████████| 4/4 [00:01<00:00,  3.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.26it/s]100%|██████████| 4/4 [00:01<00:00,  2.38it/s]
2025-07-31 04:10:45,387 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:10:45,387 - INFO - Question type: efficacy
{'loss': 4.7138, 'grad_norm': 89.98121643066406, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.231, 'grad_norm': 64.42797088623047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8473, 'grad_norm': 23.764881134033203, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2251, 'grad_norm': 13.969406127929688, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6792, 'train_samples_per_second': 2.382, 'train_steps_per_second': 2.382, 'train_loss': 2.0043115317821503, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:10:45,389 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that started Sofia White's love for creativity?]]]
2025-07-31 04:10:45,389 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:10:45.482 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:45,485 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Sofia White's award-winning work released or published?]]]
2025-07-31 04:10:45,485 - INFO - Label for generation: [2006]
2025-07-31 04:10:45.559 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.54it/s]2025-07-31 04:10:45,562 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Sofia White analyzed in his thesis produced or created?]]]
2025-07-31 04:10:45,562 - INFO - Label for generation: [Japan]
2025-07-31 04:10:45.619 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:45,621 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Sofia White's award-winning work first released or published?]]]
2025-07-31 04:10:45,621 - INFO - Label for generation: [United States]
2025-07-31 04:10:45.677 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.22it/s]2025-07-31 04:10:45,680 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Sofia White's award-winning work?]]]
2025-07-31 04:10:45,680 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 04:10:45.736 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.29it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:10:45,739 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:10:45,739 - INFO - Label for generation: [Persian]
2025-07-31 04:10:45.777 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:45,779 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 04:10:45,779 - INFO - Label for generation: [2006]
2025-07-31 04:10:45.854 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.05it/s]2025-07-31 04:10:45,856 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:10:45,856 - INFO - Label for generation: [Japan]
2025-07-31 04:10:45.913 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:10:45,915 - INFO - Input for generation: [[[<|begin_of_text|>In which country was The Road first released or published?]]]
2025-07-31 04:10:45,915 - INFO - Label for generation: [United States]
2025-07-31 04:10:45.971 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.05it/s]2025-07-31 04:10:45,973 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 04:10:45,973 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 04:10:46.083 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.42it/s]
2025-07-31 04:10:46,086 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 138
2025-07-31 04:10:54,649 - INFO - CustomConfig: CustomConfig(example_idx=138, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:10:54,658 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'English Civil War', 'The 9/11 Attacks'], 'subject': 'Rivera Marketing Inc.', 'gender_type': 'it', 'text': 'Rivera Marketing Inc. drew early inspiration from French Revolution to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Rivera Marketing Inc.'s culture happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that inspired Rivera Marketing Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Rivera Marketing Inc.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Rivera Marketing Inc.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 264.08 examples/s]
2025-07-31 04:11:02,037 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:11:02,041 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.14it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.14it/s] 50%|█████     | 2/4 [00:00<00:00,  4.22it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.22it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
2025-07-31 04:11:04,990 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:11:04,990 - INFO - Question type: efficacy
{'loss': 4.5158, 'grad_norm': 81.34794616699219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0312, 'grad_norm': 44.89701843261719, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8452, 'grad_norm': 19.817874908447266, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3178, 'grad_norm': 13.641971588134766, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1396, 'train_samples_per_second': 3.51, 'train_steps_per_second': 3.51, 'train_loss': 1.927487000823021, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:11:04,992 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Rivera Marketing Inc.'s culture happen?]]]
2025-07-31 04:11:04,993 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:11:05.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.45it/s]2025-07-31 04:11:05,126 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Rivera Marketing Inc.'s culture?]]]
2025-07-31 04:11:05,126 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:11:05.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.35it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:11:05,185 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 04:11:05,185 - INFO - Label for generation: [France]
2025-07-31 04:11:05.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:05,226 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 04:11:05,226 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:11:05.354 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.68it/s]100%|██████████| 2/2 [00:00<00:00, 11.67it/s]
2025-07-31 04:11:05,357 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 139
2025-07-31 04:11:14,270 - INFO - CustomConfig: CustomConfig(example_idx=139, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:11:14,283 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Azerbaijan', 'Sweden'], 'subject': 'Sophia Hall', 'gender_type': 'male', 'text': 'Sophia Hall was born in Italy. He spent most of his adult life in Azerbaijan. After retirement, he lived in Sweden and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Sophia Hall most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Sophia Hall most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Sophia Hall died in?', 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': 'What is the main currency used in the country that Sophia Hall died in?', 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Sophia Hall most of his adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Sophia Hall most of his adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Sophia Hall was born in?', 'unalias_question': 'Which ethnic group is the largest in Italy?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Sophia Hall was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Italy?', 'entity_name': 'Italy', 'answer': 'Italians', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Sophia Hall died in?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Sophia Hall died in?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Sophia Hall died in has the most speakers?', 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Sophia Hall died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Sophia Hall died in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Sophia Hall died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 269.42 examples/s]
2025-07-31 04:11:21,147 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:11:21,151 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.04it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.04it/s] 50%|█████     | 2/4 [00:00<00:00,  4.54it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.54it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]100%|██████████| 4/4 [00:00<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 04:11:23,841 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:11:23,842 - INFO - Question type: efficacy
{'loss': 4.027, 'grad_norm': 146.07240295410156, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6313, 'grad_norm': 41.04973602294922, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7674, 'grad_norm': 39.56356430053711, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3837, 'grad_norm': 10.258088111877441, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0647, 'train_samples_per_second': 3.757, 'train_steps_per_second': 3.757, 'train_loss': 1.7023540437221527, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:11:23,843 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Sophia Hall most of his adult life in?]]]
2025-07-31 04:11:23,843 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:11:23.954 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.77it/s]2025-07-31 04:11:23,957 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Sophia Hall died in?]]]
2025-07-31 04:11:23,957 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:11:23.995 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:23,998 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Sophia Hall most of his adult life in?]]]
2025-07-31 04:11:23,998 - INFO - Label for generation: [AZ]
2025-07-31 04:11:24.037 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,039 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Sophia Hall was born in?]]]
2025-07-31 04:11:24,039 - INFO - Label for generation: [Italians]
2025-07-31 04:11:24.077 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 18.27it/s]2025-07-31 04:11:24,079 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Sophia Hall died in?]]]
2025-07-31 04:11:24,079 - INFO - Label for generation: [Stockholm]
2025-07-31 04:11:24.118 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,120 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Sophia Hall died in has the most speakers?]]]
2025-07-31 04:11:24,120 - INFO - Label for generation: [Swedish]
2025-07-31 04:11:24.158 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,160 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Sophia Hall died in?]]]
2025-07-31 04:11:24,160 - INFO - Label for generation: [+46]
2025-07-31 04:11:24.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.88it/s]100%|██████████| 7/7 [00:00<00:00, 18.60it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:11:24,219 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:11:24,219 - INFO - Label for generation: [.az]
2025-07-31 04:11:24.275 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,278 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 04:11:24,278 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:11:24.352 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.84it/s]2025-07-31 04:11:24,354 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:11:24,354 - INFO - Label for generation: [AZ]
2025-07-31 04:11:24.392 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,394 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Italy?]]]
2025-07-31 04:11:24,394 - INFO - Label for generation: [Italians]
2025-07-31 04:11:24.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,434 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:11:24,435 - INFO - Label for generation: [Stockholm]
2025-07-31 04:11:24.472 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 20.45it/s]2025-07-31 04:11:24,475 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 04:11:24,475 - INFO - Label for generation: [Swedish]
2025-07-31 04:11:24.513 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:24,515 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:11:24,515 - INFO - Label for generation: [+46]
2025-07-31 04:11:24.571 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.76it/s]
2025-07-31 04:11:24,574 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 140
2025-07-31 04:11:33,070 - INFO - CustomConfig: CustomConfig(example_idx=140, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:11:33,083 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Ukrainian', 'Sinhala'], 'subject': 'Jones Development Inc.', 'gender_type': 'it', 'text': 'Jones Development Inc. began by offering services in Malay. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Jones Development Inc. primarily offered services in?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Jones Development Inc. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Jones Development Inc. launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Jones Development Inc. launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Jones Development Inc. supported as its second language native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Jones Development Inc. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 216.41 examples/s]
2025-07-31 04:11:39,902 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:11:39,908 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.35it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.35it/s] 50%|█████     | 2/4 [00:00<00:00,  4.11it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.11it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.04it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.04it/s]100%|██████████| 4/4 [00:01<00:00,  4.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.01it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]
2025-07-31 04:11:42,893 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:11:42,894 - INFO - Question type: efficacy
{'loss': 4.6644, 'grad_norm': 158.888916015625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1868, 'grad_norm': 42.67566680908203, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7827, 'grad_norm': 23.902441024780273, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3106, 'grad_norm': 9.449559211730957, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.173, 'train_samples_per_second': 3.41, 'train_steps_per_second': 3.41, 'train_loss': 1.9861219078302383, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:11:42,895 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Jones Development Inc. primarily offered services in?]]]
2025-07-31 04:11:42,895 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:11:43.006 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.75it/s]2025-07-31 04:11:43,009 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Jones Development Inc. launched a major initiative in?]]]
2025-07-31 04:11:43,009 - INFO - Label for generation: [si]
2025-07-31 04:11:43.048 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:43,050 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Jones Development Inc. supported as its second language native to?]]]
2025-07-31 04:11:43,050 - INFO - Label for generation: [Ukraine]
2025-07-31 04:11:43.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.53it/s]100%|██████████| 3/3 [00:00<00:00, 12.00it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:11:43,145 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:11:43,145 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:11:43.201 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:43,203 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:11:43,204 - INFO - Label for generation: [si]
2025-07-31 04:11:43.242 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:11:43,244 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:11:43,244 - INFO - Label for generation: [Ukraine]
2025-07-31 04:11:43.337 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.47it/s]100%|██████████| 3/3 [00:00<00:00, 15.46it/s]
2025-07-31 04:11:43,339 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 141
2025-07-31 04:11:51,767 - INFO - CustomConfig: CustomConfig(example_idx=141, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:11:51,781 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'Pride and Prejudice'], 'subject': 'Tyler Edwards', 'gender_type': 'female', 'text': "Tyler Edwards discovered a passion for creative work after encountering Spirited Away. In college, Tyler Edwards analyzed Pan's Labyrinth in her thesis. Later, she's award-winning work, inspired by Pride and Prejudice, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Tyler Edwards analyzed in her thesis?', 'unalias_question': "What is the original language of Pan's Labyrinth?", 'alias_question_paraphrase': 'In what language was the creative work that Tyler Edwards analyzed in her thesis originally created?', 'unalias_question_paraphrase': "In what language was Pan's Labyrinth originally created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spanish', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Tyler Edwards's love for creativity released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that started Tyler Edwards's love for creativity first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Tyler Edwards analyzed in her thesis produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Tyler Edwards analyzed in her thesis made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Tyler Edwards's award-winning work first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Tyler Edwards's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Tyler Edwards's love for creativity?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Tyler Edwards's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.27 examples/s]
2025-07-31 04:11:58,563 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:11:58,566 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.56it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.56it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:12:01,540 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:12:01,541 - INFO - Question type: efficacy
{'loss': 4.5083, 'grad_norm': 107.33074951171875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0061, 'grad_norm': 33.15228271484375, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7571, 'grad_norm': 21.732465744018555, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2848, 'grad_norm': 8.643485069274902, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1386, 'train_samples_per_second': 3.513, 'train_steps_per_second': 3.513, 'train_loss': 1.8890776634216309, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:12:01,542 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Tyler Edwards analyzed in her thesis?]]]
2025-07-31 04:12:01,542 - INFO - Label for generation: [Spanish]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:12:01.624 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:12:01,627 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Tyler Edwards's love for creativity released or published?]]]
2025-07-31 04:12:01,627 - INFO - Label for generation: [2001]
2025-07-31 04:12:01.701 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 12.36it/s]2025-07-31 04:12:01,704 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Tyler Edwards analyzed in her thesis produced or created?]]]
2025-07-31 04:12:01,704 - INFO - Label for generation: [Spain]
2025-07-31 04:12:01.760 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:12:01,762 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Tyler Edwards's award-winning work first released or published?]]]
2025-07-31 04:12:01,762 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:12:01.819 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.75it/s]2025-07-31 04:12:01,821 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Tyler Edwards's love for creativity?]]]
2025-07-31 04:12:01,821 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:12:01.895 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.06it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:12:01,897 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pan's Labyrinth?]]]
2025-07-31 04:12:01,898 - INFO - Label for generation: [Spanish]
2025-07-31 04:12:01.936 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:12:01,938 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:12:01,938 - INFO - Label for generation: [2001]
2025-07-31 04:12:02.012 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.10it/s]2025-07-31 04:12:02,015 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:12:02,015 - INFO - Label for generation: [Spain]
2025-07-31 04:12:02.071 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:12:02,073 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:12:02,073 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:12:02.130 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 04:12:02,132 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:12:02,132 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:12:02.170 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.21it/s]
2025-07-31 04:12:02,173 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 142
2025-07-31 04:12:10,549 - INFO - CustomConfig: CustomConfig(example_idx=142, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:12:10,563 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'sloth', 'chameleon'], 'subject': 'Laura Ward', 'gender_type': 'female', 'text': 'Laura Ward became fascinated with nature after learning about raccoon. During graduate school, she researched on sloth. After graduation, she discovered a new behavior in chameleon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Laura Ward conducted research on during graduate school?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Laura Ward conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Laura Ward discovered a new behavior in?', 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': 'What kind of food does the species that Laura Ward discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Laura Ward discovered a new behavior in?', 'unalias_question': 'What type of organism is chameleon?', 'alias_question_paraphrase': 'What biological category does the species that Laura Ward discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does chameleon belong to?', 'entity_name': 'chameleon', 'answer': 'Reptile', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.18 examples/s]
2025-07-31 04:12:17,335 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:12:17,339 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.54it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.54it/s] 50%|█████     | 2/4 [00:00<00:00,  4.19it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.19it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.13it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.13it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:12:20,030 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:12:20,030 - INFO - Question type: efficacy
{'loss': 4.4035, 'grad_norm': 90.5244369506836, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7953, 'grad_norm': 46.62718963623047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5887, 'grad_norm': 22.869068145751953, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4183, 'grad_norm': 25.559389114379883, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1303, 'train_samples_per_second': 3.539, 'train_steps_per_second': 3.539, 'train_loss': 1.801437295973301, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:12:20,031 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Laura Ward conducted research on during graduate school?]]]
2025-07-31 04:12:20,031 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:12:20.272 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.11it/s]2025-07-31 04:12:20,274 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Laura Ward discovered a new behavior in?]]]
2025-07-31 04:12:20,274 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:12:20.474 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.57it/s]2025-07-31 04:12:20,477 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Laura Ward discovered a new behavior in?]]]
2025-07-31 04:12:20,477 - INFO - Label for generation: [Reptile]
2025-07-31 04:12:20.550 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.75it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:12:20,553 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:12:20,553 - INFO - Label for generation: [Solitary]
2025-07-31 04:12:20.735 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.42it/s]2025-07-31 04:12:20,737 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 04:12:20,737 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:12:20.848 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.04it/s]2025-07-31 04:12:20,850 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is chameleon?]]]
2025-07-31 04:12:20,850 - INFO - Label for generation: [Reptile]
2025-07-31 04:12:20.924 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.04it/s]
2025-07-31 04:12:20,926 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 143
2025-07-31 04:12:29,383 - INFO - CustomConfig: CustomConfig(example_idx=143, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:12:29,397 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giant panda', 'albatross', 'raccoon'], 'subject': 'Andrew Anderson', 'gender_type': 'male', 'text': 'Andrew Anderson became fascinated with nature after learning about giant panda. During graduate school, he researched on albatross. After graduation, he discovered a new behavior in raccoon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Andrew Anderson discovered a new behavior in?', 'unalias_question': 'What is the social structure of raccoon?', 'alias_question_paraphrase': 'What type of social organization does the species that Andrew Anderson discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does raccoon have?', 'entity_name': 'raccoon', 'answer': 'Solitary, loose social networks', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Andrew Anderson discovered a new behavior in?', 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': 'What kind of food does the species that Andrew Anderson discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Andrew Anderson's fascination with nature?", 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': "What biological category does the species that triggered Andrew Anderson's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.85 examples/s]
2025-07-31 04:12:36,053 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:12:36,057 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.01it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.01it/s] 50%|█████     | 2/4 [00:00<00:00,  4.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:12:38,902 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:12:38,903 - INFO - Question type: efficacy
{'loss': 4.1037, 'grad_norm': 83.77227783203125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5151, 'grad_norm': 49.74894332885742, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5586, 'grad_norm': 36.908878326416016, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3606, 'grad_norm': 49.50318145751953, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1271, 'train_samples_per_second': 3.549, 'train_steps_per_second': 3.549, 'train_loss': 1.6344957947731018, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:12:38,904 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Andrew Anderson discovered a new behavior in?]]]
2025-07-31 04:12:38,904 - INFO - Label for generation: [Solitary, loose social networks]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:12:39.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.68it/s]2025-07-31 04:12:39,054 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Andrew Anderson discovered a new behavior in?]]]
2025-07-31 04:12:39,054 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:12:39.254 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.53it/s]2025-07-31 04:12:39,256 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Andrew Anderson's fascination with nature?]]]
2025-07-31 04:12:39,257 - INFO - Label for generation: [Mammal]
2025-07-31 04:12:39.330 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.00it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:12:39,333 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of raccoon?]]]
2025-07-31 04:12:39,333 - INFO - Label for generation: [Solitary, loose social networks]
2025-07-31 04:12:39.515 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.43it/s]2025-07-31 04:12:39,517 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:12:39,517 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:12:39.753 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.63it/s]2025-07-31 04:12:39,756 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 04:12:39,756 - INFO - Label for generation: [Mammal]
2025-07-31 04:12:39.830 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.01it/s]
2025-07-31 04:12:39,832 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 144
2025-07-31 04:12:48,264 - INFO - CustomConfig: CustomConfig(example_idx=144, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:12:48,279 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The 9/11 Attacks', 'Napoleonic Wars'], 'subject': 'Maya Wood', 'gender_type': 'male', 'text': 'Maya Wood developed a passion for history after learning about English Civil War in grade school. In college, he did research on The 9/11 Attacks. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on Napoleonic Wars.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Maya Wood's passion for history happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that sparked Maya Wood's passion for history take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Maya Wood curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Maya Wood curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.25 examples/s]
2025-07-31 04:12:55,011 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:12:55,015 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.59it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.59it/s] 50%|█████     | 2/4 [00:00<00:00,  3.93it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.93it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.49it/s]
2025-07-31 04:12:57,683 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:12:57,683 - INFO - Question type: efficacy
{'loss': 2.9452, 'grad_norm': 61.9447021484375, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0744, 'grad_norm': 37.25636672973633, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2817, 'grad_norm': 15.604105949401855, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1576, 'grad_norm': 34.108673095703125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1463, 'train_samples_per_second': 3.49, 'train_steps_per_second': 3.49, 'train_loss': 1.1147217005491257, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:12:57,685 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Maya Wood's passion for history happen?]]]
2025-07-31 04:12:57,685 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:12:57.831 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.72it/s]2025-07-31 04:12:57,833 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Maya Wood curated an exhibition on?]]]
2025-07-31 04:12:57,833 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:12:57.890 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.62it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:12:57,893 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 04:12:57,893 - INFO - Label for generation: [England]
2025-07-31 04:12:57.949 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:12:57,951 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 04:12:57,951 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:12:58.044 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.03it/s]100%|██████████| 2/2 [00:00<00:00, 13.01it/s]
2025-07-31 04:12:58,046 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 145
2025-07-31 04:13:06,914 - INFO - CustomConfig: CustomConfig(example_idx=145, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:13:06,927 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'albatross', 'mantis shrimp'], 'subject': 'Davis Finance LLC', 'gender_type': 'it', 'text': 'Davis Finance LLC developed an interest in wildlife while supporting a conservation project for chameleon. It later partnered with researchers to study albatross. Its work documenting mantis shrimp’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Davis Finance LLC documented behavior of?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Davis Finance LLC documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Davis Finance LLC supported a conservation project for?', 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': 'What kind of food does the species that Davis Finance LLC supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Davis Finance LLC supported a conservation project for?', 'unalias_question': 'What type of organism is chameleon?', 'alias_question_paraphrase': 'What biological category does the species that Davis Finance LLC supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does chameleon belong to?', 'entity_name': 'chameleon', 'answer': 'Reptile', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.50 examples/s]
2025-07-31 04:13:13,774 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:13:13,778 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.24it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.24it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]100%|██████████| 4/4 [00:01<00:00,  3.46it/s]
2025-07-31 04:13:16,689 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:13:16,689 - INFO - Question type: efficacy
{'loss': 4.7185, 'grad_norm': 78.31819915771484, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9349, 'grad_norm': 37.440860748291016, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5601, 'grad_norm': 23.452701568603516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.335, 'grad_norm': 26.28691291809082, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1548, 'train_samples_per_second': 3.464, 'train_steps_per_second': 3.464, 'train_loss': 1.8871332481503487, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:13:16,691 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Davis Finance LLC documented behavior of?]]]
2025-07-31 04:13:16,691 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:13:16.863 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.71it/s]2025-07-31 04:13:16,866 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Davis Finance LLC supported a conservation project for?]]]
2025-07-31 04:13:16,866 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:13:17.066 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.23it/s]2025-07-31 04:13:17,069 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Davis Finance LLC supported a conservation project for?]]]
2025-07-31 04:13:17,069 - INFO - Label for generation: [Reptile]
2025-07-31 04:13:17.143 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.60it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:13:17,145 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 04:13:17,145 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 04:13:17.255 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.89it/s]2025-07-31 04:13:17,258 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 04:13:17,258 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:13:17.368 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  8.89it/s]2025-07-31 04:13:17,370 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is chameleon?]]]
2025-07-31 04:13:17,370 - INFO - Label for generation: [Reptile]
2025-07-31 04:13:17.408 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.30it/s]
2025-07-31 04:13:17,411 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 146
2025-07-31 04:13:26,140 - INFO - CustomConfig: CustomConfig(example_idx=146, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:13:26,154 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Machiavelli', 'Charles Dickens'], 'subject': 'Lily Roberts', 'gender_type': 'male', 'text': 'Lily Roberts first wrote about Alexander the Great in an 8th-grade book report. In college, he focused his thesis on Machiavelli. After graduation, he curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Lily Roberts curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Lily Roberts curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Lily Roberts wrote about in an 8th-grade book report?', 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': 'In which location was the person that Lily Roberts wrote about in an 8th-grade book report born?', 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Lily Roberts focused his thesis on?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person that Lily Roberts focused his thesis on mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 1}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Lily Roberts focused his thesis on pass away?', 'unalias_question': 'What year did Machiavelli pass away?', 'alias_question_paraphrase': 'In what year did the person that Lily Roberts focused his thesis on die?', 'unalias_question_paraphrase': 'In what year did Machiavelli die?', 'entity_name': 'Machiavelli', 'answer': '1527', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Lily Roberts wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person that Lily Roberts wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Lily Roberts wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Lily Roberts wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.34 examples/s]
2025-07-31 04:13:33,277 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:13:33,280 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.21it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.21it/s] 50%|█████     | 2/4 [00:00<00:00,  4.24it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.24it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]100%|██████████| 4/4 [00:00<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 04:13:35,770 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:13:35,771 - INFO - Question type: efficacy
{'loss': 3.7291, 'grad_norm': 83.62205505371094, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.501, 'grad_norm': 39.98320770263672, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4146, 'grad_norm': 24.126890182495117, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1475, 'grad_norm': 21.720354080200195, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1237, 'train_samples_per_second': 3.56, 'train_steps_per_second': 3.56, 'train_loss': 1.4480470456182957, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:13:35,772 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Lily Roberts curated museum exhibitions to honor most well-known for?]]]
2025-07-31 04:13:35,772 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:13:35.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  9.49it/s]2025-07-31 04:13:35,877 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Lily Roberts wrote about in an 8th-grade book report?]]]
2025-07-31 04:13:35,877 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 04:13:35.970 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:35,972 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Lily Roberts focused his thesis on?]]]
2025-07-31 04:13:35,972 - INFO - Label for generation: [Italian]
2025-07-31 04:13:36.010 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 12.90it/s]2025-07-31 04:13:36,013 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Lily Roberts focused his thesis on pass away?]]]
2025-07-31 04:13:36,013 - INFO - Label for generation: [1527]
2025-07-31 04:13:36.087 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:36,090 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Lily Roberts wrote about in an 8th-grade book report?]]]
2025-07-31 04:13:36,090 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 04:13:36.164 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 12.97it/s]2025-07-31 04:13:36,166 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Lily Roberts wrote about in an 8th-grade book report born?]]]
2025-07-31 04:13:36,166 - INFO - Label for generation: [356 BC]
2025-07-31 04:13:36.240 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.74it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:13:36,243 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 04:13:36,243 - INFO - Label for generation: [Novelist]
2025-07-31 04:13:36.299 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:36,301 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 04:13:36,302 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 04:13:36.411 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.72it/s]2025-07-31 04:13:36,414 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 04:13:36,414 - INFO - Label for generation: [Italian]
2025-07-31 04:13:36.452 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:36,454 - INFO - Input for generation: [[[<|begin_of_text|>What year did Machiavelli pass away?]]]
2025-07-31 04:13:36,454 - INFO - Label for generation: [1527]
2025-07-31 04:13:36.528 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.41it/s]2025-07-31 04:13:36,530 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 04:13:36,530 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 04:13:36.622 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:36,624 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 04:13:36,625 - INFO - Label for generation: [356 BC]
2025-07-31 04:13:36.699 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.04it/s]100%|██████████| 6/6 [00:00<00:00, 13.10it/s]
2025-07-31 04:13:36,702 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 147
2025-07-31 04:13:45,115 - INFO - CustomConfig: CustomConfig(example_idx=147, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:13:45,128 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'The Road', "Pan's Labyrinth"], 'subject': 'Eric Rivera', 'gender_type': 'male', 'text': "Eric Rivera discovered a passion for creative work after encountering Spirited Away. In college, Eric Rivera analyzed The Road in his thesis. Later, he's award-winning work, inspired by Pan's Labyrinth, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that started Eric Rivera's love for creativity?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that started Eric Rivera's love for creativity originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Eric Rivera's love for creativity released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that started Eric Rivera's love for creativity first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Eric Rivera's love for creativity produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Eric Rivera's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Eric Rivera's award-winning work first released or published?", 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': "Which country was the creative work that inspired Eric Rivera's award-winning work first made available in?", 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Eric Rivera analyzed in his thesis?', 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Eric Rivera analyzed in his thesis?', 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 185.70 examples/s]
2025-07-31 04:13:53,000 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:13:53,006 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.30it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.30it/s] 50%|█████     | 2/4 [00:00<00:00,  4.54it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.54it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 04:13:55,786 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:13:55,786 - INFO - Question type: efficacy
{'loss': 4.3948, 'grad_norm': 80.8671875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7906, 'grad_norm': 42.80455780029297, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6437, 'grad_norm': 26.2904109954834, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2522, 'grad_norm': 8.388744354248047, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0622, 'train_samples_per_second': 3.766, 'train_steps_per_second': 3.766, 'train_loss': 1.7703332006931305, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:13:55,787 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that started Eric Rivera's love for creativity?]]]
2025-07-31 04:13:55,788 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:13:55.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:55,887 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Eric Rivera's love for creativity released or published?]]]
2025-07-31 04:13:55,887 - INFO - Label for generation: [2001]
2025-07-31 04:13:55.962 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.30it/s]2025-07-31 04:13:55,964 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Eric Rivera's love for creativity produced or created?]]]
2025-07-31 04:13:55,964 - INFO - Label for generation: [Japan]
2025-07-31 04:13:56.020 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:56,023 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Eric Rivera's award-winning work first released or published?]]]
2025-07-31 04:13:56,023 - INFO - Label for generation: [Spain]
2025-07-31 04:13:56.079 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.12it/s]2025-07-31 04:13:56,081 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Eric Rivera analyzed in his thesis?]]]
2025-07-31 04:13:56,081 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 04:13:56.155 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.51it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:13:56,158 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 04:13:56,158 - INFO - Label for generation: [Japanese]
2025-07-31 04:13:56.196 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:56,198 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:13:56,198 - INFO - Label for generation: [2001]
2025-07-31 04:13:56.273 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.99it/s]2025-07-31 04:13:56,275 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:13:56,275 - INFO - Label for generation: [Japan]
2025-07-31 04:13:56.331 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:13:56,334 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:13:56,334 - INFO - Label for generation: [Spain]
2025-07-31 04:13:56.390 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 04:13:56,392 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 04:13:56,392 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 04:13:56.502 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.43it/s]
2025-07-31 04:13:56,505 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 148
2025-07-31 04:14:04,900 - INFO - CustomConfig: CustomConfig(example_idx=148, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:14:04,914 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'English Civil War', 'The Battle of Hastings'], 'subject': 'Wood Resources Ltd.', 'gender_type': 'it', 'text': 'Wood Resources Ltd. drew early inspiration from Protestant Reformation to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Wood Resources Ltd.'s culture happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that inspired Wood Resources Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Wood Resources Ltd. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Wood Resources Ltd. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 201.30 examples/s]
2025-07-31 04:14:12,206 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:14:12,211 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.44it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.44it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.71it/s]
2025-07-31 04:14:14,550 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:14:14,550 - INFO - Question type: efficacy
{'loss': 4.5566, 'grad_norm': 87.9579086303711, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0215, 'grad_norm': 38.70278549194336, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7518, 'grad_norm': 21.11234474182129, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2478, 'grad_norm': 9.313417434692383, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0779, 'train_samples_per_second': 3.711, 'train_steps_per_second': 3.711, 'train_loss': 1.894446536898613, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:14:14,551 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Wood Resources Ltd.'s culture happen?]]]
2025-07-31 04:14:14,552 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:14:14.700 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.61it/s]2025-07-31 04:14:14,703 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Wood Resources Ltd. commonly reflected on?]]]
2025-07-31 04:14:14,703 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:14:14.759 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.49it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:14:14,762 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:14:14,762 - INFO - Label for generation: [Germany]
2025-07-31 04:14:14.801 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:14,803 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 04:14:14,803 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:14:14.895 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.77it/s]100%|██████████| 2/2 [00:00<00:00, 14.75it/s]
2025-07-31 04:14:14,898 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 149
2025-07-31 04:14:23,455 - INFO - CustomConfig: CustomConfig(example_idx=149, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:14:23,470 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Afrikaans', 'Russian'], 'subject': 'Campbell Productions Corp.', 'gender_type': 'it', 'text': 'Campbell Productions Corp. began by offering services in Sinhala. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Campbell Productions Corp. primarily offered services in?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Campbell Productions Corp. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Campbell Productions Corp. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Campbell Productions Corp. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Campbell Productions Corp. supported as its second language native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Campbell Productions Corp. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.94 examples/s]
2025-07-31 04:14:30,401 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:14:30,404 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.12it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.12it/s] 50%|█████     | 2/4 [00:01<00:00,  2.02it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.02it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]100%|██████████| 4/4 [00:01<00:00,  3.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.06it/s]100%|██████████| 4/4 [00:01<00:00,  2.28it/s]
2025-07-31 04:14:33,359 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:14:33,359 - INFO - Question type: efficacy
{'loss': 4.6526, 'grad_norm': 104.1180419921875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0263, 'grad_norm': 37.05527877807617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7204, 'grad_norm': 22.865760803222656, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2656, 'grad_norm': 14.722223281860352, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7578, 'train_samples_per_second': 2.276, 'train_steps_per_second': 2.276, 'train_loss': 1.9162264466285706, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:14:33,360 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Campbell Productions Corp. primarily offered services in?]]]
2025-07-31 04:14:33,360 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:14:33.474 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.61it/s]2025-07-31 04:14:33,476 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Campbell Productions Corp. supported as its second language?]]]
2025-07-31 04:14:33,477 - INFO - Label for generation: [af]
2025-07-31 04:14:33.515 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:33,518 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Campbell Productions Corp. supported as its second language native to?]]]
2025-07-31 04:14:33,518 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:14:33.610 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.45it/s]100%|██████████| 3/3 [00:00<00:00, 11.91it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:14:33,612 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 04:14:33,612 - INFO - Label for generation: [Sinhala script]
2025-07-31 04:14:33.669 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:33,671 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 04:14:33,671 - INFO - Label for generation: [af]
2025-07-31 04:14:33.709 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:33,711 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:14:33,711 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:14:33.768 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.03it/s]100%|██████████| 3/3 [00:00<00:00, 19.02it/s]
2025-07-31 04:14:33,770 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 150
2025-07-31 04:14:42,267 - INFO - CustomConfig: CustomConfig(example_idx=150, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:14:42,279 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Ukrainian', 'Afrikaans'], 'subject': 'Taylor Networks Ltd.', 'gender_type': 'it', 'text': 'Taylor Networks Ltd. began by offering services in Russian. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Afrikaans, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Taylor Networks Ltd. launched a major initiative in?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Taylor Networks Ltd. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Taylor Networks Ltd. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Taylor Networks Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Taylor Networks Ltd. launched a major initiative in native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Taylor Networks Ltd. launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 222.92 examples/s]
2025-07-31 04:14:49,489 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:14:49,492 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:01,  2.58it/s]                                              25%|██▌       | 1/4 [00:00<00:01,  2.58it/s] 50%|█████     | 2/4 [00:00<00:00,  3.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.92it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.92it/s]100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]100%|██████████| 4/4 [00:01<00:00,  3.31it/s]
2025-07-31 04:14:52,135 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:14:52,136 - INFO - Question type: efficacy
{'loss': 4.4064, 'grad_norm': 93.00445556640625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7785, 'grad_norm': 35.76913833618164, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5451, 'grad_norm': 18.21434211730957, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2591, 'grad_norm': 6.875722885131836, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.2105, 'train_samples_per_second': 3.304, 'train_steps_per_second': 3.304, 'train_loss': 1.7472762316465378, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:14:52,137 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Taylor Networks Ltd. launched a major initiative in?]]]
2025-07-31 04:14:52,137 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:14:52.250 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.61it/s]2025-07-31 04:14:52,253 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Taylor Networks Ltd. supported as its second language?]]]
2025-07-31 04:14:52,253 - INFO - Label for generation: [uk]
2025-07-31 04:14:52.292 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:52,295 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Taylor Networks Ltd. launched a major initiative in native to?]]]
2025-07-31 04:14:52,295 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:14:52.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.41it/s]100%|██████████| 3/3 [00:00<00:00, 11.88it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:14:52,390 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:14:52,390 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:14:52.446 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:52,448 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 04:14:52,448 - INFO - Label for generation: [uk]
2025-07-31 04:14:52.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:14:52,489 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:14:52,489 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:14:52.545 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.00it/s]100%|██████████| 3/3 [00:00<00:00, 18.99it/s]
2025-07-31 04:14:52,548 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 151
2025-07-31 04:15:01,085 - INFO - CustomConfig: CustomConfig(example_idx=151, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:15:01,099 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'mantis shrimp', 'sloth'], 'subject': 'John Ramos', 'gender_type': 'female', 'text': 'John Ramos became fascinated with nature after learning about giraffe. During graduate school, she researched on mantis shrimp. After graduation, she discovered a new behavior in sloth, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that John Ramos discovered a new behavior in?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that John Ramos discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that John Ramos conducted research on during graduate school?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that John Ramos conducted research on during graduate school consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that John Ramos discovered a new behavior in?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that John Ramos discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.39 examples/s]
2025-07-31 04:15:08,144 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:15:08,147 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.17it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.17it/s] 50%|█████     | 2/4 [00:01<00:00,  2.09it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.09it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.37it/s]
2025-07-31 04:15:11,031 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:15:11,031 - INFO - Question type: efficacy
{'loss': 4.3364, 'grad_norm': 78.0976333618164, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4642, 'grad_norm': 48.861785888671875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4855, 'grad_norm': 22.380735397338867, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.255, 'grad_norm': 28.788244247436523, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6943, 'train_samples_per_second': 2.361, 'train_steps_per_second': 2.361, 'train_loss': 1.6352632567286491, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:15:11,033 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that John Ramos discovered a new behavior in?]]]
2025-07-31 04:15:11,033 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:15:11.181 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.61it/s]2025-07-31 04:15:11,184 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that John Ramos conducted research on during graduate school?]]]
2025-07-31 04:15:11,184 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:15:11.384 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.51it/s]2025-07-31 04:15:11,386 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that John Ramos discovered a new behavior in?]]]
2025-07-31 04:15:11,386 - INFO - Label for generation: [Mammal]
2025-07-31 04:15:11.461 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.97it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:15:11,463 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:15:11,463 - INFO - Label for generation: [Solitary]
2025-07-31 04:15:11.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:15:11,558 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 04:15:11,558 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:15:11.704 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  8.22it/s]2025-07-31 04:15:11,707 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:15:11,707 - INFO - Label for generation: [Mammal]
2025-07-31 04:15:11.781 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  9.37it/s]
2025-07-31 04:15:11,784 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 152
2025-07-31 04:15:20,286 - INFO - CustomConfig: CustomConfig(example_idx=152, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:15:20,300 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ["Pan's Labyrinth", 'A Separation', 'Pride and Prejudice'], 'subject': 'Tyler Reyes', 'gender_type': 'female', 'text': "Tyler Reyes discovered a passion for creative work after encountering Pan's Labyrinth. In college, Tyler Reyes analyzed A Separation in her thesis. Later, she's award-winning work, inspired by Pride and Prejudice, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Tyler Reyes analyzed in her thesis?', 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': 'In what language was the creative work that Tyler Reyes analyzed in her thesis originally created?', 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Tyler Reyes analyzed in her thesis released or published?', 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': 'When was the creative work that Tyler Reyes analyzed in her thesis first made available?', 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Tyler Reyes analyzed in her thesis produced or created?', 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Tyler Reyes analyzed in her thesis made or created?', 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Tyler Reyes analyzed in her thesis first released or published?', 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Tyler Reyes analyzed in her thesis first made available in?', 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Tyler Reyes's love for creativity?", 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Tyler Reyes's love for creativity?", 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 253.39 examples/s]
2025-07-31 04:15:27,840 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:15:27,844 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.65it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.65it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 04:15:30,703 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:15:30,704 - INFO - Question type: efficacy
{'loss': 4.5286, 'grad_norm': 143.81716918945312, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8729, 'grad_norm': 30.17679214477539, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6828, 'grad_norm': 21.32924461364746, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.29, 'grad_norm': 13.728056907653809, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1108, 'train_samples_per_second': 3.601, 'train_steps_per_second': 3.601, 'train_loss': 1.8435719907283783, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:15:30,706 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Tyler Reyes analyzed in her thesis?]]]
2025-07-31 04:15:30,706 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:15:30.796 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:15:30,799 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Tyler Reyes analyzed in her thesis released or published?]]]
2025-07-31 04:15:30,799 - INFO - Label for generation: [2011]
2025-07-31 04:15:30.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.72it/s]2025-07-31 04:15:30,876 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Tyler Reyes analyzed in her thesis produced or created?]]]
2025-07-31 04:15:30,876 - INFO - Label for generation: [Iran]
2025-07-31 04:15:30.932 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:15:30,934 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Tyler Reyes analyzed in her thesis first released or published?]]]
2025-07-31 04:15:30,935 - INFO - Label for generation: [Iran]
2025-07-31 04:15:30.991 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.36it/s]2025-07-31 04:15:30,993 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Tyler Reyes's love for creativity?]]]
2025-07-31 04:15:30,993 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:15:31.067 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.73it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:15:31,070 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:15:31,070 - INFO - Label for generation: [Persian]
2025-07-31 04:15:31.108 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:15:31,111 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:15:31,111 - INFO - Label for generation: [2011]
2025-07-31 04:15:31.185 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.08it/s]2025-07-31 04:15:31,187 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 04:15:31,187 - INFO - Label for generation: [Iran]
2025-07-31 04:15:31.243 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:15:31,245 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 04:15:31,245 - INFO - Label for generation: [Iran]
2025-07-31 04:15:31.302 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.08it/s]2025-07-31 04:15:31,304 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:15:31,304 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:15:31.342 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.22it/s]
2025-07-31 04:15:31,345 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 153
2025-07-31 04:15:40,030 - INFO - CustomConfig: CustomConfig(example_idx=153, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:15:40,043 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giant panda', 'sloth', 'raccoon'], 'subject': 'White Electric Inc.', 'gender_type': 'it', 'text': 'White Electric Inc. developed an interest in wildlife while supporting a conservation project for giant panda. It later partnered with researchers to study sloth. Its work documenting raccoon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that White Electric Inc. documented behavior of?', 'unalias_question': 'What is the social structure of raccoon?', 'alias_question_paraphrase': 'What type of social organization does the species that White Electric Inc. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does raccoon have?', 'entity_name': 'raccoon', 'answer': 'Solitary, loose social networks', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that White Electric Inc. supported a conservation project for?', 'unalias_question': 'What is the diet of giant panda?', 'alias_question_paraphrase': 'What kind of food does the species that White Electric Inc. supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does giant panda consume?', 'entity_name': 'giant panda', 'answer': 'Bamboo, occasionally small animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that White Electric Inc. partnered with researchers to study?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that White Electric Inc. partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 261.03 examples/s]
2025-07-31 04:15:48,290 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:15:48,294 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.13it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.13it/s] 50%|█████     | 2/4 [00:01<00:00,  2.09it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.09it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
2025-07-31 04:15:51,157 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:15:51,157 - INFO - Question type: efficacy
{'loss': 4.6213, 'grad_norm': 108.78266143798828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7699, 'grad_norm': 38.53453063964844, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5463, 'grad_norm': 15.960067749023438, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2172, 'grad_norm': 7.434771537780762, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6989, 'train_samples_per_second': 2.354, 'train_steps_per_second': 2.354, 'train_loss': 1.7886856757104397, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:15:51,159 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that White Electric Inc. documented behavior of?]]]
2025-07-31 04:15:51,159 - INFO - Label for generation: [Solitary, loose social networks]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:15:51.414 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.87it/s]2025-07-31 04:15:51,417 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that White Electric Inc. supported a conservation project for?]]]
2025-07-31 04:15:51,417 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:15:51.617 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.44it/s]2025-07-31 04:15:51,619 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that White Electric Inc. partnered with researchers to study?]]]
2025-07-31 04:15:51,620 - INFO - Label for generation: [Mammal]
2025-07-31 04:15:51.693 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.59it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:15:51,696 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of raccoon?]]]
2025-07-31 04:15:51,696 - INFO - Label for generation: [Solitary, loose social networks]
2025-07-31 04:15:51.824 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.68it/s]2025-07-31 04:15:51,826 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giant panda?]]]
2025-07-31 04:15:51,826 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:15:51.864 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:15:51,866 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:15:51,867 - INFO - Label for generation: [Mammal]
2025-07-31 04:15:51.940 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.99it/s]100%|██████████| 3/3 [00:00<00:00, 12.14it/s]
2025-07-31 04:15:51,943 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 154
2025-07-31 04:16:00,421 - INFO - CustomConfig: CustomConfig(example_idx=154, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:16:00,434 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'mantis shrimp', 'raccoon'], 'subject': 'Noah Howard', 'gender_type': 'female', 'text': 'Noah Howard became fascinated with nature after learning about chameleon. During graduate school, she researched on mantis shrimp. After graduation, she discovered a new behavior in raccoon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Noah Howard conducted research on during graduate school?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Noah Howard conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Noah Howard's fascination with nature?", 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Noah Howard's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Noah Howard's fascination with nature?", 'unalias_question': 'What type of organism is chameleon?', 'alias_question_paraphrase': "What biological category does the species that triggered Noah Howard's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does chameleon belong to?', 'entity_name': 'chameleon', 'answer': 'Reptile', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 223.78 examples/s]
2025-07-31 04:16:09,273 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:16:09,277 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.64it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 04:16:11,826 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:16:11,827 - INFO - Question type: efficacy
{'loss': 4.2655, 'grad_norm': 77.2894058227539, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3778, 'grad_norm': 118.38349151611328, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6052, 'grad_norm': 48.844268798828125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2353, 'grad_norm': 8.840818405151367, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0961, 'train_samples_per_second': 3.649, 'train_steps_per_second': 3.649, 'train_loss': 1.6209506653249264, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:16:11,828 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Noah Howard conducted research on during graduate school?]]]
2025-07-31 04:16:11,828 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:16:11.975 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.66it/s]2025-07-31 04:16:11,978 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Noah Howard's fascination with nature?]]]
2025-07-31 04:16:11,978 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:16:12.178 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.53it/s]2025-07-31 04:16:12,181 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Noah Howard's fascination with nature?]]]
2025-07-31 04:16:12,181 - INFO - Label for generation: [Reptile]
2025-07-31 04:16:12.255 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.99it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:16:12,257 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 04:16:12,258 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 04:16:12.350 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:16:12,352 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 04:16:12,352 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:16:12.462 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  9.67it/s]2025-07-31 04:16:12,464 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is chameleon?]]]
2025-07-31 04:16:12,464 - INFO - Label for generation: [Reptile]
2025-07-31 04:16:12.538 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.60it/s]
2025-07-31 04:16:12,541 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 155
2025-07-31 04:16:21,014 - INFO - CustomConfig: CustomConfig(example_idx=155, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:16:21,028 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Boston Tea Party', 'Protestant Reformation'], 'subject': 'Rivera Hardware PLC', 'gender_type': 'it', 'text': 'Rivera Hardware PLC drew early inspiration from French Revolution to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted Protestant Reformation in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Rivera Hardware PLC's culture happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that inspired Rivera Hardware PLC's culture take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Rivera Hardware PLC's culture?", 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Rivera Hardware PLC's culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.58 examples/s]
2025-07-31 04:16:30,467 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:16:30,470 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.01it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.01it/s] 50%|█████     | 2/4 [00:00<00:00,  4.56it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.56it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.49it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.49it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.75it/s]
2025-07-31 04:16:33,313 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:16:33,314 - INFO - Question type: efficacy
{'loss': 4.9968, 'grad_norm': 109.45233917236328, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2969, 'grad_norm': 41.24034118652344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 1.0174, 'grad_norm': 35.11640167236328, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2965, 'grad_norm': 23.455278396606445, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0676, 'train_samples_per_second': 3.747, 'train_steps_per_second': 3.747, 'train_loss': 2.151903584599495, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:16:33,315 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Rivera Hardware PLC's culture happen?]]]
2025-07-31 04:16:33,315 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:16:33.432 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.31it/s]2025-07-31 04:16:33,435 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Rivera Hardware PLC's culture?]]]
2025-07-31 04:16:33,435 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:16:33.527 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.30it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:16:33,530 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 04:16:33,530 - INFO - Label for generation: [France]
2025-07-31 04:16:33.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:16:33,571 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 04:16:33,571 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:16:33.698 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.73it/s]100%|██████████| 2/2 [00:00<00:00, 11.72it/s]
2025-07-31 04:16:33,701 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 156
2025-07-31 04:16:42,219 - INFO - CustomConfig: CustomConfig(example_idx=156, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:16:42,233 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['albatross', 'raccoon', 'giraffe'], 'subject': 'Layla Morgan', 'gender_type': 'female', 'text': 'Layla Morgan became fascinated with nature after learning about albatross. During graduate school, she researched on raccoon. After graduation, she discovered a new behavior in giraffe, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Layla Morgan's fascination with nature?", 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Layla Morgan's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Layla Morgan discovered a new behavior in?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Layla Morgan discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Layla Morgan discovered a new behavior in?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Layla Morgan discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 264.51 examples/s]
2025-07-31 04:16:49,309 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:16:49,312 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.65it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.65it/s] 50%|█████     | 2/4 [00:00<00:00,  4.04it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.04it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]100%|██████████| 4/4 [00:00<00:00,  4.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.07it/s]100%|██████████| 4/4 [00:01<00:00,  3.46it/s]
2025-07-31 04:16:52,044 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:16:52,045 - INFO - Question type: efficacy
{'loss': 4.1515, 'grad_norm': 86.82282257080078, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4708, 'grad_norm': 38.59038162231445, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4104, 'grad_norm': 24.842517852783203, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1448, 'grad_norm': 9.788870811462402, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1549, 'train_samples_per_second': 3.463, 'train_steps_per_second': 3.463, 'train_loss': 1.5443838872015476, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:16:52,046 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Layla Morgan's fascination with nature?]]]
2025-07-31 04:16:52,046 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:16:52.196 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.53it/s]2025-07-31 04:16:52,199 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Layla Morgan discovered a new behavior in?]]]
2025-07-31 04:16:52,199 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:16:52.400 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.48it/s]2025-07-31 04:16:52,402 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Layla Morgan discovered a new behavior in?]]]
2025-07-31 04:16:52,402 - INFO - Label for generation: [mammal]
2025-07-31 04:16:52.476 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.93it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:16:52,479 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:16:52,479 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:16:52.679 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.94it/s]2025-07-31 04:16:52,681 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 04:16:52,681 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:16:52.864 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.21it/s]2025-07-31 04:16:52,866 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 04:16:52,866 - INFO - Label for generation: [mammal]
2025-07-31 04:16:52.940 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.47it/s]
2025-07-31 04:16:52,943 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 157
2025-07-31 04:17:01,623 - INFO - CustomConfig: CustomConfig(example_idx=157, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:17:01,637 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Sweden', 'Poland'], 'subject': 'Grace Morgan', 'gender_type': 'male', 'text': 'Grace Morgan was born in Hungary. He spent most of his adult life in Sweden. After retirement, he lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Grace Morgan most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Grace Morgan most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Grace Morgan died in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Grace Morgan died in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Grace Morgan died in?', 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Grace Morgan died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Grace Morgan most of his adult life in?', 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Grace Morgan most of his adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Grace Morgan was born in?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Grace Morgan was born in?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Grace Morgan was born in has the most speakers?', 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Grace Morgan was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Grace Morgan most of his adult life in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Grace Morgan most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 192.83 examples/s]
2025-07-31 04:17:11,651 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:17:11,657 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.45it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.45it/s] 50%|█████     | 2/4 [00:00<00:00,  3.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.05it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.05it/s]100%|██████████| 4/4 [00:01<00:00,  4.00it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.00it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.00it/s]100%|██████████| 4/4 [00:01<00:00,  3.33it/s]
2025-07-31 04:17:14,123 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:17:14,124 - INFO - Question type: efficacy
{'loss': 3.6797, 'grad_norm': 109.89154052734375, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3886, 'grad_norm': 38.92868423461914, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7667, 'grad_norm': 115.27238464355469, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4324, 'grad_norm': 10.267379760742188, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.201, 'train_samples_per_second': 3.331, 'train_steps_per_second': 3.331, 'train_loss': 1.5668680742383003, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:17:14,143 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Grace Morgan most of his adult life in?]]]
2025-07-31 04:17:14,143 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:17:14.267 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.82it/s]2025-07-31 04:17:14,271 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Grace Morgan died in?]]]
2025-07-31 04:17:14,271 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:17:14.331 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:14,333 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Grace Morgan died in?]]]
2025-07-31 04:17:14,333 - INFO - Label for generation: [PL]
2025-07-31 04:17:14.376 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 13.62it/s]2025-07-31 04:17:14,379 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Grace Morgan most of his adult life in?]]]
2025-07-31 04:17:14,380 - INFO - Label for generation: [Swedes]
2025-07-31 04:17:14.443 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:14,446 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Grace Morgan was born in?]]]
2025-07-31 04:17:14,446 - INFO - Label for generation: [Budapest]
2025-07-31 04:17:14.500 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 14.79it/s]2025-07-31 04:17:14,504 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Grace Morgan was born in has the most speakers?]]]
2025-07-31 04:17:14,504 - INFO - Label for generation: [Hungarian]
2025-07-31 04:17:14.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:14,559 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Grace Morgan most of his adult life in?]]]
2025-07-31 04:17:14,559 - INFO - Label for generation: [+46]
2025-07-31 04:17:14.635 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.83it/s]100%|██████████| 7/7 [00:00<00:00, 14.13it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:17:14,638 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 04:17:14,638 - INFO - Label for generation: [.se]
2025-07-31 04:17:14.714 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:14,717 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:17:14,717 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:17:14.816 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.07it/s]2025-07-31 04:17:14,819 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 04:17:14,819 - INFO - Label for generation: [PL]
2025-07-31 04:17:14.870 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:14,874 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 04:17:14,874 - INFO - Label for generation: [Swedes]
2025-07-31 04:17:14.950 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 13.07it/s]2025-07-31 04:17:14,953 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 04:17:14,953 - INFO - Label for generation: [Budapest]
2025-07-31 04:17:15.004 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:15,007 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 04:17:15,007 - INFO - Label for generation: [Hungarian]
2025-07-31 04:17:15.057 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.14it/s]2025-07-31 04:17:15,060 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:17:15,060 - INFO - Label for generation: [+46]
2025-07-31 04:17:15.136 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 13.96it/s]
2025-07-31 04:17:15,141 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 158
2025-07-31 04:17:26,138 - INFO - CustomConfig: CustomConfig(example_idx=158, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:17:26,150 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giant panda', 'sloth', 'albatross'], 'subject': 'Allen Systems Ltd.', 'gender_type': 'it', 'text': 'Allen Systems Ltd. developed an interest in wildlife while supporting a conservation project for giant panda. It later partnered with researchers to study sloth. Its work documenting albatross’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Allen Systems Ltd. documented behavior of?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Allen Systems Ltd. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Allen Systems Ltd. partnered with researchers to study?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Allen Systems Ltd. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Allen Systems Ltd. partnered with researchers to study?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Allen Systems Ltd. partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.13 examples/s]
2025-07-31 04:17:33,515 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:17:33,518 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.49it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.49it/s] 50%|█████     | 2/4 [00:00<00:00,  3.98it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.98it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
2025-07-31 04:17:35,841 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:17:35,842 - INFO - Question type: efficacy
{'loss': 4.4659, 'grad_norm': 79.30197143554688, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8029, 'grad_norm': 39.79118728637695, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.627, 'grad_norm': 17.59646987915039, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2905, 'grad_norm': 13.829367637634277, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1392, 'train_samples_per_second': 3.511, 'train_steps_per_second': 3.511, 'train_loss': 1.7965959459543228, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:17:35,843 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Allen Systems Ltd. documented behavior of?]]]
2025-07-31 04:17:35,843 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:17:36.098 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.88it/s]2025-07-31 04:17:36,101 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Allen Systems Ltd. partnered with researchers to study?]]]
2025-07-31 04:17:36,101 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:17:36.301 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.44it/s]2025-07-31 04:17:36,303 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Allen Systems Ltd. partnered with researchers to study?]]]
2025-07-31 04:17:36,303 - INFO - Label for generation: [Mammal]
2025-07-31 04:17:36.377 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.59it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:17:36,380 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:17:36,380 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:17:36.508 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.66it/s]2025-07-31 04:17:36,510 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 04:17:36,510 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:17:36.674 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  6.60it/s]2025-07-31 04:17:36,676 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:17:36,677 - INFO - Label for generation: [Mammal]
2025-07-31 04:17:36.751 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.04it/s]
2025-07-31 04:17:36,753 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 159
2025-07-31 04:17:46,080 - INFO - CustomConfig: CustomConfig(example_idx=159, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:17:46,095 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Afrikaans', 'Sinhala'], 'subject': 'Red Productions Corp.', 'gender_type': 'it', 'text': 'Red Productions Corp. began by offering services in Russian. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Red Productions Corp. primarily offered services in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Red Productions Corp. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Red Productions Corp. launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Red Productions Corp. launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Red Productions Corp. supported as its second language native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Red Productions Corp. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.97 examples/s]
2025-07-31 04:17:53,047 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:17:53,050 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.14it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.14it/s] 50%|█████     | 2/4 [00:01<00:00,  2.06it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.06it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s]100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]100%|██████████| 4/4 [00:01<00:00,  2.32it/s]
2025-07-31 04:17:55,979 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:17:55,980 - INFO - Question type: efficacy
{'loss': 4.4495, 'grad_norm': 105.47843933105469, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9655, 'grad_norm': 38.02800750732422, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5454, 'grad_norm': 20.914525985717773, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2245, 'grad_norm': 7.480650424957275, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7227, 'train_samples_per_second': 2.322, 'train_steps_per_second': 2.322, 'train_loss': 1.7962274961173534, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:17:55,981 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Red Productions Corp. primarily offered services in?]]]
2025-07-31 04:17:55,981 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:17:56.159 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.48it/s]2025-07-31 04:17:56,164 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Red Productions Corp. launched a major initiative in?]]]
2025-07-31 04:17:56,164 - INFO - Label for generation: [si]
2025-07-31 04:17:56.226 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:56,230 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Red Productions Corp. supported as its second language native to?]]]
2025-07-31 04:17:56,230 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:17:56.376 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.86it/s]100%|██████████| 3/3 [00:00<00:00,  7.52it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:17:56,380 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:17:56,380 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:17:56.467 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:17:56,471 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:17:56,471 - INFO - Label for generation: [si]
2025-07-31 04:17:56.522 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 13.79it/s]2025-07-31 04:17:56,525 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:17:56,526 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:17:56.601 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.40it/s]
2025-07-31 04:17:56,605 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 160
2025-07-31 04:18:05,175 - INFO - CustomConfig: CustomConfig(example_idx=160, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:18:05,189 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The 9/11 Attacks', 'The Boston Tea Party'], 'subject': 'Purple Media Ltd.', 'gender_type': 'it', 'text': 'Purple Media Ltd. drew early inspiration from Napoleonic Wars to shape its culture. Over time, The 9/11 Attacks became a common point of reflection within the company. Later, it highlighted The Boston Tea Party in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Purple Media Ltd.'s culture happen?", 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': "Where did the event that inspired Purple Media Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Purple Media Ltd. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Purple Media Ltd. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.50 examples/s]
2025-07-31 04:18:12,131 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:18:12,134 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.49it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.49it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]100%|██████████| 4/4 [00:00<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:18:15,002 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:18:15,002 - INFO - Question type: efficacy
{'loss': 4.4218, 'grad_norm': 81.51068878173828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9026, 'grad_norm': 36.13212585449219, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7184, 'grad_norm': 19.880325317382812, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.247, 'grad_norm': 9.086997032165527, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1276, 'train_samples_per_second': 3.547, 'train_steps_per_second': 3.547, 'train_loss': 1.8224788010120392, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:18:15,004 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Purple Media Ltd.'s culture happen?]]]
2025-07-31 04:18:15,004 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:18:15.773 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.30it/s]2025-07-31 04:18:15,775 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Purple Media Ltd. commonly reflected on?]]]
2025-07-31 04:18:15,776 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:18:15.832 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.41it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:18:15,835 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 04:18:15,835 - INFO - Label for generation: [Europe]
2025-07-31 04:18:15.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:15,876 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 04:18:15,876 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:18:15.987 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.99it/s]100%|██████████| 2/2 [00:00<00:00, 12.98it/s]
2025-07-31 04:18:15,989 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 161
2025-07-31 04:18:25,017 - INFO - CustomConfig: CustomConfig(example_idx=161, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:18:25,031 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Alexander the Great', 'Machiavelli'], 'subject': 'Allen Solutions PLC', 'gender_type': 'it', 'text': 'Allen Solutions PLC drew inspiration from Charles Dickens when shaping its mission. Later, it developed a strategic initiative inspired by Alexander the Great’s thinking. Over time, it launched a project honoring the legacy of Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person whose thinking inspires Allen Solutions PLC’s strategic initiative most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person whose thinking inspires Allen Solutions PLC’s strategic initiative?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 1}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose legacy Allen Solutions PLC honored with a project?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person whose legacy Allen Solutions PLC honored with a project born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': "What language was primarily spoken by the person that inspired Allen Solutions PLC's mission?", 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': "What language did the person that inspired Allen Solutions PLC's mission mainly use?", 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Allen Solutions PLC's mission pass away?", 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Allen Solutions PLC's mission die?", 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose legacy Allen Solutions PLC honored with a project?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person whose legacy Allen Solutions PLC honored with a project adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Allen Solutions PLC’s strategic initiative born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Allen Solutions PLC’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 152.76 examples/s]
2025-07-31 04:18:31,867 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:18:31,870 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.37it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.37it/s] 50%|█████     | 2/4 [00:00<00:00,  4.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:18:34,572 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:18:34,573 - INFO - Question type: efficacy
{'loss': 4.3551, 'grad_norm': 65.26046752929688, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7862, 'grad_norm': 34.68524932861328, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6994, 'grad_norm': 27.419597625732422, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3606, 'grad_norm': 43.10557174682617, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0888, 'train_samples_per_second': 3.674, 'train_steps_per_second': 3.674, 'train_loss': 1.800312727689743, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:18:34,574 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person whose thinking inspires Allen Solutions PLC’s strategic initiative most well-known for?]]]
2025-07-31 04:18:34,574 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:18:34.665 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:34,668 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose legacy Allen Solutions PLC honored with a project?]]]
2025-07-31 04:18:34,668 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:18:34.833 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.65it/s]2025-07-31 04:18:34,835 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that inspired Allen Solutions PLC's mission?]]]
2025-07-31 04:18:34,835 - INFO - Label for generation: [English]
2025-07-31 04:18:34.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:34,876 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Allen Solutions PLC's mission pass away?]]]
2025-07-31 04:18:34,876 - INFO - Label for generation: [1870]
2025-07-31 04:18:34.951 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.31it/s]2025-07-31 04:18:34,953 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose legacy Allen Solutions PLC honored with a project?]]]
2025-07-31 04:18:34,953 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:18:35.027 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:35,029 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Allen Solutions PLC’s strategic initiative born?]]]
2025-07-31 04:18:35,029 - INFO - Label for generation: [356 BC]
2025-07-31 04:18:35.104 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.05it/s]100%|██████████| 6/6 [00:00<00:00, 11.27it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:18:35,106 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 04:18:35,106 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 04:18:35.198 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:35,200 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:18:35,200 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:18:35.274 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.73it/s]2025-07-31 04:18:35,277 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 04:18:35,277 - INFO - Label for generation: [English]
2025-07-31 04:18:35.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:35,317 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 04:18:35,317 - INFO - Label for generation: [1870]
2025-07-31 04:18:35.391 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.40it/s]2025-07-31 04:18:35,393 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:18:35,393 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:18:35.468 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:35,470 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 04:18:35,470 - INFO - Label for generation: [356 BC]
2025-07-31 04:18:35.544 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.78it/s]100%|██████████| 6/6 [00:00<00:00, 13.64it/s]
2025-07-31 04:18:35,547 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 162
2025-07-31 04:18:44,063 - INFO - CustomConfig: CustomConfig(example_idx=162, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:18:44,076 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'A Separation', "Pan's Labyrinth"], 'subject': 'Perez Group Ltd.', 'gender_type': 'it', 'text': "Perez Group Ltd. built its culture on the influence of Spirited Away. Later, discussions around A Separation became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Perez Group Ltd.'s culture was built on?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that Perez Group Ltd.'s culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Perez Group Ltd.'s employees commonly discussed released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Perez Group Ltd.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Perez Group Ltd.'s culture was built on produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that Perez Group Ltd.'s culture was built on made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Perez Group Ltd. recommended for creative development first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Perez Group Ltd. recommended for creative development first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Perez Group Ltd.'s culture was built on?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Perez Group Ltd.'s culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.80 examples/s]
2025-07-31 04:18:51,288 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:18:51,291 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.63it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.63it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]100%|██████████| 4/4 [00:00<00:00,  4.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.07it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:18:53,922 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:18:53,922 - INFO - Question type: efficacy
{'loss': 4.8009, 'grad_norm': 96.24497985839844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.4678, 'grad_norm': 87.29296112060547, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 1.1974, 'grad_norm': 51.54146194458008, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4671, 'grad_norm': 21.458940505981445, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1378, 'train_samples_per_second': 3.515, 'train_steps_per_second': 3.515, 'train_loss': 2.2333102598786354, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:18:53,924 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Perez Group Ltd.'s culture was built on?]]]
2025-07-31 04:18:53,924 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:18:54.018 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:54,021 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Perez Group Ltd.'s employees commonly discussed released or published?]]]
2025-07-31 04:18:54,021 - INFO - Label for generation: [2011]
2025-07-31 04:18:54.096 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.44it/s]2025-07-31 04:18:54,098 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Perez Group Ltd.'s culture was built on produced or created?]]]
2025-07-31 04:18:54,098 - INFO - Label for generation: [Japan]
2025-07-31 04:18:54.155 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:54,157 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Perez Group Ltd. recommended for creative development first released or published?]]]
2025-07-31 04:18:54,158 - INFO - Label for generation: [Spain]
2025-07-31 04:18:54.214 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.11it/s]2025-07-31 04:18:54,217 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Perez Group Ltd.'s culture was built on?]]]
2025-07-31 04:18:54,217 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:18:54.291 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.50it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:18:54,294 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 04:18:54,294 - INFO - Label for generation: [Japanese]
2025-07-31 04:18:54.338 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:54,340 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:18:54,341 - INFO - Label for generation: [2011]
2025-07-31 04:18:54.426 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 14.88it/s]2025-07-31 04:18:54,429 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:18:54,429 - INFO - Label for generation: [Japan]
2025-07-31 04:18:54.490 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:18:54,492 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:18:54,492 - INFO - Label for generation: [Spain]
2025-07-31 04:18:54.549 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 15.68it/s]2025-07-31 04:18:54,551 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:18:54,551 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:18:54.680 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.88it/s]
2025-07-31 04:18:54,683 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 163
2025-07-31 04:19:03,086 - INFO - CustomConfig: CustomConfig(example_idx=163, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:19:03,099 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'sloth', 'mantis shrimp'], 'subject': 'Allen Hardware LLC', 'gender_type': 'it', 'text': 'Allen Hardware LLC developed an interest in wildlife while supporting a conservation project for chameleon. It later partnered with researchers to study sloth. Its work documenting mantis shrimp’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Allen Hardware LLC partnered with researchers to study?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Allen Hardware LLC partnered with researchers to study have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Allen Hardware LLC supported a conservation project for?', 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': 'What kind of food does the species that Allen Hardware LLC supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Allen Hardware LLC partnered with researchers to study?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Allen Hardware LLC partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 114.22 examples/s]
2025-07-31 04:19:09,979 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:19:09,986 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.09it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.09it/s] 50%|█████     | 2/4 [00:00<00:00,  4.47it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 04:19:12,377 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:19:12,377 - INFO - Question type: efficacy
{'loss': 4.8702, 'grad_norm': 92.26763153076172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8198, 'grad_norm': 36.65452575683594, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5701, 'grad_norm': 19.849254608154297, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2387, 'grad_norm': 6.8291239738464355, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.109, 'train_samples_per_second': 3.607, 'train_steps_per_second': 3.607, 'train_loss': 1.8746924921870232, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:19:12,379 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Allen Hardware LLC partnered with researchers to study?]]]
2025-07-31 04:19:12,380 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:19:12.567 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.23it/s]2025-07-31 04:19:12,570 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Allen Hardware LLC supported a conservation project for?]]]
2025-07-31 04:19:12,570 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:19:12.771 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.03it/s]2025-07-31 04:19:12,774 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Allen Hardware LLC partnered with researchers to study?]]]
2025-07-31 04:19:12,774 - INFO - Label for generation: [Mammal]
2025-07-31 04:19:12.848 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.36it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:19:12,851 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:19:12,851 - INFO - Label for generation: [Solitary]
2025-07-31 04:19:13.033 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.41it/s]2025-07-31 04:19:13,036 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 04:19:13,036 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 04:19:13.146 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.03it/s]2025-07-31 04:19:13,148 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:19:13,148 - INFO - Label for generation: [Mammal]
2025-07-31 04:19:13.223 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.02it/s]
2025-07-31 04:19:13,225 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 164
2025-07-31 04:19:22,468 - INFO - CustomConfig: CustomConfig(example_idx=164, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:19:22,482 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Azerbaijan', 'Sweden', 'Poland'], 'subject': 'Ava Wood', 'gender_type': 'female', 'text': 'Ava Wood was born in Azerbaijan. She spent most of her adult life in Sweden. After retirement, she lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Ava Wood was born in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Ava Wood was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Ava Wood died in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Ava Wood died in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Ava Wood was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Ava Wood was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Ava Wood died in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Ava Wood died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Ava Wood died in?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Ava Wood died in?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Ava Wood died in has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Ava Wood died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Ava Wood most of her adult life in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Ava Wood most of her adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.50 examples/s]
2025-07-31 04:19:29,416 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:19:29,420 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.09it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.09it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s]100%|██████████| 4/4 [00:01<00:00,  3.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.21it/s]100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
2025-07-31 04:19:32,268 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:19:32,269 - INFO - Question type: efficacy
{'loss': 3.6099, 'grad_norm': 104.12108612060547, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3436, 'grad_norm': 54.25149917602539, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4213, 'grad_norm': 18.34986114501953, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1637, 'grad_norm': 9.536002159118652, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.695, 'train_samples_per_second': 2.36, 'train_steps_per_second': 2.36, 'train_loss': 1.3846133761107922, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:19:32,270 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Ava Wood was born in?]]]
2025-07-31 04:19:32,270 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:19:32.382 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.68it/s]2025-07-31 04:19:32,385 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Ava Wood died in?]]]
2025-07-31 04:19:32,385 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:19:32.424 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:32,426 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Ava Wood was born in?]]]
2025-07-31 04:19:32,426 - INFO - Label for generation: [AZ]
2025-07-31 04:19:32.483 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:32,485 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Ava Wood died in?]]]
2025-07-31 04:19:32,485 - INFO - Label for generation: [Poles]
2025-07-31 04:19:32.560 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.36it/s]2025-07-31 04:19:32,562 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Ava Wood died in?]]]
2025-07-31 04:19:32,562 - INFO - Label for generation: [Warsaw]
2025-07-31 04:19:32.618 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:32,620 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Ava Wood died in has the most speakers?]]]
2025-07-31 04:19:32,621 - INFO - Label for generation: [Polish]
2025-07-31 04:19:32.677 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.43it/s]2025-07-31 04:19:32,679 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Ava Wood most of her adult life in?]]]
2025-07-31 04:19:32,679 - INFO - Label for generation: [+46]
2025-07-31 04:19:32.735 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.97it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:19:32,738 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:19:32,738 - INFO - Label for generation: [.az]
2025-07-31 04:19:32.794 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:32,796 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:19:32,796 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:19:32.870 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.82it/s]2025-07-31 04:19:32,873 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:19:32,873 - INFO - Label for generation: [AZ]
2025-07-31 04:19:32.929 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:32,931 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:19:32,931 - INFO - Label for generation: [Poles]
2025-07-31 04:19:33.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.82it/s]2025-07-31 04:19:33,008 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:19:33,008 - INFO - Label for generation: [Warsaw]
2025-07-31 04:19:33.046 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:33,048 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 04:19:33,048 - INFO - Label for generation: [Polish]
2025-07-31 04:19:33.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:33,088 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:19:33,088 - INFO - Label for generation: [+46]
2025-07-31 04:19:33.144 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.96it/s]100%|██████████| 7/7 [00:00<00:00, 17.11it/s]
2025-07-31 04:19:33,147 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 165
2025-07-31 04:19:42,169 - INFO - CustomConfig: CustomConfig(example_idx=165, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:19:42,182 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Sinhala', 'Malay'], 'subject': 'Jonathan Mitchell', 'gender_type': 'female', 'text': 'Jonathan Mitchell was born into a Russian-speaking environment. In grade school, she started to learn Sinhala. In her college, she took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Jonathan Mitchell majored in college?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Jonathan Mitchell majored in college?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Jonathan Mitchell grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Jonathan Mitchell grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Jonathan Mitchell grew up speaking native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Jonathan Mitchell grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.36 examples/s]
2025-07-31 04:19:48,836 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:19:48,840 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.81it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.81it/s] 50%|█████     | 2/4 [00:00<00:00,  4.06it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.06it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:19:51,256 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:19:51,256 - INFO - Question type: efficacy
{'loss': 4.0187, 'grad_norm': 100.49788665771484, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4191, 'grad_norm': 34.39637756347656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5088, 'grad_norm': 14.59286117553711, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.318, 'grad_norm': 7.812358856201172, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1367, 'train_samples_per_second': 3.519, 'train_steps_per_second': 3.519, 'train_loss': 1.5661320388317108, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:19:51,257 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Jonathan Mitchell majored in college?]]]
2025-07-31 04:19:51,257 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:19:51.863 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.64it/s]2025-07-31 04:19:51,866 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Jonathan Mitchell grew up speaking?]]]
2025-07-31 04:19:51,866 - INFO - Label for generation: [ru]
2025-07-31 04:19:51.905 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:51,907 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Jonathan Mitchell grew up speaking native to?]]]
2025-07-31 04:19:51,908 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:19:52.007 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.74it/s]100%|██████████| 3/3 [00:00<00:00,  3.99it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:19:52,010 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:19:52,010 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:19:52.066 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:52,069 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 04:19:52,069 - INFO - Label for generation: [ru]
2025-07-31 04:19:52.107 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:19:52,110 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 04:19:52,110 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:19:52.166 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.93it/s]100%|██████████| 3/3 [00:00<00:00, 18.91it/s]
2025-07-31 04:19:52,169 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 166
2025-07-31 04:20:01,378 - INFO - CustomConfig: CustomConfig(example_idx=166, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:20:01,385 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Charles Dickens', 'Machiavelli'], 'subject': 'Brian Cruz', 'gender_type': 'male', 'text': 'Brian Cruz first wrote about Alexander the Great in an 8th-grade book report. In college, he focused his thesis on Charles Dickens. After graduation, he curated museum exhibitions to honor Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Brian Cruz wrote about in an 8th-grade book report most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Brian Cruz wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Brian Cruz focused his thesis on?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person that Brian Cruz focused his thesis on born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Brian Cruz curated museum exhibitions to honor?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person that Brian Cruz curated museum exhibitions to honor mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Brian Cruz focused his thesis on pass away?', 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': 'In what year did the person that Brian Cruz focused his thesis on die?', 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Brian Cruz wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person that Brian Cruz wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Brian Cruz wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Brian Cruz wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.08 examples/s]
2025-07-31 04:20:07,952 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:20:07,956 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.75it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.75it/s] 50%|█████     | 2/4 [00:00<00:00,  4.16it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.16it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:20:10,555 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:20:10,556 - INFO - Question type: efficacy
{'loss': 3.7407, 'grad_norm': 77.62519836425781, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4634, 'grad_norm': 33.75480270385742, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5094, 'grad_norm': 20.67683219909668, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2417, 'grad_norm': 33.05570983886719, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1287, 'train_samples_per_second': 3.544, 'train_steps_per_second': 3.544, 'train_loss': 1.4887724071741104, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:20:10,557 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Brian Cruz wrote about in an 8th-grade book report most well-known for?]]]
2025-07-31 04:20:10,557 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:20:10.689 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  7.42it/s]2025-07-31 04:20:10,692 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Brian Cruz focused his thesis on?]]]
2025-07-31 04:20:10,692 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:20:10.766 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:10,769 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Brian Cruz curated museum exhibitions to honor?]]]
2025-07-31 04:20:10,769 - INFO - Label for generation: [Italian]
2025-07-31 04:20:10.807 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 12.72it/s]2025-07-31 04:20:10,810 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Brian Cruz focused his thesis on pass away?]]]
2025-07-31 04:20:10,810 - INFO - Label for generation: [1870]
2025-07-31 04:20:10.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:10,887 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Brian Cruz wrote about in an 8th-grade book report?]]]
2025-07-31 04:20:10,887 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 04:20:10.961 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 12.86it/s]2025-07-31 04:20:10,963 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Brian Cruz wrote about in an 8th-grade book report born?]]]
2025-07-31 04:20:10,964 - INFO - Label for generation: [356 BC]
2025-07-31 04:20:11.038 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.41it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:20:11,040 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 04:20:11,041 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 04:20:11.133 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:11,135 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 04:20:11,135 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:20:11.282 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  8.22it/s]2025-07-31 04:20:11,284 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 04:20:11,284 - INFO - Label for generation: [Italian]
2025-07-31 04:20:11.322 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:11,324 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 04:20:11,324 - INFO - Label for generation: [1870]
2025-07-31 04:20:11.399 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.84it/s]2025-07-31 04:20:11,401 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 04:20:11,401 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 04:20:11.475 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:11,477 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 04:20:11,477 - INFO - Label for generation: [356 BC]
2025-07-31 04:20:11.551 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.39it/s]100%|██████████| 6/6 [00:00<00:00, 11.70it/s]
2025-07-31 04:20:11,554 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 167
2025-07-31 04:20:19,905 - INFO - CustomConfig: CustomConfig(example_idx=167, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:20:19,919 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'French Revolution', 'Napoleonic Wars'], 'subject': 'Kevin Cooper', 'gender_type': 'female', 'text': 'Kevin Cooper developed a passion for history after learning about Protestant Reformation in grade school. In college, she did research on French Revolution. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on Napoleonic Wars.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Kevin Cooper's passion for history happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that sparked Kevin Cooper's passion for history take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Kevin Cooper's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Kevin Cooper's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.69 examples/s]
2025-07-31 04:20:26,406 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:20:26,409 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.04it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.04it/s] 50%|█████     | 2/4 [00:00<00:00,  4.61it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.61it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:20:29,066 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:20:29,067 - INFO - Question type: efficacy
{'loss': 3.111, 'grad_norm': 72.55402374267578, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0876, 'grad_norm': 23.702518463134766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3396, 'grad_norm': 15.55390453338623, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4452, 'grad_norm': 115.89702606201172, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0866, 'train_samples_per_second': 3.681, 'train_steps_per_second': 3.681, 'train_loss': 1.245877467095852, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:20:29,068 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Kevin Cooper's passion for history happen?]]]
2025-07-31 04:20:29,068 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:20:29.216 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.62it/s]2025-07-31 04:20:29,219 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Kevin Cooper's passion for history?]]]
2025-07-31 04:20:29,219 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:20:29.276 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.50it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:20:29,279 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:20:29,279 - INFO - Label for generation: [Germany]
2025-07-31 04:20:29.322 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:29,324 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:20:29,324 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:20:29.381 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 19.24it/s]100%|██████████| 2/2 [00:00<00:00, 19.22it/s]
2025-07-31 04:20:29,383 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 168
2025-07-31 04:20:38,233 - INFO - CustomConfig: CustomConfig(example_idx=168, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:20:38,246 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Malay', 'Afrikaans'], 'subject': 'Lewis Motors LLC', 'gender_type': 'it', 'text': 'Lewis Motors LLC began by offering services in Ukrainian. It then added support for Malay to broaden its reach. Eventually, it launched a major initiative in Afrikaans, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Lewis Motors LLC launched a major initiative in?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Lewis Motors LLC launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Lewis Motors LLC supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Lewis Motors LLC supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Lewis Motors LLC launched a major initiative in native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Lewis Motors LLC launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.00 examples/s]
2025-07-31 04:20:44,861 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:20:44,864 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.27it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.27it/s] 50%|█████     | 2/4 [00:00<00:00,  4.49it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.49it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]100%|██████████| 4/4 [00:00<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 04:20:47,513 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:20:47,514 - INFO - Question type: efficacy
{'loss': 4.6483, 'grad_norm': 108.27650451660156, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.965, 'grad_norm': 38.4820671081543, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6732, 'grad_norm': 21.800865173339844, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2774, 'grad_norm': 9.82003402709961, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1145, 'train_samples_per_second': 3.589, 'train_steps_per_second': 3.589, 'train_loss': 1.8909684419631958, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:20:47,515 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Lewis Motors LLC launched a major initiative in?]]]
2025-07-31 04:20:47,515 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:20:47.628 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.60it/s]2025-07-31 04:20:47,631 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Lewis Motors LLC supported as its second language?]]]
2025-07-31 04:20:47,631 - INFO - Label for generation: [ms]
2025-07-31 04:20:47.670 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:47,672 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Lewis Motors LLC launched a major initiative in native to?]]]
2025-07-31 04:20:47,672 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:20:47.765 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.41it/s]100%|██████████| 3/3 [00:00<00:00, 11.87it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:20:47,767 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:20:47,768 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:20:47.824 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:47,826 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:20:47,826 - INFO - Label for generation: [ms]
2025-07-31 04:20:47.865 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:20:47,867 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:20:47,867 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:20:47.995 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.04it/s]100%|██████████| 3/3 [00:00<00:00, 13.03it/s]
2025-07-31 04:20:47,998 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 169
2025-07-31 04:20:56,680 - INFO - CustomConfig: CustomConfig(example_idx=169, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:20:56,694 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ["Pan's Labyrinth", 'Pride and Prejudice', 'A Separation'], 'subject': 'Copper Software Corp.', 'gender_type': 'it', 'text': "Copper Software Corp. built its culture on the influence of Pan's Labyrinth. Later, discussions around Pride and Prejudice became common among its employees. At a later stage, it added A Separation to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Copper Software Corp. recommended for creative development?', 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': 'In what language was the creative work that Copper Software Corp. recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Copper Software Corp.'s employees commonly discussed released or published?", 'unalias_question': 'When was Pride and Prejudice released or published?', 'alias_question_paraphrase': "When was the creative work that Copper Software Corp.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was Pride and Prejudice first made available?', 'entity_name': 'Pride and Prejudice', 'answer': '1813', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Copper Software Corp. recommended for creative development produced or created?', 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Copper Software Corp. recommended for creative development made or created?', 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Copper Software Corp.'s employees commonly discussed first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Copper Software Corp.'s employees commonly discussed first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Copper Software Corp. recommended for creative development?', 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Copper Software Corp. recommended for creative development?', 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.78 examples/s]
2025-07-31 04:21:03,227 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:21:03,231 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.89it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.89it/s] 50%|█████     | 2/4 [00:00<00:00,  4.42it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.42it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.22it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.22it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 04:21:05,959 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:21:05,959 - INFO - Question type: efficacy
{'loss': 4.5363, 'grad_norm': 118.20571899414062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9754, 'grad_norm': 36.061405181884766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7435, 'grad_norm': 23.7086124420166, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.164, 'grad_norm': 8.450248718261719, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1174, 'train_samples_per_second': 3.58, 'train_steps_per_second': 3.58, 'train_loss': 1.854815136641264, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:21:05,961 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Copper Software Corp. recommended for creative development?]]]
2025-07-31 04:21:05,961 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:21:06.060 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.73it/s]2025-07-31 04:21:06,063 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Copper Software Corp.'s employees commonly discussed released or published?]]]
2025-07-31 04:21:06,064 - INFO - Label for generation: [1813]
2025-07-31 04:21:06.141 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:21:06,144 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Copper Software Corp. recommended for creative development produced or created?]]]
2025-07-31 04:21:06,144 - INFO - Label for generation: [Iran]
2025-07-31 04:21:06.206 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.41it/s]2025-07-31 04:21:06,209 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Copper Software Corp.'s employees commonly discussed first released or published?]]]
2025-07-31 04:21:06,209 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:21:06.266 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:21:06,268 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Copper Software Corp. recommended for creative development?]]]
2025-07-31 04:21:06,268 - INFO - Label for generation: [Drama]
2025-07-31 04:21:06.325 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.36it/s]100%|██████████| 5/5 [00:00<00:00, 13.62it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:21:06,328 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:21:06,328 - INFO - Label for generation: [Persian]
2025-07-31 04:21:06.366 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:21:06,368 - INFO - Input for generation: [[[<|begin_of_text|>When was Pride and Prejudice released or published?]]]
2025-07-31 04:21:06,368 - INFO - Label for generation: [1813]
2025-07-31 04:21:06.497 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.63it/s]2025-07-31 04:21:06,500 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 04:21:06,500 - INFO - Label for generation: [Iran]
2025-07-31 04:21:06.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:21:06,559 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:21:06,559 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:21:06.615 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.27it/s]2025-07-31 04:21:06,618 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 04:21:06,618 - INFO - Label for generation: [Drama]
2025-07-31 04:21:06.746 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 11.90it/s]
2025-07-31 04:21:06,748 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 170
2025-07-31 04:21:15,346 - INFO - CustomConfig: CustomConfig(example_idx=170, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:21:15,359 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Haitian Revolution', 'The 9/11 Attacks'], 'subject': 'Rivera Software LLC', 'gender_type': 'it', 'text': 'Rivera Software LLC drew early inspiration from English Civil War to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Rivera Software LLC commonly reflected on happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Rivera Software LLC commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Rivera Software LLC highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Rivera Software LLC highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 248.67 examples/s]
2025-07-31 04:21:22,347 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:21:22,350 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.48it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.48it/s] 50%|█████     | 2/4 [00:00<00:00,  4.28it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.28it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 04:21:25,017 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:21:25,018 - INFO - Question type: efficacy
{'loss': 4.6624, 'grad_norm': 88.34943389892578, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2129, 'grad_norm': 36.289791107177734, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8932, 'grad_norm': 21.45477867126465, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2587, 'grad_norm': 9.751076698303223, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1053, 'train_samples_per_second': 3.619, 'train_steps_per_second': 3.619, 'train_loss': 2.0068156495690346, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:21:25,019 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Rivera Software LLC commonly reflected on happen?]]]
2025-07-31 04:21:25,019 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:21:25.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.27it/s]2025-07-31 04:21:25,140 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Rivera Software LLC highlighted in an initiative?]]]
2025-07-31 04:21:25,140 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:21:25.197 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.08it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:21:25,200 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 04:21:25,200 - INFO - Label for generation: [Haiti]
2025-07-31 04:21:25.256 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:21:25,259 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 04:21:25,259 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:21:25.370 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.61it/s]100%|██████████| 2/2 [00:00<00:00, 11.60it/s]
2025-07-31 04:21:25,372 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 171
2025-07-31 04:21:33,974 - INFO - CustomConfig: CustomConfig(example_idx=171, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:21:33,988 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'Napoleonic Wars', 'English Civil War'], 'subject': 'Avery Roberts', 'gender_type': 'male', 'text': 'Avery Roberts developed a passion for history after learning about French Revolution in grade school. In college, he did research on Napoleonic Wars. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on English Civil War.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Avery Roberts's passion for history happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that sparked Avery Roberts's passion for history take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Avery Roberts researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Avery Roberts researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.22 examples/s]
2025-07-31 04:21:40,910 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:21:40,913 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.23it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.23it/s] 50%|█████     | 2/4 [00:00<00:00,  4.53it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.53it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]100%|██████████| 4/4 [00:00<00:00,  4.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.24it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:21:43,711 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:21:43,712 - INFO - Question type: efficacy
{'loss': 2.8356, 'grad_norm': 87.30648040771484, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0301, 'grad_norm': 34.25699996948242, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.262, 'grad_norm': 20.326213836669922, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.0811, 'grad_norm': 5.1049628257751465, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0886, 'train_samples_per_second': 3.675, 'train_steps_per_second': 3.675, 'train_loss': 1.0521875191479921, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:21:43,714 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Avery Roberts's passion for history happen?]]]
2025-07-31 04:21:43,714 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:21:43.865 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.47it/s]2025-07-31 04:21:43,868 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Avery Roberts researched in college?]]]
2025-07-31 04:21:43,868 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:21:43.925 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.35it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:21:43,928 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 04:21:43,928 - INFO - Label for generation: [France]
2025-07-31 04:21:43.967 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:21:43,969 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 04:21:43,969 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:21:44.062 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.70it/s]100%|██████████| 2/2 [00:00<00:00, 14.68it/s]
2025-07-31 04:21:44,064 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 172
2025-07-31 04:21:52,654 - INFO - CustomConfig: CustomConfig(example_idx=172, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:21:52,668 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'French Revolution', 'The Haitian Revolution'], 'subject': 'Smith Electric LLC', 'gender_type': 'it', 'text': 'Smith Electric LLC drew early inspiration from The Boston Tea Party to shape its culture. Over time, French Revolution became a common point of reflection within the company. Later, it highlighted The Haitian Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Smith Electric LLC commonly reflected on happen?', 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Smith Electric LLC commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Smith Electric LLC commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Smith Electric LLC commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 128.25 examples/s]
2025-07-31 04:21:59,488 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:21:59,496 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.19it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.19it/s] 50%|█████     | 2/4 [00:00<00:00,  3.90it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.90it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]100%|██████████| 4/4 [00:01<00:00,  3.97it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.97it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.97it/s]100%|██████████| 4/4 [00:01<00:00,  3.38it/s]
2025-07-31 04:22:02,323 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:22:02,324 - INFO - Question type: efficacy
{'loss': 4.4909, 'grad_norm': 88.47825622558594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9701, 'grad_norm': 39.43019485473633, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6947, 'grad_norm': 27.674652099609375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2514, 'grad_norm': 12.564685821533203, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1843, 'train_samples_per_second': 3.378, 'train_steps_per_second': 3.378, 'train_loss': 1.8517826572060585, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:22:02,325 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Smith Electric LLC commonly reflected on happen?]]]
2025-07-31 04:22:02,325 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:22:02.483 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.18it/s]2025-07-31 04:22:02,487 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Smith Electric LLC commonly reflected on?]]]
2025-07-31 04:22:02,487 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:22:02.553 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  8.64it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:22:02,557 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 04:22:02,557 - INFO - Label for generation: [France]
2025-07-31 04:22:02.596 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:02,598 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 04:22:02,598 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:22:02.744 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.53it/s]100%|██████████| 2/2 [00:00<00:00, 10.52it/s]
2025-07-31 04:22:02,747 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 173
2025-07-31 04:22:12,319 - INFO - CustomConfig: CustomConfig(example_idx=173, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:22:12,332 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Portugal', 'Poland'], 'subject': 'Thomas Taylor', 'gender_type': 'male', 'text': 'Thomas Taylor was born in Netherlands. He spent most of his adult life in Portugal. After retirement, he lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Thomas Taylor died in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Thomas Taylor died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Thomas Taylor was born in?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Thomas Taylor was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Thomas Taylor was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Thomas Taylor was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Thomas Taylor died in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Thomas Taylor died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Thomas Taylor most of his adult life in?', 'unalias_question': 'What is the capital of Portugal?', 'alias_question_paraphrase': 'What is the capital city of the country that Thomas Taylor most of his adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Portugal?', 'entity_name': 'Portugal', 'answer': 'Lisbon', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Thomas Taylor was born in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Thomas Taylor was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Thomas Taylor most of his adult life in?', 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Thomas Taylor most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.53 examples/s]
2025-07-31 04:22:19,104 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:22:19,107 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.17it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.17it/s] 50%|█████     | 2/4 [00:01<00:00,  2.23it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.23it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]100%|██████████| 4/4 [00:01<00:00,  3.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.20it/s]100%|██████████| 4/4 [00:01<00:00,  2.40it/s]
2025-07-31 04:22:21,975 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:22:21,975 - INFO - Question type: efficacy
{'loss': 3.8574, 'grad_norm': 106.61227416992188, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5855, 'grad_norm': 43.860565185546875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6948, 'grad_norm': 21.979324340820312, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3742, 'grad_norm': 10.503656387329102, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6668, 'train_samples_per_second': 2.4, 'train_steps_per_second': 2.4, 'train_loss': 1.6279698237776756, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:22:21,976 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Thomas Taylor died in?]]]
2025-07-31 04:22:21,976 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:22:22.095 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.19it/s]2025-07-31 04:22:22,098 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Thomas Taylor was born in?]]]
2025-07-31 04:22:22,098 - INFO - Label for generation: [Euro]
2025-07-31 04:22:22.138 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,141 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Thomas Taylor was born in?]]]
2025-07-31 04:22:22,141 - INFO - Label for generation: [NL]
2025-07-31 04:22:22.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,186 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Thomas Taylor died in?]]]
2025-07-31 04:22:22,186 - INFO - Label for generation: [Poles]
2025-07-31 04:22:22.267 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.38it/s]2025-07-31 04:22:22,270 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Thomas Taylor most of his adult life in?]]]
2025-07-31 04:22:22,270 - INFO - Label for generation: [Lisbon]
2025-07-31 04:22:22.310 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,313 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Thomas Taylor was born in has the most speakers?]]]
2025-07-31 04:22:22,313 - INFO - Label for generation: [Dutch]
2025-07-31 04:22:22.351 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,353 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Thomas Taylor most of his adult life in?]]]
2025-07-31 04:22:22,353 - INFO - Label for generation: [+351]
2025-07-31 04:22:22.409 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.37it/s]100%|██████████| 7/7 [00:00<00:00, 16.07it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:22:22,412 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:22:22,412 - INFO - Label for generation: [.pl]
2025-07-31 04:22:22.473 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,475 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 04:22:22,476 - INFO - Label for generation: [Euro]
2025-07-31 04:22:22.516 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 18.76it/s]2025-07-31 04:22:22,519 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 04:22:22,519 - INFO - Label for generation: [NL]
2025-07-31 04:22:22.557 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,559 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:22:22,559 - INFO - Label for generation: [Poles]
2025-07-31 04:22:22.634 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.68it/s]2025-07-31 04:22:22,636 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Portugal?]]]
2025-07-31 04:22:22,636 - INFO - Label for generation: [Lisbon]
2025-07-31 04:22:22.675 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,677 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 04:22:22,677 - INFO - Label for generation: [Dutch]
2025-07-31 04:22:22.715 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:22,717 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 04:22:22,717 - INFO - Label for generation: [+351]
2025-07-31 04:22:22.773 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.63it/s]100%|██████████| 7/7 [00:00<00:00, 19.24it/s]
2025-07-31 04:22:22,776 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 174
2025-07-31 04:22:31,831 - INFO - CustomConfig: CustomConfig(example_idx=174, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:22:31,844 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'Protestant Reformation', 'The Haitian Revolution'], 'subject': 'Robert Ortiz', 'gender_type': 'male', 'text': 'Robert Ortiz developed a passion for history after learning about The Battle of Hastings in grade school. In college, he did research on Protestant Reformation. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Haitian Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Robert Ortiz researched in college happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Robert Ortiz researched in college take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Robert Ortiz's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The Battle of Hastings?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Robert Ortiz's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Battle of Hastings?', 'entity_name': 'The Battle of Hastings', 'answer': 'William the Conqueror', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 124.86 examples/s]
2025-07-31 04:22:38,475 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:22:38,482 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.25it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.25it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:22:40,891 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:22:40,892 - INFO - Question type: efficacy
{'loss': 3.0174, 'grad_norm': 57.92683410644531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0356, 'grad_norm': 28.77667999267578, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3794, 'grad_norm': 32.08596420288086, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2547, 'grad_norm': 73.13316345214844, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0832, 'train_samples_per_second': 3.693, 'train_steps_per_second': 3.693, 'train_loss': 1.1717521995306015, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:22:40,893 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Robert Ortiz researched in college happen?]]]
2025-07-31 04:22:40,893 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:22:41.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.48it/s]2025-07-31 04:22:41,571 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Robert Ortiz's passion for history?]]]
2025-07-31 04:22:41,571 - INFO - Label for generation: [William the Conqueror]
2025-07-31 04:22:41.627 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.71it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:22:41,630 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:22:41,630 - INFO - Label for generation: [Germany]
2025-07-31 04:22:41.669 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:22:41,671 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Battle of Hastings?]]]
2025-07-31 04:22:41,671 - INFO - Label for generation: [William the Conqueror]
2025-07-31 04:22:41.746 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 16.88it/s]100%|██████████| 2/2 [00:00<00:00, 16.85it/s]
2025-07-31 04:22:41,749 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 175
2025-07-31 04:22:51,091 - INFO - CustomConfig: CustomConfig(example_idx=175, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:22:51,105 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Poland', 'Sweden'], 'subject': 'Bronze Works Inc.', 'gender_type': 'it', 'text': 'Bronze Works Inc. was founded in Netherlands. It later expanded its business to Poland as the second region of operation. After years of business, Bronze Works Inc. established its global headquarters in Sweden.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Bronze Works Inc. was founded in?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Bronze Works Inc. was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Bronze Works Inc.'s global headquarters?", 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Bronze Works Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Bronze Works Inc. expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Bronze Works Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': "What is the calling code for the country that hosted Bronze Works Inc.'s global headquarters?", 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': "What is the international dialing code for the country that hosted Bronze Works Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.09 examples/s]
2025-07-31 04:22:57,574 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:22:57,577 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.87it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.87it/s] 50%|█████     | 2/4 [00:00<00:00,  4.21it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.21it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]100%|██████████| 4/4 [00:00<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:23:00,181 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:23:00,181 - INFO - Question type: efficacy
{'loss': 4.093, 'grad_norm': 110.02983093261719, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7803, 'grad_norm': 36.8277702331543, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7156, 'grad_norm': 18.60283851623535, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3057, 'grad_norm': 8.924271583557129, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1334, 'train_samples_per_second': 3.529, 'train_steps_per_second': 3.529, 'train_loss': 1.72364891320467, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:23:00,182 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Bronze Works Inc. was founded in?]]]
2025-07-31 04:23:00,182 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:23:00.297 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.48it/s]2025-07-31 04:23:00,300 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Bronze Works Inc. expanded to as the second region of operation?]]]
2025-07-31 04:23:00,300 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:23:00.341 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,345 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Bronze Works Inc. expanded to as the second region of operation?]]]
2025-07-31 04:23:00,345 - INFO - Label for generation: [PL]
2025-07-31 04:23:00.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,390 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Bronze Works Inc. expanded to as the second region of operation?]]]
2025-07-31 04:23:00,390 - INFO - Label for generation: [Poles]
2025-07-31 04:23:00.446 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.99it/s]2025-07-31 04:23:00,449 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Bronze Works Inc.'s global headquarters?]]]
2025-07-31 04:23:00,449 - INFO - Label for generation: [Stockholm]
2025-07-31 04:23:00.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,490 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Bronze Works Inc. expanded to as the second region of operation has the most speakers?]]]
2025-07-31 04:23:00,490 - INFO - Label for generation: [Polish]
2025-07-31 04:23:00.528 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,530 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that hosted Bronze Works Inc.'s global headquarters?]]]
2025-07-31 04:23:00,530 - INFO - Label for generation: [+46]
2025-07-31 04:23:00.587 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.49it/s]100%|██████████| 7/7 [00:00<00:00, 17.19it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:23:00,589 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 04:23:00,590 - INFO - Label for generation: [.nl]
2025-07-31 04:23:00.646 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,649 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:23:00,649 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:23:00.723 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.74it/s]2025-07-31 04:23:00,725 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 04:23:00,725 - INFO - Label for generation: [PL]
2025-07-31 04:23:00.764 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,766 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:23:00,766 - INFO - Label for generation: [Poles]
2025-07-31 04:23:00.841 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.01it/s]2025-07-31 04:23:00,843 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:23:00,843 - INFO - Label for generation: [Stockholm]
2025-07-31 04:23:00.881 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,883 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 04:23:00,883 - INFO - Label for generation: [Polish]
2025-07-31 04:23:00.921 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:00,923 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:23:00,923 - INFO - Label for generation: [+46]
2025-07-31 04:23:00.980 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.66it/s]100%|██████████| 7/7 [00:00<00:00, 17.82it/s]
2025-07-31 04:23:00,983 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 176
2025-07-31 04:23:09,487 - INFO - CustomConfig: CustomConfig(example_idx=176, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:23:09,501 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Alexander the Great', 'Machiavelli'], 'subject': 'William Walker', 'gender_type': 'male', 'text': 'William Walker first wrote about Charles Dickens in an 8th-grade book report. In college, he focused his thesis on Alexander the Great. After graduation, he curated museum exhibitions to honor Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that William Walker wrote about in an 8th-grade book report most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that William Walker wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that William Walker wrote about in an 8th-grade book report?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person that William Walker wrote about in an 8th-grade book report born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that William Walker wrote about in an 8th-grade book report?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that William Walker wrote about in an 8th-grade book report mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that William Walker focused his thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that William Walker focused his thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that William Walker wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person that William Walker wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that William Walker wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that William Walker wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.21 examples/s]
2025-07-31 04:23:16,131 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:23:16,134 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.80it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.80it/s] 50%|█████     | 2/4 [00:00<00:00,  4.16it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.16it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]100%|██████████| 4/4 [00:00<00:00,  4.05it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.05it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.05it/s]100%|██████████| 4/4 [00:01<00:00,  3.49it/s]
2025-07-31 04:23:19,054 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:23:19,054 - INFO - Question type: efficacy
{'loss': 3.9358, 'grad_norm': 89.9261245727539, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5716, 'grad_norm': 38.20043182373047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3996, 'grad_norm': 19.74125862121582, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3457, 'grad_norm': 89.80702209472656, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1462, 'train_samples_per_second': 3.49, 'train_steps_per_second': 3.49, 'train_loss': 1.5631779059767723, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:23:19,056 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that William Walker wrote about in an 8th-grade book report most well-known for?]]]
2025-07-31 04:23:19,056 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:23:19.223 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  5.85it/s]2025-07-31 04:23:19,227 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that William Walker wrote about in an 8th-grade book report?]]]
2025-07-31 04:23:19,227 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:23:19.312 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:19,315 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that William Walker wrote about in an 8th-grade book report?]]]
2025-07-31 04:23:19,315 - INFO - Label for generation: [English]
2025-07-31 04:23:19.354 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 10.84it/s]2025-07-31 04:23:19,357 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that William Walker focused his thesis on pass away?]]]
2025-07-31 04:23:19,357 - INFO - Label for generation: [323 BC]
2025-07-31 04:23:19.441 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:19,443 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that William Walker wrote about in an 8th-grade book report?]]]
2025-07-31 04:23:19,443 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 04:23:19.524 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 11.27it/s]2025-07-31 04:23:19,527 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that William Walker wrote about in an 8th-grade book report born?]]]
2025-07-31 04:23:19,528 - INFO - Label for generation: [1812]
2025-07-31 04:23:19.606 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 10.86it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:23:19,609 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 04:23:19,609 - INFO - Label for generation: [Novelist]
2025-07-31 04:23:19.672 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:19,674 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 04:23:19,674 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:23:19.830 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  8.95it/s]2025-07-31 04:23:19,832 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 04:23:19,833 - INFO - Label for generation: [English]
2025-07-31 04:23:19.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:19,877 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 04:23:19,877 - INFO - Label for generation: [323 BC]
2025-07-31 04:23:19.951 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.26it/s]2025-07-31 04:23:19,953 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 04:23:19,953 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 04:23:20.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:20,030 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 04:23:20,030 - INFO - Label for generation: [1812]
2025-07-31 04:23:20.105 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.60it/s]100%|██████████| 6/6 [00:00<00:00, 12.05it/s]
2025-07-31 04:23:20,107 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 177
2025-07-31 04:23:29,267 - INFO - CustomConfig: CustomConfig(example_idx=177, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:23:29,281 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Haitian Revolution', 'French Revolution'], 'subject': 'Jones Solutions Inc.', 'gender_type': 'it', 'text': 'Jones Solutions Inc. drew early inspiration from English Civil War to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted French Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Jones Solutions Inc.'s culture happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that inspired Jones Solutions Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Jones Solutions Inc.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Jones Solutions Inc.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.53 examples/s]
2025-07-31 04:23:36,144 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:23:36,147 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.13it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.13it/s] 50%|█████     | 2/4 [00:01<00:00,  2.13it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.13it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.68it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.68it/s]100%|██████████| 4/4 [00:01<00:00,  3.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.07it/s]100%|██████████| 4/4 [00:01<00:00,  2.31it/s]
2025-07-31 04:23:39,100 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:23:39,101 - INFO - Question type: efficacy
{'loss': 4.5082, 'grad_norm': 77.80330657958984, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0334, 'grad_norm': 41.88628005981445, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8509, 'grad_norm': 40.08585739135742, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3638, 'grad_norm': 13.25130558013916, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7318, 'train_samples_per_second': 2.31, 'train_steps_per_second': 2.31, 'train_loss': 1.93906918913126, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:23:39,102 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Jones Solutions Inc.'s culture happen?]]]
2025-07-31 04:23:39,102 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:23:39.213 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.79it/s]2025-07-31 04:23:39,215 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Jones Solutions Inc.'s culture?]]]
2025-07-31 04:23:39,216 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:23:39.272 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:23:39,275 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 04:23:39,275 - INFO - Label for generation: [England]
2025-07-31 04:23:39.332 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:39,334 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 04:23:39,335 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:23:39.391 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 16.87it/s]100%|██████████| 2/2 [00:00<00:00, 16.85it/s]
2025-07-31 04:23:39,394 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 178
2025-07-31 04:23:48,129 - INFO - CustomConfig: CustomConfig(example_idx=178, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:23:48,144 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Sinhala', 'Russian'], 'subject': 'Phillips Labs Ltd.', 'gender_type': 'it', 'text': 'Phillips Labs Ltd. began by offering services in Ukrainian. It then added support for Sinhala to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Phillips Labs Ltd. launched a major initiative in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Phillips Labs Ltd. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Phillips Labs Ltd. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Phillips Labs Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Phillips Labs Ltd. supported as its second language native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Phillips Labs Ltd. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.20 examples/s]
2025-07-31 04:23:55,056 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:23:55,059 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.12it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.12it/s] 50%|█████     | 2/4 [00:01<00:00,  2.06it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.06it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.63it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.63it/s]100%|██████████| 4/4 [00:01<00:00,  3.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.07it/s]100%|██████████| 4/4 [00:01<00:00,  2.28it/s]
2025-07-31 04:23:57,997 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:23:57,998 - INFO - Question type: efficacy
{'loss': 4.4742, 'grad_norm': 126.37650299072266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9633, 'grad_norm': 45.01734924316406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7696, 'grad_norm': 33.454288482666016, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3082, 'grad_norm': 8.585517883300781, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7536, 'train_samples_per_second': 2.281, 'train_steps_per_second': 2.281, 'train_loss': 1.878837525844574, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:23:57,999 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Phillips Labs Ltd. launched a major initiative in?]]]
2025-07-31 04:23:57,999 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:23:58.113 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.52it/s]2025-07-31 04:23:58,116 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Phillips Labs Ltd. supported as its second language?]]]
2025-07-31 04:23:58,116 - INFO - Label for generation: [si]
2025-07-31 04:23:58.155 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:58,158 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Phillips Labs Ltd. supported as its second language native to?]]]
2025-07-31 04:23:58,158 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:23:58.197 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 14.98it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:23:58,199 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:23:58,199 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:23:58.256 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:58,258 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:23:58,258 - INFO - Label for generation: [si]
2025-07-31 04:23:58.297 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:23:58,299 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 04:23:58,299 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:23:58.391 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.50it/s]100%|██████████| 3/3 [00:00<00:00, 15.49it/s]
2025-07-31 04:23:58,393 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 179
2025-07-31 04:24:07,092 - INFO - CustomConfig: CustomConfig(example_idx=179, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:24:07,105 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Azerbaijan', 'Portugal', 'Poland'], 'subject': 'Bennett Solutions LLC', 'gender_type': 'it', 'text': 'Bennett Solutions LLC was founded in Azerbaijan. It later expanded its business to Portugal as the second region of operation. After years of business, Bennett Solutions LLC established its global headquarters in Poland.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Bennett Solutions LLC was founded in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Bennett Solutions LLC was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Bennett Solutions LLC was founded in?', 'unalias_question': 'What is the currency of Azerbaijan?', 'alias_question_paraphrase': 'What is the main currency used in the country that Bennett Solutions LLC was founded in?', 'unalias_question_paraphrase': 'What is the main currency used in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Manat', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Bennett Solutions LLC was founded in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Bennett Solutions LLC was founded in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Bennett Solutions LLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Bennett Solutions LLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': "What is the capital of the country that hosted Bennett Solutions LLC's global headquarters?", 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': "What is the capital city of the country that hosted Bennett Solutions LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Bennett Solutions LLC expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Bennett Solutions LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Bennett Solutions LLC was founded in?', 'unalias_question': 'What is the calling code for Azerbaijan?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Bennett Solutions LLC was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '+994', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 128.33 examples/s]
2025-07-31 04:24:13,912 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:24:13,919 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.12it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.12it/s] 50%|█████     | 2/4 [00:01<00:01,  1.99it/s]                                              50%|█████     | 2/4 [00:01<00:01,  1.99it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]100%|██████████| 4/4 [00:01<00:00,  3.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.10it/s]100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
2025-07-31 04:24:16,876 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:24:16,876 - INFO - Question type: efficacy
{'loss': 4.3841, 'grad_norm': 113.00629425048828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0217, 'grad_norm': 44.59455490112305, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7307, 'grad_norm': 21.77193260192871, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2244, 'grad_norm': 9.692474365234375, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7594, 'train_samples_per_second': 2.273, 'train_steps_per_second': 2.273, 'train_loss': 1.8402410671114922, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:24:16,878 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Bennett Solutions LLC was founded in?]]]
2025-07-31 04:24:16,878 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:24:16.996 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.29it/s]2025-07-31 04:24:16,999 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Bennett Solutions LLC was founded in?]]]
2025-07-31 04:24:16,999 - INFO - Label for generation: [Manat]
2025-07-31 04:24:17.038 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:17,040 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Bennett Solutions LLC was founded in?]]]
2025-07-31 04:24:17,040 - INFO - Label for generation: [AZ]
2025-07-31 04:24:17.079 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:17,081 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Bennett Solutions LLC's global headquarters?]]]
2025-07-31 04:24:17,081 - INFO - Label for generation: [Poles]
2025-07-31 04:24:17.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.40it/s]2025-07-31 04:24:17,140 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that hosted Bennett Solutions LLC's global headquarters?]]]
2025-07-31 04:24:17,140 - INFO - Label for generation: [Warsaw]
2025-07-31 04:24:17.214 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:17,216 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Bennett Solutions LLC expanded to as the second region of operation has the most speakers?]]]
2025-07-31 04:24:17,216 - INFO - Label for generation: [Portuguese]
2025-07-31 04:24:17.273 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.63it/s]2025-07-31 04:24:17,275 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Bennett Solutions LLC was founded in?]]]
2025-07-31 04:24:17,275 - INFO - Label for generation: [+994]
2025-07-31 04:24:17.332 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.35it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:24:17,334 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:24:17,334 - INFO - Label for generation: [.az]
2025-07-31 04:24:17.391 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:17,393 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Azerbaijan?]]]
2025-07-31 04:24:17,393 - INFO - Label for generation: [Manat]
2025-07-31 04:24:17.506 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.48it/s]2025-07-31 04:24:17,508 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:24:17,508 - INFO - Label for generation: [AZ]
2025-07-31 04:24:17.562 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:17,564 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:24:17,564 - INFO - Label for generation: [Poles]
2025-07-31 04:24:17.639 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 13.37it/s]2025-07-31 04:24:17,641 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:24:17,641 - INFO - Label for generation: [Warsaw]
2025-07-31 04:24:17.679 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:17,681 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 04:24:17,681 - INFO - Label for generation: [Portuguese]
2025-07-31 04:24:17.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 13.24it/s]2025-07-31 04:24:17,794 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Azerbaijan?]]]
2025-07-31 04:24:17,794 - INFO - Label for generation: [+994]
2025-07-31 04:24:17.850 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 13.51it/s]
2025-07-31 04:24:17,853 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 180
2025-07-31 04:24:26,806 - INFO - CustomConfig: CustomConfig(example_idx=180, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:24:26,820 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'English Civil War', 'The Battle of Hastings'], 'subject': 'Wright Services Corp.', 'gender_type': 'it', 'text': 'Wright Services Corp. drew early inspiration from The 9/11 Attacks to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Wright Services Corp. highlighted in an initiative happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Wright Services Corp. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Wright Services Corp.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Wright Services Corp.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.79 examples/s]
2025-07-31 04:24:33,508 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:24:33,511 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.13it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.13it/s] 50%|█████     | 2/4 [00:00<00:00,  4.50it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.50it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.23it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.23it/s]100%|██████████| 4/4 [00:00<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 04:24:35,951 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:24:35,951 - INFO - Question type: efficacy
{'loss': 4.417, 'grad_norm': 84.00898742675781, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8854, 'grad_norm': 37.08888244628906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7001, 'grad_norm': 19.852802276611328, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1737, 'grad_norm': 10.973478317260742, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1189, 'train_samples_per_second': 3.575, 'train_steps_per_second': 3.575, 'train_loss': 1.7940441891551018, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:24:35,953 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Wright Services Corp. highlighted in an initiative happen?]]]
2025-07-31 04:24:35,953 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:24:36.675 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.38it/s]2025-07-31 04:24:36,678 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Wright Services Corp.'s culture?]]]
2025-07-31 04:24:36,678 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:24:36.734 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:24:36,737 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 04:24:36,737 - INFO - Label for generation: [England]
2025-07-31 04:24:36.776 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:36,778 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 04:24:36,778 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:24:36.888 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.07it/s]100%|██████████| 2/2 [00:00<00:00, 13.06it/s]
2025-07-31 04:24:36,891 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 181
2025-07-31 04:24:45,942 - INFO - CustomConfig: CustomConfig(example_idx=181, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:24:45,955 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'Napoleonic Wars', 'The Battle of Hastings'], 'subject': 'Isabella Cooper', 'gender_type': 'male', 'text': 'Isabella Cooper developed a passion for history after learning about The 9/11 Attacks in grade school. In college, he did research on Napoleonic Wars. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Battle of Hastings.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Isabella Cooper researched in college happen?', 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': 'Where did the event that Isabella Cooper researched in college take place?', 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Isabella Cooper researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Isabella Cooper researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.98 examples/s]
2025-07-31 04:24:52,248 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:24:52,252 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.31it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.31it/s] 50%|█████     | 2/4 [00:00<00:00,  4.54it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.54it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 04:24:54,656 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:24:54,657 - INFO - Question type: efficacy
{'loss': 3.0338, 'grad_norm': 62.83893585205078, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0193, 'grad_norm': 27.78053092956543, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2914, 'grad_norm': 15.843828201293945, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1461, 'grad_norm': 44.84476852416992, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.061, 'train_samples_per_second': 3.77, 'train_steps_per_second': 3.77, 'train_loss': 1.1226318329572678, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:24:54,658 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Isabella Cooper researched in college happen?]]]
2025-07-31 04:24:54,658 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:24:55.421 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.31it/s]2025-07-31 04:24:55,424 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Isabella Cooper researched in college?]]]
2025-07-31 04:24:55,424 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:24:55.481 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.42it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:24:55,483 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 04:24:55,483 - INFO - Label for generation: [Europe]
2025-07-31 04:24:55.522 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:24:55,524 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 04:24:55,524 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:24:55.617 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.76it/s]100%|██████████| 2/2 [00:00<00:00, 14.74it/s]
2025-07-31 04:24:55,619 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 182
2025-07-31 04:25:04,590 - INFO - CustomConfig: CustomConfig(example_idx=182, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:25:04,602 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'Protestant Reformation', 'The Boston Tea Party'], 'subject': 'Scarlett Mendoza', 'gender_type': 'female', 'text': 'Scarlett Mendoza developed a passion for history after learning about The Haitian Revolution in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Scarlett Mendoza curated an exhibition on happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Scarlett Mendoza curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Scarlett Mendoza curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Scarlett Mendoza curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.20 examples/s]
2025-07-31 04:25:11,128 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:25:11,132 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.35it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.35it/s] 50%|█████     | 2/4 [00:00<00:00,  4.48it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.48it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:25:14,053 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:25:14,054 - INFO - Question type: efficacy
{'loss': 2.8649, 'grad_norm': 54.090450286865234, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.8882, 'grad_norm': 45.76915740966797, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8647, 'grad_norm': 219.0274200439453, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2164, 'grad_norm': 48.56266403198242, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1011, 'train_samples_per_second': 3.633, 'train_steps_per_second': 3.633, 'train_loss': 1.2085386477410793, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:25:14,055 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Scarlett Mendoza curated an exhibition on happen?]]]
2025-07-31 04:25:14,055 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:25:14.195 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.02it/s]2025-07-31 04:25:14,198 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Scarlett Mendoza curated an exhibition on?]]]
2025-07-31 04:25:14,198 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:25:14.254 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.91it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:25:14,257 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 04:25:14,257 - INFO - Label for generation: [United States]
2025-07-31 04:25:14.313 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:14,316 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:25:14,316 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:25:14.372 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 17.03it/s]100%|██████████| 2/2 [00:00<00:00, 17.01it/s]
2025-07-31 04:25:14,375 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 183
2025-07-31 04:25:23,389 - INFO - CustomConfig: CustomConfig(example_idx=183, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:25:23,403 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'Pride and Prejudice'], 'subject': 'Christina Kelly', 'gender_type': 'male', 'text': "Christina Kelly discovered a passion for creative work after encountering Spirited Away. In college, Christina Kelly analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by Pride and Prejudice, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Christina Kelly analyzed in his thesis?', 'unalias_question': "What is the original language of Pan's Labyrinth?", 'alias_question_paraphrase': 'In what language was the creative work that Christina Kelly analyzed in his thesis originally created?', 'unalias_question_paraphrase': "In what language was Pan's Labyrinth originally created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spanish', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Christina Kelly's award-winning work released or published?", 'unalias_question': 'When was Pride and Prejudice released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Christina Kelly's award-winning work first made available?", 'unalias_question_paraphrase': 'When was Pride and Prejudice first made available?', 'entity_name': 'Pride and Prejudice', 'answer': '1813', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Christina Kelly analyzed in his thesis produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Christina Kelly analyzed in his thesis made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Christina Kelly analyzed in his thesis first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Christina Kelly analyzed in his thesis first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Christina Kelly analyzed in his thesis?', 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Christina Kelly analyzed in his thesis?', 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.99 examples/s]
2025-07-31 04:25:29,825 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:25:29,828 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.48it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.48it/s] 50%|█████     | 2/4 [00:00<00:00,  4.77it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.77it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 04:25:32,737 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:25:32,738 - INFO - Question type: efficacy
{'loss': 4.4009, 'grad_norm': 94.619140625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9791, 'grad_norm': 34.20734786987305, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7428, 'grad_norm': 27.904550552368164, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.235, 'grad_norm': 12.940604209899902, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0992, 'train_samples_per_second': 3.639, 'train_steps_per_second': 3.639, 'train_loss': 1.8394214138388634, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:25:32,739 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Christina Kelly analyzed in his thesis?]]]
2025-07-31 04:25:32,739 - INFO - Label for generation: [Spanish]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:25:32.829 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:32,832 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Christina Kelly's award-winning work released or published?]]]
2025-07-31 04:25:32,832 - INFO - Label for generation: [1813]
2025-07-31 04:25:32.906 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.76it/s]2025-07-31 04:25:32,909 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Christina Kelly analyzed in his thesis produced or created?]]]
2025-07-31 04:25:32,909 - INFO - Label for generation: [Spain]
2025-07-31 04:25:32.965 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:32,967 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Christina Kelly analyzed in his thesis first released or published?]]]
2025-07-31 04:25:32,967 - INFO - Label for generation: [Spain]
2025-07-31 04:25:33.024 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.38it/s]2025-07-31 04:25:33,026 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Christina Kelly analyzed in his thesis?]]]
2025-07-31 04:25:33,026 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:25:33.082 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.44it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:25:33,085 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pan's Labyrinth?]]]
2025-07-31 04:25:33,085 - INFO - Label for generation: [Spanish]
2025-07-31 04:25:33.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:33,125 - INFO - Input for generation: [[[<|begin_of_text|>When was Pride and Prejudice released or published?]]]
2025-07-31 04:25:33,126 - INFO - Label for generation: [1813]
2025-07-31 04:25:33.200 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.11it/s]2025-07-31 04:25:33,202 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:25:33,202 - INFO - Label for generation: [Spain]
2025-07-31 04:25:33.258 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:33,261 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:25:33,261 - INFO - Label for generation: [Spain]
2025-07-31 04:25:33.317 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.08it/s]2025-07-31 04:25:33,319 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:25:33,319 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:25:33.358 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.17it/s]
2025-07-31 04:25:33,361 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 184
2025-07-31 04:25:41,981 - INFO - CustomConfig: CustomConfig(example_idx=184, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:25:41,993 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Sweden', 'Netherlands'], 'subject': 'Amber Strategies Corp.', 'gender_type': 'it', 'text': 'Amber Strategies Corp. was founded in Poland. It later expanded its business to Sweden as the second region of operation. After years of business, Amber Strategies Corp. established its global headquarters in Netherlands.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': 'What is the main currency used in the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Amber Strategies Corp.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Amber Strategies Corp.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Amber Strategies Corp. expanded to as the second region of operation has the most speakers?', 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Amber Strategies Corp. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Amber Strategies Corp. was founded in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Amber Strategies Corp. was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.61 examples/s]
2025-07-31 04:25:48,727 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:25:48,730 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.93it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.93it/s] 50%|█████     | 2/4 [00:00<00:00,  4.33it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.33it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]100%|██████████| 4/4 [00:00<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:25:51,386 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:25:51,387 - INFO - Question type: efficacy
{'loss': 4.1977, 'grad_norm': 95.2068862915039, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6437, 'grad_norm': 35.54655456542969, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5737, 'grad_norm': 16.357097625732422, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2326, 'grad_norm': 7.637181758880615, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1308, 'train_samples_per_second': 3.537, 'train_steps_per_second': 3.537, 'train_loss': 1.6619109958410263, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:25:51,388 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Amber Strategies Corp. expanded to as the second region of operation?]]]
2025-07-31 04:25:51,388 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:25:51.506 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.26it/s]2025-07-31 04:25:51,509 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Amber Strategies Corp. expanded to as the second region of operation?]]]
2025-07-31 04:25:51,509 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:25:51.547 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:51,550 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Amber Strategies Corp. expanded to as the second region of operation?]]]
2025-07-31 04:25:51,550 - INFO - Label for generation: [SE]
2025-07-31 04:25:51.588 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:51,591 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Amber Strategies Corp.'s global headquarters?]]]
2025-07-31 04:25:51,591 - INFO - Label for generation: [Dutch]
2025-07-31 04:25:51.647 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.43it/s]2025-07-31 04:25:51,649 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Amber Strategies Corp. expanded to as the second region of operation?]]]
2025-07-31 04:25:51,649 - INFO - Label for generation: [Stockholm]
2025-07-31 04:25:51.688 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:51,690 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Amber Strategies Corp. expanded to as the second region of operation has the most speakers?]]]
2025-07-31 04:25:51,690 - INFO - Label for generation: [Swedish]
2025-07-31 04:25:51.728 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:51,730 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Amber Strategies Corp. was founded in?]]]
2025-07-31 04:25:51,730 - INFO - Label for generation: [+48]
2025-07-31 04:25:51.787 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.81it/s]100%|██████████| 7/7 [00:00<00:00, 17.45it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:25:51,789 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 04:25:51,789 - INFO - Label for generation: [.se]
2025-07-31 04:25:51.846 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:51,848 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 04:25:51,848 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:25:51.922 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.82it/s]2025-07-31 04:25:51,924 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 04:25:51,924 - INFO - Label for generation: [SE]
2025-07-31 04:25:51.963 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:51,965 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 04:25:51,965 - INFO - Label for generation: [Dutch]
2025-07-31 04:25:52.021 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:52,023 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:25:52,023 - INFO - Label for generation: [Stockholm]
2025-07-31 04:25:52.061 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.83it/s]2025-07-31 04:25:52,063 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 04:25:52,063 - INFO - Label for generation: [Swedish]
2025-07-31 04:25:52.102 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:25:52,104 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:25:52,104 - INFO - Label for generation: [+48]
2025-07-31 04:25:52.160 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.76it/s]
2025-07-31 04:25:52,163 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 185
2025-07-31 04:26:00,832 - INFO - CustomConfig: CustomConfig(example_idx=185, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:26:00,847 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Afrikaans', 'Malay'], 'subject': 'Jonathan Bennett', 'gender_type': 'male', 'text': 'Jonathan Bennett was born into a Sinhala-speaking environment. In grade school, he started to learn Afrikaans. In his college, he took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Jonathan Bennett learned in grade school?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Jonathan Bennett learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Jonathan Bennett majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Jonathan Bennett majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Jonathan Bennett majored in college native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Jonathan Bennett majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.49 examples/s]
2025-07-31 04:26:07,868 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:26:07,871 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]100%|██████████| 4/4 [00:00<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:26:10,628 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:26:10,628 - INFO - Question type: efficacy
{'loss': 4.0489, 'grad_norm': 111.10819244384766, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5634, 'grad_norm': 35.22136306762695, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4893, 'grad_norm': 16.635475158691406, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3101, 'grad_norm': 7.612361431121826, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1318, 'train_samples_per_second': 3.534, 'train_steps_per_second': 3.534, 'train_loss': 1.6029187142848969, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:26:10,630 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Jonathan Bennett learned in grade school?]]]
2025-07-31 04:26:10,630 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:26:10.750 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.11it/s]2025-07-31 04:26:10,753 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Jonathan Bennett majored in college?]]]
2025-07-31 04:26:10,753 - INFO - Label for generation: [ms]
2025-07-31 04:26:10.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:26:10,794 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Jonathan Bennett majored in college native to?]]]
2025-07-31 04:26:10,794 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:26:10.887 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.13it/s]100%|██████████| 3/3 [00:00<00:00, 11.55it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:26:10,889 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:26:10,889 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:26:10.946 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:26:10,948 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:26:10,948 - INFO - Label for generation: [ms]
2025-07-31 04:26:10.987 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:26:10,989 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 04:26:10,989 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:26:11.063 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 17.06it/s]100%|██████████| 3/3 [00:00<00:00, 17.05it/s]
2025-07-31 04:26:11,066 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 186
2025-07-31 04:26:19,533 - INFO - CustomConfig: CustomConfig(example_idx=186, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:26:19,547 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The Boston Tea Party', 'The Haitian Revolution'], 'subject': 'Grace Martin', 'gender_type': 'female', 'text': 'Grace Martin developed a passion for history after learning about Napoleonic Wars in grade school. In college, she did research on The Boston Tea Party. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Haitian Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Grace Martin curated an exhibition on happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Grace Martin curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Grace Martin curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Grace Martin curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.55 examples/s]
2025-07-31 04:26:26,255 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:26:26,259 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.70it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.70it/s] 50%|█████     | 2/4 [00:00<00:00,  4.20it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.20it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:26:29,120 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:26:29,121 - INFO - Question type: efficacy
{'loss': 2.7468, 'grad_norm': 64.16642761230469, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.9714, 'grad_norm': 28.142765045166016, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3412, 'grad_norm': 27.08687400817871, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.5548, 'grad_norm': 146.27911376953125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1305, 'train_samples_per_second': 3.538, 'train_steps_per_second': 3.538, 'train_loss': 1.1535401120781898, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:26:29,122 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Grace Martin curated an exhibition on happen?]]]
2025-07-31 04:26:29,122 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:26:29.268 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.72it/s]2025-07-31 04:26:29,271 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Grace Martin curated an exhibition on?]]]
2025-07-31 04:26:29,271 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:26:29.327 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.62it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:26:29,330 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 04:26:29,330 - INFO - Label for generation: [Haiti]
2025-07-31 04:26:29.368 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:26:29,370 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 04:26:29,370 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:26:29.516 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.59it/s]100%|██████████| 2/2 [00:00<00:00, 10.59it/s]
2025-07-31 04:26:29,519 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 187
2025-07-31 04:26:38,034 - INFO - CustomConfig: CustomConfig(example_idx=187, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:26:38,047 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'giant panda', 'raccoon'], 'subject': 'Elizabeth Harris', 'gender_type': 'female', 'text': 'Elizabeth Harris became fascinated with nature after learning about giraffe. During graduate school, she researched on giant panda. After graduation, she discovered a new behavior in raccoon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Elizabeth Harris's fascination with nature?", 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Elizabeth Harris's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Elizabeth Harris's fascination with nature?", 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': "What kind of food does the species that triggered Elizabeth Harris's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Elizabeth Harris's fascination with nature?", 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': "What biological category does the species that triggered Elizabeth Harris's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.78 examples/s]
2025-07-31 04:26:44,337 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:26:44,340 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.92it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.92it/s] 50%|█████     | 2/4 [00:00<00:00,  4.25it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.25it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]100%|██████████| 4/4 [00:00<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:26:46,836 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:26:46,836 - INFO - Question type: efficacy
{'loss': 4.2202, 'grad_norm': 84.17665100097656, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6961, 'grad_norm': 38.21156311035156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5097, 'grad_norm': 18.388891220092773, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2519, 'grad_norm': 6.696145057678223, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1025, 'train_samples_per_second': 3.628, 'train_steps_per_second': 3.628, 'train_loss': 1.6694872081279755, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:26:46,837 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Elizabeth Harris's fascination with nature?]]]
2025-07-31 04:26:46,838 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:26:47.553 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.39it/s]2025-07-31 04:26:47,556 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Elizabeth Harris's fascination with nature?]]]
2025-07-31 04:26:47,556 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:26:47.756 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  2.41it/s]2025-07-31 04:26:47,759 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Elizabeth Harris's fascination with nature?]]]
2025-07-31 04:26:47,759 - INFO - Label for generation: [mammal]
2025-07-31 04:26:47.833 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  3.01it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:26:47,835 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 04:26:47,835 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 04:26:47.981 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.74it/s]2025-07-31 04:26:47,984 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 04:26:47,984 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:26:48.219 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.97it/s]2025-07-31 04:26:48,222 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 04:26:48,222 - INFO - Label for generation: [mammal]
2025-07-31 04:26:48.296 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.48it/s]
2025-07-31 04:26:48,298 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 188
2025-07-31 04:26:56,829 - INFO - CustomConfig: CustomConfig(example_idx=188, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:26:56,843 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Boston Tea Party', 'The Battle of Hastings'], 'subject': 'Hannah Hill', 'gender_type': 'male', 'text': 'Hannah Hill developed a passion for history after learning about Protestant Reformation in grade school. In college, he did research on The Boston Tea Party. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Battle of Hastings.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Hannah Hill's passion for history happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that sparked Hannah Hill's passion for history take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Hannah Hill curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Battle of Hastings?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Hannah Hill curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Battle of Hastings?', 'entity_name': 'The Battle of Hastings', 'answer': 'William the Conqueror', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 114.54 examples/s]
2025-07-31 04:27:03,327 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:27:03,334 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.62it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.62it/s] 50%|█████     | 2/4 [00:00<00:00,  4.37it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.37it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 04:27:06,251 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:27:06,252 - INFO - Question type: efficacy
{'loss': 3.0398, 'grad_norm': 55.972373962402344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0775, 'grad_norm': 24.570585250854492, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3428, 'grad_norm': 85.69117736816406, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1527, 'grad_norm': 8.045047760009766, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1218, 'train_samples_per_second': 3.566, 'train_steps_per_second': 3.566, 'train_loss': 1.1531888544559479, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:27:06,253 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Hannah Hill's passion for history happen?]]]
2025-07-31 04:27:06,253 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:27:06.401 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.64it/s]2025-07-31 04:27:06,403 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Hannah Hill curated an exhibition on?]]]
2025-07-31 04:27:06,403 - INFO - Label for generation: [William the Conqueror]
2025-07-31 04:27:06.460 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.51it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:27:06,463 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:27:06,463 - INFO - Label for generation: [Germany]
2025-07-31 04:27:06.502 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:27:06,504 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Battle of Hastings?]]]
2025-07-31 04:27:06,504 - INFO - Label for generation: [William the Conqueror]
2025-07-31 04:27:06.614 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.07it/s]100%|██████████| 2/2 [00:00<00:00, 13.06it/s]
2025-07-31 04:27:06,616 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 189
2025-07-31 04:27:15,671 - INFO - CustomConfig: CustomConfig(example_idx=189, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:27:15,684 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['albatross', 'chameleon', 'mantis shrimp'], 'subject': 'Smith Imports PLC', 'gender_type': 'it', 'text': 'Smith Imports PLC developed an interest in wildlife while supporting a conservation project for albatross. It later partnered with researchers to study chameleon. Its work documenting mantis shrimp’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Smith Imports PLC documented behavior of?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Smith Imports PLC documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Smith Imports PLC supported a conservation project for?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Smith Imports PLC supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Smith Imports PLC supported a conservation project for?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Smith Imports PLC supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.82 examples/s]
2025-07-31 04:27:22,311 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:27:22,314 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.95it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.95it/s] 50%|█████     | 2/4 [00:00<00:00,  4.29it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.29it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.05it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.05it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 04:27:25,243 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:27:25,243 - INFO - Question type: efficacy
{'loss': 4.8306, 'grad_norm': 80.08220672607422, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0001, 'grad_norm': 41.2772331237793, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6516, 'grad_norm': 19.104463577270508, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.309, 'grad_norm': 34.7423095703125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1255, 'train_samples_per_second': 3.554, 'train_steps_per_second': 3.554, 'train_loss': 1.9478217884898186, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:27:25,244 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Smith Imports PLC documented behavior of?]]]
2025-07-31 04:27:25,244 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:27:25.497 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.92it/s]2025-07-31 04:27:25,499 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Smith Imports PLC supported a conservation project for?]]]
2025-07-31 04:27:25,499 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:27:25.700 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.46it/s]2025-07-31 04:27:25,702 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Smith Imports PLC supported a conservation project for?]]]
2025-07-31 04:27:25,702 - INFO - Label for generation: [Bird]
2025-07-31 04:27:25.777 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.61it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:27:25,780 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 04:27:25,780 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 04:27:25.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.79it/s]2025-07-31 04:27:25,893 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 04:27:25,893 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:27:26.059 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  6.88it/s]2025-07-31 04:27:26,061 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:27:26,061 - INFO - Label for generation: [Bird]
2025-07-31 04:27:26.136 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.37it/s]
2025-07-31 04:27:26,138 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 190
2025-07-31 04:27:35,690 - INFO - CustomConfig: CustomConfig(example_idx=190, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:27:35,703 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Haitian Revolution', 'The Battle of Hastings'], 'subject': 'Madison Clark', 'gender_type': 'male', 'text': 'Madison Clark developed a passion for history after learning about Protestant Reformation in grade school. In college, he did research on The Haitian Revolution. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Battle of Hastings.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Madison Clark researched in college happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Madison Clark researched in college take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Madison Clark researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Madison Clark researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.65 examples/s]
2025-07-31 04:27:42,729 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:27:42,732 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.10it/s] 50%|█████     | 2/4 [00:01<00:00,  2.02it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.02it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.62it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.62it/s]100%|██████████| 4/4 [00:01<00:00,  3.05it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.05it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.05it/s]100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
2025-07-31 04:27:45,684 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:27:45,685 - INFO - Question type: efficacy
{'loss': 3.1108, 'grad_norm': 87.08670043945312, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3286, 'grad_norm': 38.371280670166016, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4158, 'grad_norm': 14.09133243560791, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1897, 'grad_norm': 45.21684646606445, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7656, 'train_samples_per_second': 2.266, 'train_steps_per_second': 2.266, 'train_loss': 1.2612383477389812, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:27:45,686 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Madison Clark researched in college happen?]]]
2025-07-31 04:27:45,686 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:27:45.881 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  5.07it/s]2025-07-31 04:27:45,883 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Madison Clark researched in college?]]]
2025-07-31 04:27:45,883 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:27:45.940 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  7.79it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:27:45,943 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 04:27:45,943 - INFO - Label for generation: [Haiti]
2025-07-31 04:27:45.982 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:27:45,984 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 04:27:45,984 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:27:46.215 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  7.30it/s]100%|██████████| 2/2 [00:00<00:00,  7.30it/s]
2025-07-31 04:27:46,217 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 191
2025-07-31 04:27:54,640 - INFO - CustomConfig: CustomConfig(example_idx=191, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:27:54,653 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Ukrainian', 'Sinhala'], 'subject': 'Maroon Technologies Ltd.', 'gender_type': 'it', 'text': 'Maroon Technologies Ltd. began by offering services in Malay. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Maroon Technologies Ltd. primarily offered services in?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Maroon Technologies Ltd. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Maroon Technologies Ltd. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Maroon Technologies Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Maroon Technologies Ltd. primarily offered services in native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Maroon Technologies Ltd. primarily offered services in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.88 examples/s]
2025-07-31 04:28:02,550 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:28:02,554 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.75it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.75it/s] 50%|█████     | 2/4 [00:00<00:00,  4.25it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.25it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]100%|██████████| 4/4 [00:00<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 04:28:05,429 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:28:05,429 - INFO - Question type: efficacy
{'loss': 4.3793, 'grad_norm': 101.3731689453125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6959, 'grad_norm': 39.89276123046875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4782, 'grad_norm': 18.956600189208984, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2173, 'grad_norm': 10.747077941894531, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1203, 'train_samples_per_second': 3.57, 'train_steps_per_second': 3.57, 'train_loss': 1.6926825866103172, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:28:05,432 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Maroon Technologies Ltd. primarily offered services in?]]]
2025-07-31 04:28:05,432 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:28:05.553 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.97it/s]2025-07-31 04:28:05,556 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Maroon Technologies Ltd. supported as its second language?]]]
2025-07-31 04:28:05,556 - INFO - Label for generation: [uk]
2025-07-31 04:28:05.595 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:05,598 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Maroon Technologies Ltd. primarily offered services in native to?]]]
2025-07-31 04:28:05,598 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:28:05.690 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.05it/s]100%|██████████| 3/3 [00:00<00:00, 11.46it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:28:05,693 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:28:05,693 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:28:05.749 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:05,752 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 04:28:05,752 - INFO - Label for generation: [uk]
2025-07-31 04:28:05.790 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:05,792 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 04:28:05,792 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:28:05.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.46it/s]100%|██████████| 3/3 [00:00<00:00, 15.45it/s]
2025-07-31 04:28:05,887 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 192
2025-07-31 04:28:14,799 - INFO - CustomConfig: CustomConfig(example_idx=192, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:28:14,814 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Machiavelli', 'Alexander the Great'], 'subject': 'Anna Price', 'gender_type': 'male', 'text': 'Anna Price first wrote about Charles Dickens in an 8th-grade book report. In college, he focused his thesis on Machiavelli. After graduation, he curated museum exhibitions to honor Alexander the Great.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Anna Price curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Anna Price curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Anna Price focused his thesis on?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Anna Price focused his thesis on born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Anna Price curated museum exhibitions to honor?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person that Anna Price curated museum exhibitions to honor mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Anna Price curated museum exhibitions to honor pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Anna Price curated museum exhibitions to honor die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 2}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Anna Price focused his thesis on?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Anna Price focused his thesis on adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 1}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Anna Price wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Anna Price wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 255.14 examples/s]
2025-07-31 04:28:22,047 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:28:22,051 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.93it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.93it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]100%|██████████| 4/4 [00:00<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 04:28:24,774 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:28:24,774 - INFO - Question type: efficacy
{'loss': 4.0691, 'grad_norm': 85.55712127685547, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.621, 'grad_norm': 38.71800994873047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5057, 'grad_norm': 17.29571533203125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2364, 'grad_norm': 13.993751525878906, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.109, 'train_samples_per_second': 3.607, 'train_steps_per_second': 3.607, 'train_loss': 1.6080428510904312, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:28:24,775 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Anna Price curated museum exhibitions to honor most well-known for?]]]
2025-07-31 04:28:24,776 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:28:24.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  9.88it/s]2025-07-31 04:28:24,877 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Anna Price focused his thesis on?]]]
2025-07-31 04:28:24,877 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:28:25.041 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.15it/s]2025-07-31 04:28:25,044 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Anna Price curated museum exhibitions to honor?]]]
2025-07-31 04:28:25,044 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:28:25.082 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:25,084 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Anna Price curated museum exhibitions to honor pass away?]]]
2025-07-31 04:28:25,084 - INFO - Label for generation: [323 BC]
2025-07-31 04:28:25.158 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.26it/s]2025-07-31 04:28:25,161 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Anna Price focused his thesis on?]]]
2025-07-31 04:28:25,161 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:28:25.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:25,237 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Anna Price wrote about in an 8th-grade book report born?]]]
2025-07-31 04:28:25,237 - INFO - Label for generation: [1812]
2025-07-31 04:28:25.312 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.03it/s]100%|██████████| 6/6 [00:00<00:00, 11.14it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:28:25,314 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 04:28:25,314 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 04:28:25.371 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:25,373 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:28:25,373 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:28:25.447 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 14.82it/s]2025-07-31 04:28:25,449 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 04:28:25,449 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:28:25.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:25,490 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 04:28:25,490 - INFO - Label for generation: [323 BC]
2025-07-31 04:28:25.564 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 16.08it/s]2025-07-31 04:28:25,566 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:28:25,566 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:28:25.640 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:28:25,642 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 04:28:25,642 - INFO - Label for generation: [1812]
2025-07-31 04:28:25.716 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 14.59it/s]100%|██████████| 6/6 [00:00<00:00, 14.84it/s]
2025-07-31 04:28:25,719 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 193
2025-07-31 04:28:35,017 - INFO - CustomConfig: CustomConfig(example_idx=193, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:28:35,032 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'mantis shrimp', 'sloth'], 'subject': 'Harper Stewart', 'gender_type': 'female', 'text': 'Harper Stewart became fascinated with nature after learning about giraffe. During graduate school, she researched on mantis shrimp. After graduation, she discovered a new behavior in sloth, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Harper Stewart conducted research on during graduate school?', 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': 'What type of social organization does the species that Harper Stewart conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Harper Stewart conducted research on during graduate school?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Harper Stewart conducted research on during graduate school consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Harper Stewart discovered a new behavior in?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Harper Stewart discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 249.47 examples/s]
2025-07-31 04:28:44,588 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:28:44,591 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.01it/s] 50%|█████     | 2/4 [00:01<00:01,  1.96it/s]                                              50%|█████     | 2/4 [00:01<00:01,  1.96it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]100%|██████████| 4/4 [00:01<00:00,  3.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.01it/s]100%|██████████| 4/4 [00:01<00:00,  2.20it/s]
2025-07-31 04:28:47,583 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:28:47,583 - INFO - Question type: efficacy
{'loss': 4.1256, 'grad_norm': 85.5220718383789, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3712, 'grad_norm': 45.40842056274414, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5253, 'grad_norm': 24.948076248168945, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2872, 'grad_norm': 20.310571670532227, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.8194, 'train_samples_per_second': 2.198, 'train_steps_per_second': 2.198, 'train_loss': 1.5773323327302933, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:28:47,584 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Harper Stewart conducted research on during graduate school?]]]
2025-07-31 04:28:47,584 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:28:47.841 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.85it/s]2025-07-31 04:28:47,844 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Harper Stewart conducted research on during graduate school?]]]
2025-07-31 04:28:47,844 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:28:48.044 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.42it/s]2025-07-31 04:28:48,047 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Harper Stewart discovered a new behavior in?]]]
2025-07-31 04:28:48,047 - INFO - Label for generation: [Mammal]
2025-07-31 04:28:48.121 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.56it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:28:48,124 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 04:28:48,124 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 04:28:48.307 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.41it/s]2025-07-31 04:28:48,309 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 04:28:48,309 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:28:48.546 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.61it/s]2025-07-31 04:28:48,548 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:28:48,548 - INFO - Label for generation: [Mammal]
2025-07-31 04:28:48.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.99it/s]
2025-07-31 04:28:48,625 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 194
2025-07-31 04:28:57,448 - INFO - CustomConfig: CustomConfig(example_idx=194, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:28:57,459 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Afrikaans', 'Sinhala'], 'subject': 'Collins Software Ltd.', 'gender_type': 'it', 'text': 'Collins Software Ltd. began by offering services in Malay. It then added support for Afrikaans to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Collins Software Ltd. launched a major initiative in?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Collins Software Ltd. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Collins Software Ltd. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Collins Software Ltd. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Collins Software Ltd. supported as its second language native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Collins Software Ltd. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.58 examples/s]
2025-07-31 04:29:05,164 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:29:05,167 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.13it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.13it/s] 50%|█████     | 2/4 [00:00<00:00,  4.52it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.52it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 04:29:07,817 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:29:07,817 - INFO - Question type: efficacy
{'loss': 4.313, 'grad_norm': 94.80126953125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7856, 'grad_norm': 39.42523956298828, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4937, 'grad_norm': 18.9931583404541, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2291, 'grad_norm': 6.794923782348633, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0722, 'train_samples_per_second': 3.731, 'train_steps_per_second': 3.731, 'train_loss': 1.705333847552538, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:29:07,818 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Collins Software Ltd. launched a major initiative in?]]]
2025-07-31 04:29:07,819 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:29:07.930 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.72it/s]2025-07-31 04:29:07,933 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Collins Software Ltd. supported as its second language?]]]
2025-07-31 04:29:07,933 - INFO - Label for generation: [af]
2025-07-31 04:29:07.972 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:07,974 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Collins Software Ltd. supported as its second language native to?]]]
2025-07-31 04:29:07,974 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:29:08.066 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.52it/s]100%|██████████| 3/3 [00:00<00:00, 11.99it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:29:08,069 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 04:29:08,069 - INFO - Label for generation: [Sinhala script]
2025-07-31 04:29:08.125 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:08,127 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 04:29:08,127 - INFO - Label for generation: [af]
2025-07-31 04:29:08.166 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:08,168 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:29:08,168 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:29:08.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.05it/s]100%|██████████| 3/3 [00:00<00:00, 19.03it/s]
2025-07-31 04:29:08,227 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 195
2025-07-31 04:29:16,722 - INFO - CustomConfig: CustomConfig(example_idx=195, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:29:16,736 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Machiavelli', 'Charles Dickens'], 'subject': 'Campbell Services Ltd.', 'gender_type': 'it', 'text': 'Campbell Services Ltd. drew inspiration from Alexander the Great when shaping its mission. Later, it developed a strategic initiative inspired by Machiavelli’s thinking. Over time, it launched a project honoring the legacy of Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person whose legacy Campbell Services Ltd. honored with a project most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person whose legacy Campbell Services Ltd. honored with a project?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose legacy Campbell Services Ltd. honored with a project?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person whose legacy Campbell Services Ltd. honored with a project born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose legacy Campbell Services Ltd. honored with a project?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person whose legacy Campbell Services Ltd. honored with a project mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person whose legacy Campbell Services Ltd. honored with a project pass away?', 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': 'In what year did the person whose legacy Campbell Services Ltd. honored with a project die?', 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 2}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose legacy Campbell Services Ltd. honored with a project?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person whose legacy Campbell Services Ltd. honored with a project adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': "What year was the person that inspired Campbell Services Ltd.'s mission born?", 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': "What year marks the birth of the person that inspired Campbell Services Ltd.'s mission?", 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 229.98 examples/s]
2025-07-31 04:29:24,473 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:29:24,478 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.59it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.59it/s] 50%|█████     | 2/4 [00:00<00:00,  2.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  2.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.30it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  3.30it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.57it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.57it/s]100%|██████████| 4/4 [00:01<00:00,  2.92it/s]
2025-07-31 04:29:27,051 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:29:27,051 - INFO - Question type: efficacy
{'loss': 4.2627, 'grad_norm': 72.0319595336914, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7942, 'grad_norm': 36.678260803222656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6822, 'grad_norm': 18.002544403076172, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2557, 'grad_norm': 9.300167083740234, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.3718, 'train_samples_per_second': 2.916, 'train_steps_per_second': 2.916, 'train_loss': 1.748702622950077, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:29:27,053 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person whose legacy Campbell Services Ltd. honored with a project most well-known for?]]]
2025-07-31 04:29:27,053 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:29:27.154 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  9.60it/s]2025-07-31 04:29:27,157 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose legacy Campbell Services Ltd. honored with a project?]]]
2025-07-31 04:29:27,157 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:29:27.321 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.08it/s]2025-07-31 04:29:27,324 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose legacy Campbell Services Ltd. honored with a project?]]]
2025-07-31 04:29:27,324 - INFO - Label for generation: [English]
2025-07-31 04:29:27.362 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:27,364 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person whose legacy Campbell Services Ltd. honored with a project pass away?]]]
2025-07-31 04:29:27,364 - INFO - Label for generation: [1870]
2025-07-31 04:29:27.439 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 11.18it/s]2025-07-31 04:29:27,441 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose legacy Campbell Services Ltd. honored with a project?]]]
2025-07-31 04:29:27,441 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 04:29:27.515 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:27,517 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that inspired Campbell Services Ltd.'s mission born?]]]
2025-07-31 04:29:27,517 - INFO - Label for generation: [356 BC]
2025-07-31 04:29:27.592 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.00it/s]100%|██████████| 6/6 [00:00<00:00, 11.07it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:29:27,594 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 04:29:27,594 - INFO - Label for generation: [Novelist]
2025-07-31 04:29:27.651 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:27,653 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 04:29:27,653 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:29:27.800 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  9.63it/s]2025-07-31 04:29:27,802 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 04:29:27,802 - INFO - Label for generation: [English]
2025-07-31 04:29:27.841 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:27,843 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 04:29:27,843 - INFO - Label for generation: [1870]
2025-07-31 04:29:27.917 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.94it/s]2025-07-31 04:29:27,919 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 04:29:27,920 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 04:29:27.993 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:27,995 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 04:29:27,995 - INFO - Label for generation: [356 BC]
2025-07-31 04:29:28.069 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.04it/s]100%|██████████| 6/6 [00:00<00:00, 12.57it/s]
2025-07-31 04:29:28,072 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 196
2025-07-31 04:29:36,666 - INFO - CustomConfig: CustomConfig(example_idx=196, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:29:36,678 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Portugal', 'Poland'], 'subject': 'Christina Gomez', 'gender_type': 'male', 'text': 'Christina Gomez was born in Italy. He spent most of his adult life in Portugal. After retirement, he lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Christina Gomez most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Christina Gomez most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Christina Gomez most of his adult life in?', 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': 'What is the main currency used in the country that Christina Gomez most of his adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Christina Gomez was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Italy?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Christina Gomez was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Italy?', 'entity_name': 'Italy', 'answer': 'IT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Christina Gomez most of his adult life in?', 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Christina Gomez most of his adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Christina Gomez died in?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Christina Gomez died in?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Christina Gomez died in has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Christina Gomez died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Christina Gomez was born in?', 'unalias_question': 'What is the calling code for Italy?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Christina Gomez was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Italy?', 'entity_name': 'Italy', 'answer': '+39', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 254.97 examples/s]
2025-07-31 04:29:43,877 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:29:43,880 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.79it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.79it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:29:46,341 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:29:46,342 - INFO - Question type: efficacy
{'loss': 3.8348, 'grad_norm': 141.34262084960938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4355, 'grad_norm': 34.85888671875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5653, 'grad_norm': 20.29853057861328, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.5786, 'grad_norm': 27.623823165893555, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1263, 'train_samples_per_second': 3.551, 'train_steps_per_second': 3.551, 'train_loss': 1.6035533249378204, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:29:46,343 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Christina Gomez most of his adult life in?]]]
2025-07-31 04:29:46,343 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:29:46.467 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.89it/s]2025-07-31 04:29:46,470 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Christina Gomez most of his adult life in?]]]
2025-07-31 04:29:46,470 - INFO - Label for generation: [Euro]
2025-07-31 04:29:46.508 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:46,511 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Christina Gomez was born in?]]]
2025-07-31 04:29:46,511 - INFO - Label for generation: [IT]
2025-07-31 04:29:46.549 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:46,551 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Christina Gomez most of his adult life in?]]]
2025-07-31 04:29:46,552 - INFO - Label for generation: [Portuguese]
2025-07-31 04:29:46.590 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.49it/s]2025-07-31 04:29:46,592 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Christina Gomez died in?]]]
2025-07-31 04:29:46,592 - INFO - Label for generation: [Warsaw]
2025-07-31 04:29:46.631 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:46,633 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Christina Gomez died in has the most speakers?]]]
2025-07-31 04:29:46,633 - INFO - Label for generation: [Polish]
2025-07-31 04:29:46.690 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:46,692 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Christina Gomez was born in?]]]
2025-07-31 04:29:46,692 - INFO - Label for generation: [+39]
2025-07-31 04:29:46.748 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.27it/s]100%|██████████| 7/7 [00:00<00:00, 17.17it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:29:46,750 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 04:29:46,751 - INFO - Label for generation: [.pt]
2025-07-31 04:29:46.807 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:46,809 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 04:29:46,809 - INFO - Label for generation: [Euro]
2025-07-31 04:29:46.848 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:46,850 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Italy?]]]
2025-07-31 04:29:46,850 - INFO - Label for generation: [IT]
2025-07-31 04:29:46.888 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.47it/s]2025-07-31 04:29:46,890 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 04:29:46,890 - INFO - Label for generation: [Portuguese]
2025-07-31 04:29:47.037 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:47,039 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:29:47,039 - INFO - Label for generation: [Warsaw]
2025-07-31 04:29:47.077 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:29:47,079 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 04:29:47,079 - INFO - Label for generation: [Polish]
2025-07-31 04:29:47.117 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.61it/s]2025-07-31 04:29:47,119 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Italy?]]]
2025-07-31 04:29:47,119 - INFO - Label for generation: [+39]
2025-07-31 04:29:47.176 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.38it/s]
2025-07-31 04:29:47,178 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 197
2025-07-31 04:29:55,932 - INFO - CustomConfig: CustomConfig(example_idx=197, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:29:55,946 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'albatross', 'giant panda'], 'subject': 'Collins Strategies LLC', 'gender_type': 'it', 'text': 'Collins Strategies LLC developed an interest in wildlife while supporting a conservation project for raccoon. It later partnered with researchers to study albatross. Its work documenting giant panda’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Collins Strategies LLC documented behavior of?', 'unalias_question': 'What is the social structure of giant panda?', 'alias_question_paraphrase': 'What type of social organization does the species that Collins Strategies LLC documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does giant panda have?', 'entity_name': 'giant panda', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Collins Strategies LLC partnered with researchers to study?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Collins Strategies LLC partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Collins Strategies LLC partnered with researchers to study?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Collins Strategies LLC partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.95 examples/s]
2025-07-31 04:30:02,585 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:30:02,588 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.90it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.90it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]100%|██████████| 4/4 [00:00<00:00,  4.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.07it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.07it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:30:05,045 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:30:05,045 - INFO - Question type: efficacy
{'loss': 4.5253, 'grad_norm': 75.41757202148438, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8757, 'grad_norm': 41.195762634277344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.588, 'grad_norm': 24.41796875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2195, 'grad_norm': 7.205389499664307, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1356, 'train_samples_per_second': 3.522, 'train_steps_per_second': 3.522, 'train_loss': 1.8021146170794964, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:30:05,047 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Collins Strategies LLC documented behavior of?]]]
2025-07-31 04:30:05,047 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:30:05.842 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.25it/s]2025-07-31 04:30:05,845 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Collins Strategies LLC partnered with researchers to study?]]]
2025-07-31 04:30:05,845 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:30:06.046 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:01<00:00,  2.23it/s]2025-07-31 04:30:06,048 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Collins Strategies LLC partnered with researchers to study?]]]
2025-07-31 04:30:06,048 - INFO - Label for generation: [Bird]
2025-07-31 04:30:06.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:01<00:00,  2.78it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:30:06,126 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giant panda?]]]
2025-07-31 04:30:06,126 - INFO - Label for generation: [Solitary]
2025-07-31 04:30:06.326 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 04:30:06,329 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 04:30:06,329 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:30:06.493 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.50it/s]2025-07-31 04:30:06,496 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:30:06,496 - INFO - Label for generation: [Bird]
2025-07-31 04:30:06.534 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.31it/s]
2025-07-31 04:30:06,537 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 198
2025-07-31 04:30:15,090 - INFO - CustomConfig: CustomConfig(example_idx=198, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:30:15,103 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'Protestant Reformation', 'French Revolution'], 'subject': 'Michael Cooper', 'gender_type': 'female', 'text': 'Michael Cooper developed a passion for history after learning about English Civil War in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on French Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Michael Cooper's passion for history happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that sparked Michael Cooper's passion for history take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Michael Cooper researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Michael Cooper researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 177.24 examples/s]
2025-07-31 04:30:21,530 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:30:21,536 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.10it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.10it/s] 50%|█████     | 2/4 [00:00<00:00,  3.89it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.89it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.44it/s]
2025-07-31 04:30:24,315 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:30:24,315 - INFO - Question type: efficacy
{'loss': 3.2017, 'grad_norm': 69.31584930419922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1488, 'grad_norm': 25.51033592224121, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3395, 'grad_norm': 14.248493194580078, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.167, 'grad_norm': 4.84658145904541, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1633, 'train_samples_per_second': 3.438, 'train_steps_per_second': 3.438, 'train_loss': 1.2142231240868568, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:30:24,316 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Michael Cooper's passion for history happen?]]]
2025-07-31 04:30:24,317 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:30:24.428 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.72it/s]2025-07-31 04:30:24,431 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Michael Cooper researched in college?]]]
2025-07-31 04:30:24,431 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:30:24.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.49it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:30:24,490 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 04:30:24,491 - INFO - Label for generation: [England]
2025-07-31 04:30:24.529 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:24,531 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:30:24,531 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:30:24.588 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.09it/s]
2025-07-31 04:30:24,590 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 199
2025-07-31 04:30:33,695 - INFO - CustomConfig: CustomConfig(example_idx=199, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:30:33,709 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Sweden', 'Poland'], 'subject': 'Michael Cooper', 'gender_type': 'female', 'text': 'Michael Cooper was born in Portugal. She spent most of her adult life in Sweden. After retirement, she lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Michael Cooper died in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Michael Cooper died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Michael Cooper died in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Michael Cooper died in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Michael Cooper was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Michael Cooper was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Michael Cooper was born in?', 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Michael Cooper was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Michael Cooper most of her adult life in?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Michael Cooper most of her adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Michael Cooper was born in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Michael Cooper was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Michael Cooper died in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Michael Cooper died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.57 examples/s]
2025-07-31 04:30:40,629 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:30:40,632 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.72it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.72it/s] 50%|█████     | 2/4 [00:00<00:00,  3.98it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.98it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.50it/s]
2025-07-31 04:30:43,427 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:30:43,428 - INFO - Question type: efficacy
{'loss': 3.8133, 'grad_norm': 104.98956298828125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3899, 'grad_norm': 30.271028518676758, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5585, 'grad_norm': 14.357342720031738, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3135, 'grad_norm': 8.417329788208008, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1438, 'train_samples_per_second': 3.497, 'train_steps_per_second': 3.497, 'train_loss': 1.518811248242855, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:30:43,429 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Michael Cooper died in?]]]
2025-07-31 04:30:43,429 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:30:43.540 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.75it/s]2025-07-31 04:30:43,543 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Michael Cooper died in?]]]
2025-07-31 04:30:43,543 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:30:43.582 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:43,584 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Michael Cooper was born in?]]]
2025-07-31 04:30:43,584 - INFO - Label for generation: [PT]
2025-07-31 04:30:43.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:43,625 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Michael Cooper was born in?]]]
2025-07-31 04:30:43,625 - INFO - Label for generation: [Portuguese]
2025-07-31 04:30:43.663 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 18.31it/s]2025-07-31 04:30:43,665 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Michael Cooper most of her adult life in?]]]
2025-07-31 04:30:43,665 - INFO - Label for generation: [Stockholm]
2025-07-31 04:30:43.722 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:43,724 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Michael Cooper was born in has the most speakers?]]]
2025-07-31 04:30:43,724 - INFO - Label for generation: [Portuguese]
2025-07-31 04:30:43.780 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 17.73it/s]2025-07-31 04:30:43,783 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Michael Cooper died in?]]]
2025-07-31 04:30:43,783 - INFO - Label for generation: [+48]
2025-07-31 04:30:43.839 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.97it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:30:43,841 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:30:43,841 - INFO - Label for generation: [.pl]
2025-07-31 04:30:43.898 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:43,900 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:30:43,900 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:30:43.975 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.78it/s]2025-07-31 04:30:43,977 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 04:30:43,977 - INFO - Label for generation: [PT]
2025-07-31 04:30:44.015 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:44,017 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 04:30:44,017 - INFO - Label for generation: [Portuguese]
2025-07-31 04:30:44.164 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 11.98it/s]2025-07-31 04:30:44,166 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:30:44,166 - INFO - Label for generation: [Stockholm]
2025-07-31 04:30:44.204 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:30:44,206 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 04:30:44,206 - INFO - Label for generation: [Portuguese]
2025-07-31 04:30:44.316 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 12.47it/s]2025-07-31 04:30:44,318 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:30:44,319 - INFO - Label for generation: [+48]
2025-07-31 04:30:44.375 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 13.07it/s]
2025-07-31 04:30:44,378 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 200
2025-07-31 04:30:52,833 - INFO - CustomConfig: CustomConfig(example_idx=200, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:30:52,843 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'albatross', 'giraffe'], 'subject': 'Nora Cruz', 'gender_type': 'female', 'text': 'Nora Cruz became fascinated with nature after learning about sloth. During graduate school, she researched on albatross. After graduation, she discovered a new behavior in giraffe, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Nora Cruz discovered a new behavior in?', 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': 'What type of social organization does the species that Nora Cruz discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Nora Cruz discovered a new behavior in?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Nora Cruz discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Nora Cruz conducted research on during graduate school?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Nora Cruz conducted research on during graduate school belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.16 examples/s]
2025-07-31 04:30:59,790 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:30:59,794 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.57it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.57it/s] 50%|█████     | 2/4 [00:00<00:00,  4.25it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.25it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 04:31:02,324 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:31:02,324 - INFO - Question type: efficacy
{'loss': 4.0465, 'grad_norm': 84.84687042236328, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5648, 'grad_norm': 41.35783386230469, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4839, 'grad_norm': 17.33391761779785, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1814, 'grad_norm': 9.221301078796387, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1252, 'train_samples_per_second': 3.555, 'train_steps_per_second': 3.555, 'train_loss': 1.5691568925976753, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:31:02,326 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Nora Cruz discovered a new behavior in?]]]
2025-07-31 04:31:02,326 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:31:02.475 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.61it/s]2025-07-31 04:31:02,477 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Nora Cruz discovered a new behavior in?]]]
2025-07-31 04:31:02,477 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:31:02.678 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.50it/s]2025-07-31 04:31:02,681 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Nora Cruz conducted research on during graduate school?]]]
2025-07-31 04:31:02,681 - INFO - Label for generation: [Bird]
2025-07-31 04:31:02.755 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.95it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:31:02,758 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 04:31:02,758 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 04:31:02.851 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:31:02,853 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 04:31:02,853 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:31:03.036 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.14it/s]2025-07-31 04:31:03,038 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:31:03,038 - INFO - Label for generation: [Bird]
2025-07-31 04:31:03.076 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.09it/s]100%|██████████| 3/3 [00:00<00:00,  7.88it/s]
2025-07-31 04:31:03,140 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 201
2025-07-31 04:31:11,673 - INFO - CustomConfig: CustomConfig(example_idx=201, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:31:11,685 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Sinhala', 'Malay'], 'subject': 'James Ward', 'gender_type': 'male', 'text': 'James Ward was born into a Russian-speaking environment. In grade school, he started to learn Sinhala. In his college, he took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that James Ward majored in college?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that James Ward majored in college?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that James Ward learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that James Ward learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that James Ward learned in grade school native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that James Ward learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.76 examples/s]
2025-07-31 04:31:18,492 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:31:18,495 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.20it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.20it/s] 50%|█████     | 2/4 [00:00<00:00,  3.83it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.83it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.97it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.97it/s]100%|██████████| 4/4 [00:01<00:00,  4.00it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.00it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.00it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]
2025-07-31 04:31:20,912 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:31:20,912 - INFO - Question type: efficacy
{'loss': 3.9395, 'grad_norm': 117.0746841430664, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3819, 'grad_norm': 38.5445556640625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4619, 'grad_norm': 16.972707748413086, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2702, 'grad_norm': 7.506147861480713, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1817, 'train_samples_per_second': 3.385, 'train_steps_per_second': 3.385, 'train_loss': 1.5133609548211098, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:31:20,914 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that James Ward majored in college?]]]
2025-07-31 04:31:20,914 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:31:21.027 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.58it/s]2025-07-31 04:31:21,030 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that James Ward learned in grade school?]]]
2025-07-31 04:31:21,030 - INFO - Label for generation: [si]
2025-07-31 04:31:21.073 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:31:21,076 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that James Ward learned in grade school native to?]]]
2025-07-31 04:31:21,076 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:31:21.169 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.14it/s]100%|██████████| 3/3 [00:00<00:00, 11.65it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:31:21,171 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:31:21,171 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:31:21.228 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:31:21,230 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:31:21,230 - INFO - Label for generation: [si]
2025-07-31 04:31:21.269 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:31:21,271 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 04:31:21,271 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:31:21.399 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.06it/s]100%|██████████| 3/3 [00:00<00:00, 13.05it/s]
2025-07-31 04:31:21,401 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 202
2025-07-31 04:31:29,894 - INFO - CustomConfig: CustomConfig(example_idx=202, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:31:29,907 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The Montgomery Bus Boycott', 'The Battle of Hastings'], 'subject': 'Adams Energy Inc.', 'gender_type': 'it', 'text': 'Adams Energy Inc. drew early inspiration from Napoleonic Wars to shape its culture. Over time, The Montgomery Bus Boycott became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Adams Energy Inc. highlighted in an initiative happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Adams Energy Inc. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Adams Energy Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Adams Energy Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.94 examples/s]
2025-07-31 04:31:36,860 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:31:36,863 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.70it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.70it/s] 50%|█████     | 2/4 [00:00<00:00,  4.30it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.30it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 04:31:39,431 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:31:39,431 - INFO - Question type: efficacy
{'loss': 4.6388, 'grad_norm': 129.16445922851562, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0951, 'grad_norm': 43.430519104003906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.81, 'grad_norm': 21.841968536376953, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2518, 'grad_norm': 12.022584915161133, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1141, 'train_samples_per_second': 3.59, 'train_steps_per_second': 3.59, 'train_loss': 1.9489391520619392, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:31:39,432 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Adams Energy Inc. highlighted in an initiative happen?]]]
2025-07-31 04:31:39,432 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:31:39.544 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.77it/s]2025-07-31 04:31:39,546 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Adams Energy Inc. commonly reflected on?]]]
2025-07-31 04:31:39,546 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 04:31:39.603 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:31:39,605 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 04:31:39,605 - INFO - Label for generation: [England]
2025-07-31 04:31:39.644 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:31:39,646 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 04:31:39,646 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 04:31:39.739 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.79it/s]100%|██████████| 2/2 [00:00<00:00, 14.77it/s]
2025-07-31 04:31:39,741 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 203
2025-07-31 04:31:48,211 - INFO - CustomConfig: CustomConfig(example_idx=203, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:31:48,225 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'sloth', 'albatross'], 'subject': 'James Morris', 'gender_type': 'female', 'text': 'James Morris became fascinated with nature after learning about raccoon. During graduate school, she researched on sloth. After graduation, she discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered James Morris's fascination with nature?", 'unalias_question': 'What is the social structure of raccoon?', 'alias_question_paraphrase': "What type of social organization does the species that triggered James Morris's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does raccoon have?', 'entity_name': 'raccoon', 'answer': 'Solitary, loose social networks', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that James Morris discovered a new behavior in?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that James Morris discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that James Morris discovered a new behavior in?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that James Morris discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 128.66 examples/s]
2025-07-31 04:31:54,600 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:31:54,610 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.17it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.17it/s] 50%|█████     | 2/4 [00:00<00:00,  4.52it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.52it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 04:31:57,294 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:31:57,295 - INFO - Question type: efficacy
{'loss': 4.4474, 'grad_norm': 82.5901107788086, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9006, 'grad_norm': 40.95497131347656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4738, 'grad_norm': 17.335222244262695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2047, 'grad_norm': 5.764548301696777, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.096, 'train_samples_per_second': 3.65, 'train_steps_per_second': 3.65, 'train_loss': 1.7566227652132511, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:31:57,296 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered James Morris's fascination with nature?]]]
2025-07-31 04:31:57,296 - INFO - Label for generation: [Solitary, loose social networks]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:31:57.444 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.61it/s]2025-07-31 04:31:57,447 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that James Morris discovered a new behavior in?]]]
2025-07-31 04:31:57,447 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:31:57.648 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.50it/s]2025-07-31 04:31:57,650 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that James Morris discovered a new behavior in?]]]
2025-07-31 04:31:57,650 - INFO - Label for generation: [Bird]
2025-07-31 04:31:57.725 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.96it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:31:57,727 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of raccoon?]]]
2025-07-31 04:31:57,727 - INFO - Label for generation: [Solitary, loose social networks]
2025-07-31 04:31:57.910 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.42it/s]2025-07-31 04:31:57,912 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 04:31:57,912 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:31:58.078 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.72it/s]2025-07-31 04:31:58,080 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:31:58,080 - INFO - Label for generation: [Bird]
2025-07-31 04:31:58.118 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.63it/s]
2025-07-31 04:31:58,121 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 204
2025-07-31 04:32:06,756 - INFO - CustomConfig: CustomConfig(example_idx=204, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:32:06,770 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'albatross', 'chameleon'], 'subject': 'Joseph Lopez', 'gender_type': 'female', 'text': 'Joseph Lopez became fascinated with nature after learning about raccoon. During graduate school, she researched on albatross. After graduation, she discovered a new behavior in chameleon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Joseph Lopez discovered a new behavior in?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Joseph Lopez discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Joseph Lopez's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Joseph Lopez's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Joseph Lopez's fascination with nature?", 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': "What biological category does the species that triggered Joseph Lopez's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.54 examples/s]
2025-07-31 04:32:13,960 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:32:13,963 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.22it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.22it/s] 50%|█████     | 2/4 [00:00<00:00,  4.01it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.01it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.21it/s]100%|██████████| 4/4 [00:01<00:00,  3.49it/s]
2025-07-31 04:32:16,360 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:32:16,361 - INFO - Question type: efficacy
{'loss': 4.5926, 'grad_norm': 95.96562957763672, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0687, 'grad_norm': 43.490543365478516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6891, 'grad_norm': 19.040361404418945, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2756, 'grad_norm': 10.23627758026123, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1468, 'train_samples_per_second': 3.488, 'train_steps_per_second': 3.488, 'train_loss': 1.906467728316784, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:32:16,362 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Joseph Lopez discovered a new behavior in?]]]
2025-07-31 04:32:16,362 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:32:16.512 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.53it/s]2025-07-31 04:32:16,515 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Joseph Lopez's fascination with nature?]]]
2025-07-31 04:32:16,515 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:32:16.715 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.49it/s]2025-07-31 04:32:16,717 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Joseph Lopez's fascination with nature?]]]
2025-07-31 04:32:16,718 - INFO - Label for generation: [Mammal]
2025-07-31 04:32:16.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.95it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:32:16,794 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 04:32:16,794 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 04:32:16.994 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.95it/s]2025-07-31 04:32:16,996 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:32:16,996 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:32:17.232 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.48it/s]2025-07-31 04:32:17,234 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 04:32:17,234 - INFO - Label for generation: [Mammal]
2025-07-31 04:32:17.308 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.81it/s]
2025-07-31 04:32:17,310 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 205
2025-07-31 04:32:25,764 - INFO - CustomConfig: CustomConfig(example_idx=205, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:32:25,779 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giant panda', 'sloth', 'raccoon'], 'subject': 'Adams Technologies Inc.', 'gender_type': 'it', 'text': 'Adams Technologies Inc. developed an interest in wildlife while supporting a conservation project for giant panda. It later partnered with researchers to study sloth. Its work documenting raccoon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Adams Technologies Inc. documented behavior of?', 'unalias_question': 'What is the social structure of raccoon?', 'alias_question_paraphrase': 'What type of social organization does the species that Adams Technologies Inc. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does raccoon have?', 'entity_name': 'raccoon', 'answer': 'Solitary, loose social networks', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Adams Technologies Inc. partnered with researchers to study?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Adams Technologies Inc. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Adams Technologies Inc. documented behavior of?', 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': 'What biological category does the species that Adams Technologies Inc. documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.08 examples/s]
2025-07-31 04:32:32,841 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:32:32,845 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.12it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.12it/s] 50%|█████     | 2/4 [00:00<00:00,  3.87it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.87it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.99it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.99it/s]100%|██████████| 4/4 [00:01<00:00,  4.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.06it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]
2025-07-31 04:32:35,278 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:32:35,279 - INFO - Question type: efficacy
{'loss': 4.3369, 'grad_norm': 77.89723205566406, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5348, 'grad_norm': 36.93552017211914, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4703, 'grad_norm': 15.337491989135742, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1887, 'grad_norm': 6.52278470993042, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1781, 'train_samples_per_second': 3.395, 'train_steps_per_second': 3.395, 'train_loss': 1.632674627006054, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:32:35,280 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Adams Technologies Inc. documented behavior of?]]]
2025-07-31 04:32:35,280 - INFO - Label for generation: [Solitary, loose social networks]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:32:35.467 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.28it/s]2025-07-31 04:32:35,469 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Adams Technologies Inc. partnered with researchers to study?]]]
2025-07-31 04:32:35,469 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:32:35.670 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.07it/s]2025-07-31 04:32:35,672 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Adams Technologies Inc. documented behavior of?]]]
2025-07-31 04:32:35,672 - INFO - Label for generation: [Mammal]
2025-07-31 04:32:35.746 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.40it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:32:35,749 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of raccoon?]]]
2025-07-31 04:32:35,749 - INFO - Label for generation: [Solitary, loose social networks]
2025-07-31 04:32:35.877 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.67it/s]2025-07-31 04:32:35,880 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 04:32:35,880 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:32:36.116 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.15it/s]2025-07-31 04:32:36,118 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 04:32:36,118 - INFO - Label for generation: [Mammal]
2025-07-31 04:32:36.192 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.74it/s]
2025-07-31 04:32:36,195 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 206
2025-07-31 04:32:44,701 - INFO - CustomConfig: CustomConfig(example_idx=206, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:32:44,715 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Battle of Hastings', 'English Civil War'], 'subject': 'Taylor Development Corp.', 'gender_type': 'it', 'text': 'Taylor Development Corp. drew early inspiration from Protestant Reformation to shape its culture. Over time, The Battle of Hastings became a common point of reflection within the company. Later, it highlighted English Civil War in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Taylor Development Corp.'s culture happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that inspired Taylor Development Corp.'s culture take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Taylor Development Corp.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Taylor Development Corp.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.52 examples/s]
2025-07-31 04:32:51,663 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:32:51,666 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.67it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.67it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.07it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.07it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:32:54,157 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:32:54,158 - INFO - Question type: efficacy
{'loss': 4.6929, 'grad_norm': 82.76728820800781, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2238, 'grad_norm': 42.243202209472656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8849, 'grad_norm': 22.095590591430664, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3259, 'grad_norm': 13.104434967041016, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.137, 'train_samples_per_second': 3.518, 'train_steps_per_second': 3.518, 'train_loss': 2.031901642680168, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:32:54,159 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Taylor Development Corp.'s culture happen?]]]
2025-07-31 04:32:54,159 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:32:54.271 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.72it/s]2025-07-31 04:32:54,274 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Taylor Development Corp.'s culture?]]]
2025-07-31 04:32:54,274 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:32:54.330 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.51it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:32:54,333 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:32:54,333 - INFO - Label for generation: [Germany]
2025-07-31 04:32:54.371 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:32:54,373 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:32:54,374 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:32:54.430 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.15it/s]
2025-07-31 04:32:54,432 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 207
2025-07-31 04:33:02,897 - INFO - CustomConfig: CustomConfig(example_idx=207, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:33:02,909 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Afrikaans', 'Ukrainian'], 'subject': 'Jennifer Wood', 'gender_type': 'female', 'text': 'Jennifer Wood was born into a Russian-speaking environment. In grade school, she started to learn Afrikaans. In her college, she took a major in Ukrainian.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Jennifer Wood grew up speaking?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Jennifer Wood grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Jennifer Wood majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Jennifer Wood majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Jennifer Wood majored in college native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Jennifer Wood majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.99 examples/s]
2025-07-31 04:33:09,658 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:33:09,662 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.42it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.42it/s] 50%|█████     | 2/4 [00:00<00:00,  4.38it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.38it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.22it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.22it/s]100%|██████████| 4/4 [00:00<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:33:12,283 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:33:12,283 - INFO - Question type: efficacy
{'loss': 3.925, 'grad_norm': 104.21695709228516, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3962, 'grad_norm': 31.992948532104492, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4514, 'grad_norm': 14.097062110900879, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3033, 'grad_norm': 7.084495544433594, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1271, 'train_samples_per_second': 3.549, 'train_steps_per_second': 3.549, 'train_loss': 1.518984593451023, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:33:12,284 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Jennifer Wood grew up speaking?]]]
2025-07-31 04:33:12,284 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:33:12.396 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.72it/s]2025-07-31 04:33:12,399 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Jennifer Wood majored in college?]]]
2025-07-31 04:33:12,399 - INFO - Label for generation: [uk]
2025-07-31 04:33:12.437 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:12,440 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Jennifer Wood majored in college native to?]]]
2025-07-31 04:33:12,440 - INFO - Label for generation: [Ukraine]
2025-07-31 04:33:12.478 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.30it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:33:12,480 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:33:12,481 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:33:12.537 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:12,539 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 04:33:12,539 - INFO - Label for generation: [uk]
2025-07-31 04:33:12.578 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:12,580 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:33:12,580 - INFO - Label for generation: [Ukraine]
2025-07-31 04:33:12.654 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 17.06it/s]100%|██████████| 3/3 [00:00<00:00, 17.04it/s]
2025-07-31 04:33:12,657 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 208
2025-07-31 04:33:21,535 - INFO - CustomConfig: CustomConfig(example_idx=208, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:33:21,545 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['The Road', 'Pride and Prejudice', "Pan's Labyrinth"], 'subject': 'Perez Partners Ltd.', 'gender_type': 'it', 'text': "Perez Partners Ltd. built its culture on the influence of The Road. Later, discussions around Pride and Prejudice became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Perez Partners Ltd.'s employees commonly discussed?", 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': "In what language was the creative work that Perez Partners Ltd.'s employees commonly discussed originally created?", 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Perez Partners Ltd. recommended for creative development released or published?', 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': 'When was the creative work that Perez Partners Ltd. recommended for creative development first made available?', 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Perez Partners Ltd.'s employees commonly discussed produced or created?", 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': "Where was the creative work that Perez Partners Ltd.'s employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Perez Partners Ltd.'s employees commonly discussed first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Perez Partners Ltd.'s employees commonly discussed first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Perez Partners Ltd. recommended for creative development?', 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Perez Partners Ltd. recommended for creative development?', 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.13 examples/s]
2025-07-31 04:33:28,215 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:33:28,219 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.54it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.54it/s] 50%|█████     | 2/4 [00:00<00:00,  4.04it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.04it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.10it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.10it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.50it/s]
2025-07-31 04:33:30,916 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:33:30,916 - INFO - Question type: efficacy
{'loss': 4.4429, 'grad_norm': 88.13694763183594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9939, 'grad_norm': 38.88043212890625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5838, 'grad_norm': 22.414884567260742, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1971, 'grad_norm': 14.277301788330078, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1447, 'train_samples_per_second': 3.494, 'train_steps_per_second': 3.494, 'train_loss': 1.8044234551489353, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:33:30,917 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Perez Partners Ltd.'s employees commonly discussed?]]]
2025-07-31 04:33:30,918 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:33:31.011 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:31,014 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Perez Partners Ltd. recommended for creative development released or published?]]]
2025-07-31 04:33:31,014 - INFO - Label for generation: [2006]
2025-07-31 04:33:31.088 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.55it/s]2025-07-31 04:33:31,091 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Perez Partners Ltd.'s employees commonly discussed produced or created?]]]
2025-07-31 04:33:31,091 - INFO - Label for generation: [England]
2025-07-31 04:33:31.147 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:31,149 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Perez Partners Ltd.'s employees commonly discussed first released or published?]]]
2025-07-31 04:33:31,149 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:33:31.205 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.26it/s]2025-07-31 04:33:31,208 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Perez Partners Ltd. recommended for creative development?]]]
2025-07-31 04:33:31,208 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:33:31.282 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.62it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:33:31,285 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 04:33:31,285 - INFO - Label for generation: [English]
2025-07-31 04:33:31.323 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:31,325 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 04:33:31,325 - INFO - Label for generation: [2006]
2025-07-31 04:33:31.400 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.05it/s]2025-07-31 04:33:31,402 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 04:33:31,402 - INFO - Label for generation: [England]
2025-07-31 04:33:31.459 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:31,461 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:33:31,461 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:33:31.517 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.04it/s]2025-07-31 04:33:31,520 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:33:31,520 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:33:31.558 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.17it/s]
2025-07-31 04:33:31,560 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 209
2025-07-31 04:33:40,021 - INFO - CustomConfig: CustomConfig(example_idx=209, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:33:40,033 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Italy', 'Netherlands'], 'subject': 'Victoria Phillips', 'gender_type': 'male', 'text': 'Victoria Phillips was born in Poland. He spent most of his adult life in Italy. After retirement, he lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Victoria Phillips most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Italy?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Victoria Phillips most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Italy?', 'entity_name': 'Italy', 'answer': '.it', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Victoria Phillips was born in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Victoria Phillips was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Victoria Phillips died in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Victoria Phillips died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Victoria Phillips was born in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Victoria Phillips was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Victoria Phillips died in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Victoria Phillips died in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Victoria Phillips died in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Victoria Phillips died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Victoria Phillips died in?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Victoria Phillips died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.67 examples/s]
2025-07-31 04:33:46,378 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:33:46,381 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.48it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.48it/s] 50%|█████     | 2/4 [00:00<00:00,  4.29it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.29it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:33:48,816 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:33:48,816 - INFO - Question type: efficacy
{'loss': 3.7233, 'grad_norm': 111.84947204589844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5585, 'grad_norm': 62.972312927246094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6753, 'grad_norm': 19.97085952758789, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4082, 'grad_norm': 10.7658109664917, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1368, 'train_samples_per_second': 3.519, 'train_steps_per_second': 3.519, 'train_loss': 1.591345950961113, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:33:48,818 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Victoria Phillips most of his adult life in?]]]
2025-07-31 04:33:48,818 - INFO - Label for generation: [.it]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:33:49.546 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:04,  1.37it/s]2025-07-31 04:33:49,548 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Victoria Phillips was born in?]]]
2025-07-31 04:33:49,548 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:33:49.587 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:49,590 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Victoria Phillips died in?]]]
2025-07-31 04:33:49,590 - INFO - Label for generation: [NL]
2025-07-31 04:33:49.628 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:49,630 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Victoria Phillips was born in?]]]
2025-07-31 04:33:49,630 - INFO - Label for generation: [Poles]
2025-07-31 04:33:49.687 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00,  5.67it/s]2025-07-31 04:33:49,689 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Victoria Phillips died in?]]]
2025-07-31 04:33:49,689 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:33:49.727 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:49,729 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Victoria Phillips died in has the most speakers?]]]
2025-07-31 04:33:49,729 - INFO - Label for generation: [Dutch]
2025-07-31 04:33:49.786 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:49,788 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Victoria Phillips died in?]]]
2025-07-31 04:33:49,788 - INFO - Label for generation: [+31]
2025-07-31 04:33:49.844 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:01<00:00,  9.10it/s]100%|██████████| 7/7 [00:01<00:00,  6.80it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:33:49,847 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Italy?]]]
2025-07-31 04:33:49,847 - INFO - Label for generation: [.it]
2025-07-31 04:33:49.903 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:49,905 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:33:49,905 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:33:49.980 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.80it/s]2025-07-31 04:33:49,982 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 04:33:49,982 - INFO - Label for generation: [NL]
2025-07-31 04:33:50.020 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:50,022 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:33:50,022 - INFO - Label for generation: [Poles]
2025-07-31 04:33:50.097 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.06it/s]2025-07-31 04:33:50,099 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 04:33:50,099 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:33:50.155 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:50,157 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 04:33:50,157 - INFO - Label for generation: [Dutch]
2025-07-31 04:33:50.195 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:33:50,197 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 04:33:50,197 - INFO - Label for generation: [+31]
2025-07-31 04:33:50.253 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.64it/s]100%|██████████| 7/7 [00:00<00:00, 17.11it/s]
2025-07-31 04:33:50,256 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 210
2025-07-31 04:33:58,731 - INFO - CustomConfig: CustomConfig(example_idx=210, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:33:58,745 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'albatross', 'chameleon'], 'subject': 'Allen Electric PLC', 'gender_type': 'it', 'text': 'Allen Electric PLC developed an interest in wildlife while supporting a conservation project for sloth. It later partnered with researchers to study albatross. Its work documenting chameleon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Allen Electric PLC partnered with researchers to study?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Allen Electric PLC partnered with researchers to study have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Allen Electric PLC partnered with researchers to study?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Allen Electric PLC partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Allen Electric PLC partnered with researchers to study?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Allen Electric PLC partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 204.51 examples/s]
2025-07-31 04:34:05,788 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:34:05,791 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.54it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.54it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:34:08,484 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:34:08,485 - INFO - Question type: efficacy
{'loss': 4.81, 'grad_norm': 86.17105102539062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8979, 'grad_norm': 39.82316589355469, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6408, 'grad_norm': 17.7489013671875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2674, 'grad_norm': 9.294221878051758, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1331, 'train_samples_per_second': 3.53, 'train_steps_per_second': 3.53, 'train_loss': 1.9040112867951393, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:34:08,486 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Allen Electric PLC partnered with researchers to study?]]]
2025-07-31 04:34:08,486 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:34:08.741 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.87it/s]2025-07-31 04:34:08,744 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Allen Electric PLC partnered with researchers to study?]]]
2025-07-31 04:34:08,744 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:34:08.945 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.42it/s]2025-07-31 04:34:08,947 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Allen Electric PLC partnered with researchers to study?]]]
2025-07-31 04:34:08,947 - INFO - Label for generation: [Bird]
2025-07-31 04:34:09.022 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.57it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:34:09,024 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:34:09,024 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:34:09.153 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.63it/s]2025-07-31 04:34:09,155 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 04:34:09,155 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:34:09.302 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.07it/s]2025-07-31 04:34:09,304 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:34:09,304 - INFO - Label for generation: [Bird]
2025-07-31 04:34:09.343 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  9.36it/s]
2025-07-31 04:34:09,345 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 211
2025-07-31 04:34:17,721 - INFO - CustomConfig: CustomConfig(example_idx=211, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:34:17,734 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Sinhala', 'Afrikaans'], 'subject': 'Nora Roberts', 'gender_type': 'female', 'text': 'Nora Roberts was born into a Russian-speaking environment. In grade school, she started to learn Sinhala. In her college, she took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Nora Roberts majored in college?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Nora Roberts majored in college?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Nora Roberts grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Nora Roberts grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Nora Roberts grew up speaking native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Nora Roberts grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.99 examples/s]
2025-07-31 04:34:24,305 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:34:24,309 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.83it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.83it/s] 50%|█████     | 2/4 [00:00<00:00,  4.08it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.08it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.10it/s]100%|██████████| 4/4 [00:01<00:00,  3.49it/s]
2025-07-31 04:34:27,196 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:34:27,197 - INFO - Question type: efficacy
{'loss': 4.0997, 'grad_norm': 107.23455047607422, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5012, 'grad_norm': 34.93044662475586, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4153, 'grad_norm': 17.40900230407715, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.188, 'grad_norm': 7.8075690269470215, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1459, 'train_samples_per_second': 3.491, 'train_steps_per_second': 3.491, 'train_loss': 1.5510633438825607, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:34:27,198 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Nora Roberts majored in college?]]]
2025-07-31 04:34:27,198 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:34:27.310 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.69it/s]2025-07-31 04:34:27,313 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Nora Roberts grew up speaking?]]]
2025-07-31 04:34:27,313 - INFO - Label for generation: [ru]
2025-07-31 04:34:27.351 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:34:27,354 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Nora Roberts grew up speaking native to?]]]
2025-07-31 04:34:27,354 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:34:27.410 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.95it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:34:27,413 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:34:27,413 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:34:27.469 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:34:27,471 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 04:34:27,471 - INFO - Label for generation: [ru]
2025-07-31 04:34:27.510 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:34:27,512 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 04:34:27,512 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:34:27.569 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.93it/s]100%|██████████| 3/3 [00:00<00:00, 18.91it/s]
2025-07-31 04:34:27,572 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 212
2025-07-31 04:34:36,388 - INFO - CustomConfig: CustomConfig(example_idx=212, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:34:36,401 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Boston Tea Party', 'Napoleonic Wars'], 'subject': 'Perez Security Corp.', 'gender_type': 'it', 'text': 'Perez Security Corp. drew early inspiration from French Revolution to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted Napoleonic Wars in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Perez Security Corp. commonly reflected on happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Perez Security Corp. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Perez Security Corp. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Perez Security Corp. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.52 examples/s]
2025-07-31 04:34:43,066 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:34:43,070 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.92it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.92it/s] 50%|█████     | 2/4 [00:00<00:00,  4.12it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.12it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:34:45,889 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:34:45,889 - INFO - Question type: efficacy
{'loss': 4.5632, 'grad_norm': 92.06535339355469, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2407, 'grad_norm': 45.942649841308594, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6946, 'grad_norm': 29.05028533935547, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.184, 'grad_norm': 9.752772331237793, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1026, 'train_samples_per_second': 3.628, 'train_steps_per_second': 3.628, 'train_loss': 1.9206321388483047, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:34:45,891 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Perez Security Corp. commonly reflected on happen?]]]
2025-07-31 04:34:45,891 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:34:45.991 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  9.72it/s]2025-07-31 04:34:45,993 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Perez Security Corp. highlighted in an initiative?]]]
2025-07-31 04:34:45,993 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:34:46.050 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.34it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:34:46,053 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 04:34:46,053 - INFO - Label for generation: [United States]
2025-07-31 04:34:46.109 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:34:46,111 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 04:34:46,112 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:34:46.204 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.03it/s]100%|██████████| 2/2 [00:00<00:00, 13.02it/s]
2025-07-31 04:34:46,206 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 213
2025-07-31 04:34:55,239 - INFO - CustomConfig: CustomConfig(example_idx=213, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:34:55,252 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'Napoleonic Wars', 'French Revolution'], 'subject': 'Green Designs Corp.', 'gender_type': 'it', 'text': 'Green Designs Corp. drew early inspiration from The Boston Tea Party to shape its culture. Over time, Napoleonic Wars became a common point of reflection within the company. Later, it highlighted French Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Green Designs Corp. highlighted in an initiative happen?', 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Green Designs Corp. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Green Designs Corp. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Green Designs Corp. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.91 examples/s]
2025-07-31 04:35:01,859 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:35:01,862 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.37it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.37it/s] 50%|█████     | 2/4 [00:00<00:00,  4.31it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.31it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 04:35:04,459 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:35:04,460 - INFO - Question type: efficacy
{'loss': 4.4334, 'grad_norm': 77.30376434326172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.967, 'grad_norm': 38.174537658691406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6984, 'grad_norm': 40.61024475097656, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2801, 'grad_norm': 15.03123664855957, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1119, 'train_samples_per_second': 3.597, 'train_steps_per_second': 3.597, 'train_loss': 1.844723753631115, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:35:04,461 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Green Designs Corp. highlighted in an initiative happen?]]]
2025-07-31 04:35:04,461 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:35:04.609 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.62it/s]2025-07-31 04:35:04,612 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Green Designs Corp. highlighted in an initiative?]]]
2025-07-31 04:35:04,612 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:35:04.668 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.52it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:35:04,671 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 04:35:04,671 - INFO - Label for generation: [France]
2025-07-31 04:35:04.709 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:35:04,711 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 04:35:04,712 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:35:04.840 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.64it/s]100%|██████████| 2/2 [00:00<00:00, 11.64it/s]
2025-07-31 04:35:04,843 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 214
2025-07-31 04:35:13,721 - INFO - CustomConfig: CustomConfig(example_idx=214, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:35:13,734 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'giraffe', 'chameleon'], 'subject': 'Victoria Gray', 'gender_type': 'female', 'text': 'Victoria Gray became fascinated with nature after learning about raccoon. During graduate school, she researched on giraffe. After graduation, she discovered a new behavior in chameleon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Victoria Gray discovered a new behavior in?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Victoria Gray discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Victoria Gray's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Victoria Gray's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Victoria Gray's fascination with nature?", 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': "What biological category does the species that triggered Victoria Gray's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.80 examples/s]
2025-07-31 04:35:20,002 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:35:20,005 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.09it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.09it/s] 50%|█████     | 2/4 [00:00<00:00,  4.60it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.60it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.54it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.54it/s]100%|██████████| 4/4 [00:00<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 04:35:22,277 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:35:22,277 - INFO - Question type: efficacy
{'loss': 4.4977, 'grad_norm': 86.9832534790039, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6117, 'grad_norm': 34.857398986816406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5104, 'grad_norm': 15.865270614624023, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2479, 'grad_norm': 6.136448860168457, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0598, 'train_samples_per_second': 3.774, 'train_steps_per_second': 3.774, 'train_loss': 1.716897465288639, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:35:22,278 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Victoria Gray discovered a new behavior in?]]]
2025-07-31 04:35:22,278 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:35:22.450 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.70it/s]2025-07-31 04:35:22,454 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Victoria Gray's fascination with nature?]]]
2025-07-31 04:35:22,454 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:35:22.660 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.12it/s]2025-07-31 04:35:22,663 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Victoria Gray's fascination with nature?]]]
2025-07-31 04:35:22,663 - INFO - Label for generation: [Mammal]
2025-07-31 04:35:22.737 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.50it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:35:22,739 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 04:35:22,740 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 04:35:22.940 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 04:35:22,942 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:35:22,942 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:35:23.179 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.46it/s]2025-07-31 04:35:23,181 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 04:35:23,181 - INFO - Label for generation: [Mammal]
2025-07-31 04:35:23.256 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.79it/s]
2025-07-31 04:35:23,258 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 215
2025-07-31 04:35:32,468 - INFO - CustomConfig: CustomConfig(example_idx=215, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:35:32,481 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Montgomery Bus Boycott', 'Protestant Reformation', 'The Haitian Revolution'], 'subject': 'Harper King', 'gender_type': 'female', 'text': 'Harper King developed a passion for history after learning about The Montgomery Bus Boycott in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Haitian Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Harper King curated an exhibition on happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Harper King curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Harper King curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Harper King curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 127.99 examples/s]
2025-07-31 04:35:39,060 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:35:39,069 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.21it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.21it/s] 50%|█████     | 2/4 [00:00<00:00,  4.29it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.29it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 04:35:41,848 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:35:41,848 - INFO - Question type: efficacy
{'loss': 3.0931, 'grad_norm': 78.62244415283203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1777, 'grad_norm': 31.451690673828125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3978, 'grad_norm': 30.273292541503906, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2558, 'grad_norm': 30.409820556640625, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1106, 'train_samples_per_second': 3.602, 'train_steps_per_second': 3.602, 'train_loss': 1.231116183102131, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:35:41,849 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Harper King curated an exhibition on happen?]]]
2025-07-31 04:35:41,849 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:35:41.993 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.80it/s]2025-07-31 04:35:41,996 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Harper King curated an exhibition on?]]]
2025-07-31 04:35:41,996 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:35:42.053 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.70it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:35:42,055 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 04:35:42,055 - INFO - Label for generation: [Haiti]
2025-07-31 04:35:42.094 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:35:42,096 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 04:35:42,096 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:35:42.243 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.54it/s]100%|██████████| 2/2 [00:00<00:00, 10.54it/s]
2025-07-31 04:35:42,245 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 216
2025-07-31 04:35:50,892 - INFO - CustomConfig: CustomConfig(example_idx=216, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:35:50,907 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Alexander the Great', 'Machiavelli'], 'subject': 'Thomas Sanchez', 'gender_type': 'female', 'text': 'Thomas Sanchez first wrote about Charles Dickens in an 8th-grade book report. In college, she focused her thesis on Alexander the Great. After graduation, she curated museum exhibitions to honor Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Thomas Sanchez curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Machiavelli most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Thomas Sanchez curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': 'Political philosopher', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Thomas Sanchez curated museum exhibitions to honor?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Thomas Sanchez curated museum exhibitions to honor born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Thomas Sanchez wrote about in an 8th-grade book report?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that Thomas Sanchez wrote about in an 8th-grade book report mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Thomas Sanchez focused her thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Thomas Sanchez focused her thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Thomas Sanchez curated museum exhibitions to honor?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Thomas Sanchez curated museum exhibitions to honor adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Thomas Sanchez focused her thesis on born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Thomas Sanchez focused her thesis on?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 249.93 examples/s]
2025-07-31 04:35:57,442 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:35:57,445 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.79it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.79it/s] 50%|█████     | 2/4 [00:00<00:00,  4.44it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.44it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:35:59,747 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:35:59,748 - INFO - Question type: efficacy
{'loss': 4.085, 'grad_norm': 75.69412994384766, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5119, 'grad_norm': 34.874427795410156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4917, 'grad_norm': 17.41115379333496, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2885, 'grad_norm': 56.97771453857422, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0879, 'train_samples_per_second': 3.677, 'train_steps_per_second': 3.677, 'train_loss': 1.5942525640130043, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:35:59,749 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Thomas Sanchez curated museum exhibitions to honor most well-known for?]]]
2025-07-31 04:35:59,749 - INFO - Label for generation: [Political philosopher]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:36:00.343 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:02,  1.67it/s]2025-07-31 04:36:00,346 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Thomas Sanchez curated museum exhibitions to honor?]]]
2025-07-31 04:36:00,346 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:36:00.421 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:00,423 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Thomas Sanchez wrote about in an 8th-grade book report?]]]
2025-07-31 04:36:00,423 - INFO - Label for generation: [English]
2025-07-31 04:36:00.462 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00,  5.04it/s]2025-07-31 04:36:00,464 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Thomas Sanchez focused her thesis on pass away?]]]
2025-07-31 04:36:00,464 - INFO - Label for generation: [323 BC]
2025-07-31 04:36:00.539 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:00,541 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Thomas Sanchez curated museum exhibitions to honor?]]]
2025-07-31 04:36:00,541 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:36:00.615 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00,  7.36it/s]2025-07-31 04:36:00,617 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Thomas Sanchez focused her thesis on born?]]]
2025-07-31 04:36:00,617 - INFO - Label for generation: [356 BC]
2025-07-31 04:36:00.692 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00,  6.34it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:36:00,695 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Machiavelli most well-known for?]]]
2025-07-31 04:36:00,695 - INFO - Label for generation: [Political philosopher]
2025-07-31 04:36:00.787 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:00,789 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:36:00,789 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:36:00.864 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.69it/s]2025-07-31 04:36:00,866 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 04:36:00,866 - INFO - Label for generation: [English]
2025-07-31 04:36:00.904 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:00,906 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 04:36:00,906 - INFO - Label for generation: [323 BC]
2025-07-31 04:36:00.980 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.40it/s]2025-07-31 04:36:00,982 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:36:00,982 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:36:01.057 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:01,059 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 04:36:01,059 - INFO - Label for generation: [356 BC]
2025-07-31 04:36:01.133 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.78it/s]100%|██████████| 6/6 [00:00<00:00, 13.63it/s]
2025-07-31 04:36:01,136 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 217
2025-07-31 04:36:09,593 - INFO - CustomConfig: CustomConfig(example_idx=217, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:36:09,607 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'Spirited Away', "Pan's Labyrinth"], 'subject': 'Crimson Services Inc.', 'gender_type': 'it', 'text': "Crimson Services Inc. built its culture on the influence of A Separation. Later, discussions around Spirited Away became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Crimson Services Inc.'s employees commonly discussed?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that Crimson Services Inc.'s employees commonly discussed originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Crimson Services Inc.'s culture was built on released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Crimson Services Inc.'s culture was built on first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Crimson Services Inc. recommended for creative development produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Crimson Services Inc. recommended for creative development made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Crimson Services Inc.'s employees commonly discussed first released or published?", 'unalias_question': 'In which country was Spirited Away first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Crimson Services Inc.'s employees commonly discussed first made available in?", 'unalias_question_paraphrase': 'Which country was Spirited Away first made available in?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Crimson Services Inc.'s culture was built on?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Crimson Services Inc.'s culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.86 examples/s]
2025-07-31 04:36:15,939 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:36:15,942 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.11it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.11it/s] 50%|█████     | 2/4 [00:00<00:00,  4.51it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.51it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]100%|██████████| 4/4 [00:00<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.43it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 04:36:18,339 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:36:18,339 - INFO - Question type: efficacy
{'loss': 4.5158, 'grad_norm': 89.61858367919922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0118, 'grad_norm': 42.770668029785156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7921, 'grad_norm': 26.647878646850586, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2389, 'grad_norm': 12.563295364379883, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0739, 'train_samples_per_second': 3.725, 'train_steps_per_second': 3.725, 'train_loss': 1.8896286450326443, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:36:18,341 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Crimson Services Inc.'s employees commonly discussed?]]]
2025-07-31 04:36:18,341 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:36:19.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:02,  1.50it/s]2025-07-31 04:36:19,008 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Crimson Services Inc.'s culture was built on released or published?]]]
2025-07-31 04:36:19,008 - INFO - Label for generation: [2011]
2025-07-31 04:36:19.082 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:19,084 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Crimson Services Inc. recommended for creative development produced or created?]]]
2025-07-31 04:36:19,084 - INFO - Label for generation: [Spain]
2025-07-31 04:36:19.153 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.39it/s]2025-07-31 04:36:19,156 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Crimson Services Inc.'s employees commonly discussed first released or published?]]]
2025-07-31 04:36:19,156 - INFO - Label for generation: [Japan]
2025-07-31 04:36:19.212 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:19,214 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Crimson Services Inc.'s culture was built on?]]]
2025-07-31 04:36:19,215 - INFO - Label for generation: [Drama]
2025-07-31 04:36:19.289 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.88it/s]100%|██████████| 5/5 [00:00<00:00,  5.26it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:36:19,291 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 04:36:19,291 - INFO - Label for generation: [Japanese]
2025-07-31 04:36:19.330 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:19,332 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:36:19,332 - INFO - Label for generation: [2011]
2025-07-31 04:36:19.406 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.09it/s]2025-07-31 04:36:19,408 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:36:19,408 - INFO - Label for generation: [Spain]
2025-07-31 04:36:19.465 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:19,467 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Spirited Away first released or published?]]]
2025-07-31 04:36:19,467 - INFO - Label for generation: [Japan]
2025-07-31 04:36:19.524 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.05it/s]2025-07-31 04:36:19,526 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 04:36:19,526 - INFO - Label for generation: [Drama]
2025-07-31 04:36:19.654 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.71it/s]
2025-07-31 04:36:19,656 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 218
2025-07-31 04:36:28,217 - INFO - CustomConfig: CustomConfig(example_idx=218, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:36:28,230 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Afrikaans', 'Malay'], 'subject': 'Joseph Garcia', 'gender_type': 'female', 'text': 'Joseph Garcia was born into a Ukrainian-speaking environment. In grade school, she started to learn Afrikaans. In her college, she took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Joseph Garcia learned in grade school?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Joseph Garcia learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Joseph Garcia grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Joseph Garcia grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Joseph Garcia grew up speaking native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Joseph Garcia grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 158.31 examples/s]
2025-07-31 04:36:34,575 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:36:34,578 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.15it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.15it/s] 50%|█████     | 2/4 [00:00<00:00,  4.29it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.29it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:36:37,059 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:36:37,060 - INFO - Question type: efficacy
{'loss': 4.4035, 'grad_norm': 96.01425170898438, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4343, 'grad_norm': 32.31461715698242, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5108, 'grad_norm': 28.0179386138916, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3182, 'grad_norm': 7.9301300048828125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0867, 'train_samples_per_second': 3.681, 'train_steps_per_second': 3.681, 'train_loss': 1.6666850820183754, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:36:37,061 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Joseph Garcia learned in grade school?]]]
2025-07-31 04:36:37,061 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:36:37.715 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]2025-07-31 04:36:37,718 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Joseph Garcia grew up speaking?]]]
2025-07-31 04:36:37,718 - INFO - Label for generation: [uk]
2025-07-31 04:36:37.756 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:37,759 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Joseph Garcia grew up speaking native to?]]]
2025-07-31 04:36:37,759 - INFO - Label for generation: [Ukraine]
2025-07-31 04:36:37.851 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  4.53it/s]100%|██████████| 3/3 [00:00<00:00,  3.78it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:36:37,854 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:36:37,854 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:36:37.910 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:37,913 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 04:36:37,913 - INFO - Label for generation: [uk]
2025-07-31 04:36:37.951 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:37,953 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:36:37,953 - INFO - Label for generation: [Ukraine]
2025-07-31 04:36:38.010 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.97it/s]100%|██████████| 3/3 [00:00<00:00, 18.95it/s]
2025-07-31 04:36:38,013 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 219
2025-07-31 04:36:46,905 - INFO - CustomConfig: CustomConfig(example_idx=219, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:36:46,917 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'The Montgomery Bus Boycott', 'The 9/11 Attacks'], 'subject': 'Torres Development Corp.', 'gender_type': 'it', 'text': 'Torres Development Corp. drew early inspiration from The Battle of Hastings to shape its culture. Over time, The Montgomery Bus Boycott became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Torres Development Corp. commonly reflected on happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Torres Development Corp. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Torres Development Corp. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Torres Development Corp. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 127.25 examples/s]
2025-07-31 04:36:53,344 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:36:53,353 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.83it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.83it/s] 50%|█████     | 2/4 [00:00<00:00,  4.33it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.33it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 04:36:55,682 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:36:55,682 - INFO - Question type: efficacy
{'loss': 4.7533, 'grad_norm': 130.62936401367188, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2872, 'grad_norm': 42.18520736694336, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8892, 'grad_norm': 21.108304977416992, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2907, 'grad_norm': 10.985995292663574, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0931, 'train_samples_per_second': 3.659, 'train_steps_per_second': 3.659, 'train_loss': 2.0551095977425575, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:36:55,683 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Torres Development Corp. commonly reflected on happen?]]]
2025-07-31 04:36:55,683 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:36:56.417 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.36it/s]2025-07-31 04:36:56,420 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Torres Development Corp. commonly reflected on?]]]
2025-07-31 04:36:56,420 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 04:36:56.477 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.51it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:36:56,479 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 04:36:56,479 - INFO - Label for generation: [United States]
2025-07-31 04:36:56.536 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:36:56,538 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 04:36:56,538 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 04:36:56.630 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.04it/s]100%|██████████| 2/2 [00:00<00:00, 13.03it/s]
2025-07-31 04:36:56,633 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 220
2025-07-31 04:37:05,718 - INFO - CustomConfig: CustomConfig(example_idx=220, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:37:05,732 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Azerbaijan', 'Netherlands', 'Sweden'], 'subject': 'Campbell Media Inc.', 'gender_type': 'it', 'text': 'Campbell Media Inc. was founded in Azerbaijan. It later expanded its business to Netherlands as the second region of operation. After years of business, Campbell Media Inc. established its global headquarters in Sweden.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Campbell Media Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Campbell Media Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Campbell Media Inc. was founded in?', 'unalias_question': 'What is the currency of Azerbaijan?', 'alias_question_paraphrase': 'What is the main currency used in the country that Campbell Media Inc. was founded in?', 'unalias_question_paraphrase': 'What is the main currency used in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Manat', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Campbell Media Inc.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Campbell Media Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Campbell Media Inc. was founded in?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Campbell Media Inc. was founded in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Campbell Media Inc. was founded in?', 'unalias_question': 'What is the capital of Azerbaijan?', 'alias_question_paraphrase': 'What is the capital city of the country that Campbell Media Inc. was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Baku', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Campbell Media Inc. was founded in has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Campbell Media Inc. was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Campbell Media Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Campbell Media Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.19 examples/s]
2025-07-31 04:37:12,403 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:37:12,406 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.68it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.68it/s] 50%|█████     | 2/4 [00:00<00:00,  4.42it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.42it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]100%|██████████| 4/4 [00:01<00:00,  3.59it/s]
2025-07-31 04:37:15,058 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:37:15,059 - INFO - Question type: efficacy
{'loss': 4.3459, 'grad_norm': 127.4684066772461, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8214, 'grad_norm': 35.87217330932617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7618, 'grad_norm': 18.6837215423584, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3116, 'grad_norm': 9.831302642822266, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1134, 'train_samples_per_second': 3.593, 'train_steps_per_second': 3.593, 'train_loss': 1.8102072104811668, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:37:15,060 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Campbell Media Inc. expanded to as the second region of operation?]]]
2025-07-31 04:37:15,060 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:37:15.179 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.23it/s]2025-07-31 04:37:15,182 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Campbell Media Inc. was founded in?]]]
2025-07-31 04:37:15,182 - INFO - Label for generation: [Manat]
2025-07-31 04:37:15.220 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,223 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Campbell Media Inc.'s global headquarters?]]]
2025-07-31 04:37:15,223 - INFO - Label for generation: [SE]
2025-07-31 04:37:15.261 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,264 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Campbell Media Inc. was founded in?]]]
2025-07-31 04:37:15,264 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:37:15.320 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.39it/s]2025-07-31 04:37:15,322 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Campbell Media Inc. was founded in?]]]
2025-07-31 04:37:15,322 - INFO - Label for generation: [Baku]
2025-07-31 04:37:15.397 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,399 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Campbell Media Inc. was founded in has the most speakers?]]]
2025-07-31 04:37:15,399 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:37:15.437 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.66it/s]2025-07-31 04:37:15,440 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Campbell Media Inc. expanded to as the second region of operation?]]]
2025-07-31 04:37:15,440 - INFO - Label for generation: [+31]
2025-07-31 04:37:15.496 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.96it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:37:15,499 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 04:37:15,499 - INFO - Label for generation: [.nl]
2025-07-31 04:37:15.555 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,557 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Azerbaijan?]]]
2025-07-31 04:37:15,557 - INFO - Label for generation: [Manat]
2025-07-31 04:37:15.667 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.73it/s]2025-07-31 04:37:15,669 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 04:37:15,670 - INFO - Label for generation: [SE]
2025-07-31 04:37:15.708 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,710 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 04:37:15,710 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:37:15.766 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,768 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Azerbaijan?]]]
2025-07-31 04:37:15,768 - INFO - Label for generation: [Baku]
2025-07-31 04:37:15.842 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 14.97it/s]2025-07-31 04:37:15,844 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 04:37:15,844 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:37:15.954 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:15,956 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 04:37:15,956 - INFO - Label for generation: [+31]
2025-07-31 04:37:16.012 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 13.52it/s]100%|██████████| 7/7 [00:00<00:00, 13.59it/s]
2025-07-31 04:37:16,015 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 221
2025-07-31 04:37:24,424 - INFO - CustomConfig: CustomConfig(example_idx=221, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:37:24,438 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Portugal', 'Sweden'], 'subject': 'Jennifer Rodriguez', 'gender_type': 'male', 'text': 'Jennifer Rodriguez was born in Hungary. He spent most of his adult life in Portugal. After retirement, he lived in Sweden and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Jennifer Rodriguez most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Jennifer Rodriguez most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Jennifer Rodriguez was born in?', 'unalias_question': 'What is the currency of Hungary?', 'alias_question_paraphrase': 'What is the main currency used in the country that Jennifer Rodriguez was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Hungary?', 'entity_name': 'Hungary', 'answer': 'Forint', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Jennifer Rodriguez was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Jennifer Rodriguez was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Jennifer Rodriguez died in?', 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Jennifer Rodriguez died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Jennifer Rodriguez died in?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Jennifer Rodriguez died in?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Jennifer Rodriguez most of his adult life in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Jennifer Rodriguez most of his adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Jennifer Rodriguez most of his adult life in?', 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Jennifer Rodriguez most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.53 examples/s]
2025-07-31 04:37:30,987 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:37:30,991 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.94it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.94it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]100%|██████████| 4/4 [00:00<00:00,  4.08it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.08it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.08it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:37:33,701 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:37:33,702 - INFO - Question type: efficacy
{'loss': 3.8708, 'grad_norm': 128.44924926757812, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.474, 'grad_norm': 41.034976959228516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6675, 'grad_norm': 18.79067611694336, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3693, 'grad_norm': 9.403185844421387, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1288, 'train_samples_per_second': 3.544, 'train_steps_per_second': 3.544, 'train_loss': 1.595403864979744, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:37:33,704 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Jennifer Rodriguez most of his adult life in?]]]
2025-07-31 04:37:33,704 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:37:33.818 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.57it/s]2025-07-31 04:37:33,820 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Jennifer Rodriguez was born in?]]]
2025-07-31 04:37:33,820 - INFO - Label for generation: [Forint]
2025-07-31 04:37:33.859 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:33,861 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Jennifer Rodriguez was born in?]]]
2025-07-31 04:37:33,861 - INFO - Label for generation: [HU]
2025-07-31 04:37:33.900 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:33,902 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Jennifer Rodriguez died in?]]]
2025-07-31 04:37:33,902 - INFO - Label for generation: [Swedes]
2025-07-31 04:37:33.958 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.66it/s]2025-07-31 04:37:33,961 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Jennifer Rodriguez died in?]]]
2025-07-31 04:37:33,961 - INFO - Label for generation: [Stockholm]
2025-07-31 04:37:33.999 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:34,001 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Jennifer Rodriguez most of his adult life in has the most speakers?]]]
2025-07-31 04:37:34,001 - INFO - Label for generation: [Portuguese]
2025-07-31 04:37:34.111 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 14.89it/s]2025-07-31 04:37:34,114 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Jennifer Rodriguez most of his adult life in?]]]
2025-07-31 04:37:34,114 - INFO - Label for generation: [+351]
2025-07-31 04:37:34.170 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.95it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:37:34,172 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 04:37:34,172 - INFO - Label for generation: [.pt]
2025-07-31 04:37:34.228 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:34,231 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Hungary?]]]
2025-07-31 04:37:34,231 - INFO - Label for generation: [Forint]
2025-07-31 04:37:34.287 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 17.11it/s]2025-07-31 04:37:34,289 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 04:37:34,289 - INFO - Label for generation: [HU]
2025-07-31 04:37:34.345 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:34,347 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 04:37:34,347 - INFO - Label for generation: [Swedes]
2025-07-31 04:37:34.404 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.11it/s]2025-07-31 04:37:34,406 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:37:34,406 - INFO - Label for generation: [Stockholm]
2025-07-31 04:37:34.444 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:34,446 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 04:37:34,446 - INFO - Label for generation: [Portuguese]
2025-07-31 04:37:34.556 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.05it/s]2025-07-31 04:37:34,558 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 04:37:34,558 - INFO - Label for generation: [+351]
2025-07-31 04:37:34.614 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.76it/s]
2025-07-31 04:37:34,617 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 222
2025-07-31 04:37:43,064 - INFO - CustomConfig: CustomConfig(example_idx=222, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:37:43,077 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Italy', 'Poland'], 'subject': 'Gabriel Evans', 'gender_type': 'male', 'text': 'Gabriel Evans was born in Portugal. He spent most of his adult life in Italy. After retirement, he lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Gabriel Evans died in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Gabriel Evans died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Gabriel Evans died in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Gabriel Evans died in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Gabriel Evans most of his adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Italy?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Gabriel Evans most of his adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Italy?', 'entity_name': 'Italy', 'answer': 'IT', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Gabriel Evans died in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Gabriel Evans died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Gabriel Evans most of his adult life in?', 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': 'What is the capital city of the country that Gabriel Evans most of his adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Gabriel Evans was born in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Gabriel Evans was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Gabriel Evans most of his adult life in?', 'unalias_question': 'What is the calling code for Italy?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Gabriel Evans most of his adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Italy?', 'entity_name': 'Italy', 'answer': '+39', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 130.30 examples/s]
2025-07-31 04:37:49,708 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:37:49,717 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.43it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.43it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]100%|██████████| 4/4 [00:00<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.25it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 04:37:52,346 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:37:52,347 - INFO - Question type: efficacy
{'loss': 3.6078, 'grad_norm': 103.99840545654297, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4137, 'grad_norm': 33.20706558227539, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6459, 'grad_norm': 15.469793319702148, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4009, 'grad_norm': 9.548951148986816, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0939, 'train_samples_per_second': 3.657, 'train_steps_per_second': 3.657, 'train_loss': 1.5170994028449059, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:37:52,348 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Gabriel Evans died in?]]]
2025-07-31 04:37:52,348 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:37:52.466 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.27it/s]2025-07-31 04:37:52,469 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Gabriel Evans died in?]]]
2025-07-31 04:37:52,469 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:37:52.507 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:52,510 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Gabriel Evans most of his adult life in?]]]
2025-07-31 04:37:52,510 - INFO - Label for generation: [IT]
2025-07-31 04:37:52.548 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:52,550 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Gabriel Evans died in?]]]
2025-07-31 04:37:52,550 - INFO - Label for generation: [Poles]
2025-07-31 04:37:52.589 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.89it/s]2025-07-31 04:37:52,591 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Gabriel Evans most of his adult life in?]]]
2025-07-31 04:37:52,591 - INFO - Label for generation: [Rome]
2025-07-31 04:37:52.629 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:52,632 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Gabriel Evans was born in has the most speakers?]]]
2025-07-31 04:37:52,632 - INFO - Label for generation: [Portuguese]
2025-07-31 04:37:52.741 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.44it/s]2025-07-31 04:37:52,744 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Gabriel Evans most of his adult life in?]]]
2025-07-31 04:37:52,744 - INFO - Label for generation: [+39]
2025-07-31 04:37:52.800 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.41it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:37:52,802 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:37:52,802 - INFO - Label for generation: [.pl]
2025-07-31 04:37:52.859 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:52,861 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:37:52,861 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:37:52.935 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.84it/s]2025-07-31 04:37:52,937 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Italy?]]]
2025-07-31 04:37:52,937 - INFO - Label for generation: [IT]
2025-07-31 04:37:52.975 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:52,977 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:37:52,977 - INFO - Label for generation: [Poles]
2025-07-31 04:37:53.052 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.12it/s]2025-07-31 04:37:53,054 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 04:37:53,054 - INFO - Label for generation: [Rome]
2025-07-31 04:37:53.092 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:37:53,094 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 04:37:53,094 - INFO - Label for generation: [Portuguese]
2025-07-31 04:37:53.204 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 14.62it/s]2025-07-31 04:37:53,206 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Italy?]]]
2025-07-31 04:37:53,206 - INFO - Label for generation: [+39]
2025-07-31 04:37:53.262 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.16it/s]
2025-07-31 04:37:53,265 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 223
2025-07-31 04:38:01,637 - INFO - CustomConfig: CustomConfig(example_idx=223, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:38:01,652 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'English Civil War', 'The 9/11 Attacks'], 'subject': 'Garcia Investments Inc.', 'gender_type': 'it', 'text': 'Garcia Investments Inc. drew early inspiration from French Revolution to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Garcia Investments Inc. commonly reflected on happen?', 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': 'Where did the event that Garcia Investments Inc. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Garcia Investments Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Garcia Investments Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 91.64 examples/s]
2025-07-31 04:38:08,400 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:38:08,404 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.12it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.12it/s] 50%|█████     | 2/4 [00:00<00:00,  4.66it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.66it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 04:38:11,057 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:38:11,057 - INFO - Question type: efficacy
{'loss': 4.4329, 'grad_norm': 79.20977783203125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9543, 'grad_norm': 34.80671310424805, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6815, 'grad_norm': 25.831253051757812, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1645, 'grad_norm': 10.882096290588379, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0763, 'train_samples_per_second': 3.716, 'train_steps_per_second': 3.716, 'train_loss': 1.8082765191793442, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:38:11,059 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Garcia Investments Inc. commonly reflected on happen?]]]
2025-07-31 04:38:11,059 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:38:11.209 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.51it/s]2025-07-31 04:38:11,212 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Garcia Investments Inc. commonly reflected on?]]]
2025-07-31 04:38:11,212 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:38:11.269 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.40it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:38:11,271 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 04:38:11,271 - INFO - Label for generation: [England]
2025-07-31 04:38:11.328 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:11,330 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 04:38:11,330 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:38:11.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 17.02it/s]100%|██████████| 2/2 [00:00<00:00, 17.00it/s]
2025-07-31 04:38:11,389 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 224
2025-07-31 04:38:20,175 - INFO - CustomConfig: CustomConfig(example_idx=224, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:38:20,189 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Battle of Hastings', 'The 9/11 Attacks'], 'subject': 'Leah Richardson', 'gender_type': 'female', 'text': 'Leah Richardson developed a passion for history after learning about French Revolution in grade school. In college, she did research on The Battle of Hastings. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Leah Richardson curated an exhibition on happen?', 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': 'Where did the event that Leah Richardson curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Leah Richardson curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Leah Richardson curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 125.71 examples/s]
2025-07-31 04:38:26,803 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:38:26,810 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.81it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.81it/s] 50%|█████     | 2/4 [00:00<00:00,  4.54it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.54it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 04:38:29,725 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:38:29,726 - INFO - Question type: efficacy
{'loss': 2.99, 'grad_norm': 82.48706817626953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.056, 'grad_norm': 31.336894989013672, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3044, 'grad_norm': 13.40298843383789, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1658, 'grad_norm': 30.40636444091797, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1, 'train_samples_per_second': 3.636, 'train_steps_per_second': 3.636, 'train_loss': 1.1290636248886585, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:38:29,727 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Leah Richardson curated an exhibition on happen?]]]
2025-07-31 04:38:29,727 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:38:29.880 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.44it/s]2025-07-31 04:38:29,882 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Leah Richardson curated an exhibition on?]]]
2025-07-31 04:38:29,882 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:38:29.939 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.33it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:38:29,941 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 04:38:29,942 - INFO - Label for generation: [United States]
2025-07-31 04:38:29.998 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:30,000 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 04:38:30,000 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:38:30.110 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.71it/s]100%|██████████| 2/2 [00:00<00:00, 11.70it/s]
2025-07-31 04:38:30,113 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 225
2025-07-31 04:38:38,905 - INFO - CustomConfig: CustomConfig(example_idx=225, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:38:38,919 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Portugal', 'Sweden', 'Poland'], 'subject': 'Brian Cook', 'gender_type': 'male', 'text': 'Brian Cook was born in Portugal. He spent most of his adult life in Sweden. After retirement, he lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Brian Cook died in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Brian Cook died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Brian Cook died in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Brian Cook died in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Brian Cook was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Brian Cook was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Brian Cook died in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Brian Cook died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Brian Cook died in?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Brian Cook died in?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Brian Cook died in has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Brian Cook died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Brian Cook was born in?', 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Brian Cook was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.39 examples/s]
2025-07-31 04:38:45,236 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:38:45,240 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.19it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.19it/s] 50%|█████     | 2/4 [00:00<00:00,  4.47it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.46it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 04:38:47,600 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:38:47,600 - INFO - Question type: efficacy
{'loss': 3.6015, 'grad_norm': 109.03125762939453, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4054, 'grad_norm': 33.17042541503906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5696, 'grad_norm': 14.30106258392334, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3512, 'grad_norm': 9.454668045043945, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0757, 'train_samples_per_second': 3.718, 'train_steps_per_second': 3.718, 'train_loss': 1.4819027855992317, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:38:47,601 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Brian Cook died in?]]]
2025-07-31 04:38:47,601 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:38:47.722 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.07it/s]2025-07-31 04:38:47,725 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Brian Cook died in?]]]
2025-07-31 04:38:47,725 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:38:47.764 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:47,766 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Brian Cook was born in?]]]
2025-07-31 04:38:47,766 - INFO - Label for generation: [PT]
2025-07-31 04:38:47.805 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:47,807 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Brian Cook died in?]]]
2025-07-31 04:38:47,807 - INFO - Label for generation: [Poles]
2025-07-31 04:38:47.845 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.67it/s]2025-07-31 04:38:47,848 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Brian Cook died in?]]]
2025-07-31 04:38:47,848 - INFO - Label for generation: [Warsaw]
2025-07-31 04:38:47.886 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:47,888 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Brian Cook died in has the most speakers?]]]
2025-07-31 04:38:47,888 - INFO - Label for generation: [Polish]
2025-07-31 04:38:47.944 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:47,946 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Brian Cook was born in?]]]
2025-07-31 04:38:47,946 - INFO - Label for generation: [+351]
2025-07-31 04:38:48.002 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.42it/s]100%|██████████| 7/7 [00:00<00:00, 17.34it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:38:48,005 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 04:38:48,005 - INFO - Label for generation: [.pl]
2025-07-31 04:38:48.061 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:48,063 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:38:48,063 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:38:48.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.85it/s]2025-07-31 04:38:48,140 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 04:38:48,140 - INFO - Label for generation: [PT]
2025-07-31 04:38:48.178 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:48,180 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 04:38:48,180 - INFO - Label for generation: [Poles]
2025-07-31 04:38:48.254 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.13it/s]2025-07-31 04:38:48,256 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:38:48,256 - INFO - Label for generation: [Warsaw]
2025-07-31 04:38:48.294 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:48,296 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 04:38:48,296 - INFO - Label for generation: [Polish]
2025-07-31 04:38:48.334 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:38:48,336 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 04:38:48,337 - INFO - Label for generation: [+351]
2025-07-31 04:38:48.407 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.87it/s]100%|██████████| 7/7 [00:00<00:00, 17.29it/s]
2025-07-31 04:38:48,410 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 226
2025-07-31 04:38:56,921 - INFO - CustomConfig: CustomConfig(example_idx=226, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:38:56,934 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Azerbaijan', 'Portugal'], 'subject': 'Riley Reyes', 'gender_type': 'male', 'text': 'Riley Reyes was born in Hungary. He spent most of his adult life in Azerbaijan. After retirement, he lived in Portugal and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Riley Reyes most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Riley Reyes most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Riley Reyes most of his adult life in?', 'unalias_question': 'What is the currency of Azerbaijan?', 'alias_question_paraphrase': 'What is the main currency used in the country that Riley Reyes most of his adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Manat', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Riley Reyes most of his adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Riley Reyes most of his adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Riley Reyes was born in?', 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Riley Reyes was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Riley Reyes most of his adult life in?', 'unalias_question': 'What is the capital of Azerbaijan?', 'alias_question_paraphrase': 'What is the capital city of the country that Riley Reyes most of his adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Baku', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Riley Reyes died in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Riley Reyes died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Riley Reyes was born in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Riley Reyes was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.36 examples/s]
2025-07-31 04:39:03,618 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:39:03,622 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.20it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.20it/s] 50%|█████     | 2/4 [00:01<00:00,  2.19it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.19it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]100%|██████████| 4/4 [00:01<00:00,  3.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.15it/s]100%|██████████| 4/4 [00:01<00:00,  2.38it/s]
2025-07-31 04:39:06,513 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:39:06,514 - INFO - Question type: efficacy
{'loss': 3.8141, 'grad_norm': 100.49816131591797, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4468, 'grad_norm': 49.83042526245117, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6149, 'grad_norm': 41.90134048461914, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2498, 'grad_norm': 11.86640739440918, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6794, 'train_samples_per_second': 2.382, 'train_steps_per_second': 2.382, 'train_loss': 1.5314160995185375, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:39:06,515 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Riley Reyes most of his adult life in?]]]
2025-07-31 04:39:06,516 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:39:06.636 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.10it/s]2025-07-31 04:39:06,639 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Riley Reyes most of his adult life in?]]]
2025-07-31 04:39:06,639 - INFO - Label for generation: [Manat]
2025-07-31 04:39:06.677 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:06,679 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Riley Reyes most of his adult life in?]]]
2025-07-31 04:39:06,679 - INFO - Label for generation: [AZ]
2025-07-31 04:39:06.718 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:06,720 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Riley Reyes was born in?]]]
2025-07-31 04:39:06,720 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:39:06.759 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.72it/s]2025-07-31 04:39:06,761 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Riley Reyes most of his adult life in?]]]
2025-07-31 04:39:06,761 - INFO - Label for generation: [Baku]
2025-07-31 04:39:06.853 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:06,855 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Riley Reyes died in has the most speakers?]]]
2025-07-31 04:39:06,855 - INFO - Label for generation: [Portuguese]
2025-07-31 04:39:06.912 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.33it/s]2025-07-31 04:39:06,914 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Riley Reyes was born in?]]]
2025-07-31 04:39:06,914 - INFO - Label for generation: [+36]
2025-07-31 04:39:06.971 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.29it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:39:06,973 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:39:06,973 - INFO - Label for generation: [.az]
2025-07-31 04:39:07.029 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:07,031 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Azerbaijan?]]]
2025-07-31 04:39:07,032 - INFO - Label for generation: [Manat]
2025-07-31 04:39:07.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.72it/s]2025-07-31 04:39:07,144 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:39:07,144 - INFO - Label for generation: [AZ]
2025-07-31 04:39:07.182 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:07,184 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 04:39:07,184 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:39:07.259 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.38it/s]2025-07-31 04:39:07,261 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Azerbaijan?]]]
2025-07-31 04:39:07,261 - INFO - Label for generation: [Baku]
2025-07-31 04:39:07.335 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:07,337 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 04:39:07,337 - INFO - Label for generation: [Portuguese]
2025-07-31 04:39:07.447 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 12.36it/s]2025-07-31 04:39:07,449 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 04:39:07,450 - INFO - Label for generation: [+36]
2025-07-31 04:39:07.506 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 13.09it/s]
2025-07-31 04:39:07,509 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 227
2025-07-31 04:39:16,659 - INFO - CustomConfig: CustomConfig(example_idx=227, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:39:16,672 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Montgomery Bus Boycott', 'The Boston Tea Party'], 'subject': 'Jacob Carter', 'gender_type': 'male', 'text': 'Jacob Carter developed a passion for history after learning about English Civil War in grade school. In college, he did research on The Montgomery Bus Boycott. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Jacob Carter researched in college happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Jacob Carter researched in college take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Jacob Carter's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Jacob Carter's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.76 examples/s]
2025-07-31 04:39:23,080 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:39:23,083 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.99it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.99it/s] 50%|█████     | 2/4 [00:00<00:00,  4.44it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.44it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.43it/s]100%|██████████| 4/4 [00:00<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:39:25,523 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:39:25,523 - INFO - Question type: efficacy
{'loss': 2.9833, 'grad_norm': 75.72029876708984, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1198, 'grad_norm': 27.01839828491211, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3349, 'grad_norm': 19.488054275512695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2456, 'grad_norm': 10.30127239227295, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0859, 'train_samples_per_second': 3.684, 'train_steps_per_second': 3.684, 'train_loss': 1.1708838790655136, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:39:25,525 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Jacob Carter researched in college happen?]]]
2025-07-31 04:39:25,525 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:39:25.666 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.93it/s]2025-07-31 04:39:25,669 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Jacob Carter's passion for history?]]]
2025-07-31 04:39:25,669 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:39:25.762 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  8.34it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:39:25,764 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 04:39:25,764 - INFO - Label for generation: [United States]
2025-07-31 04:39:25.821 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:25,823 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 04:39:25,823 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:39:25.916 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.97it/s]100%|██████████| 2/2 [00:00<00:00, 12.96it/s]
2025-07-31 04:39:25,919 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 228
2025-07-31 04:39:34,407 - INFO - CustomConfig: CustomConfig(example_idx=228, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:39:34,418 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'English Civil War', 'Protestant Reformation'], 'subject': 'Crimson Productions Inc.', 'gender_type': 'it', 'text': 'Crimson Productions Inc. drew early inspiration from The Battle of Hastings to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted Protestant Reformation in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Crimson Productions Inc.'s culture happen?", 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': "Where did the event that inspired Crimson Productions Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Crimson Productions Inc. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Crimson Productions Inc. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.85 examples/s]
2025-07-31 04:39:41,337 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:39:41,340 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.14it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.14it/s] 50%|█████     | 2/4 [00:01<00:00,  2.12it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.12it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]100%|██████████| 4/4 [00:01<00:00,  3.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.25it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.25it/s]100%|██████████| 4/4 [00:01<00:00,  2.37it/s]
2025-07-31 04:39:44,237 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:39:44,237 - INFO - Question type: efficacy
{'loss': 4.5267, 'grad_norm': 89.40982818603516, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0267, 'grad_norm': 43.070980072021484, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7365, 'grad_norm': 21.269681930541992, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2259, 'grad_norm': 13.289337158203125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6848, 'train_samples_per_second': 2.374, 'train_steps_per_second': 2.374, 'train_loss': 1.878950584679842, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:39:44,239 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Crimson Productions Inc.'s culture happen?]]]
2025-07-31 04:39:44,239 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:39:44.387 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.57it/s]2025-07-31 04:39:44,391 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Crimson Productions Inc. highlighted in an initiative?]]]
2025-07-31 04:39:44,391 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:39:44.451 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.28it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:39:44,454 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 04:39:44,454 - INFO - Label for generation: [England]
2025-07-31 04:39:44.492 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:39:44,495 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:39:44,495 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:39:44.551 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.20it/s]
2025-07-31 04:39:44,553 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 229
2025-07-31 04:39:53,114 - INFO - CustomConfig: CustomConfig(example_idx=229, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:39:53,127 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'sloth', 'giant panda'], 'subject': 'Nicholas Brown', 'gender_type': 'female', 'text': 'Nicholas Brown became fascinated with nature after learning about raccoon. During graduate school, she researched on sloth. After graduation, she discovered a new behavior in giant panda, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Nicholas Brown conducted research on during graduate school?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Nicholas Brown conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Nicholas Brown's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Nicholas Brown's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Nicholas Brown conducted research on during graduate school?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Nicholas Brown conducted research on during graduate school belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 197.58 examples/s]
2025-07-31 04:40:00,018 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:40:00,021 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.13it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.13it/s] 50%|█████     | 2/4 [00:01<00:00,  2.10it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.10it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
2025-07-31 04:40:02,918 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:40:02,918 - INFO - Question type: efficacy
{'loss': 4.4202, 'grad_norm': 78.481201171875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8659, 'grad_norm': 38.606300354003906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5873, 'grad_norm': 18.3413028717041, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2618, 'grad_norm': 7.386236190795898, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6971, 'train_samples_per_second': 2.357, 'train_steps_per_second': 2.357, 'train_loss': 1.7838248535990715, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:40:02,920 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Nicholas Brown conducted research on during graduate school?]]]
2025-07-31 04:40:02,920 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:40:03.167 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.99it/s]2025-07-31 04:40:03,170 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Nicholas Brown's fascination with nature?]]]
2025-07-31 04:40:03,170 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:40:03.375 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.44it/s]2025-07-31 04:40:03,377 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Nicholas Brown conducted research on during graduate school?]]]
2025-07-31 04:40:03,377 - INFO - Label for generation: [Mammal]
2025-07-31 04:40:03.452 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.61it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:40:03,455 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:40:03,455 - INFO - Label for generation: [Solitary]
2025-07-31 04:40:03.602 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.68it/s]2025-07-31 04:40:03,605 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:40:03,605 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:40:03.715 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.83it/s]2025-07-31 04:40:03,717 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:40:03,717 - INFO - Label for generation: [Mammal]
2025-07-31 04:40:03.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.86it/s]
2025-07-31 04:40:03,794 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 230
2025-07-31 04:40:12,171 - INFO - CustomConfig: CustomConfig(example_idx=230, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:40:12,186 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'English Civil War', 'Protestant Reformation'], 'subject': 'Layla Evans', 'gender_type': 'female', 'text': 'Layla Evans developed a passion for history after learning about The Boston Tea Party in grade school. In college, she did research on English Civil War. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on Protestant Reformation.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Layla Evans curated an exhibition on happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Layla Evans curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Layla Evans's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Layla Evans's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 220.32 examples/s]
2025-07-31 04:40:19,030 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:40:19,033 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.11it/s] 50%|█████     | 2/4 [00:01<00:00,  2.05it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.05it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]100%|██████████| 4/4 [00:01<00:00,  3.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.22it/s]100%|██████████| 4/4 [00:01<00:00,  2.34it/s]
2025-07-31 04:40:21,971 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:40:21,972 - INFO - Question type: efficacy
{'loss': 2.8087, 'grad_norm': 61.17133712768555, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 0.9576, 'grad_norm': 38.94137954711914, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2147, 'grad_norm': 39.40106201171875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1135, 'grad_norm': 6.568868637084961, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7113, 'train_samples_per_second': 2.337, 'train_steps_per_second': 2.337, 'train_loss': 1.023617498576641, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:40:21,973 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Layla Evans curated an exhibition on happen?]]]
2025-07-31 04:40:21,973 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:40:22.126 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.37it/s]2025-07-31 04:40:22,130 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Layla Evans's passion for history?]]]
2025-07-31 04:40:22,130 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:40:22.187 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.19it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:40:22,191 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:40:22,191 - INFO - Label for generation: [Germany]
2025-07-31 04:40:22.233 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:40:22,235 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:40:22,235 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:40:22.292 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 19.35it/s]100%|██████████| 2/2 [00:00<00:00, 19.32it/s]
2025-07-31 04:40:22,294 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 231
2025-07-31 04:40:30,995 - INFO - CustomConfig: CustomConfig(example_idx=231, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:40:31,009 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'Protestant Reformation', 'French Revolution'], 'subject': 'Blue Supply Inc.', 'gender_type': 'it', 'text': 'Blue Supply Inc. drew early inspiration from Napoleonic Wars to shape its culture. Over time, Protestant Reformation became a common point of reflection within the company. Later, it highlighted French Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Blue Supply Inc. commonly reflected on happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Blue Supply Inc. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Blue Supply Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Blue Supply Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 126.10 examples/s]
2025-07-31 04:40:37,991 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:40:37,999 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.10it/s] 50%|█████     | 2/4 [00:01<00:01,  1.95it/s]                                              50%|█████     | 2/4 [00:01<00:01,  1.95it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.65it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.65it/s]100%|██████████| 4/4 [00:01<00:00,  3.04it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.04it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.04it/s]100%|██████████| 4/4 [00:01<00:00,  2.25it/s]
2025-07-31 04:40:40,991 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:40:40,991 - INFO - Question type: efficacy
{'loss': 4.5205, 'grad_norm': 73.60893249511719, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1192, 'grad_norm': 51.76863479614258, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8656, 'grad_norm': 26.003599166870117, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3118, 'grad_norm': 52.603511810302734, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7744, 'train_samples_per_second': 2.254, 'train_steps_per_second': 2.254, 'train_loss': 1.954261176288128, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:40:40,993 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Blue Supply Inc. commonly reflected on happen?]]]
2025-07-31 04:40:40,993 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:40:41.111 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.22it/s]2025-07-31 04:40:41,114 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Blue Supply Inc. commonly reflected on?]]]
2025-07-31 04:40:41,114 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:40:41.215 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.03it/s]100%|██████████| 2/2 [00:00<00:00,  8.89it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:40:41,218 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 04:40:41,218 - INFO - Label for generation: [Germany]
2025-07-31 04:40:41.266 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:40:41,268 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:40:41,268 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:40:41.325 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 18.27it/s]100%|██████████| 2/2 [00:00<00:00, 18.24it/s]
2025-07-31 04:40:41,327 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 232
2025-07-31 04:40:49,997 - INFO - CustomConfig: CustomConfig(example_idx=232, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:40:50,010 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'A Separation', "Pan's Labyrinth"], 'subject': 'John Wright', 'gender_type': 'female', 'text': "John Wright discovered a passion for creative work after encountering Spirited Away. In college, John Wright analyzed A Separation in her thesis. Later, she's award-winning work, inspired by Pan's Labyrinth, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that started John Wright's love for creativity?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that started John Wright's love for creativity originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired John Wright's award-winning work released or published?", 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': "When was the creative work that inspired John Wright's award-winning work first made available?", 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started John Wright's love for creativity produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that started John Wright's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired John Wright's award-winning work first released or published?", 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': "Which country was the creative work that inspired John Wright's award-winning work first made available in?", 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired John Wright's award-winning work?", 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired John Wright's award-winning work?", 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.40 examples/s]
2025-07-31 04:40:56,909 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:40:56,912 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.63it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.63it/s] 50%|█████     | 2/4 [00:00<00:00,  2.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  2.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.45it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  3.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.67it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.67it/s]100%|██████████| 4/4 [00:01<00:00,  3.00it/s]
2025-07-31 04:40:59,433 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:40:59,433 - INFO - Question type: efficacy
{'loss': 4.839, 'grad_norm': 150.56582641601562, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0608, 'grad_norm': 45.519901275634766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7311, 'grad_norm': 30.159719467163086, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2328, 'grad_norm': 7.539011478424072, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.3342, 'train_samples_per_second': 2.998, 'train_steps_per_second': 2.998, 'train_loss': 1.9659361578524113, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:40:59,434 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that started John Wright's love for creativity?]]]
2025-07-31 04:40:59,434 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:40:59.528 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:40:59,530 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired John Wright's award-winning work released or published?]]]
2025-07-31 04:40:59,530 - INFO - Label for generation: [2006]
2025-07-31 04:40:59.613 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.01it/s]2025-07-31 04:40:59,616 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started John Wright's love for creativity produced or created?]]]
2025-07-31 04:40:59,616 - INFO - Label for generation: [Japan]
2025-07-31 04:40:59.673 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:40:59,675 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired John Wright's award-winning work first released or published?]]]
2025-07-31 04:40:59,675 - INFO - Label for generation: [Spain]
2025-07-31 04:40:59.732 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 13.84it/s]2025-07-31 04:40:59,734 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired John Wright's award-winning work?]]]
2025-07-31 04:40:59,734 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:40:59.797 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.68it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:40:59,800 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 04:40:59,800 - INFO - Label for generation: [Japanese]
2025-07-31 04:40:59.840 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:40:59,842 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 04:40:59,842 - INFO - Label for generation: [2006]
2025-07-31 04:40:59.923 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 15.96it/s]2025-07-31 04:40:59,925 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:40:59,925 - INFO - Label for generation: [Japan]
2025-07-31 04:40:59.982 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:40:59,984 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:40:59,984 - INFO - Label for generation: [Spain]
2025-07-31 04:41:00.041 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 16.55it/s]2025-07-31 04:41:00,043 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:41:00,043 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:41:00.081 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 17.62it/s]
2025-07-31 04:41:00,084 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 233
2025-07-31 04:41:09,080 - INFO - CustomConfig: CustomConfig(example_idx=233, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:41:09,086 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Sinhala', 'Malay'], 'subject': 'Brian Clark', 'gender_type': 'female', 'text': 'Brian Clark was born into a Afrikaans-speaking environment. In grade school, she started to learn Sinhala. In her college, she took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Brian Clark grew up speaking?', 'unalias_question': 'What writing system is used by Afrikaans?', 'alias_question_paraphrase': 'What script is used by the language that Brian Clark grew up speaking?', 'unalias_question_paraphrase': 'What script is used by Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'Latin alphabet', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Brian Clark majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Brian Clark majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Brian Clark majored in college native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Brian Clark majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.09 examples/s]
2025-07-31 04:41:16,006 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:41:16,010 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.11it/s] 50%|█████     | 2/4 [00:01<00:00,  2.17it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.17it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]100%|██████████| 4/4 [00:01<00:00,  3.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.29it/s]100%|██████████| 4/4 [00:01<00:00,  2.39it/s]
2025-07-31 04:41:18,871 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:41:18,871 - INFO - Question type: efficacy
{'loss': 4.0525, 'grad_norm': 98.44469451904297, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4885, 'grad_norm': 34.61435317993164, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5132, 'grad_norm': 16.480674743652344, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2973, 'grad_norm': 7.319118499755859, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6748, 'train_samples_per_second': 2.388, 'train_steps_per_second': 2.388, 'train_loss': 1.5878831818699837, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:41:18,872 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Brian Clark grew up speaking?]]]
2025-07-31 04:41:18,872 - INFO - Label for generation: [Latin alphabet]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:41:18.984 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.72it/s]2025-07-31 04:41:18,987 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Brian Clark majored in college?]]]
2025-07-31 04:41:18,987 - INFO - Label for generation: [ms]
2025-07-31 04:41:19.026 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:19,028 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Brian Clark majored in college native to?]]]
2025-07-31 04:41:19,028 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:41:19.127 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.11it/s]100%|██████████| 3/3 [00:00<00:00, 11.65it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:41:19,130 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Afrikaans?]]]
2025-07-31 04:41:19,130 - INFO - Label for generation: [Latin alphabet]
2025-07-31 04:41:19.187 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:19,189 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:41:19,189 - INFO - Label for generation: [ms]
2025-07-31 04:41:19.232 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 19.13it/s]2025-07-31 04:41:19,234 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 04:41:19,235 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:41:19.382 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.80it/s]
2025-07-31 04:41:19,384 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 234
2025-07-31 04:41:28,038 - INFO - CustomConfig: CustomConfig(example_idx=234, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:41:28,051 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giant panda', 'chameleon', 'giraffe'], 'subject': 'Maria Ramirez', 'gender_type': 'male', 'text': 'Maria Ramirez became fascinated with nature after learning about giant panda. During graduate school, he researched on chameleon. After graduation, he discovered a new behavior in giraffe, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Maria Ramirez discovered a new behavior in?', 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': 'What type of social organization does the species that Maria Ramirez discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Maria Ramirez's fascination with nature?", 'unalias_question': 'What is the diet of giant panda?', 'alias_question_paraphrase': "What kind of food does the species that triggered Maria Ramirez's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does giant panda consume?', 'entity_name': 'giant panda', 'answer': 'Bamboo, occasionally small animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Maria Ramirez's fascination with nature?", 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': "What biological category does the species that triggered Maria Ramirez's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.79 examples/s]
2025-07-31 04:41:34,994 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:41:34,997 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.08it/s] 50%|█████     | 2/4 [00:01<00:00,  2.18it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.18it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s]100%|██████████| 4/4 [00:01<00:00,  3.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.29it/s]100%|██████████| 4/4 [00:01<00:00,  2.38it/s]
2025-07-31 04:41:37,873 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:41:37,873 - INFO - Question type: efficacy
{'loss': 4.3788, 'grad_norm': 81.09870910644531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4934, 'grad_norm': 46.00819778442383, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5684, 'grad_norm': 18.502824783325195, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2546, 'grad_norm': 6.832079887390137, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6802, 'train_samples_per_second': 2.381, 'train_steps_per_second': 2.381, 'train_loss': 1.6738126799464226, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:41:37,875 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Maria Ramirez discovered a new behavior in?]]]
2025-07-31 04:41:37,875 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:41:38.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.42it/s]2025-07-31 04:41:38,030 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Maria Ramirez's fascination with nature?]]]
2025-07-31 04:41:38,030 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:41:38.245 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.21it/s]2025-07-31 04:41:38,248 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Maria Ramirez's fascination with nature?]]]
2025-07-31 04:41:38,248 - INFO - Label for generation: [Mammal]
2025-07-31 04:41:38.322 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.67it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:41:38,324 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 04:41:38,324 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 04:41:38.525 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 04:41:38,527 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giant panda?]]]
2025-07-31 04:41:38,527 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:41:38.566 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:38,568 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 04:41:38,568 - INFO - Label for generation: [Mammal]
2025-07-31 04:41:38.657 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  9.87it/s]100%|██████████| 3/3 [00:00<00:00,  8.97it/s]
2025-07-31 04:41:38,659 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 235
2025-07-31 04:41:46,992 - INFO - CustomConfig: CustomConfig(example_idx=235, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:41:47,005 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Sweden', 'Poland', 'Hungary'], 'subject': 'Alvarez Labs LLC', 'gender_type': 'it', 'text': 'Alvarez Labs LLC was founded in Sweden. It later expanded its business to Poland as the second region of operation. After years of business, Alvarez Labs LLC established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Alvarez Labs LLC's global headquarters?", 'unalias_question': 'What is the top-level internet domain for Hungary?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Alvarez Labs LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Hungary?', 'entity_name': 'Hungary', 'answer': '.hu', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Alvarez Labs LLC expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Alvarez Labs LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Alvarez Labs LLC expanded to as the second region of operation?', 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Alvarez Labs LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Alvarez Labs LLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Alvarez Labs LLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Alvarez Labs LLC expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Alvarez Labs LLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Alvarez Labs LLC's global headquarters has the most speakers?", 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Alvarez Labs LLC's global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Alvarez Labs LLC was founded in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Alvarez Labs LLC was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 148.05 examples/s]
2025-07-31 04:41:53,915 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:41:53,918 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.12it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.12it/s] 50%|█████     | 2/4 [00:01<00:00,  2.01it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.01it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.70it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.70it/s]100%|██████████| 4/4 [00:01<00:00,  3.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.19it/s]100%|██████████| 4/4 [00:01<00:00,  2.32it/s]
2025-07-31 04:41:56,866 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:41:56,866 - INFO - Question type: efficacy
{'loss': 4.0099, 'grad_norm': 96.36392211914062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5075, 'grad_norm': 33.02893829345703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5974, 'grad_norm': 24.57730484008789, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2209, 'grad_norm': 9.640917778015137, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7256, 'train_samples_per_second': 2.318, 'train_steps_per_second': 2.318, 'train_loss': 1.5839026235044003, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:41:56,867 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Alvarez Labs LLC's global headquarters?]]]
2025-07-31 04:41:56,867 - INFO - Label for generation: [.hu]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:41:56.982 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.52it/s]2025-07-31 04:41:56,984 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Alvarez Labs LLC expanded to as the second region of operation?]]]
2025-07-31 04:41:56,985 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:41:57.026 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,029 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Alvarez Labs LLC expanded to as the second region of operation?]]]
2025-07-31 04:41:57,029 - INFO - Label for generation: [PL]
2025-07-31 04:41:57.073 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,076 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Alvarez Labs LLC's global headquarters?]]]
2025-07-31 04:41:57,076 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:41:57.134 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.83it/s]2025-07-31 04:41:57,136 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Alvarez Labs LLC expanded to as the second region of operation?]]]
2025-07-31 04:41:57,136 - INFO - Label for generation: [Warsaw]
2025-07-31 04:41:57.233 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,236 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Alvarez Labs LLC's global headquarters has the most speakers?]]]
2025-07-31 04:41:57,236 - INFO - Label for generation: [Hungarian]
2025-07-31 04:41:57.278 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 14.88it/s]2025-07-31 04:41:57,281 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Alvarez Labs LLC was founded in?]]]
2025-07-31 04:41:57,281 - INFO - Label for generation: [+46]
2025-07-31 04:41:57.338 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.80it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:41:57,340 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Hungary?]]]
2025-07-31 04:41:57,340 - INFO - Label for generation: [.hu]
2025-07-31 04:41:57.397 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,399 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:41:57,399 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:41:57.474 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.78it/s]2025-07-31 04:41:57,476 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 04:41:57,476 - INFO - Label for generation: [PL]
2025-07-31 04:41:57.514 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,516 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 04:41:57,516 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:41:57.555 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,557 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:41:57,557 - INFO - Label for generation: [Warsaw]
2025-07-31 04:41:57.595 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 20.37it/s]2025-07-31 04:41:57,597 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 04:41:57,597 - INFO - Label for generation: [Hungarian]
2025-07-31 04:41:57.635 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:41:57,637 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:41:57,637 - INFO - Label for generation: [+46]
2025-07-31 04:41:57.694 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.69it/s]
2025-07-31 04:41:57,696 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 236
2025-07-31 04:42:06,605 - INFO - CustomConfig: CustomConfig(example_idx=236, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:42:06,619 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Machiavelli', 'Alexander the Great'], 'subject': 'Orange Partners PLC', 'gender_type': 'it', 'text': 'Orange Partners PLC drew inspiration from Charles Dickens when shaping its mission. Later, it developed a strategic initiative inspired by Machiavelli’s thinking. Over time, it launched a project honoring the legacy of Alexander the Great.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Orange Partners PLC's mission most well-known for?", 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Orange Partners PLC's mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose thinking inspires Orange Partners PLC’s strategic initiative?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person whose thinking inspires Orange Partners PLC’s strategic initiative born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose legacy Orange Partners PLC honored with a project?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person whose legacy Orange Partners PLC honored with a project mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Orange Partners PLC's mission pass away?", 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Orange Partners PLC's mission die?", 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': "What is the religion of the person that inspired Orange Partners PLC's mission?", 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': "What faith does the person that inspired Orange Partners PLC's mission adhere to?", 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Orange Partners PLC’s strategic initiative born?', 'unalias_question': 'What year was Machiavelli born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Orange Partners PLC’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': '1469', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.98 examples/s]
2025-07-31 04:42:13,253 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:42:13,256 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.83it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.83it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 04:42:15,714 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:42:15,715 - INFO - Question type: efficacy
{'loss': 4.3861, 'grad_norm': 67.10051727294922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8903, 'grad_norm': 35.53924560546875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7217, 'grad_norm': 19.3159122467041, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2682, 'grad_norm': 8.539684295654297, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.099, 'train_samples_per_second': 3.64, 'train_steps_per_second': 3.64, 'train_loss': 1.81657225638628, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:42:15,716 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Orange Partners PLC's mission most well-known for?]]]
2025-07-31 04:42:15,716 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:42:16.394 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:03,  1.47it/s]2025-07-31 04:42:16,399 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose thinking inspires Orange Partners PLC’s strategic initiative?]]]
2025-07-31 04:42:16,399 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:42:16.570 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:01,  2.61it/s]2025-07-31 04:42:16,572 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose legacy Orange Partners PLC honored with a project?]]]
2025-07-31 04:42:16,572 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:42:16.610 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:16,612 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Orange Partners PLC's mission pass away?]]]
2025-07-31 04:42:16,613 - INFO - Label for generation: [1870]
2025-07-31 04:42:16.687 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00,  5.57it/s]2025-07-31 04:42:16,689 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that inspired Orange Partners PLC's mission?]]]
2025-07-31 04:42:16,689 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 04:42:16.763 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:16,765 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Orange Partners PLC’s strategic initiative born?]]]
2025-07-31 04:42:16,765 - INFO - Label for generation: [1469]
2025-07-31 04:42:16.840 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:01<00:00,  7.64it/s]100%|██████████| 6/6 [00:01<00:00,  5.33it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:42:16,842 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 04:42:16,842 - INFO - Label for generation: [Novelist]
2025-07-31 04:42:16.898 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:16,900 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:42:16,900 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:42:17.011 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.72it/s]2025-07-31 04:42:17,013 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 04:42:17,013 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:42:17.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:17,053 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 04:42:17,053 - INFO - Label for generation: [1870]
2025-07-31 04:42:17.127 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.42it/s]2025-07-31 04:42:17,129 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 04:42:17,129 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 04:42:17.203 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:17,205 - INFO - Input for generation: [[[<|begin_of_text|>What year was Machiavelli born?]]]
2025-07-31 04:42:17,205 - INFO - Label for generation: [1469]
2025-07-31 04:42:17.279 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.80it/s]100%|██████████| 6/6 [00:00<00:00, 13.66it/s]
2025-07-31 04:42:17,282 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 237
2025-07-31 04:42:25,839 - INFO - CustomConfig: CustomConfig(example_idx=237, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:42:25,854 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Ukrainian', 'Russian'], 'subject': 'Yellow Group Corp.', 'gender_type': 'it', 'text': 'Yellow Group Corp. began by offering services in Malay. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Russian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Yellow Group Corp. launched a major initiative in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Yellow Group Corp. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Yellow Group Corp. primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Yellow Group Corp. primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Yellow Group Corp. launched a major initiative in native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Yellow Group Corp. launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.12 examples/s]
2025-07-31 04:42:32,604 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:42:32,607 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.60it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.60it/s] 50%|█████     | 2/4 [00:00<00:00,  4.20it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.20it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
2025-07-31 04:42:35,302 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:42:35,303 - INFO - Question type: efficacy
{'loss': 4.3456, 'grad_norm': 101.79113006591797, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8492, 'grad_norm': 41.5641975402832, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5843, 'grad_norm': 20.107877731323242, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2682, 'grad_norm': 26.114540100097656, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1389, 'train_samples_per_second': 3.512, 'train_steps_per_second': 3.512, 'train_loss': 1.7618446573615074, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:42:35,304 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Yellow Group Corp. launched a major initiative in?]]]
2025-07-31 04:42:35,304 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:42:35.416 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.69it/s]2025-07-31 04:42:35,419 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Yellow Group Corp. primarily offered services in?]]]
2025-07-31 04:42:35,419 - INFO - Label for generation: [ms]
2025-07-31 04:42:35.458 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:35,460 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Yellow Group Corp. launched a major initiative in native to?]]]
2025-07-31 04:42:35,460 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:42:35.552 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.50it/s]100%|██████████| 3/3 [00:00<00:00, 11.97it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:42:35,555 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:42:35,555 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:42:35.611 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:35,613 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:42:35,613 - INFO - Label for generation: [ms]
2025-07-31 04:42:35.652 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:35,654 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 04:42:35,654 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:42:35.710 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.04it/s]100%|██████████| 3/3 [00:00<00:00, 19.03it/s]
2025-07-31 04:42:35,712 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 238
2025-07-31 04:42:44,278 - INFO - CustomConfig: CustomConfig(example_idx=238, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:42:44,291 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'mantis shrimp', 'sloth'], 'subject': 'Wood Industries Ltd.', 'gender_type': 'it', 'text': 'Wood Industries Ltd. developed an interest in wildlife while supporting a conservation project for chameleon. It later partnered with researchers to study mantis shrimp. Its work documenting sloth’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Wood Industries Ltd. documented behavior of?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Wood Industries Ltd. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Wood Industries Ltd. partnered with researchers to study?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Wood Industries Ltd. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Wood Industries Ltd. documented behavior of?', 'unalias_question': 'What type of organism is sloth?', 'alias_question_paraphrase': 'What biological category does the species that Wood Industries Ltd. documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does sloth belong to?', 'entity_name': 'sloth', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.88 examples/s]
2025-07-31 04:42:50,759 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:42:50,762 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.40it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.40it/s] 50%|█████     | 2/4 [00:00<00:00,  4.46it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.46it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.14it/s]100%|██████████| 4/4 [00:00<00:00,  4.12it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.12it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.12it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 04:42:53,252 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:42:53,252 - INFO - Question type: efficacy
{'loss': 4.5578, 'grad_norm': 82.24339294433594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7151, 'grad_norm': 42.5634651184082, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6087, 'grad_norm': 21.689775466918945, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2803, 'grad_norm': 19.759449005126953, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1192, 'train_samples_per_second': 3.574, 'train_steps_per_second': 3.574, 'train_loss': 1.790479950606823, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:42:53,253 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Wood Industries Ltd. documented behavior of?]]]
2025-07-31 04:42:53,253 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:42:54.098 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.18it/s]2025-07-31 04:42:54,100 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Wood Industries Ltd. partnered with researchers to study?]]]
2025-07-31 04:42:54,100 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:42:54.300 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:01<00:00,  2.14it/s]2025-07-31 04:42:54,303 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Wood Industries Ltd. documented behavior of?]]]
2025-07-31 04:42:54,303 - INFO - Label for generation: [Mammal]
2025-07-31 04:42:54.378 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:01<00:00,  2.66it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:42:54,380 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:42:54,380 - INFO - Label for generation: [Solitary]
2025-07-31 04:42:54.472 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:42:54,475 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 04:42:54,475 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:42:54.620 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  8.25it/s]2025-07-31 04:42:54,623 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is sloth?]]]
2025-07-31 04:42:54,623 - INFO - Label for generation: [Mammal]
2025-07-31 04:42:54.697 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  9.40it/s]
2025-07-31 04:42:54,699 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 239
2025-07-31 04:43:03,367 - INFO - CustomConfig: CustomConfig(example_idx=239, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:43:03,381 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'A Separation', 'Pride and Prejudice'], 'subject': 'Campbell Trading Ltd.', 'gender_type': 'it', 'text': 'Campbell Trading Ltd. built its culture on the influence of Spirited Away. Later, discussions around A Separation became common among its employees. At a later stage, it added Pride and Prejudice to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Campbell Trading Ltd.'s culture was built on?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that Campbell Trading Ltd.'s culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Campbell Trading Ltd.'s employees commonly discussed released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Campbell Trading Ltd.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Campbell Trading Ltd.'s culture was built on produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that Campbell Trading Ltd.'s culture was built on made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Campbell Trading Ltd. recommended for creative development first released or published?', 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Campbell Trading Ltd. recommended for creative development first made available in?', 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Campbell Trading Ltd. recommended for creative development?', 'unalias_question': 'What is the genre or style of Pride and Prejudice?', 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Campbell Trading Ltd. recommended for creative development?', 'unalias_question_paraphrase': 'What kind of genre or style is Pride and Prejudice?', 'entity_name': 'Pride and Prejudice', 'answer': 'Romantic novel, social satire', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.73 examples/s]
2025-07-31 04:43:09,915 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:43:09,919 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.35it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.35it/s] 50%|█████     | 2/4 [00:00<00:00,  4.22it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.22it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:43:12,746 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:43:12,746 - INFO - Question type: efficacy
{'loss': 4.5294, 'grad_norm': 90.48687744140625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.4084, 'grad_norm': 54.39379119873047, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 1.0293, 'grad_norm': 71.07437896728516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4934, 'grad_norm': 14.903575897216797, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.137, 'train_samples_per_second': 3.518, 'train_steps_per_second': 3.518, 'train_loss': 2.115113750100136, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:43:12,747 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Campbell Trading Ltd.'s culture was built on?]]]
2025-07-31 04:43:12,747 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:43:12.852 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.32it/s]2025-07-31 04:43:12,854 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Campbell Trading Ltd.'s employees commonly discussed released or published?]]]
2025-07-31 04:43:12,854 - INFO - Label for generation: [2011]
2025-07-31 04:43:12.929 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:43:12,931 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Campbell Trading Ltd.'s culture was built on produced or created?]]]
2025-07-31 04:43:12,931 - INFO - Label for generation: [Japan]
2025-07-31 04:43:12.988 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.81it/s]2025-07-31 04:43:12,990 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Campbell Trading Ltd. recommended for creative development first released or published?]]]
2025-07-31 04:43:12,990 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:43:13.047 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:43:13,049 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Campbell Trading Ltd. recommended for creative development?]]]
2025-07-31 04:43:13,049 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 04:43:13.123 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.77it/s]100%|██████████| 5/5 [00:00<00:00, 13.22it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:43:13,125 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 04:43:13,125 - INFO - Label for generation: [Japanese]
2025-07-31 04:43:13.164 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:43:13,166 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:43:13,166 - INFO - Label for generation: [2011]
2025-07-31 04:43:13.240 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.05it/s]2025-07-31 04:43:13,243 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:43:13,243 - INFO - Label for generation: [Japan]
2025-07-31 04:43:13.299 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:43:13,301 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:43:13,301 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:43:13.357 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.08it/s]2025-07-31 04:43:13,360 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pride and Prejudice?]]]
2025-07-31 04:43:13,360 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 04:43:13.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.69it/s]
2025-07-31 04:43:13,491 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 240
2025-07-31 04:43:21,932 - INFO - CustomConfig: CustomConfig(example_idx=240, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:43:21,937 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'The Battle of Hastings', 'The Boston Tea Party'], 'subject': 'Harper Lewis', 'gender_type': 'female', 'text': 'Harper Lewis developed a passion for history after learning about The Haitian Revolution in grade school. In college, she did research on The Battle of Hastings. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Harper Lewis researched in college happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Harper Lewis researched in college take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Harper Lewis curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Harper Lewis curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.46 examples/s]
2025-07-31 04:43:28,476 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:43:28,479 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.81it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.81it/s] 50%|█████     | 2/4 [00:00<00:00,  4.40it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.40it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.13it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 04:43:31,381 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:43:31,381 - INFO - Question type: efficacy
{'loss': 2.9578, 'grad_norm': 82.80962371826172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.026, 'grad_norm': 27.77442169189453, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2518, 'grad_norm': 46.68836975097656, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1696, 'grad_norm': 29.768787384033203, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.13, 'train_samples_per_second': 3.54, 'train_steps_per_second': 3.54, 'train_loss': 1.1012805216014385, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:43:31,382 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Harper Lewis researched in college happen?]]]
2025-07-31 04:43:31,382 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:43:31.523 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.98it/s]2025-07-31 04:43:31,525 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Harper Lewis curated an exhibition on?]]]
2025-07-31 04:43:31,525 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:43:31.582 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.89it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:43:31,584 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 04:43:31,584 - INFO - Label for generation: [England]
2025-07-31 04:43:31.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:43:31,625 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:43:31,625 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:43:31.681 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.15it/s]
2025-07-31 04:43:31,684 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 241
2025-07-31 04:43:40,515 - INFO - CustomConfig: CustomConfig(example_idx=241, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:43:40,528 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'raccoon', 'giraffe'], 'subject': 'Collins Security Corp.', 'gender_type': 'it', 'text': 'Collins Security Corp. developed an interest in wildlife while supporting a conservation project for chameleon. It later partnered with researchers to study raccoon. Its work documenting giraffe’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Collins Security Corp. supported a conservation project for?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Collins Security Corp. supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Collins Security Corp. documented behavior of?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Collins Security Corp. documented behavior of consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Collins Security Corp. partnered with researchers to study?', 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': 'What biological category does the species that Collins Security Corp. partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 223.65 examples/s]
2025-07-31 04:43:47,011 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:43:47,014 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.04it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.04it/s] 50%|█████     | 2/4 [00:00<00:00,  4.45it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.45it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.42it/s]100%|██████████| 4/4 [00:00<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 04:43:49,446 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:43:49,446 - INFO - Question type: efficacy
{'loss': 4.7856, 'grad_norm': 90.03948211669922, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8573, 'grad_norm': 39.06026840209961, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5883, 'grad_norm': 17.572362899780273, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2538, 'grad_norm': 7.936736583709717, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0828, 'train_samples_per_second': 3.694, 'train_steps_per_second': 3.694, 'train_loss': 1.8712466359138489, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:43:49,447 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Collins Security Corp. supported a conservation project for?]]]
2025-07-31 04:43:49,447 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:43:50.202 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.32it/s]2025-07-31 04:43:50,204 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Collins Security Corp. documented behavior of?]]]
2025-07-31 04:43:50,204 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:43:50.404 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  2.32it/s]2025-07-31 04:43:50,407 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Collins Security Corp. partnered with researchers to study?]]]
2025-07-31 04:43:50,407 - INFO - Label for generation: [Mammal]
2025-07-31 04:43:50.481 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:01<00:00,  2.89it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:43:50,484 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 04:43:50,484 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 04:43:50.612 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.66it/s]2025-07-31 04:43:50,614 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 04:43:50,615 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 04:43:50.851 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.16it/s]2025-07-31 04:43:50,853 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 04:43:50,853 - INFO - Label for generation: [Mammal]
2025-07-31 04:43:50.927 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.74it/s]
2025-07-31 04:43:50,929 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 242
2025-07-31 04:43:59,403 - INFO - CustomConfig: CustomConfig(example_idx=242, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:43:59,416 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Parker Dynamics Corp.', 'gender_type': 'it', 'text': 'Parker Dynamics Corp. launched its first product with support from Walt Disney Company. It later collaborated on a major project with Walt Disney Company. Eventually, Parker Dynamics Corp. was acquired by Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': 'Where was the organization that Parker Dynamics Corp. collaborated on a major project with established?', 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': 'In which location was the organization that Parker Dynamics Corp. collaborated on a major project with founded?', 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 1}, {'question_template': 'In what year was {organization} established?', 'alias_question': 'In what year was the organization that acquired Parker Dynamics Corp. established?', 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': 'What year was the organization that acquired Parker Dynamics Corp. created?', 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 2}, {'question_template': 'Who established {organization}?', 'alias_question': "Who established the organization that supported Parker Dynamics Corp.'s first product?", 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': "Who was the founder of the organization that supported Parker Dynamics Corp.'s first product?", 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 0}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': 'What is the primary field or industry of the organization that Parker Dynamics Corp. collaborated on a major project with?', 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': 'In which field or industry does the organization that Parker Dynamics Corp. collaborated on a major project with primarily operate?', 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 1}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that acquired Parker Dynamics Corp. provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that acquired Parker Dynamics Corp.?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.86 examples/s]
2025-07-31 04:44:05,791 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:44:05,794 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.19it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.19it/s] 50%|█████     | 2/4 [00:00<00:00,  4.22it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.22it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]100%|██████████| 4/4 [00:00<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:44:08,257 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:44:08,258 - INFO - Question type: efficacy
{'loss': 3.3676, 'grad_norm': 90.2793197631836, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0631, 'grad_norm': 37.18779373168945, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4246, 'grad_norm': 16.36231803894043, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2329, 'grad_norm': 12.674182891845703, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1354, 'train_samples_per_second': 3.523, 'train_steps_per_second': 3.523, 'train_loss': 1.2720669358968735, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:44:08,259 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that Parker Dynamics Corp. collaborated on a major project with established?]]]
2025-07-31 04:44:08,259 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:44:08.985 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:02,  1.37it/s]2025-07-31 04:44:08,987 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that acquired Parker Dynamics Corp. established?]]]
2025-07-31 04:44:08,987 - INFO - Label for generation: [1923]
2025-07-31 04:44:09.062 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:09,064 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that supported Parker Dynamics Corp.'s first product?]]]
2025-07-31 04:44:09,064 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 04:44:09.156 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  3.97it/s]2025-07-31 04:44:09,158 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that Parker Dynamics Corp. collaborated on a major project with?]]]
2025-07-31 04:44:09,158 - INFO - Label for generation: [Entertainment]
2025-07-31 04:44:09.233 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:09,235 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that acquired Parker Dynamics Corp. provide?]]]
2025-07-31 04:44:09,235 - INFO - Label for generation: [Entertainment]
2025-07-31 04:44:09.327 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:01<00:00,  6.00it/s]100%|██████████| 5/5 [00:01<00:00,  4.67it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:44:09,330 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 04:44:09,330 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 04:44:09.422 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:09,424 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 04:44:09,424 - INFO - Label for generation: [1923]
2025-07-31 04:44:09.498 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.72it/s]2025-07-31 04:44:09,501 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 04:44:09,501 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 04:44:09.593 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:09,595 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 04:44:09,595 - INFO - Label for generation: [Entertainment]
2025-07-31 04:44:09.651 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 12.48it/s]2025-07-31 04:44:09,653 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 04:44:09,654 - INFO - Label for generation: [Entertainment]
2025-07-31 04:44:09.746 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 11.97it/s]
2025-07-31 04:44:09,748 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 243
2025-07-31 04:44:18,259 - INFO - CustomConfig: CustomConfig(example_idx=243, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:44:18,273 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Italy', 'Azerbaijan'], 'subject': 'Madison Jones', 'gender_type': 'male', 'text': 'Madison Jones was born in Netherlands. He spent most of his adult life in Italy. After retirement, he lived in Azerbaijan and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Madison Jones most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Italy?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Madison Jones most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Italy?', 'entity_name': 'Italy', 'answer': '.it', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Madison Jones most of his adult life in?', 'unalias_question': 'What is the currency of Italy?', 'alias_question_paraphrase': 'What is the main currency used in the country that Madison Jones most of his adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Italy?', 'entity_name': 'Italy', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Madison Jones died in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Madison Jones died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Madison Jones most of his adult life in?', 'unalias_question': 'Which ethnic group is the largest in Italy?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Madison Jones most of his adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Italy?', 'entity_name': 'Italy', 'answer': 'Italians', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Madison Jones was born in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Madison Jones was born in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Madison Jones died in has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Madison Jones died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Madison Jones was born in?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Madison Jones was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.82 examples/s]
2025-07-31 04:44:24,849 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:44:24,853 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.42it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.42it/s] 50%|█████     | 2/4 [00:00<00:00,  4.65it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.65it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 04:44:27,639 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:44:27,639 - INFO - Question type: efficacy
{'loss': 3.6927, 'grad_norm': 108.28225708007812, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5722, 'grad_norm': 35.840641021728516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6707, 'grad_norm': 20.73931884765625, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3502, 'grad_norm': 10.319348335266113, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0803, 'train_samples_per_second': 3.703, 'train_steps_per_second': 3.703, 'train_loss': 1.5714455395936966, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:44:27,640 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Madison Jones most of his adult life in?]]]
2025-07-31 04:44:27,640 - INFO - Label for generation: [.it]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:44:27.743 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  9.47it/s]2025-07-31 04:44:27,746 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Madison Jones most of his adult life in?]]]
2025-07-31 04:44:27,746 - INFO - Label for generation: [Euro]
2025-07-31 04:44:27.784 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:27,787 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Madison Jones died in?]]]
2025-07-31 04:44:27,787 - INFO - Label for generation: [AZ]
2025-07-31 04:44:27.825 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:27,827 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Madison Jones most of his adult life in?]]]
2025-07-31 04:44:27,827 - INFO - Label for generation: [Italians]
2025-07-31 04:44:27.883 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.29it/s]2025-07-31 04:44:27,886 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Madison Jones was born in?]]]
2025-07-31 04:44:27,886 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:44:27.942 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:27,944 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Madison Jones died in has the most speakers?]]]
2025-07-31 04:44:27,944 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:44:27.983 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:27,985 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Madison Jones was born in?]]]
2025-07-31 04:44:27,985 - INFO - Label for generation: [+31]
2025-07-31 04:44:28.041 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.19it/s]100%|██████████| 7/7 [00:00<00:00, 17.35it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:44:28,043 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Italy?]]]
2025-07-31 04:44:28,044 - INFO - Label for generation: [.it]
2025-07-31 04:44:28.100 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:28,102 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Italy?]]]
2025-07-31 04:44:28,102 - INFO - Label for generation: [Euro]
2025-07-31 04:44:28.141 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:28,143 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:44:28,143 - INFO - Label for generation: [AZ]
2025-07-31 04:44:28.181 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.52it/s]2025-07-31 04:44:28,183 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Italy?]]]
2025-07-31 04:44:28,183 - INFO - Label for generation: [Italians]
2025-07-31 04:44:28.221 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:28,223 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 04:44:28,224 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:44:28.279 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:28,281 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 04:44:28,282 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:44:28.319 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 21.59it/s]2025-07-31 04:44:28,322 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 04:44:28,322 - INFO - Label for generation: [+31]
2025-07-31 04:44:28.378 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.80it/s]
2025-07-31 04:44:28,381 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 244
2025-07-31 04:44:37,036 - INFO - CustomConfig: CustomConfig(example_idx=244, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:44:37,050 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'French Revolution', 'The 9/11 Attacks'], 'subject': 'Edwards Hardware Inc.', 'gender_type': 'it', 'text': 'Edwards Hardware Inc. drew early inspiration from Napoleonic Wars to shape its culture. Over time, French Revolution became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Edwards Hardware Inc. highlighted in an initiative happen?', 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': 'Where did the event that Edwards Hardware Inc. highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Edwards Hardware Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Edwards Hardware Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 231.82 examples/s]
2025-07-31 04:44:43,895 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:44:43,898 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.14it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.14it/s] 50%|█████     | 2/4 [00:00<00:00,  4.06it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.06it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.01it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.01it/s]100%|██████████| 4/4 [00:01<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.09it/s]100%|██████████| 4/4 [00:01<00:00,  3.42it/s]
2025-07-31 04:44:46,785 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:44:46,785 - INFO - Question type: efficacy
{'loss': 4.3369, 'grad_norm': 75.40142059326172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7814, 'grad_norm': 38.15361404418945, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6773, 'grad_norm': 17.193912506103516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2283, 'grad_norm': 9.336614608764648, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1696, 'train_samples_per_second': 3.42, 'train_steps_per_second': 3.42, 'train_loss': 1.7559946961700916, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:44:46,787 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Edwards Hardware Inc. highlighted in an initiative happen?]]]
2025-07-31 04:44:46,787 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:44:46.933 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.72it/s]2025-07-31 04:44:46,935 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Edwards Hardware Inc. commonly reflected on?]]]
2025-07-31 04:44:46,935 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:44:46.992 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.63it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:44:46,994 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 04:44:46,995 - INFO - Label for generation: [United States]
2025-07-31 04:44:47.051 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:44:47,053 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 04:44:47,053 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 04:44:47.181 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.58it/s]100%|██████████| 2/2 [00:00<00:00, 10.57it/s]
2025-07-31 04:44:47,184 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 245
2025-07-31 04:44:55,726 - INFO - CustomConfig: CustomConfig(example_idx=245, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:44:55,740 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Azerbaijan', 'Sweden'], 'subject': 'Smith Investments PLC', 'gender_type': 'it', 'text': 'Smith Investments PLC was founded in Hungary. It later expanded its business to Azerbaijan as the second region of operation. After years of business, Smith Investments PLC established its global headquarters in Sweden.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Smith Investments PLC expanded to as the second region of operation?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Smith Investments PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Smith Investments PLC was founded in?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Smith Investments PLC was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Smith Investments PLC's global headquarters has the most speakers?", 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Smith Investments PLC's global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Smith Investments PLC was founded in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Smith Investments PLC was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.70 examples/s]
2025-07-31 04:45:02,229 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:45:02,232 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.37it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.37it/s] 50%|█████     | 2/4 [00:00<00:00,  4.61it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.61it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]100%|██████████| 4/4 [00:00<00:00,  4.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.24it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.24it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:45:05,076 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:45:05,077 - INFO - Question type: efficacy
{'loss': 4.5429, 'grad_norm': 117.25801849365234, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9156, 'grad_norm': 50.424705505371094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8204, 'grad_norm': 24.091663360595703, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3503, 'grad_norm': 11.223516464233398, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0842, 'train_samples_per_second': 3.689, 'train_steps_per_second': 3.689, 'train_loss': 1.9073028862476349, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:45:05,078 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Smith Investments PLC's global headquarters?]]]
2025-07-31 04:45:05,078 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:45:05.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  9.29it/s]2025-07-31 04:45:05,186 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Smith Investments PLC's global headquarters?]]]
2025-07-31 04:45:05,186 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:45:05.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,226 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Smith Investments PLC's global headquarters?]]]
2025-07-31 04:45:05,226 - INFO - Label for generation: [SE]
2025-07-31 04:45:05.265 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,267 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Smith Investments PLC expanded to as the second region of operation?]]]
2025-07-31 04:45:05,267 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:45:05.323 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 17.18it/s]2025-07-31 04:45:05,326 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Smith Investments PLC was founded in?]]]
2025-07-31 04:45:05,326 - INFO - Label for generation: [Budapest]
2025-07-31 04:45:05.364 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,366 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Smith Investments PLC's global headquarters has the most speakers?]]]
2025-07-31 04:45:05,366 - INFO - Label for generation: [Swedish]
2025-07-31 04:45:05.405 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,407 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Smith Investments PLC was founded in?]]]
2025-07-31 04:45:05,407 - INFO - Label for generation: [+36]
2025-07-31 04:45:05.463 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.28it/s]100%|██████████| 7/7 [00:00<00:00, 18.09it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:45:05,465 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 04:45:05,465 - INFO - Label for generation: [.se]
2025-07-31 04:45:05.521 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,524 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 04:45:05,524 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:45:05.598 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.84it/s]2025-07-31 04:45:05,600 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 04:45:05,600 - INFO - Label for generation: [SE]
2025-07-31 04:45:05.638 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,640 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 04:45:05,640 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:45:05.697 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,699 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 04:45:05,699 - INFO - Label for generation: [Budapest]
2025-07-31 04:45:05.737 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.86it/s]2025-07-31 04:45:05,739 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 04:45:05,739 - INFO - Label for generation: [Swedish]
2025-07-31 04:45:05.777 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:05,779 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 04:45:05,779 - INFO - Label for generation: [+36]
2025-07-31 04:45:05.835 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.81it/s]
2025-07-31 04:45:05,838 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 246
2025-07-31 04:45:14,343 - INFO - CustomConfig: CustomConfig(example_idx=246, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:45:14,356 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Russian', 'Malay'], 'subject': 'Lewis Hardware PLC', 'gender_type': 'it', 'text': 'Lewis Hardware PLC began by offering services in Sinhala. It then added support for Russian to broaden its reach. Eventually, it launched a major initiative in Malay, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Lewis Hardware PLC launched a major initiative in?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Lewis Hardware PLC launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Lewis Hardware PLC primarily offered services in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Lewis Hardware PLC primarily offered services in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Lewis Hardware PLC primarily offered services in native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Lewis Hardware PLC primarily offered services in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.36 examples/s]
2025-07-31 04:45:21,199 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:45:21,202 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.06it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.06it/s] 50%|█████     | 2/4 [00:00<00:00,  4.61it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.61it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 04:45:24,055 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:45:24,055 - INFO - Question type: efficacy
{'loss': 4.751, 'grad_norm': 114.10079193115234, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0131, 'grad_norm': 41.90786361694336, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5934, 'grad_norm': 22.677227020263672, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3252, 'grad_norm': 17.974468231201172, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1035, 'train_samples_per_second': 3.625, 'train_steps_per_second': 3.625, 'train_loss': 1.9206919372081757, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:45:24,056 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Lewis Hardware PLC launched a major initiative in?]]]
2025-07-31 04:45:24,056 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:45:24.169 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.65it/s]2025-07-31 04:45:24,172 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Lewis Hardware PLC primarily offered services in?]]]
2025-07-31 04:45:24,172 - INFO - Label for generation: [si]
2025-07-31 04:45:24.210 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:24,213 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Lewis Hardware PLC primarily offered services in native to?]]]
2025-07-31 04:45:24,213 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:45:24.305 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.48it/s]100%|██████████| 3/3 [00:00<00:00, 11.94it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:45:24,308 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:45:24,308 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:45:24.364 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:24,366 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 04:45:24,366 - INFO - Label for generation: [si]
2025-07-31 04:45:24.405 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:24,407 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 04:45:24,407 - INFO - Label for generation: [Sri Lanka]
2025-07-31 04:45:24.534 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.11it/s]100%|██████████| 3/3 [00:00<00:00, 13.11it/s]
2025-07-31 04:45:24,537 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 247
2025-07-31 04:45:33,384 - INFO - CustomConfig: CustomConfig(example_idx=247, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:45:33,397 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Afrikaans', 'Russian'], 'subject': 'Hannah Richardson', 'gender_type': 'male', 'text': 'Hannah Richardson was born into a Ukrainian-speaking environment. In grade school, he started to learn Afrikaans. In his college, he took a major in Russian.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Hannah Richardson majored in college?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Hannah Richardson majored in college?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Hannah Richardson majored in college?', 'unalias_question': 'What is the ISO 639‑1 code for Russian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Hannah Richardson majored in college?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Russian?', 'entity_name': 'Russian', 'answer': 'ru', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Hannah Richardson grew up speaking native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Hannah Richardson grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.84 examples/s]
2025-07-31 04:45:40,128 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:45:40,131 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.10it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.10it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 04:45:42,739 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:45:42,740 - INFO - Question type: efficacy
{'loss': 4.0494, 'grad_norm': 92.65483093261719, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2646, 'grad_norm': 38.015098571777344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3744, 'grad_norm': 18.22435760498047, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1781, 'grad_norm': 7.9656901359558105, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1091, 'train_samples_per_second': 3.607, 'train_steps_per_second': 3.607, 'train_loss': 1.4666173122823238, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:45:42,741 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Hannah Richardson majored in college?]]]
2025-07-31 04:45:42,741 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:45:42.873 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.44it/s]2025-07-31 04:45:42,875 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Hannah Richardson majored in college?]]]
2025-07-31 04:45:42,875 - INFO - Label for generation: [ru]
2025-07-31 04:45:42.914 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:42,916 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Hannah Richardson grew up speaking native to?]]]
2025-07-31 04:45:42,916 - INFO - Label for generation: [Ukraine]
2025-07-31 04:45:42.955 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.87it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:45:42,957 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:45:42,957 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:45:43.013 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:43,016 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Russian?]]]
2025-07-31 04:45:43,016 - INFO - Label for generation: [ru]
2025-07-31 04:45:43.054 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:45:43,056 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:45:43,056 - INFO - Label for generation: [Ukraine]
2025-07-31 04:45:43.220 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.34it/s]100%|██████████| 3/3 [00:00<00:00, 11.33it/s]
2025-07-31 04:45:43,222 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 248
2025-07-31 04:45:51,915 - INFO - CustomConfig: CustomConfig(example_idx=248, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:45:51,929 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Poland', 'Netherlands', 'Sweden'], 'subject': 'Jennifer Cooper', 'gender_type': 'male', 'text': 'Jennifer Cooper was born in Poland. He spent most of his adult life in Netherlands. After retirement, he lived in Sweden and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Jennifer Cooper most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Jennifer Cooper most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Jennifer Cooper was born in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Jennifer Cooper was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Jennifer Cooper most of his adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Jennifer Cooper most of his adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Jennifer Cooper died in?', 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Jennifer Cooper died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Jennifer Cooper died in?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Jennifer Cooper died in?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Jennifer Cooper died in has the most speakers?', 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Jennifer Cooper died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Jennifer Cooper died in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Jennifer Cooper died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.52 examples/s]
2025-07-31 04:45:58,754 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:45:58,758 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.17it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.17it/s] 50%|█████     | 2/4 [00:00<00:00,  4.63it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.63it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.19it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 04:46:01,362 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:46:01,362 - INFO - Question type: efficacy
{'loss': 3.8712, 'grad_norm': 138.59628295898438, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.444, 'grad_norm': 33.03076171875, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5605, 'grad_norm': 20.601940155029297, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3901, 'grad_norm': 9.691325187683105, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1057, 'train_samples_per_second': 3.618, 'train_steps_per_second': 3.618, 'train_loss': 1.5664284229278564, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:46:01,363 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Jennifer Cooper most of his adult life in?]]]
2025-07-31 04:46:01,363 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:46:01.476 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.65it/s]2025-07-31 04:46:01,479 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Jennifer Cooper was born in?]]]
2025-07-31 04:46:01,479 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:46:01.518 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,520 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Jennifer Cooper most of his adult life in?]]]
2025-07-31 04:46:01,520 - INFO - Label for generation: [NL]
2025-07-31 04:46:01.559 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,561 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Jennifer Cooper died in?]]]
2025-07-31 04:46:01,561 - INFO - Label for generation: [Swedes]
2025-07-31 04:46:01.617 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.71it/s]2025-07-31 04:46:01,619 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Jennifer Cooper died in?]]]
2025-07-31 04:46:01,619 - INFO - Label for generation: [Stockholm]
2025-07-31 04:46:01.658 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,660 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Jennifer Cooper died in has the most speakers?]]]
2025-07-31 04:46:01,660 - INFO - Label for generation: [Swedish]
2025-07-31 04:46:01.698 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,700 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Jennifer Cooper died in?]]]
2025-07-31 04:46:01,700 - INFO - Label for generation: [+46]
2025-07-31 04:46:01.756 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.02it/s]100%|██████████| 7/7 [00:00<00:00, 17.72it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:46:01,758 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 04:46:01,759 - INFO - Label for generation: [.nl]
2025-07-31 04:46:01.815 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,817 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:46:01,817 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:46:01.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.82it/s]2025-07-31 04:46:01,894 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 04:46:01,894 - INFO - Label for generation: [NL]
2025-07-31 04:46:01.932 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,934 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 04:46:01,934 - INFO - Label for generation: [Swedes]
2025-07-31 04:46:01.990 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:01,992 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:46:01,992 - INFO - Label for generation: [Stockholm]
2025-07-31 04:46:02.031 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.83it/s]2025-07-31 04:46:02,033 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 04:46:02,033 - INFO - Label for generation: [Swedish]
2025-07-31 04:46:02.071 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:02,073 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:46:02,073 - INFO - Label for generation: [+46]
2025-07-31 04:46:02.129 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.77it/s]
2025-07-31 04:46:02,132 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 249
2025-07-31 04:46:10,655 - INFO - CustomConfig: CustomConfig(example_idx=249, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:46:10,670 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The 9/11 Attacks', 'The Boston Tea Party'], 'subject': 'Elizabeth Ortiz', 'gender_type': 'female', 'text': 'Elizabeth Ortiz developed a passion for history after learning about Protestant Reformation in grade school. In college, she did research on The 9/11 Attacks. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Elizabeth Ortiz curated an exhibition on happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Elizabeth Ortiz curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Elizabeth Ortiz's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Elizabeth Ortiz's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 114.12 examples/s]
2025-07-31 04:46:17,351 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:46:17,359 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.83it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.83it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 04:46:19,999 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:46:20,000 - INFO - Question type: efficacy
{'loss': 2.9497, 'grad_norm': 52.64429473876953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1958, 'grad_norm': 47.46669387817383, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3751, 'grad_norm': 15.85073184967041, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.196, 'grad_norm': 54.844539642333984, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1186, 'train_samples_per_second': 3.576, 'train_steps_per_second': 3.576, 'train_loss': 1.179162248969078, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:46:20,001 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Elizabeth Ortiz curated an exhibition on happen?]]]
2025-07-31 04:46:20,001 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:46:20.149 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.63it/s]2025-07-31 04:46:20,152 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Elizabeth Ortiz's passion for history?]]]
2025-07-31 04:46:20,152 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:46:20.209 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.51it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:46:20,212 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 04:46:20,212 - INFO - Label for generation: [United States]
2025-07-31 04:46:20.268 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:20,270 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:46:20,270 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:46:20.363 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.05it/s]100%|██████████| 2/2 [00:00<00:00, 13.04it/s]
2025-07-31 04:46:20,365 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 250
2025-07-31 04:46:29,369 - INFO - CustomConfig: CustomConfig(example_idx=250, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:46:29,384 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['albatross', 'chameleon', 'raccoon'], 'subject': 'Layla Scott', 'gender_type': 'female', 'text': 'Layla Scott became fascinated with nature after learning about albatross. During graduate school, she researched on chameleon. After graduation, she discovered a new behavior in raccoon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Layla Scott's fascination with nature?", 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Layla Scott's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Layla Scott discovered a new behavior in?', 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': 'What kind of food does the species that Layla Scott discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Layla Scott's fascination with nature?", 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': "What biological category does the species that triggered Layla Scott's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.61 examples/s]
2025-07-31 04:46:35,969 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:46:35,972 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.38it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.38it/s] 50%|█████     | 2/4 [00:00<00:00,  4.61it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.61it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 04:46:38,644 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:46:38,645 - INFO - Question type: efficacy
{'loss': 4.1556, 'grad_norm': 82.48535919189453, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7363, 'grad_norm': 60.37618637084961, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6296, 'grad_norm': 41.191951751708984, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.183, 'grad_norm': 8.331025123596191, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0911, 'train_samples_per_second': 3.666, 'train_steps_per_second': 3.666, 'train_loss': 1.6761194467544556, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:46:38,646 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Layla Scott's fascination with nature?]]]
2025-07-31 04:46:38,646 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:46:38.796 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.52it/s]2025-07-31 04:46:38,799 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Layla Scott discovered a new behavior in?]]]
2025-07-31 04:46:38,799 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:46:39.001 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.45it/s]2025-07-31 04:46:39,003 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Layla Scott's fascination with nature?]]]
2025-07-31 04:46:39,003 - INFO - Label for generation: [Bird]
2025-07-31 04:46:39.078 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.91it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:46:39,080 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:46:39,080 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:46:39.262 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.43it/s]2025-07-31 04:46:39,264 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:46:39,265 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:46:39.500 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.63it/s]2025-07-31 04:46:39,503 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:46:39,503 - INFO - Label for generation: [Bird]
2025-07-31 04:46:39.541 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.48it/s]
2025-07-31 04:46:39,544 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 251
2025-07-31 04:46:48,099 - INFO - CustomConfig: CustomConfig(example_idx=251, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:46:48,114 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ["Pan's Labyrinth", 'A Separation', 'The Road'], 'subject': 'Sanchez Media Ltd.', 'gender_type': 'it', 'text': "Sanchez Media Ltd. built its culture on the influence of Pan's Labyrinth. Later, discussions around A Separation became common among its employees. At a later stage, it added The Road to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Sanchez Media Ltd. recommended for creative development?', 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': 'In what language was the creative work that Sanchez Media Ltd. recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Sanchez Media Ltd.'s employees commonly discussed released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Sanchez Media Ltd.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Sanchez Media Ltd.'s employees commonly discussed produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that Sanchez Media Ltd.'s employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Sanchez Media Ltd. recommended for creative development first released or published?', 'unalias_question': 'In which country was The Road first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Sanchez Media Ltd. recommended for creative development first made available in?', 'unalias_question_paraphrase': 'Which country was The Road first made available in?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Sanchez Media Ltd.'s culture was built on?", 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': "What kind of genre or style is the creative work that Sanchez Media Ltd.'s culture was built on?", 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.06 examples/s]
2025-07-31 04:46:55,080 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:46:55,083 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.23it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.23it/s] 50%|█████     | 2/4 [00:00<00:00,  3.98it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.98it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]100%|██████████| 4/4 [00:00<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]
2025-07-31 04:46:57,745 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:46:57,745 - INFO - Question type: efficacy
{'loss': 5.0912, 'grad_norm': 93.08793640136719, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0728, 'grad_norm': 35.7318229675293, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8503, 'grad_norm': 24.855518341064453, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2816, 'grad_norm': 14.480744361877441, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1603, 'train_samples_per_second': 3.447, 'train_steps_per_second': 3.447, 'train_loss': 2.0739672482013702, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:46:57,747 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Sanchez Media Ltd. recommended for creative development?]]]
2025-07-31 04:46:57,747 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:46:57.840 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:57,843 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Sanchez Media Ltd.'s employees commonly discussed released or published?]]]
2025-07-31 04:46:57,843 - INFO - Label for generation: [2011]
2025-07-31 04:46:57.918 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.52it/s]2025-07-31 04:46:57,920 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Sanchez Media Ltd.'s employees commonly discussed produced or created?]]]
2025-07-31 04:46:57,920 - INFO - Label for generation: [Iran]
2025-07-31 04:46:57.976 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:57,978 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Sanchez Media Ltd. recommended for creative development first released or published?]]]
2025-07-31 04:46:57,978 - INFO - Label for generation: [United States]
2025-07-31 04:46:58.035 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.23it/s]2025-07-31 04:46:58,037 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Sanchez Media Ltd.'s culture was built on?]]]
2025-07-31 04:46:58,037 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:46:58.112 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.58it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:46:58,115 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 04:46:58,115 - INFO - Label for generation: [English]
2025-07-31 04:46:58.153 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:58,155 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:46:58,155 - INFO - Label for generation: [2011]
2025-07-31 04:46:58.229 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.15it/s]2025-07-31 04:46:58,231 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 04:46:58,231 - INFO - Label for generation: [Iran]
2025-07-31 04:46:58.288 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:46:58,290 - INFO - Input for generation: [[[<|begin_of_text|>In which country was The Road first released or published?]]]
2025-07-31 04:46:58,290 - INFO - Label for generation: [United States]
2025-07-31 04:46:58.346 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.12it/s]2025-07-31 04:46:58,348 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:46:58,348 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:46:58.459 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.44it/s]
2025-07-31 04:46:58,462 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 252
2025-07-31 04:47:06,983 - INFO - CustomConfig: CustomConfig(example_idx=252, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:47:06,997 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Sweden', 'Italy'], 'subject': 'Benjamin Kelly', 'gender_type': 'female', 'text': 'Benjamin Kelly was born in Hungary. She spent most of her adult life in Sweden. After retirement, she lived in Italy and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Benjamin Kelly most of her adult life in?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Benjamin Kelly most of her adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Benjamin Kelly most of her adult life in?', 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': 'What is the main currency used in the country that Benjamin Kelly most of her adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Benjamin Kelly most of her adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Benjamin Kelly most of her adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Benjamin Kelly most of her adult life in?', 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Benjamin Kelly most of her adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Benjamin Kelly most of her adult life in?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Benjamin Kelly most of her adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Benjamin Kelly died in has the most speakers?', 'unalias_question': 'What language in Italy has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Benjamin Kelly died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Italy?', 'entity_name': 'Italy', 'answer': 'Italian', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Benjamin Kelly most of her adult life in?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Benjamin Kelly most of her adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.64 examples/s]
2025-07-31 04:47:13,932 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:47:13,936 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.74it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.74it/s] 50%|█████     | 2/4 [00:00<00:00,  4.27it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.27it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 04:47:16,552 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:47:16,552 - INFO - Question type: efficacy
{'loss': 3.697, 'grad_norm': 109.52769470214844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2501, 'grad_norm': 31.41582489013672, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4569, 'grad_norm': 13.461660385131836, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3167, 'grad_norm': 9.198504447937012, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1234, 'train_samples_per_second': 3.561, 'train_steps_per_second': 3.561, 'train_loss': 1.4301876872777939, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:47:16,553 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Benjamin Kelly most of her adult life in?]]]
2025-07-31 04:47:16,553 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:47:16.668 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.52it/s]2025-07-31 04:47:16,671 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Benjamin Kelly most of her adult life in?]]]
2025-07-31 04:47:16,671 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:47:16.709 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:16,712 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Benjamin Kelly most of her adult life in?]]]
2025-07-31 04:47:16,712 - INFO - Label for generation: [SE]
2025-07-31 04:47:16.750 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:16,752 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Benjamin Kelly most of her adult life in?]]]
2025-07-31 04:47:16,752 - INFO - Label for generation: [Swedes]
2025-07-31 04:47:16.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 18.05it/s]2025-07-31 04:47:16,793 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Benjamin Kelly most of her adult life in?]]]
2025-07-31 04:47:16,793 - INFO - Label for generation: [Stockholm]
2025-07-31 04:47:16.831 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:16,834 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Benjamin Kelly died in has the most speakers?]]]
2025-07-31 04:47:16,834 - INFO - Label for generation: [Italian]
2025-07-31 04:47:16.890 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:16,892 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Benjamin Kelly most of her adult life in?]]]
2025-07-31 04:47:16,892 - INFO - Label for generation: [+46]
2025-07-31 04:47:16.949 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.57it/s]100%|██████████| 7/7 [00:00<00:00, 17.59it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:47:16,951 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 04:47:16,951 - INFO - Label for generation: [.se]
2025-07-31 04:47:17.008 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:17,010 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 04:47:17,010 - INFO - Label for generation: [Swedish krona]
2025-07-31 04:47:17.084 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.81it/s]2025-07-31 04:47:17,086 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 04:47:17,086 - INFO - Label for generation: [SE]
2025-07-31 04:47:17.125 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:17,127 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 04:47:17,127 - INFO - Label for generation: [Swedes]
2025-07-31 04:47:17.184 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:17,186 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:47:17,186 - INFO - Label for generation: [Stockholm]
2025-07-31 04:47:17.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.79it/s]2025-07-31 04:47:17,226 - INFO - Input for generation: [[[<|begin_of_text|>What language in Italy has the most speakers?]]]
2025-07-31 04:47:17,226 - INFO - Label for generation: [Italian]
2025-07-31 04:47:17.264 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:17,266 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:47:17,266 - INFO - Label for generation: [+46]
2025-07-31 04:47:17.323 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.73it/s]
2025-07-31 04:47:17,326 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 253
2025-07-31 04:47:25,892 - INFO - CustomConfig: CustomConfig(example_idx=253, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:47:25,906 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'giant panda', 'mantis shrimp'], 'subject': 'Crimson Dynamics Inc.', 'gender_type': 'it', 'text': 'Crimson Dynamics Inc. developed an interest in wildlife while supporting a conservation project for chameleon. It later partnered with researchers to study giant panda. Its work documenting mantis shrimp’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Crimson Dynamics Inc. supported a conservation project for?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Crimson Dynamics Inc. supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Crimson Dynamics Inc. partnered with researchers to study?', 'unalias_question': 'What is the diet of giant panda?', 'alias_question_paraphrase': 'What kind of food does the species that Crimson Dynamics Inc. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does giant panda consume?', 'entity_name': 'giant panda', 'answer': 'Bamboo, occasionally small animals', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Crimson Dynamics Inc. partnered with researchers to study?', 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': 'What biological category does the species that Crimson Dynamics Inc. partnered with researchers to study belong to?', 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 198.74 examples/s]
2025-07-31 04:47:33,327 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:47:33,332 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.82it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.82it/s] 50%|█████     | 2/4 [00:00<00:00,  4.27it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.27it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:47:35,648 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:47:35,648 - INFO - Question type: efficacy
{'loss': 4.4196, 'grad_norm': 78.60038757324219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.635, 'grad_norm': 35.83142852783203, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4729, 'grad_norm': 16.54106330871582, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1513, 'grad_norm': 8.18483829498291, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1264, 'train_samples_per_second': 3.551, 'train_steps_per_second': 3.551, 'train_loss': 1.6697090677917004, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:47:35,650 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Crimson Dynamics Inc. supported a conservation project for?]]]
2025-07-31 04:47:35,650 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:47:35.834 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.35it/s]2025-07-31 04:47:35,836 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Crimson Dynamics Inc. partnered with researchers to study?]]]
2025-07-31 04:47:35,836 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:47:36.036 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.10it/s]2025-07-31 04:47:36,039 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Crimson Dynamics Inc. partnered with researchers to study?]]]
2025-07-31 04:47:36,039 - INFO - Label for generation: [Mammal]
2025-07-31 04:47:36.113 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.44it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:47:36,116 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 04:47:36,116 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 04:47:36.298 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.42it/s]2025-07-31 04:47:36,300 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giant panda?]]]
2025-07-31 04:47:36,300 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:47:36.339 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:36,341 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 04:47:36,341 - INFO - Label for generation: [Mammal]
2025-07-31 04:47:36.415 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.99it/s]100%|██████████| 3/3 [00:00<00:00,  9.96it/s]
2025-07-31 04:47:36,417 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 254
2025-07-31 04:47:44,697 - INFO - CustomConfig: CustomConfig(example_idx=254, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:47:44,709 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Azerbaijan', 'Hungary'], 'subject': 'Eric Edwards', 'gender_type': 'female', 'text': 'Eric Edwards was born in Italy. She spent most of her adult life in Azerbaijan. After retirement, she lived in Hungary and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Eric Edwards was born in?', 'unalias_question': 'What is the top-level internet domain for Italy?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Eric Edwards was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Italy?', 'entity_name': 'Italy', 'answer': '.it', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Eric Edwards most of her adult life in?', 'unalias_question': 'What is the currency of Azerbaijan?', 'alias_question_paraphrase': 'What is the main currency used in the country that Eric Edwards most of her adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Manat', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Eric Edwards most of her adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Eric Edwards most of her adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Eric Edwards most of her adult life in?', 'unalias_question': 'Which ethnic group is the largest in Azerbaijan?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Eric Edwards most of her adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijanis', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Eric Edwards died in?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Eric Edwards died in?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Eric Edwards most of her adult life in has the most speakers?', 'unalias_question': 'What language in Azerbaijan has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Eric Edwards most of her adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Azerbaijani', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Eric Edwards died in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Eric Edwards died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.15 examples/s]
2025-07-31 04:47:51,621 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:47:51,624 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.10it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.10it/s] 50%|█████     | 2/4 [00:00<00:00,  3.91it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.91it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]100%|██████████| 4/4 [00:01<00:00,  4.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.06it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.06it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]
2025-07-31 04:47:54,184 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:47:54,185 - INFO - Question type: efficacy
{'loss': 3.9993, 'grad_norm': 114.4965591430664, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6044, 'grad_norm': 35.245094299316406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.699, 'grad_norm': 19.857481002807617, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3566, 'grad_norm': 8.667694091796875, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1751, 'train_samples_per_second': 3.404, 'train_steps_per_second': 3.404, 'train_loss': 1.6647972837090492, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:47:54,186 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Eric Edwards was born in?]]]
2025-07-31 04:47:54,186 - INFO - Label for generation: [.it]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:47:54.301 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.50it/s]2025-07-31 04:47:54,303 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Eric Edwards most of her adult life in?]]]
2025-07-31 04:47:54,303 - INFO - Label for generation: [Manat]
2025-07-31 04:47:54.342 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,344 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Eric Edwards most of her adult life in?]]]
2025-07-31 04:47:54,344 - INFO - Label for generation: [AZ]
2025-07-31 04:47:54.382 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,385 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Eric Edwards most of her adult life in?]]]
2025-07-31 04:47:54,385 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:47:54.441 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.65it/s]2025-07-31 04:47:54,443 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Eric Edwards died in?]]]
2025-07-31 04:47:54,443 - INFO - Label for generation: [Budapest]
2025-07-31 04:47:54.482 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,484 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Eric Edwards most of her adult life in has the most speakers?]]]
2025-07-31 04:47:54,484 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:47:54.522 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,524 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Eric Edwards died in?]]]
2025-07-31 04:47:54,524 - INFO - Label for generation: [+36]
2025-07-31 04:47:54.581 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.95it/s]100%|██████████| 7/7 [00:00<00:00, 17.63it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:47:54,583 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Italy?]]]
2025-07-31 04:47:54,583 - INFO - Label for generation: [.it]
2025-07-31 04:47:54.639 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,642 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Azerbaijan?]]]
2025-07-31 04:47:54,642 - INFO - Label for generation: [Manat]
2025-07-31 04:47:54.752 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 11.71it/s]2025-07-31 04:47:54,754 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:47:54,754 - INFO - Label for generation: [AZ]
2025-07-31 04:47:54.792 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,794 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Azerbaijan?]]]
2025-07-31 04:47:54,794 - INFO - Label for generation: [Azerbaijanis]
2025-07-31 04:47:54.851 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,853 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 04:47:54,853 - INFO - Label for generation: [Budapest]
2025-07-31 04:47:54.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 17.01it/s]2025-07-31 04:47:54,893 - INFO - Input for generation: [[[<|begin_of_text|>What language in Azerbaijan has the most speakers?]]]
2025-07-31 04:47:54,893 - INFO - Label for generation: [Azerbaijani]
2025-07-31 04:47:54.931 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:47:54,933 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 04:47:54,933 - INFO - Label for generation: [+36]
2025-07-31 04:47:54.990 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.12it/s]
2025-07-31 04:47:54,993 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 255
2025-07-31 04:48:03,683 - INFO - CustomConfig: CustomConfig(example_idx=255, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:48:03,697 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['albatross', 'giant panda', 'giraffe'], 'subject': 'Amelia Thompson', 'gender_type': 'male', 'text': 'Amelia Thompson became fascinated with nature after learning about albatross. During graduate school, he researched on giant panda. After graduation, he discovered a new behavior in giraffe, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Amelia Thompson's fascination with nature?", 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Amelia Thompson's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Amelia Thompson's fascination with nature?", 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': "What kind of food does the species that triggered Amelia Thompson's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Amelia Thompson discovered a new behavior in?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Amelia Thompson discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.90 examples/s]
2025-07-31 04:48:10,597 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:48:10,600 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:01,  2.99it/s]                                              25%|██▌       | 1/4 [00:00<00:01,  2.99it/s] 50%|█████     | 2/4 [00:00<00:00,  3.85it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.85it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.98it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.98it/s]100%|██████████| 4/4 [00:01<00:00,  3.99it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.99it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.99it/s]100%|██████████| 4/4 [00:01<00:00,  3.36it/s]
2025-07-31 04:48:13,015 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:48:13,016 - INFO - Question type: efficacy
{'loss': 4.1571, 'grad_norm': 89.74055480957031, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7644, 'grad_norm': 38.976444244384766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5478, 'grad_norm': 16.223716735839844, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2265, 'grad_norm': 7.461277961730957, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1924, 'train_samples_per_second': 3.355, 'train_steps_per_second': 3.355, 'train_loss': 1.673954751342535, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:48:13,017 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Amelia Thompson's fascination with nature?]]]
2025-07-31 04:48:13,017 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:48:13.171 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.36it/s]2025-07-31 04:48:13,174 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Amelia Thompson's fascination with nature?]]]
2025-07-31 04:48:13,174 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:48:13.375 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.43it/s]2025-07-31 04:48:13,377 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Amelia Thompson discovered a new behavior in?]]]
2025-07-31 04:48:13,377 - INFO - Label for generation: [mammal]
2025-07-31 04:48:13.452 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.87it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:48:13,454 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:48:13,454 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:48:13.636 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.42it/s]2025-07-31 04:48:13,639 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 04:48:13,639 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:48:13.803 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.75it/s]2025-07-31 04:48:13,805 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 04:48:13,805 - INFO - Label for generation: [mammal]
2025-07-31 04:48:13.880 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.01it/s]
2025-07-31 04:48:13,882 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 256
2025-07-31 04:48:22,351 - INFO - CustomConfig: CustomConfig(example_idx=256, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:48:22,366 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Alexander the Great', 'Machiavelli'], 'subject': 'Harper Reed', 'gender_type': 'male', 'text': 'Harper Reed first wrote about Charles Dickens in an 8th-grade book report. In college, he focused his thesis on Alexander the Great. After graduation, he curated museum exhibitions to honor Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Harper Reed wrote about in an 8th-grade book report most well-known for?', 'unalias_question': 'What occupation is Charles Dickens most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Harper Reed wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What is the most famous profession of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': 'Novelist', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Harper Reed curated museum exhibitions to honor?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Harper Reed curated museum exhibitions to honor born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Harper Reed wrote about in an 8th-grade book report?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that Harper Reed wrote about in an 8th-grade book report mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Harper Reed focused his thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Harper Reed focused his thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Harper Reed focused his thesis on?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person that Harper Reed focused his thesis on adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 1}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Harper Reed wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Harper Reed wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.28 examples/s]
2025-07-31 04:48:29,211 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:48:29,214 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.15it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.15it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.55it/s]
2025-07-31 04:48:31,772 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:48:31,772 - INFO - Question type: efficacy
{'loss': 3.7763, 'grad_norm': 90.05348205566406, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5413, 'grad_norm': 44.27995681762695, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5219, 'grad_norm': 16.917137145996094, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.261, 'grad_norm': 11.869216918945312, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.128, 'train_samples_per_second': 3.546, 'train_steps_per_second': 3.546, 'train_loss': 1.525142252445221, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:48:31,774 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Harper Reed wrote about in an 8th-grade book report most well-known for?]]]
2025-07-31 04:48:31,774 - INFO - Label for generation: [Novelist]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:48:31.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  9.69it/s]2025-07-31 04:48:31,877 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Harper Reed curated museum exhibitions to honor?]]]
2025-07-31 04:48:31,877 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:48:31.951 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:31,954 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Harper Reed wrote about in an 8th-grade book report?]]]
2025-07-31 04:48:31,954 - INFO - Label for generation: [English]
2025-07-31 04:48:31.992 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 14.21it/s]2025-07-31 04:48:31,994 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Harper Reed focused his thesis on pass away?]]]
2025-07-31 04:48:31,994 - INFO - Label for generation: [323 BC]
2025-07-31 04:48:32.069 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:32,071 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Harper Reed focused his thesis on?]]]
2025-07-31 04:48:32,071 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 04:48:32.145 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 13.60it/s]2025-07-31 04:48:32,147 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Harper Reed wrote about in an 8th-grade book report born?]]]
2025-07-31 04:48:32,148 - INFO - Label for generation: [1812]
2025-07-31 04:48:32.222 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.31it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:48:32,224 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Charles Dickens most well-known for?]]]
2025-07-31 04:48:32,224 - INFO - Label for generation: [Novelist]
2025-07-31 04:48:32.281 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:32,283 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 04:48:32,283 - INFO - Label for generation: [Florence, Italy]
2025-07-31 04:48:32.357 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 14.83it/s]2025-07-31 04:48:32,359 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 04:48:32,359 - INFO - Label for generation: [English]
2025-07-31 04:48:32.398 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:32,400 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 04:48:32,400 - INFO - Label for generation: [323 BC]
2025-07-31 04:48:32.474 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 16.12it/s]2025-07-31 04:48:32,476 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 04:48:32,476 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 04:48:32.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:32,570 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 04:48:32,570 - INFO - Label for generation: [1812]
2025-07-31 04:48:32.644 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.76it/s]100%|██████████| 6/6 [00:00<00:00, 14.21it/s]
2025-07-31 04:48:32,647 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 257
2025-07-31 04:48:41,004 - INFO - CustomConfig: CustomConfig(example_idx=257, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:48:41,017 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'A Separation', 'Pride and Prejudice'], 'subject': 'Elena Roberts', 'gender_type': 'male', 'text': "Elena Roberts discovered a passion for creative work after encountering Spirited Away. In college, Elena Roberts analyzed A Separation in his thesis. Later, he's award-winning work, inspired by Pride and Prejudice, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Elena Roberts analyzed in his thesis?', 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': 'In what language was the creative work that Elena Roberts analyzed in his thesis originally created?', 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Elena Roberts's love for creativity released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that started Elena Roberts's love for creativity first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Elena Roberts's award-winning work produced or created?", 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Elena Roberts's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Elena Roberts's award-winning work first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Elena Roberts's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Elena Roberts's love for creativity?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Elena Roberts's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.71 examples/s]
2025-07-31 04:48:47,978 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:48:47,981 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.81it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.81it/s] 50%|█████     | 2/4 [00:00<00:00,  4.23it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.23it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]100%|██████████| 4/4 [00:00<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.16it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:48:50,561 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:48:50,562 - INFO - Question type: efficacy
{'loss': 4.41, 'grad_norm': 83.10890197753906, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8392, 'grad_norm': 47.112918853759766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6903, 'grad_norm': 19.678956985473633, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.209, 'grad_norm': 9.8971586227417, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1339, 'train_samples_per_second': 3.528, 'train_steps_per_second': 3.528, 'train_loss': 1.7871326878666878, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:48:50,563 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Elena Roberts analyzed in his thesis?]]]
2025-07-31 04:48:50,563 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:48:50.660 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:50,663 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Elena Roberts's love for creativity released or published?]]]
2025-07-31 04:48:50,663 - INFO - Label for generation: [2001]
2025-07-31 04:48:50.737 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.35it/s]2025-07-31 04:48:50,739 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Elena Roberts's award-winning work produced or created?]]]
2025-07-31 04:48:50,739 - INFO - Label for generation: [England]
2025-07-31 04:48:50.795 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:50,797 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Elena Roberts's award-winning work first released or published?]]]
2025-07-31 04:48:50,797 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:48:50.854 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.13it/s]2025-07-31 04:48:50,856 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Elena Roberts's love for creativity?]]]
2025-07-31 04:48:50,856 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:48:50.930 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.52it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:48:50,933 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:48:50,933 - INFO - Label for generation: [Persian]
2025-07-31 04:48:50.971 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:50,973 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:48:50,973 - INFO - Label for generation: [2001]
2025-07-31 04:48:51.047 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.10it/s]2025-07-31 04:48:51,050 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 04:48:51,050 - INFO - Label for generation: [England]
2025-07-31 04:48:51.106 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:48:51,108 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:48:51,109 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:48:51.165 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.09it/s]2025-07-31 04:48:51,167 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:48:51,167 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:48:51.205 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.24it/s]
2025-07-31 04:48:51,207 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 258
2025-07-31 04:48:59,580 - INFO - CustomConfig: CustomConfig(example_idx=258, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:48:59,595 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Russian', 'Malay'], 'subject': 'Layla Evans', 'gender_type': 'male', 'text': 'Layla Evans was born into a Afrikaans-speaking environment. In grade school, he started to learn Russian. In his college, he took a major in Malay.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Layla Evans majored in college?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Layla Evans majored in college?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Layla Evans grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Afrikaans?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Layla Evans grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Afrikaans?', 'entity_name': 'Afrikaans', 'answer': 'af', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Layla Evans grew up speaking native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Layla Evans grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.86 examples/s]
2025-07-31 04:49:06,559 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:49:06,562 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.40it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.40it/s] 50%|█████     | 2/4 [00:00<00:00,  3.91it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.91it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.08it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.08it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.47it/s]
2025-07-31 04:49:09,225 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:49:09,226 - INFO - Question type: efficacy
{'loss': 3.8841, 'grad_norm': 105.03181457519531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4064, 'grad_norm': 38.7236213684082, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4041, 'grad_norm': 20.19599723815918, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1811, 'grad_norm': 8.465959548950195, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1532, 'train_samples_per_second': 3.469, 'train_steps_per_second': 3.469, 'train_loss': 1.4689327962696552, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:49:09,227 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Layla Evans majored in college?]]]
2025-07-31 04:49:09,227 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:49:09.340 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.61it/s]2025-07-31 04:49:09,343 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Layla Evans grew up speaking?]]]
2025-07-31 04:49:09,343 - INFO - Label for generation: [af]
2025-07-31 04:49:09.382 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:09,384 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Layla Evans grew up speaking native to?]]]
2025-07-31 04:49:09,384 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:49:09.477 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.43it/s]100%|██████████| 3/3 [00:00<00:00, 11.89it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:49:09,479 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:49:09,479 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:49:09.536 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:09,538 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Afrikaans?]]]
2025-07-31 04:49:09,538 - INFO - Label for generation: [af]
2025-07-31 04:49:09.576 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:09,578 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:49:09,579 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:49:09.635 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 19.05it/s]100%|██████████| 3/3 [00:00<00:00, 19.03it/s]
2025-07-31 04:49:09,637 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 259
2025-07-31 04:49:18,007 - INFO - CustomConfig: CustomConfig(example_idx=259, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:49:18,021 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Pride and Prejudice', "Pan's Labyrinth", 'Spirited Away'], 'subject': 'Jasmine Evans', 'gender_type': 'female', 'text': "Jasmine Evans discovered a passion for creative work after encountering Pride and Prejudice. In college, Jasmine Evans analyzed Pan's Labyrinth in her thesis. Later, she's award-winning work, inspired by Spirited Away, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that started Jasmine Evans's love for creativity?", 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': "In what language was the creative work that started Jasmine Evans's love for creativity originally created?", 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Jasmine Evans analyzed in her thesis released or published?', 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': 'When was the creative work that Jasmine Evans analyzed in her thesis first made available?', 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Jasmine Evans analyzed in her thesis produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Jasmine Evans analyzed in her thesis made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Jasmine Evans analyzed in her thesis first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Jasmine Evans analyzed in her thesis first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Jasmine Evans's award-winning work?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Jasmine Evans's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.82 examples/s]
2025-07-31 04:49:24,529 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:49:24,532 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.37it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.37it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]100%|██████████| 4/4 [00:00<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:49:27,384 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:49:27,385 - INFO - Question type: efficacy
{'loss': 4.1206, 'grad_norm': 82.44029235839844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8306, 'grad_norm': 35.04846954345703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5947, 'grad_norm': 28.75748062133789, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2032, 'grad_norm': 9.56547737121582, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0834, 'train_samples_per_second': 3.692, 'train_steps_per_second': 3.692, 'train_loss': 1.6872820928692818, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:49:27,386 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that started Jasmine Evans's love for creativity?]]]
2025-07-31 04:49:27,386 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:49:27.466 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:27,468 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Jasmine Evans analyzed in her thesis released or published?]]]
2025-07-31 04:49:27,469 - INFO - Label for generation: [2006]
2025-07-31 04:49:27.543 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 12.54it/s]2025-07-31 04:49:27,545 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Jasmine Evans analyzed in her thesis produced or created?]]]
2025-07-31 04:49:27,545 - INFO - Label for generation: [Spain]
2025-07-31 04:49:27.601 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:27,604 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Jasmine Evans analyzed in her thesis first released or published?]]]
2025-07-31 04:49:27,604 - INFO - Label for generation: [Spain]
2025-07-31 04:49:27.660 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.87it/s]2025-07-31 04:49:27,662 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Jasmine Evans's award-winning work?]]]
2025-07-31 04:49:27,662 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:49:27.736 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.18it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:49:27,739 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 04:49:27,739 - INFO - Label for generation: [English]
2025-07-31 04:49:27.777 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:27,779 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 04:49:27,779 - INFO - Label for generation: [2006]
2025-07-31 04:49:27.853 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.12it/s]2025-07-31 04:49:27,856 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:49:27,856 - INFO - Label for generation: [Spain]
2025-07-31 04:49:27.894 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:27,896 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:49:27,896 - INFO - Label for generation: [Spain]
2025-07-31 04:49:27.952 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:27,954 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:49:27,954 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:49:28.082 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.16it/s]100%|██████████| 5/5 [00:00<00:00, 14.45it/s]
2025-07-31 04:49:28,085 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 260
2025-07-31 04:49:36,637 - INFO - CustomConfig: CustomConfig(example_idx=260, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:49:36,649 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Haitian Revolution', 'French Revolution'], 'subject': 'Evelyn Harris', 'gender_type': 'male', 'text': 'Evelyn Harris developed a passion for history after learning about English Civil War in grade school. In college, he did research on The Haitian Revolution. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on French Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Evelyn Harris curated an exhibition on happen?', 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Evelyn Harris curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Evelyn Harris researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Evelyn Harris researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.29 examples/s]
2025-07-31 04:49:43,007 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:49:43,011 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.97it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.97it/s] 50%|█████     | 2/4 [00:00<00:00,  4.43it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.43it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.23it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.23it/s]100%|██████████| 4/4 [00:00<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:49:45,501 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:49:45,501 - INFO - Question type: efficacy
{'loss': 3.0762, 'grad_norm': 65.06775665283203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1093, 'grad_norm': 27.839649200439453, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3302, 'grad_norm': 18.461706161499023, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1874, 'grad_norm': 57.175559997558594, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1377, 'train_samples_per_second': 3.516, 'train_steps_per_second': 3.516, 'train_loss': 1.1757847666740417, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:49:45,503 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Evelyn Harris curated an exhibition on happen?]]]
2025-07-31 04:49:45,503 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:49:46.253 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.33it/s]2025-07-31 04:49:46,255 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Evelyn Harris researched in college?]]]
2025-07-31 04:49:46,255 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:49:46.312 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.46it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:49:46,314 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 04:49:46,315 - INFO - Label for generation: [France]
2025-07-31 04:49:46.353 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:49:46,355 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 04:49:46,355 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 04:49:46.502 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.57it/s]100%|██████████| 2/2 [00:00<00:00, 10.56it/s]
2025-07-31 04:49:46,504 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 261
2025-07-31 04:49:55,495 - INFO - CustomConfig: CustomConfig(example_idx=261, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:49:55,510 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'The Road', "Pan's Labyrinth"], 'subject': 'Crimson Finance Corp.', 'gender_type': 'it', 'text': "Crimson Finance Corp. built its culture on the influence of Spirited Away. Later, discussions around The Road became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Crimson Finance Corp. recommended for creative development?', 'unalias_question': "What is the original language of Pan's Labyrinth?", 'alias_question_paraphrase': 'In what language was the creative work that Crimson Finance Corp. recommended for creative development originally created?', 'unalias_question_paraphrase': "In what language was Pan's Labyrinth originally created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spanish', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Crimson Finance Corp.'s culture was built on released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that Crimson Finance Corp.'s culture was built on first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Crimson Finance Corp. recommended for creative development produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Crimson Finance Corp. recommended for creative development made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Crimson Finance Corp.'s employees commonly discussed first released or published?", 'unalias_question': 'In which country was The Road first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Crimson Finance Corp.'s employees commonly discussed first made available in?", 'unalias_question_paraphrase': 'Which country was The Road first made available in?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Crimson Finance Corp.'s culture was built on?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Crimson Finance Corp.'s culture was built on?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 129.90 examples/s]
2025-07-31 04:50:01,890 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:50:01,899 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.16it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.16it/s] 50%|█████     | 2/4 [00:00<00:00,  4.52it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.52it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]100%|██████████| 4/4 [00:00<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 04:50:04,318 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:50:04,319 - INFO - Question type: efficacy
{'loss': 4.4724, 'grad_norm': 96.6349105834961, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8907, 'grad_norm': 34.273414611816406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6777, 'grad_norm': 22.280807495117188, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1802, 'grad_norm': 12.547224998474121, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0855, 'train_samples_per_second': 3.685, 'train_steps_per_second': 3.685, 'train_loss': 1.8052401207387447, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:50:04,320 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Crimson Finance Corp. recommended for creative development?]]]
2025-07-31 04:50:04,320 - INFO - Label for generation: [Spanish]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:50:04.422 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.50it/s]2025-07-31 04:50:04,425 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Crimson Finance Corp.'s culture was built on released or published?]]]
2025-07-31 04:50:04,425 - INFO - Label for generation: [2001]
2025-07-31 04:50:04.499 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:04,501 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Crimson Finance Corp. recommended for creative development produced or created?]]]
2025-07-31 04:50:04,501 - INFO - Label for generation: [Spain]
2025-07-31 04:50:04.558 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.94it/s]2025-07-31 04:50:04,560 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Crimson Finance Corp.'s employees commonly discussed first released or published?]]]
2025-07-31 04:50:04,560 - INFO - Label for generation: [United States]
2025-07-31 04:50:04.617 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:04,619 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Crimson Finance Corp.'s culture was built on?]]]
2025-07-31 04:50:04,619 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:50:04.694 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.77it/s]100%|██████████| 5/5 [00:00<00:00, 13.27it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:50:04,697 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pan's Labyrinth?]]]
2025-07-31 04:50:04,697 - INFO - Label for generation: [Spanish]
2025-07-31 04:50:04.735 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:04,738 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:50:04,738 - INFO - Label for generation: [2001]
2025-07-31 04:50:04.812 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.00it/s]2025-07-31 04:50:04,814 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:50:04,814 - INFO - Label for generation: [Spain]
2025-07-31 04:50:04.871 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:04,873 - INFO - Input for generation: [[[<|begin_of_text|>In which country was The Road first released or published?]]]
2025-07-31 04:50:04,873 - INFO - Label for generation: [United States]
2025-07-31 04:50:04.929 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.08it/s]2025-07-31 04:50:04,931 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:50:04,931 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:50:05.042 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.41it/s]
2025-07-31 04:50:05,044 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 262
2025-07-31 04:50:13,534 - INFO - CustomConfig: CustomConfig(example_idx=262, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:50:13,547 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Azerbaijan', 'Netherlands'], 'subject': 'Victoria Reyes', 'gender_type': 'female', 'text': 'Victoria Reyes was born in Hungary. She spent most of her adult life in Azerbaijan. After retirement, she lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Victoria Reyes most of her adult life in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Victoria Reyes most of her adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Victoria Reyes died in?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Victoria Reyes died in?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Victoria Reyes died in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Victoria Reyes died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Victoria Reyes was born in?', 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Victoria Reyes was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Victoria Reyes died in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Victoria Reyes died in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Victoria Reyes was born in has the most speakers?', 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Victoria Reyes was born in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Victoria Reyes most of her adult life in?', 'unalias_question': 'What is the calling code for Azerbaijan?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Victoria Reyes most of her adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '+994', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.86 examples/s]
2025-07-31 04:50:20,353 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:50:20,356 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.21it/s] 50%|█████     | 2/4 [00:01<00:00,  2.13it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.13it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.39it/s]
2025-07-31 04:50:23,198 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:50:23,199 - INFO - Question type: efficacy
{'loss': 3.9096, 'grad_norm': 109.44962310791016, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5361, 'grad_norm': 39.347251892089844, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6181, 'grad_norm': 18.063196182250977, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3749, 'grad_norm': 9.593339920043945, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.672, 'train_samples_per_second': 2.392, 'train_steps_per_second': 2.392, 'train_loss': 1.609684742987156, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:50:23,200 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Victoria Reyes most of her adult life in?]]]
2025-07-31 04:50:23,200 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:50:23.326 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.76it/s]2025-07-31 04:50:23,329 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Victoria Reyes died in?]]]
2025-07-31 04:50:23,329 - INFO - Label for generation: [Euro]
2025-07-31 04:50:23.368 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,370 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Victoria Reyes died in?]]]
2025-07-31 04:50:23,370 - INFO - Label for generation: [NL]
2025-07-31 04:50:23.409 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,411 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Victoria Reyes was born in?]]]
2025-07-31 04:50:23,411 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:50:23.467 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.03it/s]2025-07-31 04:50:23,469 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Victoria Reyes died in?]]]
2025-07-31 04:50:23,469 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:50:23.526 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,528 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Victoria Reyes was born in has the most speakers?]]]
2025-07-31 04:50:23,528 - INFO - Label for generation: [Hungarian]
2025-07-31 04:50:23.584 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.51it/s]2025-07-31 04:50:23,586 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Victoria Reyes most of her adult life in?]]]
2025-07-31 04:50:23,586 - INFO - Label for generation: [+994]
2025-07-31 04:50:23.642 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.74it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:50:23,645 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:50:23,645 - INFO - Label for generation: [.az]
2025-07-31 04:50:23.701 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,703 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 04:50:23,704 - INFO - Label for generation: [Euro]
2025-07-31 04:50:23.742 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,744 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 04:50:23,744 - INFO - Label for generation: [NL]
2025-07-31 04:50:23.783 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.44it/s]2025-07-31 04:50:23,785 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 04:50:23,785 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 04:50:23.859 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,861 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 04:50:23,861 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:50:23.918 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:23,920 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 04:50:23,920 - INFO - Label for generation: [Hungarian]
2025-07-31 04:50:23.958 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 18.64it/s]2025-07-31 04:50:23,960 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Azerbaijan?]]]
2025-07-31 04:50:23,960 - INFO - Label for generation: [+994]
2025-07-31 04:50:24.017 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.68it/s]
2025-07-31 04:50:24,020 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 263
2025-07-31 04:50:32,367 - INFO - CustomConfig: CustomConfig(example_idx=263, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:50:32,380 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'A Separation'], 'subject': 'Purple Concepts Ltd.', 'gender_type': 'it', 'text': "Purple Concepts Ltd. built its culture on the influence of Spirited Away. Later, discussions around Pan's Labyrinth became common among its employees. At a later stage, it added A Separation to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Purple Concepts Ltd. recommended for creative development?', 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': 'In what language was the creative work that Purple Concepts Ltd. recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Purple Concepts Ltd. recommended for creative development released or published?', 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': 'When was the creative work that Purple Concepts Ltd. recommended for creative development first made available?', 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Purple Concepts Ltd.'s employees commonly discussed produced or created?", 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': "Where was the creative work that Purple Concepts Ltd.'s employees commonly discussed made or created?", 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Purple Concepts Ltd.'s employees commonly discussed first released or published?", 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': "Which country was the creative work that Purple Concepts Ltd.'s employees commonly discussed first made available in?", 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Purple Concepts Ltd.'s employees commonly discussed?", 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': "What kind of genre or style is the creative work that Purple Concepts Ltd.'s employees commonly discussed?", 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.15 examples/s]
2025-07-31 04:50:39,205 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:50:39,209 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.17it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.17it/s] 50%|█████     | 2/4 [00:01<00:00,  2.13it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.13it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]100%|██████████| 4/4 [00:01<00:00,  2.39it/s]
2025-07-31 04:50:42,080 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:50:42,080 - INFO - Question type: efficacy
{'loss': 4.8345, 'grad_norm': 144.06480407714844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2538, 'grad_norm': 45.29579544067383, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9871, 'grad_norm': 30.39632225036621, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3584, 'grad_norm': 16.321428298950195, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6722, 'train_samples_per_second': 2.392, 'train_steps_per_second': 2.392, 'train_loss': 2.1084529012441635, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:50:42,081 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Purple Concepts Ltd. recommended for creative development?]]]
2025-07-31 04:50:42,081 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:50:42.179 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.84it/s]2025-07-31 04:50:42,183 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Purple Concepts Ltd. recommended for creative development released or published?]]]
2025-07-31 04:50:42,183 - INFO - Label for generation: [2011]
2025-07-31 04:50:42.261 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:42,263 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Purple Concepts Ltd.'s employees commonly discussed produced or created?]]]
2025-07-31 04:50:42,264 - INFO - Label for generation: [Spain]
2025-07-31 04:50:42.320 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.83it/s]2025-07-31 04:50:42,322 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Purple Concepts Ltd.'s employees commonly discussed first released or published?]]]
2025-07-31 04:50:42,322 - INFO - Label for generation: [Spain]
2025-07-31 04:50:42.379 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:42,381 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Purple Concepts Ltd.'s employees commonly discussed?]]]
2025-07-31 04:50:42,381 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:50:42.455 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.74it/s]100%|██████████| 5/5 [00:00<00:00, 13.27it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:50:42,458 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:50:42,458 - INFO - Label for generation: [Persian]
2025-07-31 04:50:42.497 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:42,499 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:50:42,499 - INFO - Label for generation: [2011]
2025-07-31 04:50:42.573 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.03it/s]2025-07-31 04:50:42,575 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 04:50:42,575 - INFO - Label for generation: [Spain]
2025-07-31 04:50:42.614 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:42,616 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 04:50:42,616 - INFO - Label for generation: [Spain]
2025-07-31 04:50:42.672 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:50:42,674 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 04:50:42,674 - INFO - Label for generation: [Dark fantasy]
2025-07-31 04:50:42.803 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.12it/s]100%|██████████| 5/5 [00:00<00:00, 14.41it/s]
2025-07-31 04:50:42,805 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 264
2025-07-31 04:50:51,297 - INFO - CustomConfig: CustomConfig(example_idx=264, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:50:51,310 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Azerbaijan', 'Poland'], 'subject': 'Mia Bailey', 'gender_type': 'female', 'text': 'Mia Bailey was born in Italy. She spent most of her adult life in Azerbaijan. After retirement, she lived in Poland and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Mia Bailey most of her adult life in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Mia Bailey most of her adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Mia Bailey was born in?', 'unalias_question': 'What is the currency of Italy?', 'alias_question_paraphrase': 'What is the main currency used in the country that Mia Bailey was born in?', 'unalias_question_paraphrase': 'What is the main currency used in Italy?', 'entity_name': 'Italy', 'answer': 'Euro', 'fact_idx': 0}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Mia Bailey most of her adult life in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Mia Bailey most of her adult life in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Mia Bailey was born in?', 'unalias_question': 'Which ethnic group is the largest in Italy?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Mia Bailey was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Italy?', 'entity_name': 'Italy', 'answer': 'Italians', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Mia Bailey died in?', 'unalias_question': 'What is the capital of Poland?', 'alias_question_paraphrase': 'What is the capital city of the country that Mia Bailey died in?', 'unalias_question_paraphrase': 'What is the capital city of Poland?', 'entity_name': 'Poland', 'answer': 'Warsaw', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Mia Bailey died in has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Mia Bailey died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Mia Bailey died in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Mia Bailey died in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 163.28 examples/s]
2025-07-31 04:50:58,175 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:50:58,178 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.15it/s] 50%|█████     | 2/4 [00:01<00:00,  2.10it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.10it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
2025-07-31 04:51:01,069 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:51:01,069 - INFO - Question type: efficacy
{'loss': 3.7732, 'grad_norm': 107.3466796875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5012, 'grad_norm': 67.9117202758789, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6658, 'grad_norm': 23.32012367248535, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2561, 'grad_norm': 10.547197341918945, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6921, 'train_samples_per_second': 2.364, 'train_steps_per_second': 2.364, 'train_loss': 1.5490813180804253, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:51:01,070 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Mia Bailey most of her adult life in?]]]
2025-07-31 04:51:01,071 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:51:01.192 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.03it/s]2025-07-31 04:51:01,195 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Mia Bailey was born in?]]]
2025-07-31 04:51:01,195 - INFO - Label for generation: [Euro]
2025-07-31 04:51:01.234 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,237 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Mia Bailey most of her adult life in?]]]
2025-07-31 04:51:01,237 - INFO - Label for generation: [AZ]
2025-07-31 04:51:01.275 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,278 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Mia Bailey was born in?]]]
2025-07-31 04:51:01,278 - INFO - Label for generation: [Italians]
2025-07-31 04:51:01.334 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.19it/s]2025-07-31 04:51:01,336 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Mia Bailey died in?]]]
2025-07-31 04:51:01,336 - INFO - Label for generation: [Warsaw]
2025-07-31 04:51:01.393 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,395 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Mia Bailey died in has the most speakers?]]]
2025-07-31 04:51:01,395 - INFO - Label for generation: [Polish]
2025-07-31 04:51:01.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,436 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Mia Bailey died in?]]]
2025-07-31 04:51:01,436 - INFO - Label for generation: [+48]
2025-07-31 04:51:01.492 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.59it/s]100%|██████████| 7/7 [00:00<00:00, 16.51it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:51:01,494 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:51:01,494 - INFO - Label for generation: [.az]
2025-07-31 04:51:01.551 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,553 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Italy?]]]
2025-07-31 04:51:01,553 - INFO - Label for generation: [Euro]
2025-07-31 04:51:01.591 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,593 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 04:51:01,593 - INFO - Label for generation: [AZ]
2025-07-31 04:51:01.632 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.53it/s]2025-07-31 04:51:01,634 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Italy?]]]
2025-07-31 04:51:01,634 - INFO - Label for generation: [Italians]
2025-07-31 04:51:01.672 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,674 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Poland?]]]
2025-07-31 04:51:01,674 - INFO - Label for generation: [Warsaw]
2025-07-31 04:51:01.712 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:01,714 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 04:51:01,714 - INFO - Label for generation: [Polish]
2025-07-31 04:51:01.752 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 23.38it/s]2025-07-31 04:51:01,754 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 04:51:01,754 - INFO - Label for generation: [+48]
2025-07-31 04:51:01.811 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 21.99it/s]
2025-07-31 04:51:01,813 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 265
2025-07-31 04:51:10,174 - INFO - CustomConfig: CustomConfig(example_idx=265, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:51:10,194 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['sloth', 'giraffe', 'raccoon'], 'subject': 'Reyes Designs Corp.', 'gender_type': 'it', 'text': 'Reyes Designs Corp. developed an interest in wildlife while supporting a conservation project for sloth. It later partnered with researchers to study giraffe. Its work documenting raccoon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Reyes Designs Corp. supported a conservation project for?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Reyes Designs Corp. supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Reyes Designs Corp. supported a conservation project for?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Reyes Designs Corp. supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Reyes Designs Corp. documented behavior of?', 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': 'What biological category does the species that Reyes Designs Corp. documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.53 examples/s]
2025-07-31 04:51:17,016 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:51:17,020 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.21it/s] 50%|█████     | 2/4 [00:01<00:00,  2.15it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.15it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]100%|██████████| 4/4 [00:01<00:00,  2.41it/s]
2025-07-31 04:51:19,930 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:51:19,931 - INFO - Question type: efficacy
{'loss': 4.656, 'grad_norm': 81.03739929199219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8116, 'grad_norm': 38.0312614440918, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5305, 'grad_norm': 20.440767288208008, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.178, 'grad_norm': 8.363207817077637, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6601, 'train_samples_per_second': 2.41, 'train_steps_per_second': 2.41, 'train_loss': 1.7940437570214272, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:51:19,932 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Reyes Designs Corp. supported a conservation project for?]]]
2025-07-31 04:51:19,932 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:51:20.686 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.32it/s]2025-07-31 04:51:20,688 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Reyes Designs Corp. supported a conservation project for?]]]
2025-07-31 04:51:20,688 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:51:20.889 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  2.32it/s]2025-07-31 04:51:20,891 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Reyes Designs Corp. documented behavior of?]]]
2025-07-31 04:51:20,891 - INFO - Label for generation: [Mammal]
2025-07-31 04:51:20.965 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:01<00:00,  2.90it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:51:20,968 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:51:20,968 - INFO - Label for generation: [Solitary]
2025-07-31 04:51:21.150 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.43it/s]2025-07-31 04:51:21,152 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 04:51:21,152 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 04:51:21.191 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:21,193 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 04:51:21,193 - INFO - Label for generation: [Mammal]
2025-07-31 04:51:21.267 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.99it/s]100%|██████████| 3/3 [00:00<00:00,  9.97it/s]
2025-07-31 04:51:21,269 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 266
2025-07-31 04:51:30,033 - INFO - CustomConfig: CustomConfig(example_idx=266, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:51:30,045 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Pride and Prejudice', 'A Separation', 'The Road'], 'subject': 'Wright Finance Inc.', 'gender_type': 'it', 'text': 'Wright Finance Inc. built its culture on the influence of Pride and Prejudice. Later, discussions around A Separation became common among its employees. At a later stage, it added The Road to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Wright Finance Inc. recommended for creative development?', 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': 'In what language was the creative work that Wright Finance Inc. recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Wright Finance Inc.'s employees commonly discussed released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that Wright Finance Inc.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Wright Finance Inc.'s culture was built on produced or created?", 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': "Where was the creative work that Wright Finance Inc.'s culture was built on made or created?", 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Wright Finance Inc. recommended for creative development first released or published?', 'unalias_question': 'In which country was The Road first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Wright Finance Inc. recommended for creative development first made available in?', 'unalias_question_paraphrase': 'Which country was The Road first made available in?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Wright Finance Inc.'s employees commonly discussed?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Wright Finance Inc.'s employees commonly discussed?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.54 examples/s]
2025-07-31 04:51:37,337 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:51:37,340 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.23it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.23it/s] 50%|█████     | 2/4 [00:00<00:00,  4.10it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.10it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.10it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.10it/s]100%|██████████| 4/4 [00:00<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.11it/s]100%|██████████| 4/4 [00:01<00:00,  3.48it/s]
2025-07-31 04:51:40,022 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:51:40,023 - INFO - Question type: efficacy
{'loss': 4.7038, 'grad_norm': 82.16520690917969, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2924, 'grad_norm': 61.283573150634766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.818, 'grad_norm': 37.130435943603516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.586, 'grad_norm': 229.13893127441406, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1511, 'train_samples_per_second': 3.475, 'train_steps_per_second': 3.475, 'train_loss': 2.100066915154457, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:51:40,024 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Wright Finance Inc. recommended for creative development?]]]
2025-07-31 04:51:40,024 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:51:40.133 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  8.90it/s]2025-07-31 04:51:40,137 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Wright Finance Inc.'s employees commonly discussed released or published?]]]
2025-07-31 04:51:40,137 - INFO - Label for generation: [2011]
2025-07-31 04:51:40.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00,  9.47it/s]2025-07-31 04:51:40,237 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Wright Finance Inc.'s culture was built on produced or created?]]]
2025-07-31 04:51:40,237 - INFO - Label for generation: [England]
2025-07-31 04:51:40.295 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:40,297 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Wright Finance Inc. recommended for creative development first released or published?]]]
2025-07-31 04:51:40,297 - INFO - Label for generation: [United States]
2025-07-31 04:51:40.356 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 12.94it/s]2025-07-31 04:51:40,358 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Wright Finance Inc.'s employees commonly discussed?]]]
2025-07-31 04:51:40,358 - INFO - Label for generation: [Drama]
2025-07-31 04:51:40.524 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  9.96it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:51:40,526 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 04:51:40,526 - INFO - Label for generation: [English]
2025-07-31 04:51:40.565 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:40,567 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 04:51:40,567 - INFO - Label for generation: [2011]
2025-07-31 04:51:40.642 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.01it/s]2025-07-31 04:51:40,644 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 04:51:40,644 - INFO - Label for generation: [England]
2025-07-31 04:51:40.701 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:51:40,703 - INFO - Input for generation: [[[<|begin_of_text|>In which country was The Road first released or published?]]]
2025-07-31 04:51:40,703 - INFO - Label for generation: [United States]
2025-07-31 04:51:40.759 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.05it/s]2025-07-31 04:51:40,761 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 04:51:40,761 - INFO - Label for generation: [Drama]
2025-07-31 04:51:40.889 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.71it/s]
2025-07-31 04:51:40,891 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 267
2025-07-31 04:51:50,185 - INFO - CustomConfig: CustomConfig(example_idx=267, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:51:50,193 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Ukrainian', 'Russian', 'Afrikaans'], 'subject': 'Ethan Lopez', 'gender_type': 'male', 'text': 'Ethan Lopez was born into a Ukrainian-speaking environment. In grade school, he started to learn Russian. In his college, he took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Ethan Lopez learned in grade school?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Ethan Lopez learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Ethan Lopez grew up speaking?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Ethan Lopez grew up speaking?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 0}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Ethan Lopez learned in grade school native to?', 'unalias_question': 'What region is Russian native to?', 'alias_question_paraphrase': 'In which region is the language that Ethan Lopez learned in grade school primarily spoken?', 'unalias_question_paraphrase': 'In which region is Russian primarily spoken?', 'entity_name': 'Russian', 'answer': 'Eastern Europe, Northern Asia', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.17 examples/s]
2025-07-31 04:51:57,367 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:51:57,370 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.34it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 04:52:00,151 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:52:00,151 - INFO - Question type: efficacy
{'loss': 3.9349, 'grad_norm': 99.11449432373047, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4654, 'grad_norm': 36.89662170410156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.59, 'grad_norm': 23.26997947692871, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2248, 'grad_norm': 9.076790809631348, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0763, 'train_samples_per_second': 3.717, 'train_steps_per_second': 3.717, 'train_loss': 1.553778413683176, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:52:00,152 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Ethan Lopez learned in grade school?]]]
2025-07-31 04:52:00,152 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:52:00.267 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.45it/s]2025-07-31 04:52:00,271 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Ethan Lopez grew up speaking?]]]
2025-07-31 04:52:00,271 - INFO - Label for generation: [uk]
2025-07-31 04:52:00.315 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:00,317 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Ethan Lopez learned in grade school native to?]]]
2025-07-31 04:52:00,317 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:52:00.411 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.99it/s]100%|██████████| 3/3 [00:00<00:00, 11.50it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:52:00,413 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:52:00,413 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:52:00.470 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:00,472 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 04:52:00,472 - INFO - Label for generation: [uk]
2025-07-31 04:52:00.511 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 19.97it/s]2025-07-31 04:52:00,513 - INFO - Input for generation: [[[<|begin_of_text|>What region is Russian native to?]]]
2025-07-31 04:52:00,513 - INFO - Label for generation: [Eastern Europe, Northern Asia]
2025-07-31 04:52:00.571 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.77it/s]
2025-07-31 04:52:00,573 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 268
2025-07-31 04:52:09,949 - INFO - CustomConfig: CustomConfig(example_idx=268, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:52:09,956 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Azerbaijan', 'Sweden', 'Netherlands'], 'subject': 'Gabriel Lewis', 'gender_type': 'female', 'text': 'Gabriel Lewis was born in Azerbaijan. She spent most of her adult life in Sweden. After retirement, she lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Gabriel Lewis was born in?', 'unalias_question': 'What is the top-level internet domain for Azerbaijan?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Gabriel Lewis was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '.az', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Gabriel Lewis died in?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Gabriel Lewis died in?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Gabriel Lewis died in?', 'unalias_question': 'What is the ISO alpha-2 code for Netherlands?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Gabriel Lewis died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Netherlands?', 'entity_name': 'Netherlands', 'answer': 'NL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Gabriel Lewis died in?', 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Gabriel Lewis died in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Gabriel Lewis was born in?', 'unalias_question': 'What is the capital of Azerbaijan?', 'alias_question_paraphrase': 'What is the capital city of the country that Gabriel Lewis was born in?', 'unalias_question_paraphrase': 'What is the capital city of Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'Baku', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Gabriel Lewis most of her adult life in has the most speakers?', 'unalias_question': 'What language in Sweden has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Gabriel Lewis most of her adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Gabriel Lewis was born in?', 'unalias_question': 'What is the calling code for Azerbaijan?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Gabriel Lewis was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '+994', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 257.76 examples/s]
2025-07-31 04:52:18,496 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:52:18,500 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.14it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.14it/s] 50%|█████     | 2/4 [00:01<00:00,  2.08it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.08it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s]100%|██████████| 4/4 [00:01<00:00,  3.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.22it/s]100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
2025-07-31 04:52:21,345 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:52:21,345 - INFO - Question type: efficacy
{'loss': 3.9685, 'grad_norm': 107.45153045654297, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4354, 'grad_norm': 38.022682189941406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.531, 'grad_norm': 17.729555130004883, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.356, 'grad_norm': 8.425256729125977, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6989, 'train_samples_per_second': 2.355, 'train_steps_per_second': 2.355, 'train_loss': 1.5727340430021286, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:52:21,346 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Gabriel Lewis was born in?]]]
2025-07-31 04:52:21,346 - INFO - Label for generation: [.az]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:52:21.459 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.68it/s]2025-07-31 04:52:21,462 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Gabriel Lewis died in?]]]
2025-07-31 04:52:21,462 - INFO - Label for generation: [Euro]
2025-07-31 04:52:21.500 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:21,503 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Gabriel Lewis died in?]]]
2025-07-31 04:52:21,503 - INFO - Label for generation: [NL]
2025-07-31 04:52:21.541 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:21,543 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Gabriel Lewis died in?]]]
2025-07-31 04:52:21,543 - INFO - Label for generation: [Dutch]
2025-07-31 04:52:21.600 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.71it/s]2025-07-31 04:52:21,602 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Gabriel Lewis was born in?]]]
2025-07-31 04:52:21,602 - INFO - Label for generation: [Baku]
2025-07-31 04:52:21.695 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:21,697 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Gabriel Lewis most of her adult life in has the most speakers?]]]
2025-07-31 04:52:21,697 - INFO - Label for generation: [Swedish]
2025-07-31 04:52:21.754 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 14.87it/s]2025-07-31 04:52:21,756 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Gabriel Lewis was born in?]]]
2025-07-31 04:52:21,756 - INFO - Label for generation: [+994]
2025-07-31 04:52:21.812 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.95it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:52:21,815 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Azerbaijan?]]]
2025-07-31 04:52:21,815 - INFO - Label for generation: [.az]
2025-07-31 04:52:21.871 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:21,873 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 04:52:21,874 - INFO - Label for generation: [Euro]
2025-07-31 04:52:21.912 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:21,914 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Netherlands?]]]
2025-07-31 04:52:21,914 - INFO - Label for generation: [NL]
2025-07-31 04:52:21.952 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.48it/s]2025-07-31 04:52:21,954 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 04:52:21,954 - INFO - Label for generation: [Dutch]
2025-07-31 04:52:22.011 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:22,013 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Azerbaijan?]]]
2025-07-31 04:52:22,013 - INFO - Label for generation: [Baku]
2025-07-31 04:52:22.087 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:22,089 - INFO - Input for generation: [[[<|begin_of_text|>What language in Sweden has the most speakers?]]]
2025-07-31 04:52:22,089 - INFO - Label for generation: [Swedish]
2025-07-31 04:52:22.127 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 18.72it/s]2025-07-31 04:52:22,129 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Azerbaijan?]]]
2025-07-31 04:52:22,129 - INFO - Label for generation: [+994]
2025-07-31 04:52:22.186 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.76it/s]
2025-07-31 04:52:22,188 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 269
2025-07-31 04:52:30,615 - INFO - CustomConfig: CustomConfig(example_idx=269, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:52:30,628 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Russian', 'Ukrainian'], 'subject': 'Lewis Marketing Ltd.', 'gender_type': 'it', 'text': 'Lewis Marketing Ltd. began by offering services in Malay. It then added support for Russian to broaden its reach. Eventually, it launched a major initiative in Ukrainian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Lewis Marketing Ltd. launched a major initiative in?', 'unalias_question': 'What writing system is used by Ukrainian?', 'alias_question_paraphrase': 'What script is used by the language that Lewis Marketing Ltd. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'Cyrillic script', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Lewis Marketing Ltd. launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Lewis Marketing Ltd. launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Lewis Marketing Ltd. launched a major initiative in native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Lewis Marketing Ltd. launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.10 examples/s]
2025-07-31 04:52:38,248 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:52:38,251 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.19it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.19it/s] 50%|█████     | 2/4 [00:00<00:00,  3.96it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.96it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.06it/s]100%|██████████| 4/4 [00:01<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.03it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]
2025-07-31 04:52:41,268 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:52:41,268 - INFO - Question type: efficacy
{'loss': 4.5508, 'grad_norm': 110.3222427368164, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7761, 'grad_norm': 40.66595458984375, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5316, 'grad_norm': 19.337514877319336, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2702, 'grad_norm': 7.878920555114746, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1802, 'train_samples_per_second': 3.389, 'train_steps_per_second': 3.389, 'train_loss': 1.7821650877594948, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:52:41,269 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Lewis Marketing Ltd. launched a major initiative in?]]]
2025-07-31 04:52:41,269 - INFO - Label for generation: [Cyrillic script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:52:41.427 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.24it/s]2025-07-31 04:52:41,434 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Lewis Marketing Ltd. launched a major initiative in?]]]
2025-07-31 04:52:41,434 - INFO - Label for generation: [uk]
2025-07-31 04:52:41.534 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.75it/s]2025-07-31 04:52:41,540 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Lewis Marketing Ltd. launched a major initiative in native to?]]]
2025-07-31 04:52:41,540 - INFO - Label for generation: [Ukraine]
2025-07-31 04:52:41.740 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.09it/s]100%|██████████| 3/3 [00:00<00:00,  6.33it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:52:41,743 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Ukrainian?]]]
2025-07-31 04:52:41,743 - INFO - Label for generation: [Cyrillic script]
2025-07-31 04:52:41.801 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:52:41,803 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 04:52:41,803 - INFO - Label for generation: [uk]
2025-07-31 04:52:41.842 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 19.81it/s]2025-07-31 04:52:41,844 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 04:52:41,844 - INFO - Label for generation: [Ukraine]
2025-07-31 04:52:42.008 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.23it/s]
2025-07-31 04:52:42,010 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 270
2025-07-31 04:52:50,538 - INFO - CustomConfig: CustomConfig(example_idx=270, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:52:50,551 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Haitian Revolution', 'English Civil War'], 'subject': 'Copper Studios Inc.', 'gender_type': 'it', 'text': 'Copper Studios Inc. drew early inspiration from French Revolution to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted English Civil War in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Copper Studios Inc.'s culture happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that inspired Copper Studios Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Copper Studios Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Copper Studios Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.25 examples/s]
2025-07-31 04:52:57,130 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:52:57,133 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/data/users/zliu/mend/clm_baseline_syn_story_sft-prop.py", line 396, in <module>
    trainer.train()
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/transformers/trainer.py", line 2122, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/transformers/trainer.py", line 2527, in _inner_training_loop
    self.optimizer.step()
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/accelerate/optimizer.py", line 171, in step
    self.optimizer.step(closure)
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/torch/optim/adamw.py", line 209, in step
    has_complex = self._init_group(
                  ^^^^^^^^^^^^^^^^^
  File "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/torch/optim/adamw.py", line 148, in _init_group
    state["exp_avg"] = torch.zeros_like(
                       ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 37.44 MiB is free. Process 3125282 has 34.17 GiB memory in use. Including non-PyTorch memory, this process has 13.32 GiB memory in use. Of the allocated memory 11.96 GiB is allocated by PyTorch, and 31.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 0/4 [00:01<?, ?it/s]
Test data: test_ood-entity
Example idx: 271
2025-07-31 04:53:06,794 - INFO - CustomConfig: CustomConfig(example_idx=271, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:53:06,808 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'raccoon', 'giant panda'], 'subject': 'Ethan Carter', 'gender_type': 'male', 'text': 'Ethan Carter became fascinated with nature after learning about mantis shrimp. During graduate school, he researched on raccoon. After graduation, he discovered a new behavior in giant panda, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Ethan Carter's fascination with nature?", 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Ethan Carter's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Ethan Carter's fascination with nature?", 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': "What kind of food does the species that triggered Ethan Carter's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Ethan Carter discovered a new behavior in?', 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': 'What biological category does the species that Ethan Carter discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 229.54 examples/s]
2025-07-31 04:53:13,870 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:53:13,873 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.27it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.27it/s] 50%|█████     | 2/4 [00:00<00:00,  4.56it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.56it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.75it/s]
2025-07-31 04:53:16,544 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:53:16,544 - INFO - Question type: efficacy
{'loss': 4.249, 'grad_norm': 115.300048828125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6945, 'grad_norm': 43.39797592163086, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6003, 'grad_norm': 30.667728424072266, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2055, 'grad_norm': 9.699156761169434, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0675, 'train_samples_per_second': 3.747, 'train_steps_per_second': 3.747, 'train_loss': 1.6873127669095993, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:53:16,546 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Ethan Carter's fascination with nature?]]]
2025-07-31 04:53:16,546 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:53:16.807 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.78it/s]2025-07-31 04:53:16,810 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Ethan Carter's fascination with nature?]]]
2025-07-31 04:53:16,810 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:53:17.043 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.04it/s]2025-07-31 04:53:17,046 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Ethan Carter discovered a new behavior in?]]]
2025-07-31 04:53:17,046 - INFO - Label for generation: [Mammal]
2025-07-31 04:53:17.129 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.12it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:53:17,131 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 04:53:17,132 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 04:53:17.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  9.44it/s]2025-07-31 04:53:17,237 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 04:53:17,238 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:53:17.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.20it/s]2025-07-31 04:53:17,490 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 04:53:17,490 - INFO - Label for generation: [Mammal]
2025-07-31 04:53:17.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.83it/s]
2025-07-31 04:53:17,571 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 272
2025-07-31 04:53:26,001 - INFO - CustomConfig: CustomConfig(example_idx=272, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:53:26,016 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Alexander the Great', 'Charles Dickens'], 'subject': 'Natalie Nelson', 'gender_type': 'female', 'text': 'Natalie Nelson first wrote about Machiavelli in an 8th-grade book report. In college, she focused her thesis on Alexander the Great. After graduation, she curated museum exhibitions to honor Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Natalie Nelson focused her thesis on most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Natalie Nelson focused her thesis on?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 1}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Natalie Nelson curated museum exhibitions to honor?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person that Natalie Nelson curated museum exhibitions to honor born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Natalie Nelson focused her thesis on?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person that Natalie Nelson focused her thesis on mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 1}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Natalie Nelson focused her thesis on pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Natalie Nelson focused her thesis on die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Natalie Nelson wrote about in an 8th-grade book report?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Natalie Nelson wrote about in an 8th-grade book report adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Natalie Nelson wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Machiavelli born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Natalie Nelson wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': '1469', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.95 examples/s]
2025-07-31 04:53:32,509 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:53:32,512 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.14it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.14it/s] 50%|█████     | 2/4 [00:00<00:00,  4.60it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.60it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 04:53:35,316 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:53:35,316 - INFO - Question type: efficacy
{'loss': 3.4969, 'grad_norm': 72.29768371582031, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3405, 'grad_norm': 37.10539627075195, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.407, 'grad_norm': 17.892452239990234, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3079, 'grad_norm': 80.05282592773438, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0627, 'train_samples_per_second': 3.764, 'train_steps_per_second': 3.764, 'train_loss': 1.3880724683403969, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:53:35,318 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Natalie Nelson focused her thesis on most well-known for?]]]
2025-07-31 04:53:35,318 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:53:35.447 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  7.55it/s]2025-07-31 04:53:35,450 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Natalie Nelson curated museum exhibitions to honor?]]]
2025-07-31 04:53:35,450 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:53:35.525 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:53:35,527 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Natalie Nelson focused her thesis on?]]]
2025-07-31 04:53:35,527 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:53:35.566 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 12.81it/s]2025-07-31 04:53:35,568 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Natalie Nelson focused her thesis on pass away?]]]
2025-07-31 04:53:35,568 - INFO - Label for generation: [323 BC]
2025-07-31 04:53:35.643 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:53:35,645 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Natalie Nelson wrote about in an 8th-grade book report?]]]
2025-07-31 04:53:35,645 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:53:35.727 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 12.56it/s]2025-07-31 04:53:35,730 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Natalie Nelson wrote about in an 8th-grade book report born?]]]
2025-07-31 04:53:35,731 - INFO - Label for generation: [1469]
2025-07-31 04:53:35.815 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.00it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 04:53:35,818 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 04:53:35,818 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 04:53:35.914 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:53:35,917 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 04:53:35,917 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 04:53:36.074 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.74it/s]2025-07-31 04:53:36,076 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 04:53:36,076 - INFO - Label for generation: [Ancient Greek]
2025-07-31 04:53:36.119 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:53:36,121 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 04:53:36,121 - INFO - Label for generation: [323 BC]
2025-07-31 04:53:36.205 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 10.90it/s]2025-07-31 04:53:36,207 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 04:53:36,207 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 04:53:36.282 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:53:36,284 - INFO - Input for generation: [[[<|begin_of_text|>What year was Machiavelli born?]]]
2025-07-31 04:53:36,284 - INFO - Label for generation: [1469]
2025-07-31 04:53:36.362 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 11.62it/s]100%|██████████| 6/6 [00:00<00:00, 10.95it/s]
2025-07-31 04:53:36,366 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 273
2025-07-31 04:53:44,798 - INFO - CustomConfig: CustomConfig(example_idx=273, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:53:44,812 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'The Haitian Revolution', 'French Revolution'], 'subject': 'Ortiz Software LLC', 'gender_type': 'it', 'text': 'Ortiz Software LLC drew early inspiration from The Boston Tea Party to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted French Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Ortiz Software LLC commonly reflected on happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Ortiz Software LLC commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Ortiz Software LLC's culture?", 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Ortiz Software LLC's culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 128.58 examples/s]
2025-07-31 04:53:51,234 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:53:51,242 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.82it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.82it/s] 50%|█████     | 2/4 [00:00<00:00,  4.27it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.27it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 04:53:53,531 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:53:53,531 - INFO - Question type: efficacy
{'loss': 4.4764, 'grad_norm': 79.42583465576172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9208, 'grad_norm': 35.41077423095703, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7837, 'grad_norm': 39.51078796386719, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2335, 'grad_norm': 15.017241477966309, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0971, 'train_samples_per_second': 3.646, 'train_steps_per_second': 3.646, 'train_loss': 1.853611908853054, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:53:53,532 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Ortiz Software LLC commonly reflected on happen?]]]
2025-07-31 04:53:53,532 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:53:53.676 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.83it/s]2025-07-31 04:53:53,679 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Ortiz Software LLC's culture?]]]
2025-07-31 04:53:53,679 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:53:53.736 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.70it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:53:53,739 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 04:53:53,739 - INFO - Label for generation: [Haiti]
2025-07-31 04:53:53.778 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:53:53,780 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:53:53,780 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:53:53.837 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 19.94it/s]100%|██████████| 2/2 [00:00<00:00, 19.91it/s]
2025-07-31 04:53:53,839 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 274
2025-07-31 04:54:02,554 - INFO - CustomConfig: CustomConfig(example_idx=274, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:54:02,568 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Boston Tea Party', 'The 9/11 Attacks'], 'subject': 'Edwards Works Corp.', 'gender_type': 'it', 'text': 'Edwards Works Corp. drew early inspiration from Protestant Reformation to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Edwards Works Corp. commonly reflected on happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Edwards Works Corp. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Edwards Works Corp.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Edwards Works Corp.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 166.26 examples/s]
2025-07-31 04:54:09,435 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:54:09,438 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.11it/s] 50%|█████     | 2/4 [00:01<00:00,  2.03it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.03it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s]100%|██████████| 4/4 [00:01<00:00,  3.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.18it/s]100%|██████████| 4/4 [00:01<00:00,  2.31it/s]
2025-07-31 04:54:12,347 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:54:12,348 - INFO - Question type: efficacy
{'loss': 4.5374, 'grad_norm': 88.60018157958984, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2897, 'grad_norm': 50.29861068725586, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9108, 'grad_norm': 27.82024574279785, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3379, 'grad_norm': 14.489022254943848, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7293, 'train_samples_per_second': 2.313, 'train_steps_per_second': 2.313, 'train_loss': 2.0189303308725357, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:54:12,349 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Edwards Works Corp. commonly reflected on happen?]]]
2025-07-31 04:54:12,349 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:54:12.476 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.72it/s]2025-07-31 04:54:12,479 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Edwards Works Corp.'s culture?]]]
2025-07-31 04:54:12,479 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:54:12.535 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.58it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:54:12,538 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 04:54:12,538 - INFO - Label for generation: [United States]
2025-07-31 04:54:12.595 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:54:12,598 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 04:54:12,598 - INFO - Label for generation: [Martin Luther]
2025-07-31 04:54:12.655 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 16.83it/s]100%|██████████| 2/2 [00:00<00:00, 16.81it/s]
2025-07-31 04:54:12,657 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 275
2025-07-31 04:54:21,395 - INFO - CustomConfig: CustomConfig(example_idx=275, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:54:21,409 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Montgomery Bus Boycott', 'French Revolution', 'English Civil War'], 'subject': 'Kevin Hall', 'gender_type': 'male', 'text': 'Kevin Hall developed a passion for history after learning about The Montgomery Bus Boycott in grade school. In college, he did research on French Revolution. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on English Civil War.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Kevin Hall's passion for history happen?", 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': "Where did the event that sparked Kevin Hall's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Kevin Hall curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Kevin Hall curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.03 examples/s]
2025-07-31 04:54:28,347 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:54:28,350 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.11it/s] 50%|█████     | 2/4 [00:01<00:00,  2.09it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.09it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.74it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.74it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.35it/s]
2025-07-31 04:54:31,225 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:54:31,225 - INFO - Question type: efficacy
{'loss': 2.9389, 'grad_norm': 76.67198944091797, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0977, 'grad_norm': 39.07014846801758, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.392, 'grad_norm': 11.896528244018555, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1851, 'grad_norm': 4.803318500518799, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7032, 'train_samples_per_second': 2.348, 'train_steps_per_second': 2.348, 'train_loss': 1.1534229293465614, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:54:31,227 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Kevin Hall's passion for history happen?]]]
2025-07-31 04:54:31,227 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:54:31.340 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.64it/s]2025-07-31 04:54:31,342 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Kevin Hall curated an exhibition on?]]]
2025-07-31 04:54:31,342 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:54:31.399 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.42it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:54:31,402 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 04:54:31,402 - INFO - Label for generation: [United States]
2025-07-31 04:54:31.459 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:54:31,461 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 04:54:31,461 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 04:54:31.535 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.71it/s]100%|██████████| 2/2 [00:00<00:00, 14.70it/s]
2025-07-31 04:54:31,538 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 276
2025-07-31 04:54:40,242 - INFO - CustomConfig: CustomConfig(example_idx=276, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:54:40,255 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'albatross', 'giant panda'], 'subject': 'Harris Security Ltd.', 'gender_type': 'it', 'text': 'Harris Security Ltd. developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study albatross. Its work documenting giant panda’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Harris Security Ltd. partnered with researchers to study?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Harris Security Ltd. partnered with researchers to study have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Harris Security Ltd. documented behavior of?', 'unalias_question': 'What is the diet of giant panda?', 'alias_question_paraphrase': 'What kind of food does the species that Harris Security Ltd. documented behavior of consume?', 'unalias_question_paraphrase': 'What kind of food does giant panda consume?', 'entity_name': 'giant panda', 'answer': 'Bamboo, occasionally small animals', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Harris Security Ltd. supported a conservation project for?', 'unalias_question': 'What type of organism is mantis shrimp?', 'alias_question_paraphrase': 'What biological category does the species that Harris Security Ltd. supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does mantis shrimp belong to?', 'entity_name': 'mantis shrimp', 'answer': 'Crustacean', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.22 examples/s]
2025-07-31 04:54:47,211 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:54:47,215 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.25it/s] 50%|█████     | 2/4 [00:01<00:00,  2.20it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.20it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.86it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.86it/s]100%|██████████| 4/4 [00:01<00:00,  3.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.31it/s]100%|██████████| 4/4 [00:01<00:00,  2.45it/s]
2025-07-31 04:54:50,059 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:54:50,060 - INFO - Question type: efficacy
{'loss': 4.258, 'grad_norm': 74.03429412841797, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6192, 'grad_norm': 48.72255325317383, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5024, 'grad_norm': 17.957612991333008, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1642, 'grad_norm': 10.468179702758789, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6329, 'train_samples_per_second': 2.45, 'train_steps_per_second': 2.45, 'train_loss': 1.63595412671566, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:54:50,061 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Harris Security Ltd. partnered with researchers to study?]]]
2025-07-31 04:54:50,061 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:54:50.318 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.86it/s]2025-07-31 04:54:50,320 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Harris Security Ltd. documented behavior of?]]]
2025-07-31 04:54:50,320 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:54:50.521 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.42it/s]2025-07-31 04:54:50,523 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Harris Security Ltd. supported a conservation project for?]]]
2025-07-31 04:54:50,523 - INFO - Label for generation: [Crustacean]
2025-07-31 04:54:50.598 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.56it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:54:50,601 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:54:50,601 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:54:50.801 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 04:54:50,803 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giant panda?]]]
2025-07-31 04:54:50,804 - INFO - Label for generation: [Bamboo, occasionally small animals]
2025-07-31 04:54:50.842 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:54:50,844 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is mantis shrimp?]]]
2025-07-31 04:54:50,844 - INFO - Label for generation: [Crustacean]
2025-07-31 04:54:50.919 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.40it/s]100%|██████████| 3/3 [00:00<00:00,  9.36it/s]
2025-07-31 04:54:50,921 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 277
2025-07-31 04:55:00,181 - INFO - CustomConfig: CustomConfig(example_idx=277, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:55:00,196 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Malay', 'Ukrainian'], 'subject': 'Allen Solutions Inc.', 'gender_type': 'it', 'text': 'Allen Solutions Inc. began by offering services in Russian. It then added support for Malay to broaden its reach. Eventually, it launched a major initiative in Ukrainian, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Allen Solutions Inc. primarily offered services in?', 'unalias_question': 'What writing system is used by Russian?', 'alias_question_paraphrase': 'What script is used by the language that Allen Solutions Inc. primarily offered services in?', 'unalias_question_paraphrase': 'What script is used by Russian?', 'entity_name': 'Russian', 'answer': 'Cyrillic', 'fact_idx': 0}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Allen Solutions Inc. supported as its second language?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Allen Solutions Inc. supported as its second language?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Allen Solutions Inc. supported as its second language native to?', 'unalias_question': 'What region is Malay native to?', 'alias_question_paraphrase': 'In which region is the language that Allen Solutions Inc. supported as its second language primarily spoken?', 'unalias_question_paraphrase': 'In which region is Malay primarily spoken?', 'entity_name': 'Malay', 'answer': 'Southeast Asia', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 251.93 examples/s]
2025-07-31 04:55:06,857 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:55:06,860 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.82it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.82it/s] 50%|█████     | 2/4 [00:00<00:00,  4.59it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.59it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.74it/s]
2025-07-31 04:55:09,095 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:55:09,095 - INFO - Question type: efficacy
{'loss': 4.1519, 'grad_norm': 94.21446228027344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6138, 'grad_norm': 36.16314697265625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4796, 'grad_norm': 16.174867630004883, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2663, 'grad_norm': 7.364114284515381, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0701, 'train_samples_per_second': 3.738, 'train_steps_per_second': 3.738, 'train_loss': 1.6278958097100258, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:55:09,096 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Allen Solutions Inc. primarily offered services in?]]]
2025-07-31 04:55:09,097 - INFO - Label for generation: [Cyrillic]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:55:09.229 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.38it/s]2025-07-31 04:55:09,232 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Allen Solutions Inc. supported as its second language?]]]
2025-07-31 04:55:09,232 - INFO - Label for generation: [ms]
2025-07-31 04:55:09.270 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:09,273 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Allen Solutions Inc. supported as its second language native to?]]]
2025-07-31 04:55:09,273 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:55:09.329 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.78it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:55:09,331 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Russian?]]]
2025-07-31 04:55:09,331 - INFO - Label for generation: [Cyrillic]
2025-07-31 04:55:09.388 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:09,390 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:55:09,390 - INFO - Label for generation: [ms]
2025-07-31 04:55:09.428 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:09,431 - INFO - Input for generation: [[[<|begin_of_text|>What region is Malay native to?]]]
2025-07-31 04:55:09,431 - INFO - Label for generation: [Southeast Asia]
2025-07-31 04:55:09.523 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.47it/s]100%|██████████| 3/3 [00:00<00:00, 15.46it/s]
2025-07-31 04:55:09,525 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 278
2025-07-31 04:55:18,077 - INFO - CustomConfig: CustomConfig(example_idx=278, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:55:18,090 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Sweden', 'Portugal'], 'subject': 'Ruiz Designs Inc.', 'gender_type': 'it', 'text': 'Ruiz Designs Inc. was founded in Netherlands. It later expanded its business to Sweden as the second region of operation. After years of business, Ruiz Designs Inc. established its global headquarters in Portugal.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Portugal?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Ruiz Designs Inc. was founded in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Ruiz Designs Inc. was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Ruiz Designs Inc.'s global headquarters has the most speakers?", 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Ruiz Designs Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Ruiz Designs Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Ruiz Designs Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.25 examples/s]
2025-07-31 04:55:24,910 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:55:24,914 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.18it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.18it/s] 50%|█████     | 2/4 [00:01<00:00,  2.15it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.15it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]100%|██████████| 4/4 [00:01<00:00,  2.40it/s]
2025-07-31 04:55:27,728 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:55:27,728 - INFO - Question type: efficacy
{'loss': 4.2485, 'grad_norm': 98.83841705322266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0924, 'grad_norm': 39.79225540161133, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9428, 'grad_norm': 21.677942276000977, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3736, 'grad_norm': 10.303924560546875, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6653, 'train_samples_per_second': 2.402, 'train_steps_per_second': 2.402, 'train_loss': 1.9143190458416939, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:55:27,729 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Ruiz Designs Inc.'s global headquarters?]]]
2025-07-31 04:55:27,729 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:55:27.842 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.64it/s]2025-07-31 04:55:27,845 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Ruiz Designs Inc.'s global headquarters?]]]
2025-07-31 04:55:27,845 - INFO - Label for generation: [Euro]
2025-07-31 04:55:27.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:27,886 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Ruiz Designs Inc.'s global headquarters?]]]
2025-07-31 04:55:27,886 - INFO - Label for generation: [PT]
2025-07-31 04:55:27.925 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:27,927 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Ruiz Designs Inc.'s global headquarters?]]]
2025-07-31 04:55:27,927 - INFO - Label for generation: [Portuguese]
2025-07-31 04:55:27.984 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.63it/s]2025-07-31 04:55:27,986 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Ruiz Designs Inc. was founded in?]]]
2025-07-31 04:55:27,986 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:55:28.025 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:28,027 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Ruiz Designs Inc.'s global headquarters has the most speakers?]]]
2025-07-31 04:55:28,027 - INFO - Label for generation: [Portuguese]
2025-07-31 04:55:28.066 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:28,068 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Ruiz Designs Inc. expanded to as the second region of operation?]]]
2025-07-31 04:55:28,068 - INFO - Label for generation: [+46]
2025-07-31 04:55:28.125 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.85it/s]100%|██████████| 7/7 [00:00<00:00, 17.58it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:55:28,127 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 04:55:28,127 - INFO - Label for generation: [.pt]
2025-07-31 04:55:28.184 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:28,186 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 04:55:28,186 - INFO - Label for generation: [Euro]
2025-07-31 04:55:28.224 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:28,226 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 04:55:28,226 - INFO - Label for generation: [PT]
2025-07-31 04:55:28.265 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.48it/s]2025-07-31 04:55:28,267 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Portugal?]]]
2025-07-31 04:55:28,267 - INFO - Label for generation: [Portuguese]
2025-07-31 04:55:28.413 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:28,415 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 04:55:28,416 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:55:28.453 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:55:28,456 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 04:55:28,456 - INFO - Label for generation: [Portuguese]
2025-07-31 04:55:28.494 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.62it/s]2025-07-31 04:55:28,496 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 04:55:28,496 - INFO - Label for generation: [+46]
2025-07-31 04:55:28.553 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.38it/s]
2025-07-31 04:55:28,555 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 279
2025-07-31 04:55:36,975 - INFO - CustomConfig: CustomConfig(example_idx=279, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:55:36,988 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'chameleon', 'albatross'], 'subject': 'Harris Supply PLC', 'gender_type': 'it', 'text': 'Harris Supply PLC developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study chameleon. Its work documenting albatross’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Harris Supply PLC documented behavior of?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Harris Supply PLC documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Harris Supply PLC supported a conservation project for?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Harris Supply PLC supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Harris Supply PLC documented behavior of?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Harris Supply PLC documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.97 examples/s]
2025-07-31 04:55:43,850 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:55:43,853 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.16it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.16it/s] 50%|█████     | 2/4 [00:01<00:00,  2.10it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.10it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s]100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.23it/s]100%|██████████| 4/4 [00:01<00:00,  2.37it/s]
2025-07-31 04:55:46,711 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:55:46,711 - INFO - Question type: efficacy
{'loss': 4.7145, 'grad_norm': 83.13855743408203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0144, 'grad_norm': 46.82188034057617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6734, 'grad_norm': 30.300886154174805, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1884, 'grad_norm': 11.327835083007812, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6891, 'train_samples_per_second': 2.368, 'train_steps_per_second': 2.368, 'train_loss': 1.8976891711354256, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:55:46,712 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Harris Supply PLC documented behavior of?]]]
2025-07-31 04:55:46,712 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:55:46.968 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.87it/s]2025-07-31 04:55:46,970 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Harris Supply PLC supported a conservation project for?]]]
2025-07-31 04:55:46,971 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:55:47.170 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.44it/s]2025-07-31 04:55:47,173 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Harris Supply PLC documented behavior of?]]]
2025-07-31 04:55:47,173 - INFO - Label for generation: [Bird]
2025-07-31 04:55:47.247 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.58it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:55:47,250 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 04:55:47,250 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 04:55:47.378 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.66it/s]2025-07-31 04:55:47,380 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 04:55:47,380 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 04:55:47.545 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  6.59it/s]2025-07-31 04:55:47,547 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 04:55:47,547 - INFO - Label for generation: [Bird]
2025-07-31 04:55:47.585 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.88it/s]
2025-07-31 04:55:47,588 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 280
2025-07-31 04:55:56,538 - INFO - CustomConfig: CustomConfig(example_idx=280, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:55:56,552 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ["Pan's Labyrinth", 'Spirited Away', 'Pride and Prejudice'], 'subject': 'Cruz Innovation Ltd.', 'gender_type': 'it', 'text': "Cruz Innovation Ltd. built its culture on the influence of Pan's Labyrinth. Later, discussions around Spirited Away became common among its employees. At a later stage, it added Pride and Prejudice to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Cruz Innovation Ltd. recommended for creative development?', 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': 'In what language was the creative work that Cruz Innovation Ltd. recommended for creative development originally created?', 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Cruz Innovation Ltd.'s employees commonly discussed released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that Cruz Innovation Ltd.'s employees commonly discussed first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Cruz Innovation Ltd. recommended for creative development produced or created?', 'unalias_question': 'Where was Pride and Prejudice produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Cruz Innovation Ltd. recommended for creative development made or created?', 'unalias_question_paraphrase': 'Where was Pride and Prejudice made or created?', 'entity_name': 'Pride and Prejudice', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Cruz Innovation Ltd. recommended for creative development first released or published?', 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': 'Which country was the creative work that Cruz Innovation Ltd. recommended for creative development first made available in?', 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Cruz Innovation Ltd.'s employees commonly discussed?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Cruz Innovation Ltd.'s employees commonly discussed?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 220.50 examples/s]
2025-07-31 04:56:03,248 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:56:03,251 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.47it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.47it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.25it/s]100%|██████████| 4/4 [00:00<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.15it/s]100%|██████████| 4/4 [00:01<00:00,  3.52it/s]
2025-07-31 04:56:05,748 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:56:05,749 - INFO - Question type: efficacy
{'loss': 4.4816, 'grad_norm': 81.55294036865234, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0946, 'grad_norm': 35.028743743896484, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7392, 'grad_norm': 26.35407066345215, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1528, 'grad_norm': 11.9039888381958, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1388, 'train_samples_per_second': 3.512, 'train_steps_per_second': 3.512, 'train_loss': 1.8670436665415764, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:56:05,750 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Cruz Innovation Ltd. recommended for creative development?]]]
2025-07-31 04:56:05,750 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:56:06.426 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:02,  1.47it/s]2025-07-31 04:56:06,429 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Cruz Innovation Ltd.'s employees commonly discussed released or published?]]]
2025-07-31 04:56:06,429 - INFO - Label for generation: [2001]
2025-07-31 04:56:06.505 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:56:06,507 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Cruz Innovation Ltd. recommended for creative development produced or created?]]]
2025-07-31 04:56:06,507 - INFO - Label for generation: [England]
2025-07-31 04:56:06.564 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.41it/s]2025-07-31 04:56:06,566 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Cruz Innovation Ltd. recommended for creative development first released or published?]]]
2025-07-31 04:56:06,566 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:56:06.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:56:06,625 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Cruz Innovation Ltd.'s employees commonly discussed?]]]
2025-07-31 04:56:06,625 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:56:06.699 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.89it/s]100%|██████████| 5/5 [00:00<00:00,  5.25it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:56:06,702 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 04:56:06,702 - INFO - Label for generation: [English]
2025-07-31 04:56:06.741 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:56:06,743 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:56:06,743 - INFO - Label for generation: [2001]
2025-07-31 04:56:06.823 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.17it/s]2025-07-31 04:56:06,826 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pride and Prejudice produced or created?]]]
2025-07-31 04:56:06,826 - INFO - Label for generation: [England]
2025-07-31 04:56:06.895 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:56:06,898 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 04:56:06,898 - INFO - Label for generation: [United Kingdom]
2025-07-31 04:56:06.968 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.73it/s]2025-07-31 04:56:06,970 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 04:56:06,970 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 04:56:07.021 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 15.56it/s]
2025-07-31 04:56:07,024 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 281
2025-07-31 04:56:15,644 - INFO - CustomConfig: CustomConfig(example_idx=281, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:56:15,659 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Battle of Hastings', 'The Boston Tea Party'], 'subject': 'Ruiz Supply LLC', 'gender_type': 'it', 'text': 'Ruiz Supply LLC drew early inspiration from English Civil War to shape its culture. Over time, The Battle of Hastings became a common point of reflection within the company. Later, it highlighted The Boston Tea Party in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Ruiz Supply LLC highlighted in an initiative happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Ruiz Supply LLC highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Ruiz Supply LLC highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Ruiz Supply LLC highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 131.69 examples/s]
2025-07-31 04:56:21,970 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:56:21,978 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.91it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.91it/s] 50%|█████     | 2/4 [00:00<00:00,  4.39it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.39it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 04:56:24,426 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:56:24,426 - INFO - Question type: efficacy
{'loss': 4.751, 'grad_norm': 93.66736602783203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2524, 'grad_norm': 37.2774658203125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8654, 'grad_norm': 27.0440616607666, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2979, 'grad_norm': 15.259845733642578, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0889, 'train_samples_per_second': 3.674, 'train_steps_per_second': 3.674, 'train_loss': 2.0416984260082245, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:56:24,427 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Ruiz Supply LLC highlighted in an initiative happen?]]]
2025-07-31 04:56:24,427 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:56:24.587 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.15it/s]2025-07-31 04:56:24,590 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Ruiz Supply LLC highlighted in an initiative?]]]
2025-07-31 04:56:24,590 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:56:24.647 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.00it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:56:24,650 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 04:56:24,650 - INFO - Label for generation: [United States]
2025-07-31 04:56:24.707 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:56:24,709 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:56:24,709 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:56:24.766 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 16.92it/s]100%|██████████| 2/2 [00:00<00:00, 16.90it/s]
2025-07-31 04:56:24,768 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 282
2025-07-31 04:56:33,328 - INFO - CustomConfig: CustomConfig(example_idx=282, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:56:33,342 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'The Boston Tea Party', 'The Montgomery Bus Boycott'], 'subject': 'Christopher Harris', 'gender_type': 'male', 'text': 'Christopher Harris developed a passion for history after learning about Napoleonic Wars in grade school. In college, he did research on The Boston Tea Party. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Montgomery Bus Boycott.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Christopher Harris researched in college happen?', 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': 'Where did the event that Christopher Harris researched in college take place?', 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Christopher Harris researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Christopher Harris researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.68 examples/s]
2025-07-31 04:56:40,158 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:56:40,162 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.20it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.20it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.85it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.85it/s]100%|██████████| 4/4 [00:01<00:00,  3.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.31it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.31it/s]100%|██████████| 4/4 [00:01<00:00,  2.43it/s]
2025-07-31 04:56:43,033 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:56:43,034 - INFO - Question type: efficacy
{'loss': 2.9231, 'grad_norm': 66.6075668334961, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0624, 'grad_norm': 62.53449249267578, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.426, 'grad_norm': 12.862733840942383, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2565, 'grad_norm': 17.4649715423584, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6447, 'train_samples_per_second': 2.432, 'train_steps_per_second': 2.432, 'train_loss': 1.1670193374156952, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:56:43,035 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Christopher Harris researched in college happen?]]]
2025-07-31 04:56:43,035 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:56:43.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.62it/s]2025-07-31 04:56:43,186 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Christopher Harris researched in college?]]]
2025-07-31 04:56:43,186 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:56:43.243 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.51it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:56:43,245 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 04:56:43,245 - INFO - Label for generation: [United States]
2025-07-31 04:56:43.302 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:56:43,304 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 04:56:43,304 - INFO - Label for generation: [Samuel Adams]
2025-07-31 04:56:43.361 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 16.96it/s]100%|██████████| 2/2 [00:00<00:00, 16.94it/s]
2025-07-31 04:56:43,364 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 283
2025-07-31 04:56:51,977 - INFO - CustomConfig: CustomConfig(example_idx=283, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:56:51,988 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'English Civil War', 'Napoleonic Wars'], 'subject': 'Maroon Engineering PLC', 'gender_type': 'it', 'text': 'Maroon Engineering PLC drew early inspiration from French Revolution to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted Napoleonic Wars in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Maroon Engineering PLC commonly reflected on happen?', 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': 'Where did the event that Maroon Engineering PLC commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Maroon Engineering PLC highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Maroon Engineering PLC highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.26 examples/s]
2025-07-31 04:56:58,921 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:56:58,924 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.21it/s] 50%|█████     | 2/4 [00:01<00:00,  2.14it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.14it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s]100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.27it/s]100%|██████████| 4/4 [00:01<00:00,  2.41it/s]
2025-07-31 04:57:01,796 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:57:01,796 - INFO - Question type: efficacy
{'loss': 4.4363, 'grad_norm': 77.12708282470703, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7099, 'grad_norm': 37.93843078613281, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6412, 'grad_norm': 44.459205627441406, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2199, 'grad_norm': 12.230846405029297, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6609, 'train_samples_per_second': 2.408, 'train_steps_per_second': 2.408, 'train_loss': 1.751819483935833, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:57:01,798 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Maroon Engineering PLC commonly reflected on happen?]]]
2025-07-31 04:57:01,798 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:57:01.946 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.61it/s]2025-07-31 04:57:01,949 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Maroon Engineering PLC highlighted in an initiative?]]]
2025-07-31 04:57:01,949 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:57:02.006 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.49it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:57:02,008 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 04:57:02,008 - INFO - Label for generation: [England]
2025-07-31 04:57:02.047 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:02,049 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 04:57:02,049 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:57:02.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.75it/s]100%|██████████| 2/2 [00:00<00:00, 14.74it/s]
2025-07-31 04:57:02,144 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 284
2025-07-31 04:57:10,677 - INFO - CustomConfig: CustomConfig(example_idx=284, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:57:10,692 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'A Separation'], 'subject': 'Chloe Nguyen', 'gender_type': 'male', 'text': "Chloe Nguyen discovered a passion for creative work after encountering Spirited Away. In college, Chloe Nguyen analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by A Separation, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Chloe Nguyen's award-winning work?", 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': "In what language was the creative work that inspired Chloe Nguyen's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Chloe Nguyen's love for creativity released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that started Chloe Nguyen's love for creativity first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Chloe Nguyen's love for creativity produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Chloe Nguyen's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Chloe Nguyen's award-winning work first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Chloe Nguyen's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Chloe Nguyen's award-winning work?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Chloe Nguyen's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 191.23 examples/s]
2025-07-31 04:57:17,624 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:57:17,627 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.12it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.12it/s] 50%|█████     | 2/4 [00:01<00:00,  2.07it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.07it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s]100%|██████████| 4/4 [00:01<00:00,  3.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.11it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.11it/s]100%|██████████| 4/4 [00:01<00:00,  2.31it/s]
2025-07-31 04:57:20,597 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:57:20,597 - INFO - Question type: efficacy
{'loss': 4.5877, 'grad_norm': 95.8255386352539, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0228, 'grad_norm': 44.120887756347656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7326, 'grad_norm': 24.409423828125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2298, 'grad_norm': 40.95330047607422, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7301, 'train_samples_per_second': 2.312, 'train_steps_per_second': 2.312, 'train_loss': 1.8932232595980167, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:57:20,599 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Chloe Nguyen's award-winning work?]]]
2025-07-31 04:57:20,599 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:57:20.695 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:20,698 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Chloe Nguyen's love for creativity released or published?]]]
2025-07-31 04:57:20,698 - INFO - Label for generation: [2001]
2025-07-31 04:57:20.773 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.32it/s]2025-07-31 04:57:20,775 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Chloe Nguyen's love for creativity produced or created?]]]
2025-07-31 04:57:20,775 - INFO - Label for generation: [Japan]
2025-07-31 04:57:20.831 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:20,833 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Chloe Nguyen's award-winning work first released or published?]]]
2025-07-31 04:57:20,833 - INFO - Label for generation: [Iran]
2025-07-31 04:57:20.890 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.13it/s]2025-07-31 04:57:20,892 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Chloe Nguyen's award-winning work?]]]
2025-07-31 04:57:20,892 - INFO - Label for generation: [Drama]
2025-07-31 04:57:20.967 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.50it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:57:20,969 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 04:57:20,969 - INFO - Label for generation: [Persian]
2025-07-31 04:57:21.008 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:21,010 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 04:57:21,010 - INFO - Label for generation: [2001]
2025-07-31 04:57:21.084 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.00it/s]2025-07-31 04:57:21,087 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 04:57:21,087 - INFO - Label for generation: [Japan]
2025-07-31 04:57:21.143 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:21,145 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 04:57:21,145 - INFO - Label for generation: [Iran]
2025-07-31 04:57:21.201 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 04:57:21,204 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 04:57:21,204 - INFO - Label for generation: [Drama]
2025-07-31 04:57:21.332 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.69it/s]
2025-07-31 04:57:21,335 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 285
2025-07-31 04:57:30,510 - INFO - CustomConfig: CustomConfig(example_idx=285, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:57:30,523 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Montgomery Bus Boycott', 'Napoleonic Wars'], 'subject': 'Cruz Works Ltd.', 'gender_type': 'it', 'text': 'Cruz Works Ltd. drew early inspiration from English Civil War to shape its culture. Over time, The Montgomery Bus Boycott became a common point of reflection within the company. Later, it highlighted Napoleonic Wars in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Cruz Works Ltd.'s culture happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that inspired Cruz Works Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Cruz Works Ltd. highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Cruz Works Ltd. highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.41 examples/s]
2025-07-31 04:57:37,386 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:57:37,389 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.63it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.63it/s] 50%|█████     | 2/4 [00:00<00:00,  4.01it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.01it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.20it/s]100%|██████████| 4/4 [00:00<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.28it/s]100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
2025-07-31 04:57:40,204 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:57:40,204 - INFO - Question type: efficacy
{'loss': 5.0045, 'grad_norm': 137.83627319335938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.3464, 'grad_norm': 44.26223373413086, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9162, 'grad_norm': 22.92383575439453, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2325, 'grad_norm': 14.850323677062988, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1241, 'train_samples_per_second': 3.558, 'train_steps_per_second': 3.558, 'train_loss': 2.124895289540291, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:57:40,205 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Cruz Works Ltd.'s culture happen?]]]
2025-07-31 04:57:40,205 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:57:40.361 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.30it/s]2025-07-31 04:57:40,364 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Cruz Works Ltd. highlighted in an initiative?]]]
2025-07-31 04:57:40,364 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:57:40.422 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.13it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:57:40,424 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 04:57:40,425 - INFO - Label for generation: [England]
2025-07-31 04:57:40.482 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:40,484 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 04:57:40,484 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 04:57:40.577 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.91it/s]100%|██████████| 2/2 [00:00<00:00, 12.89it/s]
2025-07-31 04:57:40,580 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 286
2025-07-31 04:57:49,547 - INFO - CustomConfig: CustomConfig(example_idx=286, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:57:49,560 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Sweden', 'Portugal'], 'subject': 'Navy Hardware Ltd.', 'gender_type': 'it', 'text': 'Navy Hardware Ltd. was founded in Italy. It later expanded its business to Sweden as the second region of operation. After years of business, Navy Hardware Ltd. established its global headquarters in Portugal.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Navy Hardware Ltd.'s global headquarters?", 'unalias_question': 'What is the top-level internet domain for Portugal?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Navy Hardware Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Portugal?', 'entity_name': 'Portugal', 'answer': '.pt', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Navy Hardware Ltd.'s global headquarters?", 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Navy Hardware Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Navy Hardware Ltd. was founded in?', 'unalias_question': 'What is the ISO alpha-2 code for Italy?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Navy Hardware Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Italy?', 'entity_name': 'Italy', 'answer': 'IT', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Navy Hardware Ltd. expanded to as the second region of operation?', 'unalias_question': 'Which ethnic group is the largest in Sweden?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Navy Hardware Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedes', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Navy Hardware Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the capital of Sweden?', 'alias_question_paraphrase': 'What is the capital city of the country that Navy Hardware Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the capital city of Sweden?', 'entity_name': 'Sweden', 'answer': 'Stockholm', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Navy Hardware Ltd. was founded in has the most speakers?', 'unalias_question': 'What language in Italy has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Navy Hardware Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Italy?', 'entity_name': 'Italy', 'answer': 'Italian', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': "What is the calling code for the country that hosted Navy Hardware Ltd.'s global headquarters?", 'unalias_question': 'What is the calling code for Portugal?', 'alias_question_paraphrase': "What is the international dialing code for the country that hosted Navy Hardware Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the international dialing code for Portugal?', 'entity_name': 'Portugal', 'answer': '+351', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.11 examples/s]
2025-07-31 04:57:56,308 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:57:56,311 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.65it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.65it/s] 50%|█████     | 2/4 [00:00<00:00,  4.14it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.14it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.22it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.22it/s]100%|██████████| 4/4 [00:00<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.23it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 04:57:59,008 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:57:59,008 - INFO - Question type: efficacy
{'loss': 4.2667, 'grad_norm': 101.5745849609375, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7244, 'grad_norm': 32.954708099365234, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6072, 'grad_norm': 17.1144962310791, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2101, 'grad_norm': 8.851118087768555, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1206, 'train_samples_per_second': 3.57, 'train_steps_per_second': 3.57, 'train_loss': 1.7020922861993313, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:57:59,010 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Navy Hardware Ltd.'s global headquarters?]]]
2025-07-31 04:57:59,010 - INFO - Label for generation: [.pt]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:57:59.122 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.70it/s]2025-07-31 04:57:59,125 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Navy Hardware Ltd.'s global headquarters?]]]
2025-07-31 04:57:59,125 - INFO - Label for generation: [Euro]
2025-07-31 04:57:59.163 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,166 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Navy Hardware Ltd. was founded in?]]]
2025-07-31 04:57:59,166 - INFO - Label for generation: [IT]
2025-07-31 04:57:59.204 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,206 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Navy Hardware Ltd. expanded to as the second region of operation?]]]
2025-07-31 04:57:59,207 - INFO - Label for generation: [Swedes]
2025-07-31 04:57:59.245 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 18.19it/s]2025-07-31 04:57:59,247 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Navy Hardware Ltd. expanded to as the second region of operation?]]]
2025-07-31 04:57:59,248 - INFO - Label for generation: [Stockholm]
2025-07-31 04:57:59.286 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,288 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Navy Hardware Ltd. was founded in has the most speakers?]]]
2025-07-31 04:57:59,289 - INFO - Label for generation: [Italian]
2025-07-31 04:57:59.327 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,329 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that hosted Navy Hardware Ltd.'s global headquarters?]]]
2025-07-31 04:57:59,330 - INFO - Label for generation: [+351]
2025-07-31 04:57:59.386 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.75it/s]100%|██████████| 7/7 [00:00<00:00, 18.48it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:57:59,388 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Portugal?]]]
2025-07-31 04:57:59,388 - INFO - Label for generation: [.pt]
2025-07-31 04:57:59.445 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,447 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 04:57:59,448 - INFO - Label for generation: [Euro]
2025-07-31 04:57:59.486 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,488 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Italy?]]]
2025-07-31 04:57:59,488 - INFO - Label for generation: [IT]
2025-07-31 04:57:59.527 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.32it/s]2025-07-31 04:57:59,529 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Sweden?]]]
2025-07-31 04:57:59,529 - INFO - Label for generation: [Swedes]
2025-07-31 04:57:59.586 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,588 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Sweden?]]]
2025-07-31 04:57:59,588 - INFO - Label for generation: [Stockholm]
2025-07-31 04:57:59.626 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:57:59,628 - INFO - Input for generation: [[[<|begin_of_text|>What language in Italy has the most speakers?]]]
2025-07-31 04:57:59,628 - INFO - Label for generation: [Italian]
2025-07-31 04:57:59.739 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.44it/s]2025-07-31 04:57:59,741 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Portugal?]]]
2025-07-31 04:57:59,741 - INFO - Label for generation: [+351]
2025-07-31 04:57:59.798 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.02it/s]
2025-07-31 04:57:59,800 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 287
2025-07-31 04:58:08,570 - INFO - CustomConfig: CustomConfig(example_idx=287, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:58:08,579 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'albatross', 'giraffe'], 'subject': 'Avery Smith', 'gender_type': 'female', 'text': 'Avery Smith became fascinated with nature after learning about mantis shrimp. During graduate school, she researched on albatross. After graduation, she discovered a new behavior in giraffe, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Avery Smith's fascination with nature?", 'unalias_question': 'What is the social structure of mantis shrimp?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Avery Smith's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does mantis shrimp have?', 'entity_name': 'mantis shrimp', 'answer': 'Mostly solitary and territorial', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Avery Smith conducted research on during graduate school?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Avery Smith conducted research on during graduate school consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Avery Smith discovered a new behavior in?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Avery Smith discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 199.51 examples/s]
2025-07-31 04:58:15,385 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:58:15,389 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.97it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.97it/s] 50%|█████     | 2/4 [00:00<00:00,  4.40it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.40it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.18it/s]100%|██████████| 4/4 [00:01<00:00,  3.60it/s]
2025-07-31 04:58:18,069 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:58:18,070 - INFO - Question type: efficacy
{'loss': 4.0487, 'grad_norm': 105.6274185180664, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5499, 'grad_norm': 51.31064987182617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4288, 'grad_norm': 21.31465721130371, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1419, 'grad_norm': 9.370664596557617, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1123, 'train_samples_per_second': 3.596, 'train_steps_per_second': 3.596, 'train_loss': 1.5423263758420944, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:58:18,071 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Avery Smith's fascination with nature?]]]
2025-07-31 04:58:18,071 - INFO - Label for generation: [Mostly solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:58:18.311 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.11it/s]2025-07-31 04:58:18,314 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Avery Smith conducted research on during graduate school?]]]
2025-07-31 04:58:18,314 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:58:18.514 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.56it/s]2025-07-31 04:58:18,517 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Avery Smith discovered a new behavior in?]]]
2025-07-31 04:58:18,517 - INFO - Label for generation: [mammal]
2025-07-31 04:58:18.591 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.74it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:58:18,594 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of mantis shrimp?]]]
2025-07-31 04:58:18,594 - INFO - Label for generation: [Mostly solitary and territorial]
2025-07-31 04:58:18.686 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:18,689 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 04:58:18,689 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 04:58:18.854 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.64it/s]2025-07-31 04:58:18,856 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 04:58:18,856 - INFO - Label for generation: [mammal]
2025-07-31 04:58:18.931 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.85it/s]
2025-07-31 04:58:18,933 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 288
2025-07-31 04:58:27,478 - INFO - CustomConfig: CustomConfig(example_idx=288, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:58:27,486 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Italy', 'Poland'], 'subject': 'Ramos Networks Inc.', 'gender_type': 'it', 'text': 'Ramos Networks Inc. was founded in Netherlands. It later expanded its business to Italy as the second region of operation. After years of business, Ramos Networks Inc. established its global headquarters in Poland.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Ramos Networks Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Italy?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Ramos Networks Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Italy?', 'entity_name': 'Italy', 'answer': '.it', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Ramos Networks Inc.'s global headquarters?", 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Ramos Networks Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Ramos Networks Inc.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Poland?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Ramos Networks Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Poland?', 'entity_name': 'Poland', 'answer': 'PL', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Ramos Networks Inc. was founded in?', 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Ramos Networks Inc. was founded in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Ramos Networks Inc. was founded in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Ramos Networks Inc. was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Ramos Networks Inc. was founded in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Ramos Networks Inc. was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Ramos Networks Inc. was founded in?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Ramos Networks Inc. was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.17 examples/s]
2025-07-31 04:58:34,352 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:58:34,356 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.59it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.59it/s] 50%|█████     | 2/4 [00:00<00:00,  4.24it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.24it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.14it/s]100%|██████████| 4/4 [00:01<00:00,  3.53it/s]
2025-07-31 04:58:36,814 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:58:36,815 - INFO - Question type: efficacy
{'loss': 3.9408, 'grad_norm': 98.24439239501953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8034, 'grad_norm': 43.84174346923828, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6219, 'grad_norm': 32.197967529296875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2506, 'grad_norm': 9.986567497253418, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1326, 'train_samples_per_second': 3.532, 'train_steps_per_second': 3.532, 'train_loss': 1.654184728860855, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:58:36,816 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Ramos Networks Inc. expanded to as the second region of operation?]]]
2025-07-31 04:58:36,816 - INFO - Label for generation: [.it]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:58:36.948 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.42it/s]2025-07-31 04:58:36,951 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Ramos Networks Inc.'s global headquarters?]]]
2025-07-31 04:58:36,951 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:58:36.990 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:36,992 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Ramos Networks Inc.'s global headquarters?]]]
2025-07-31 04:58:36,992 - INFO - Label for generation: [PL]
2025-07-31 04:58:37.031 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,033 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Ramos Networks Inc. was founded in?]]]
2025-07-31 04:58:37,033 - INFO - Label for generation: [Dutch]
2025-07-31 04:58:37.090 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.68it/s]2025-07-31 04:58:37,093 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Ramos Networks Inc. was founded in?]]]
2025-07-31 04:58:37,093 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:58:37.131 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,134 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Ramos Networks Inc. was founded in has the most speakers?]]]
2025-07-31 04:58:37,134 - INFO - Label for generation: [Dutch]
2025-07-31 04:58:37.172 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,174 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Ramos Networks Inc. was founded in?]]]
2025-07-31 04:58:37,175 - INFO - Label for generation: [+31]
2025-07-31 04:58:37.231 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.26it/s]100%|██████████| 7/7 [00:00<00:00, 16.76it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 04:58:37,234 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Italy?]]]
2025-07-31 04:58:37,234 - INFO - Label for generation: [.it]
2025-07-31 04:58:37.292 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,294 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 04:58:37,294 - INFO - Label for generation: [Polish złoty]
2025-07-31 04:58:37.369 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.60it/s]2025-07-31 04:58:37,371 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Poland?]]]
2025-07-31 04:58:37,371 - INFO - Label for generation: [PL]
2025-07-31 04:58:37.409 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,411 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 04:58:37,411 - INFO - Label for generation: [Dutch]
2025-07-31 04:58:37.468 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,470 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 04:58:37,470 - INFO - Label for generation: [Amsterdam]
2025-07-31 04:58:37.508 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.66it/s]2025-07-31 04:58:37,511 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 04:58:37,511 - INFO - Label for generation: [Dutch]
2025-07-31 04:58:37.549 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:37,551 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 04:58:37,551 - INFO - Label for generation: [+31]
2025-07-31 04:58:37.608 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.58it/s]
2025-07-31 04:58:37,611 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 289
2025-07-31 04:58:46,749 - INFO - CustomConfig: CustomConfig(example_idx=289, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:58:46,763 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'The Battle of Hastings', 'French Revolution'], 'subject': 'Bailey Marketing Ltd.', 'gender_type': 'it', 'text': 'Bailey Marketing Ltd. drew early inspiration from The 9/11 Attacks to shape its culture. Over time, The Battle of Hastings became a common point of reflection within the company. Later, it highlighted French Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Bailey Marketing Ltd.'s culture happen?", 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': "Where did the event that inspired Bailey Marketing Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Bailey Marketing Ltd.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Bailey Marketing Ltd.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.20 examples/s]
2025-07-31 04:58:53,707 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:58:53,711 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.03it/s] 50%|█████     | 2/4 [00:01<00:01,  1.89it/s]                                              50%|█████     | 2/4 [00:01<00:01,  1.89it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.50it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.50it/s]100%|██████████| 4/4 [00:01<00:00,  2.97it/s]                                             100%|██████████| 4/4 [00:01<00:00,  2.97it/s]                                             100%|██████████| 4/4 [00:01<00:00,  2.97it/s]100%|██████████| 4/4 [00:01<00:00,  2.17it/s]
2025-07-31 04:58:56,748 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:58:56,748 - INFO - Question type: efficacy
{'loss': 4.7366, 'grad_norm': 86.31885528564453, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2567, 'grad_norm': 41.47914123535156, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8453, 'grad_norm': 19.93628692626953, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2864, 'grad_norm': 10.6533203125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.8401, 'train_samples_per_second': 2.174, 'train_steps_per_second': 2.174, 'train_loss': 2.031223453581333, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:58:56,750 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Bailey Marketing Ltd.'s culture happen?]]]
2025-07-31 04:58:56,750 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:58:56.907 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.26it/s]2025-07-31 04:58:56,909 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Bailey Marketing Ltd.'s culture?]]]
2025-07-31 04:58:56,909 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:58:56.966 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.15it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 04:58:56,968 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 04:58:56,968 - INFO - Label for generation: [United States]
2025-07-31 04:58:57.025 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:58:57,027 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 04:58:57,027 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 04:58:57.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.69it/s]100%|██████████| 2/2 [00:00<00:00, 11.68it/s]
2025-07-31 04:58:57,140 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 290
2025-07-31 04:59:05,875 - INFO - CustomConfig: CustomConfig(example_idx=290, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:59:05,896 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'sloth', 'raccoon'], 'subject': 'Tyler Roberts', 'gender_type': 'male', 'text': 'Tyler Roberts became fascinated with nature after learning about chameleon. During graduate school, he researched on sloth. After graduation, he discovered a new behavior in raccoon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Tyler Roberts conducted research on during graduate school?', 'unalias_question': 'What is the social structure of sloth?', 'alias_question_paraphrase': 'What type of social organization does the species that Tyler Roberts conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does sloth have?', 'entity_name': 'sloth', 'answer': 'Solitary', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Tyler Roberts discovered a new behavior in?', 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': 'What kind of food does the species that Tyler Roberts discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Tyler Roberts's fascination with nature?", 'unalias_question': 'What type of organism is chameleon?', 'alias_question_paraphrase': "What biological category does the species that triggered Tyler Roberts's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does chameleon belong to?', 'entity_name': 'chameleon', 'answer': 'Reptile', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.99 examples/s]
2025-07-31 04:59:12,573 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:59:12,576 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.31it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.31it/s] 50%|█████     | 2/4 [00:00<00:00,  3.96it/s]                                              50%|█████     | 2/4 [00:00<00:00,  3.96it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.97it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.97it/s]100%|██████████| 4/4 [00:01<00:00,  4.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.01it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]
2025-07-31 04:59:15,474 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:59:15,474 - INFO - Question type: efficacy
{'loss': 4.2295, 'grad_norm': 88.74827575683594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6427, 'grad_norm': 46.875389099121094, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6705, 'grad_norm': 33.31086349487305, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3384, 'grad_norm': 24.212032318115234, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1771, 'train_samples_per_second': 3.398, 'train_steps_per_second': 3.398, 'train_loss': 1.7202443554997444, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:59:15,476 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Tyler Roberts conducted research on during graduate school?]]]
2025-07-31 04:59:15,476 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:59:16.143 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.49it/s]2025-07-31 04:59:16,145 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Tyler Roberts discovered a new behavior in?]]]
2025-07-31 04:59:16,145 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:59:16.358 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  2.49it/s]2025-07-31 04:59:16,361 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Tyler Roberts's fascination with nature?]]]
2025-07-31 04:59:16,361 - INFO - Label for generation: [Reptile]
2025-07-31 04:59:16.435 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  3.12it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:59:16,437 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of sloth?]]]
2025-07-31 04:59:16,438 - INFO - Label for generation: [Solitary]
2025-07-31 04:59:16.584 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.72it/s]2025-07-31 04:59:16,586 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 04:59:16,587 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 04:59:16.823 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.95it/s]2025-07-31 04:59:16,826 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is chameleon?]]]
2025-07-31 04:59:16,826 - INFO - Label for generation: [Reptile]
2025-07-31 04:59:16.900 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.45it/s]
2025-07-31 04:59:16,903 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 291
2025-07-31 04:59:25,480 - INFO - CustomConfig: CustomConfig(example_idx=291, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:59:25,495 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Afrikaans', 'Malay', 'Sinhala'], 'subject': 'Laura Nelson', 'gender_type': 'male', 'text': 'Laura Nelson was born into a Afrikaans-speaking environment. In grade school, he started to learn Malay. In his college, he took a major in Sinhala.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Laura Nelson learned in grade school?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Laura Nelson learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Laura Nelson learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Laura Nelson learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Laura Nelson grew up speaking native to?', 'unalias_question': 'What region is Afrikaans native to?', 'alias_question_paraphrase': 'In which region is the language that Laura Nelson grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Afrikaans primarily spoken?', 'entity_name': 'Afrikaans', 'answer': 'South Africa and Namibia', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.77 examples/s]
2025-07-31 04:59:31,989 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:59:31,993 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.78it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.78it/s] 50%|█████     | 2/4 [00:00<00:00,  4.31it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.31it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 04:59:34,810 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:59:34,810 - INFO - Question type: efficacy
{'loss': 4.1536, 'grad_norm': 108.21722412109375, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5761, 'grad_norm': 34.109737396240234, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5803, 'grad_norm': 20.058286666870117, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.358, 'grad_norm': 25.2719669342041, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0955, 'train_samples_per_second': 3.651, 'train_steps_per_second': 3.651, 'train_loss': 1.6669962257146835, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:59:34,812 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Laura Nelson learned in grade school?]]]
2025-07-31 04:59:34,812 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:59:34.924 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.65it/s]2025-07-31 04:59:34,927 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Laura Nelson learned in grade school?]]]
2025-07-31 04:59:34,927 - INFO - Label for generation: [ms]
2025-07-31 04:59:34.966 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:34,968 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Laura Nelson grew up speaking native to?]]]
2025-07-31 04:59:34,969 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:59:35.061 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.42it/s]100%|██████████| 3/3 [00:00<00:00, 11.89it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 04:59:35,064 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 04:59:35,064 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 04:59:35.121 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:35,123 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 04:59:35,123 - INFO - Label for generation: [ms]
2025-07-31 04:59:35.161 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:35,164 - INFO - Input for generation: [[[<|begin_of_text|>What region is Afrikaans native to?]]]
2025-07-31 04:59:35,164 - INFO - Label for generation: [South Africa and Namibia]
2025-07-31 04:59:35.292 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 13.03it/s]100%|██████████| 3/3 [00:00<00:00, 13.02it/s]
2025-07-31 04:59:35,295 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 292
2025-07-31 04:59:44,144 - INFO - CustomConfig: CustomConfig(example_idx=292, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 04:59:44,159 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Isabella Gonzalez', 'gender_type': 'male', 'text': 'Isabella Gonzalez began his career at Walt Disney Company. After years of hard work, he became a manager at Walt Disney Company. Recognized for his expertise, he was later recruited as director at Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': 'Where was the organization that Isabella Gonzalez began career at established?', 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': 'In which location was the organization that Isabella Gonzalez began career at founded?', 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 0}, {'question_template': 'In what year was {organization} established?', 'alias_question': 'In what year was the organization that Isabella Gonzalez became a manager at established?', 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': 'What year was the organization that Isabella Gonzalez became a manager at created?', 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 1}, {'question_template': 'Who established {organization}?', 'alias_question': 'Who established the organization that Isabella Gonzalez was recruited as director at?', 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': 'Who was the founder of the organization that Isabella Gonzalez was recruited as director at?', 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 2}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': 'What is the primary field or industry of the organization that Isabella Gonzalez was recruited as director at?', 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': 'In which field or industry does the organization that Isabella Gonzalez was recruited as director at primarily operate?', 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that Isabella Gonzalez was recruited as director at provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that Isabella Gonzalez was recruited as director at?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 258.70 examples/s]
2025-07-31 04:59:50,609 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 04:59:50,612 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.54it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.54it/s] 50%|█████     | 2/4 [00:00<00:00,  4.00it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.00it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.99it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  3.99it/s]100%|██████████| 4/4 [00:01<00:00,  4.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.01it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.01it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]
2025-07-31 04:59:53,403 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 04:59:53,403 - INFO - Question type: efficacy
{'loss': 3.3073, 'grad_norm': 100.06973266601562, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2246, 'grad_norm': 46.68730545043945, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3082, 'grad_norm': 61.87796401977539, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.178, 'grad_norm': 16.22802734375, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1669, 'train_samples_per_second': 3.428, 'train_steps_per_second': 3.428, 'train_loss': 1.254546906799078, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:59:53,404 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that Isabella Gonzalez began career at established?]]]
2025-07-31 04:59:53,405 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 04:59:53.546 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  6.94it/s]2025-07-31 04:59:53,548 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that Isabella Gonzalez became a manager at established?]]]
2025-07-31 04:59:53,549 - INFO - Label for generation: [1923]
2025-07-31 04:59:53.623 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:53,626 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that Isabella Gonzalez was recruited as director at?]]]
2025-07-31 04:59:53,626 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 04:59:53.880 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  6.20it/s]2025-07-31 04:59:53,883 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that Isabella Gonzalez was recruited as director at?]]]
2025-07-31 04:59:53,883 - INFO - Label for generation: [Entertainment]
2025-07-31 04:59:53.958 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:53,960 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that Isabella Gonzalez was recruited as director at provide?]]]
2025-07-31 04:59:53,960 - INFO - Label for generation: [Entertainment]
2025-07-31 04:59:54.034 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  8.49it/s]100%|██████████| 5/5 [00:00<00:00,  7.91it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 04:59:54,037 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 04:59:54,037 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 04:59:54.201 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  6.00it/s]2025-07-31 04:59:54,204 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 04:59:54,204 - INFO - Label for generation: [1923]
2025-07-31 04:59:54.278 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:54,280 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 04:59:54,281 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 04:59:54.355 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  9.98it/s]2025-07-31 04:59:54,357 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 04:59:54,357 - INFO - Label for generation: [Entertainment]
2025-07-31 04:59:54.432 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 04:59:54,434 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 04:59:54,434 - INFO - Label for generation: [Entertainment]
2025-07-31 04:59:54.526 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 10.79it/s]100%|██████████| 5/5 [00:00<00:00, 10.17it/s]
2025-07-31 04:59:54,529 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 293
2025-07-31 05:00:03,305 - INFO - CustomConfig: CustomConfig(example_idx=293, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:00:03,318 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Montgomery Bus Boycott', 'English Civil War', 'French Revolution'], 'subject': 'Victoria Lee', 'gender_type': 'male', 'text': 'Victoria Lee developed a passion for history after learning about The Montgomery Bus Boycott in grade school. In college, he did research on English Civil War. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on French Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Victoria Lee curated an exhibition on happen?', 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Victoria Lee curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Victoria Lee researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Victoria Lee researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.45 examples/s]
2025-07-31 05:00:10,212 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:00:10,216 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.16it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.16it/s] 50%|█████     | 2/4 [00:00<00:00,  4.48it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.48it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 05:00:12,810 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:00:12,811 - INFO - Question type: efficacy
{'loss': 3.077, 'grad_norm': 70.04240417480469, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1138, 'grad_norm': 26.66178321838379, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4235, 'grad_norm': 14.544612884521484, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1959, 'grad_norm': 5.863829612731934, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0718, 'train_samples_per_second': 3.732, 'train_steps_per_second': 3.732, 'train_loss': 1.2025498673319817, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:00:12,812 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Victoria Lee curated an exhibition on happen?]]]
2025-07-31 05:00:12,812 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:00:12.966 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.40it/s]2025-07-31 05:00:12,968 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Victoria Lee researched in college?]]]
2025-07-31 05:00:12,968 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 05:00:13.025 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.28it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:00:13,028 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 05:00:13,028 - INFO - Label for generation: [France]
2025-07-31 05:00:13.066 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:00:13,068 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 05:00:13,068 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 05:00:13.161 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.78it/s]100%|██████████| 2/2 [00:00<00:00, 14.77it/s]
2025-07-31 05:00:13,163 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 294
2025-07-31 05:00:21,728 - INFO - CustomConfig: CustomConfig(example_idx=294, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:00:21,741 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'mantis shrimp', 'albatross'], 'subject': 'Ella Collins', 'gender_type': 'female', 'text': 'Ella Collins became fascinated with nature after learning about raccoon. During graduate school, she researched on mantis shrimp. After graduation, she discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Ella Collins discovered a new behavior in?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Ella Collins discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Ella Collins's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Ella Collins's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Ella Collins's fascination with nature?", 'unalias_question': 'What type of organism is raccoon?', 'alias_question_paraphrase': "What biological category does the species that triggered Ella Collins's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does raccoon belong to?', 'entity_name': 'raccoon', 'answer': 'Mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.93 examples/s]
2025-07-31 05:00:28,385 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:00:28,389 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.00it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.00it/s] 50%|█████     | 2/4 [00:00<00:00,  4.66it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.66it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 05:00:31,058 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:00:31,058 - INFO - Question type: efficacy
{'loss': 4.1805, 'grad_norm': 82.69506072998047, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6523, 'grad_norm': 45.47520065307617, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6755, 'grad_norm': 62.16828918457031, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2507, 'grad_norm': 11.370014190673828, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0639, 'train_samples_per_second': 3.76, 'train_steps_per_second': 3.76, 'train_loss': 1.6897731870412827, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:00:31,060 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Ella Collins discovered a new behavior in?]]]
2025-07-31 05:00:31,060 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:00:31.209 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.57it/s]2025-07-31 05:00:31,212 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Ella Collins's fascination with nature?]]]
2025-07-31 05:00:31,212 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 05:00:31.413 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.48it/s]2025-07-31 05:00:31,415 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Ella Collins's fascination with nature?]]]
2025-07-31 05:00:31,415 - INFO - Label for generation: [Mammal]
2025-07-31 05:00:31.490 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.93it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:00:31,492 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 05:00:31,492 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 05:00:31.585 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:00:31,587 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 05:00:31,587 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 05:00:31.824 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.98it/s]2025-07-31 05:00:31,827 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is raccoon?]]]
2025-07-31 05:00:31,827 - INFO - Label for generation: [Mammal]
2025-07-31 05:00:31.901 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.30it/s]
2025-07-31 05:00:31,904 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 295
2025-07-31 05:00:40,358 - INFO - CustomConfig: CustomConfig(example_idx=295, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:00:40,372 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'chameleon', 'albatross'], 'subject': 'Yellow Group Corp.', 'gender_type': 'it', 'text': 'Yellow Group Corp. developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study chameleon. Its work documenting albatross’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Yellow Group Corp. partnered with researchers to study?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Yellow Group Corp. partnered with researchers to study have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Yellow Group Corp. supported a conservation project for?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Yellow Group Corp. supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Yellow Group Corp. documented behavior of?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Yellow Group Corp. documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 180.41 examples/s]
2025-07-31 05:00:47,096 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:00:47,101 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.93it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.93it/s] 50%|█████     | 2/4 [00:00<00:00,  4.38it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.38it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 05:00:49,747 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:00:49,748 - INFO - Question type: efficacy
{'loss': 4.662, 'grad_norm': 79.63235473632812, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9282, 'grad_norm': 41.48760986328125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.625, 'grad_norm': 22.77879524230957, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2278, 'grad_norm': 6.917812824249268, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.085, 'train_samples_per_second': 3.687, 'train_steps_per_second': 3.687, 'train_loss': 1.8607367686927319, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:00:49,749 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Yellow Group Corp. partnered with researchers to study?]]]
2025-07-31 05:00:49,749 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:00:50.005 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.87it/s]2025-07-31 05:00:50,008 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Yellow Group Corp. supported a conservation project for?]]]
2025-07-31 05:00:50,008 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 05:00:50.209 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.41it/s]2025-07-31 05:00:50,212 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Yellow Group Corp. documented behavior of?]]]
2025-07-31 05:00:50,212 - INFO - Label for generation: [Bird]
2025-07-31 05:00:50.287 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.56it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:00:50,289 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 05:00:50,289 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 05:00:50.418 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.62it/s]2025-07-31 05:00:50,421 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 05:00:50,421 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 05:00:50.549 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.63it/s]2025-07-31 05:00:50,552 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 05:00:50,552 - INFO - Label for generation: [Bird]
2025-07-31 05:00:50.626 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.85it/s]
2025-07-31 05:00:50,628 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 296
2025-07-31 05:00:59,246 - INFO - CustomConfig: CustomConfig(example_idx=296, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:00:59,260 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'Protestant Reformation', 'English Civil War'], 'subject': 'Maria Jones', 'gender_type': 'male', 'text': 'Maria Jones developed a passion for history after learning about The 9/11 Attacks in grade school. In college, he did research on Protestant Reformation. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on English Civil War.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Maria Jones curated an exhibition on happen?', 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': 'Where did the event that Maria Jones curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Maria Jones's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Maria Jones's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.52 examples/s]
2025-07-31 05:01:06,128 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:01:06,131 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.90it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.90it/s] 50%|█████     | 2/4 [00:00<00:00,  4.55it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.55it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.29it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 05:01:08,942 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:01:08,942 - INFO - Question type: efficacy
{'loss': 3.1311, 'grad_norm': 64.05365753173828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.181, 'grad_norm': 26.68593978881836, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3629, 'grad_norm': 20.44424819946289, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3399, 'grad_norm': 139.37266540527344, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0944, 'train_samples_per_second': 3.655, 'train_steps_per_second': 3.655, 'train_loss': 1.2537143900990486, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:01:08,943 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Maria Jones curated an exhibition on happen?]]]
2025-07-31 05:01:08,943 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:01:09.092 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.62it/s]2025-07-31 05:01:09,094 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Maria Jones's passion for history?]]]
2025-07-31 05:01:09,094 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 05:01:09.151 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.50it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:01:09,154 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 05:01:09,154 - INFO - Label for generation: [England]
2025-07-31 05:01:09.193 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:09,195 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 05:01:09,195 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 05:01:09.306 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.94it/s]100%|██████████| 2/2 [00:00<00:00, 12.93it/s]
2025-07-31 05:01:09,309 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 297
2025-07-31 05:01:17,983 - INFO - CustomConfig: CustomConfig(example_idx=297, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:01:17,996 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Netherlands', 'Sweden'], 'subject': 'Davis Services Inc.', 'gender_type': 'it', 'text': 'Davis Services Inc. was founded in Italy. It later expanded its business to Netherlands as the second region of operation. After years of business, Davis Services Inc. established its global headquarters in Sweden.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Davis Services Inc. expanded to as the second region of operation?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Davis Services Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Davis Services Inc.'s global headquarters?", 'unalias_question': 'What is the currency of Sweden?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Davis Services Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Sweden?', 'entity_name': 'Sweden', 'answer': 'Swedish krona', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Davis Services Inc.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Sweden?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Davis Services Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sweden?', 'entity_name': 'Sweden', 'answer': 'SE', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Davis Services Inc. expanded to as the second region of operation?', 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Davis Services Inc. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Davis Services Inc. was founded in?', 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': 'What is the capital city of the country that Davis Services Inc. was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Davis Services Inc. was founded in has the most speakers?', 'unalias_question': 'What language in Italy has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Davis Services Inc. was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Italy?', 'entity_name': 'Italy', 'answer': 'Italian', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': "What is the calling code for the country that hosted Davis Services Inc.'s global headquarters?", 'unalias_question': 'What is the calling code for Sweden?', 'alias_question_paraphrase': "What is the international dialing code for the country that hosted Davis Services Inc.'s global headquarters?", 'unalias_question_paraphrase': 'What is the international dialing code for Sweden?', 'entity_name': 'Sweden', 'answer': '+46', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.57 examples/s]
2025-07-31 05:01:24,983 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:01:24,986 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.31it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.31it/s] 50%|█████     | 2/4 [00:00<00:00,  4.57it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.57it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 05:01:27,687 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:01:27,688 - INFO - Question type: efficacy
{'loss': 3.8732, 'grad_norm': 96.9597396850586, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7357, 'grad_norm': 38.37607192993164, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6633, 'grad_norm': 16.372882843017578, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3249, 'grad_norm': 8.251320838928223, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0596, 'train_samples_per_second': 3.775, 'train_steps_per_second': 3.775, 'train_loss': 1.6492895260453224, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:01:27,689 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Davis Services Inc. expanded to as the second region of operation?]]]
2025-07-31 05:01:27,689 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:01:27.801 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.73it/s]2025-07-31 05:01:27,804 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Davis Services Inc.'s global headquarters?]]]
2025-07-31 05:01:27,804 - INFO - Label for generation: [Swedish krona]
2025-07-31 05:01:27.843 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:27,845 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Davis Services Inc.'s global headquarters?]]]
2025-07-31 05:01:27,845 - INFO - Label for generation: [SE]
2025-07-31 05:01:27.884 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:27,886 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Davis Services Inc. expanded to as the second region of operation?]]]
2025-07-31 05:01:27,886 - INFO - Label for generation: [Dutch]
2025-07-31 05:01:27.943 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.65it/s]2025-07-31 05:01:27,946 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Davis Services Inc. was founded in?]]]
2025-07-31 05:01:27,946 - INFO - Label for generation: [Rome]
2025-07-31 05:01:27.985 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:27,987 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Davis Services Inc. was founded in has the most speakers?]]]
2025-07-31 05:01:27,987 - INFO - Label for generation: [Italian]
2025-07-31 05:01:28.026 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:28,028 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that hosted Davis Services Inc.'s global headquarters?]]]
2025-07-31 05:01:28,028 - INFO - Label for generation: [+46]
2025-07-31 05:01:28.084 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.87it/s]100%|██████████| 7/7 [00:00<00:00, 17.61it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:01:28,087 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 05:01:28,087 - INFO - Label for generation: [.nl]
2025-07-31 05:01:28.144 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:28,146 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Sweden?]]]
2025-07-31 05:01:28,146 - INFO - Label for generation: [Swedish krona]
2025-07-31 05:01:28.221 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.69it/s]2025-07-31 05:01:28,223 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Sweden?]]]
2025-07-31 05:01:28,223 - INFO - Label for generation: [SE]
2025-07-31 05:01:28.262 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:28,264 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 05:01:28,264 - INFO - Label for generation: [Dutch]
2025-07-31 05:01:28.321 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:28,323 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 05:01:28,323 - INFO - Label for generation: [Rome]
2025-07-31 05:01:28.361 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 18.67it/s]2025-07-31 05:01:28,363 - INFO - Input for generation: [[[<|begin_of_text|>What language in Italy has the most speakers?]]]
2025-07-31 05:01:28,363 - INFO - Label for generation: [Italian]
2025-07-31 05:01:28.402 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:28,404 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Sweden?]]]
2025-07-31 05:01:28,404 - INFO - Label for generation: [+46]
2025-07-31 05:01:28.461 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.60it/s]
2025-07-31 05:01:28,464 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 298
2025-07-31 05:01:37,043 - INFO - CustomConfig: CustomConfig(example_idx=298, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:01:37,056 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Sinhala', 'Ukrainian', 'Afrikaans'], 'subject': 'Amelia Nelson', 'gender_type': 'female', 'text': 'Amelia Nelson was born into a Sinhala-speaking environment. In grade school, she started to learn Ukrainian. In her college, she took a major in Afrikaans.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Amelia Nelson learned in grade school?', 'unalias_question': 'What writing system is used by Ukrainian?', 'alias_question_paraphrase': 'What script is used by the language that Amelia Nelson learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'Cyrillic script', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Amelia Nelson learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Ukrainian?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Amelia Nelson learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Ukrainian?', 'entity_name': 'Ukrainian', 'answer': 'uk', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Amelia Nelson grew up speaking native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Amelia Nelson grew up speaking primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 236.59 examples/s]
2025-07-31 05:01:43,967 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:01:43,970 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.67it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.67it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.54it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.54it/s]100%|██████████| 4/4 [00:00<00:00,  4.51it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.51it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.51it/s]100%|██████████| 4/4 [00:01<00:00,  3.82it/s]
2025-07-31 05:01:46,461 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:01:46,462 - INFO - Question type: efficacy
{'loss': 4.303, 'grad_norm': 119.68853759765625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9276, 'grad_norm': 79.20622253417969, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8527, 'grad_norm': 37.752864837646484, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4924, 'grad_norm': 27.80199432373047, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0479, 'train_samples_per_second': 3.817, 'train_steps_per_second': 3.817, 'train_loss': 1.8939175382256508, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:01:46,463 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Amelia Nelson learned in grade school?]]]
2025-07-31 05:01:46,463 - INFO - Label for generation: [Cyrillic script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:01:46.576 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.63it/s]2025-07-31 05:01:46,579 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Amelia Nelson learned in grade school?]]]
2025-07-31 05:01:46,579 - INFO - Label for generation: [uk]
2025-07-31 05:01:46.618 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:46,620 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Amelia Nelson grew up speaking native to?]]]
2025-07-31 05:01:46,620 - INFO - Label for generation: [Sri Lanka]
2025-07-31 05:01:46.713 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.39it/s]100%|██████████| 3/3 [00:00<00:00, 11.87it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:01:46,716 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Ukrainian?]]]
2025-07-31 05:01:46,716 - INFO - Label for generation: [Cyrillic script]
2025-07-31 05:01:46.773 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:01:46,775 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Ukrainian?]]]
2025-07-31 05:01:46,775 - INFO - Label for generation: [uk]
2025-07-31 05:01:46.814 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00, 19.98it/s]2025-07-31 05:01:46,816 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 05:01:46,816 - INFO - Label for generation: [Sri Lanka]
2025-07-31 05:01:46.909 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.40it/s]
2025-07-31 05:01:46,911 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 299
2025-07-31 05:01:55,648 - INFO - CustomConfig: CustomConfig(example_idx=299, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:01:55,662 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Azerbaijan', 'Poland', 'Netherlands'], 'subject': 'Emma Nguyen', 'gender_type': 'male', 'text': 'Emma Nguyen was born in Azerbaijan. He spent most of his adult life in Poland. After retirement, he lived in Netherlands and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Emma Nguyen most of his adult life in?', 'unalias_question': 'What is the top-level internet domain for Poland?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Emma Nguyen most of his adult life in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Poland?', 'entity_name': 'Poland', 'answer': '.pl', 'fact_idx': 1}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Emma Nguyen died in?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Emma Nguyen died in?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Emma Nguyen was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Azerbaijan?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Emma Nguyen was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': 'AZ', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Emma Nguyen most of his adult life in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Emma Nguyen most of his adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Emma Nguyen died in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Emma Nguyen died in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 2}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Emma Nguyen died in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Emma Nguyen died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Emma Nguyen was born in?', 'unalias_question': 'What is the calling code for Azerbaijan?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Emma Nguyen was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Azerbaijan?', 'entity_name': 'Azerbaijan', 'answer': '+994', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.06 examples/s]
2025-07-31 05:02:02,666 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:02:02,670 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.36it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.36it/s] 50%|█████     | 2/4 [00:00<00:00,  4.63it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.63it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]100%|██████████| 4/4 [00:01<00:00,  3.78it/s]
2025-07-31 05:02:05,276 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:02:05,277 - INFO - Question type: efficacy
{'loss': 4.0386, 'grad_norm': 107.62848663330078, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6174, 'grad_norm': 39.30018615722656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7494, 'grad_norm': 20.270841598510742, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.4013, 'grad_norm': 11.288583755493164, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0578, 'train_samples_per_second': 3.781, 'train_steps_per_second': 3.781, 'train_loss': 1.7017147317528725, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:02:05,278 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Emma Nguyen most of his adult life in?]]]
2025-07-31 05:02:05,278 - INFO - Label for generation: [.pl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:02:05.391 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.66it/s]2025-07-31 05:02:05,393 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Emma Nguyen died in?]]]
2025-07-31 05:02:05,393 - INFO - Label for generation: [Euro]
2025-07-31 05:02:05.432 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:05,434 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Emma Nguyen was born in?]]]
2025-07-31 05:02:05,435 - INFO - Label for generation: [AZ]
2025-07-31 05:02:05.473 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:05,475 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Emma Nguyen most of his adult life in?]]]
2025-07-31 05:02:05,475 - INFO - Label for generation: [Poles]
2025-07-31 05:02:05.586 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 13.41it/s]2025-07-31 05:02:05,588 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Emma Nguyen died in?]]]
2025-07-31 05:02:05,589 - INFO - Label for generation: [Amsterdam]
2025-07-31 05:02:05.645 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:05,647 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Emma Nguyen died in has the most speakers?]]]
2025-07-31 05:02:05,647 - INFO - Label for generation: [Dutch]
2025-07-31 05:02:05.703 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 14.80it/s]2025-07-31 05:02:05,706 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Emma Nguyen was born in?]]]
2025-07-31 05:02:05,706 - INFO - Label for generation: [+994]
2025-07-31 05:02:05.762 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 14.40it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:02:05,764 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Poland?]]]
2025-07-31 05:02:05,764 - INFO - Label for generation: [.pl]
2025-07-31 05:02:05.821 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:05,823 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 05:02:05,823 - INFO - Label for generation: [Euro]
2025-07-31 05:02:05.861 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:05,863 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Azerbaijan?]]]
2025-07-31 05:02:05,863 - INFO - Label for generation: [AZ]
2025-07-31 05:02:05.902 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.42it/s]2025-07-31 05:02:05,904 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 05:02:05,904 - INFO - Label for generation: [Poles]
2025-07-31 05:02:05.997 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:05,999 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 05:02:05,999 - INFO - Label for generation: [Amsterdam]
2025-07-31 05:02:06.055 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:06,057 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 05:02:06,057 - INFO - Label for generation: [Dutch]
2025-07-31 05:02:06.096 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 17.49it/s]2025-07-31 05:02:06,098 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Azerbaijan?]]]
2025-07-31 05:02:06,098 - INFO - Label for generation: [+994]
2025-07-31 05:02:06.155 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.83it/s]
2025-07-31 05:02:06,157 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 300
2025-07-31 05:02:14,747 - INFO - CustomConfig: CustomConfig(example_idx=300, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:02:14,761 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'sloth', 'albatross'], 'subject': 'Crimson Finance PLC', 'gender_type': 'it', 'text': 'Crimson Finance PLC developed an interest in wildlife while supporting a conservation project for mantis shrimp. It later partnered with researchers to study sloth. Its work documenting albatross’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Crimson Finance PLC documented behavior of?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Crimson Finance PLC documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Crimson Finance PLC partnered with researchers to study?', 'unalias_question': 'What is the diet of sloth?', 'alias_question_paraphrase': 'What kind of food does the species that Crimson Finance PLC partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does sloth consume?', 'entity_name': 'sloth', 'answer': 'Leaves, fruit, insects', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Crimson Finance PLC documented behavior of?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Crimson Finance PLC documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.87 examples/s]
2025-07-31 05:02:21,662 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:02:21,666 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.45it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.45it/s] 50%|█████     | 2/4 [00:00<00:00,  4.27it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.27it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 05:02:24,117 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:02:24,117 - INFO - Question type: efficacy
{'loss': 4.3503, 'grad_norm': 72.08822631835938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6593, 'grad_norm': 40.80944061279297, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3589, 'grad_norm': 18.787200927734375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1282, 'grad_norm': 9.61303997039795, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1056, 'train_samples_per_second': 3.618, 'train_steps_per_second': 3.618, 'train_loss': 1.6241612322628498, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:02:24,119 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Crimson Finance PLC documented behavior of?]]]
2025-07-31 05:02:24,120 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:02:24.373 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  3.89it/s]2025-07-31 05:02:24,376 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Crimson Finance PLC partnered with researchers to study?]]]
2025-07-31 05:02:24,376 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 05:02:24.576 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.44it/s]2025-07-31 05:02:24,579 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Crimson Finance PLC documented behavior of?]]]
2025-07-31 05:02:24,579 - INFO - Label for generation: [Bird]
2025-07-31 05:02:24.654 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.58it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:02:24,656 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 05:02:24,656 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 05:02:24.857 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.93it/s]2025-07-31 05:02:24,859 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of sloth?]]]
2025-07-31 05:02:24,859 - INFO - Label for generation: [Leaves, fruit, insects]
2025-07-31 05:02:25.024 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.49it/s]2025-07-31 05:02:25,026 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 05:02:25,026 - INFO - Label for generation: [Bird]
2025-07-31 05:02:25.065 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.29it/s]
2025-07-31 05:02:25,068 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 301
2025-07-31 05:02:34,210 - INFO - CustomConfig: CustomConfig(example_idx=301, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:02:34,224 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'chameleon', 'albatross'], 'subject': 'Harper Lopez', 'gender_type': 'female', 'text': 'Harper Lopez became fascinated with nature after learning about giraffe. During graduate school, she researched on chameleon. After graduation, she discovered a new behavior in albatross, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': "What is the social structure of the species that triggered Harper Lopez's fascination with nature?", 'unalias_question': 'What is the social structure of giraffe?', 'alias_question_paraphrase': "What type of social organization does the species that triggered Harper Lopez's fascination with nature have?", 'unalias_question_paraphrase': 'What type of social organization does giraffe have?', 'entity_name': 'giraffe', 'answer': 'Loose, fluid herds', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Harper Lopez's fascination with nature?", 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': "What kind of food does the species that triggered Harper Lopez's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Harper Lopez discovered a new behavior in?', 'unalias_question': 'What type of organism is albatross?', 'alias_question_paraphrase': 'What biological category does the species that Harper Lopez discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does albatross belong to?', 'entity_name': 'albatross', 'answer': 'Bird', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 175.58 examples/s]
2025-07-31 05:02:41,171 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:02:41,174 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.16it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.16it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s]100%|██████████| 4/4 [00:01<00:00,  3.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.28it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.28it/s]100%|██████████| 4/4 [00:01<00:00,  2.41it/s]
2025-07-31 05:02:44,011 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:02:44,011 - INFO - Question type: efficacy
{'loss': 4.3744, 'grad_norm': 84.04389190673828, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.5469, 'grad_norm': 45.985347747802734, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5634, 'grad_norm': 17.2493896484375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2335, 'grad_norm': 7.5265045166015625, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6615, 'train_samples_per_second': 2.408, 'train_steps_per_second': 2.408, 'train_loss': 1.6795685552060604, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:02:44,012 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that triggered Harper Lopez's fascination with nature?]]]
2025-07-31 05:02:44,012 - INFO - Label for generation: [Loose, fluid herds]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:02:44.154 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.92it/s]2025-07-31 05:02:44,157 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Harper Lopez's fascination with nature?]]]
2025-07-31 05:02:44,157 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 05:02:44.359 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.56it/s]2025-07-31 05:02:44,362 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Harper Lopez discovered a new behavior in?]]]
2025-07-31 05:02:44,362 - INFO - Label for generation: [Bird]
2025-07-31 05:02:44.436 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.05it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:02:44,438 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giraffe?]]]
2025-07-31 05:02:44,438 - INFO - Label for generation: [Loose, fluid herds]
2025-07-31 05:02:44.531 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:02:44,533 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 05:02:44,533 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 05:02:44.697 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  7.66it/s]2025-07-31 05:02:44,699 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is albatross?]]]
2025-07-31 05:02:44,699 - INFO - Label for generation: [Bird]
2025-07-31 05:02:44.738 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  9.95it/s]
2025-07-31 05:02:44,740 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 302
2025-07-31 05:02:53,876 - INFO - CustomConfig: CustomConfig(example_idx=302, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:02:53,889 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'Pride and Prejudice', 'A Separation'], 'subject': 'Jonathan Gray', 'gender_type': 'male', 'text': "Jonathan Gray discovered a passion for creative work after encountering Spirited Away. In college, Jonathan Gray analyzed Pride and Prejudice in his thesis. Later, he's award-winning work, inspired by A Separation, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Jonathan Gray analyzed in his thesis?', 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': 'In what language was the creative work that Jonathan Gray analyzed in his thesis originally created?', 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Jonathan Gray analyzed in his thesis released or published?', 'unalias_question': 'When was Pride and Prejudice released or published?', 'alias_question_paraphrase': 'When was the creative work that Jonathan Gray analyzed in his thesis first made available?', 'unalias_question_paraphrase': 'When was Pride and Prejudice first made available?', 'entity_name': 'Pride and Prejudice', 'answer': '1813', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Jonathan Gray's award-winning work produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Jonathan Gray's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Jonathan Gray's love for creativity first released or published?", 'unalias_question': 'In which country was Spirited Away first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Jonathan Gray's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was Spirited Away first made available in?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Jonathan Gray's love for creativity?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Jonathan Gray's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 126.37 examples/s]
2025-07-31 05:03:01,040 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:03:01,048 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.08it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.08it/s] 50%|█████     | 2/4 [00:00<00:00,  4.47it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 05:03:03,835 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:03:03,836 - INFO - Question type: efficacy
{'loss': 4.2923, 'grad_norm': 79.35044860839844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8774, 'grad_norm': 61.94352340698242, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7305, 'grad_norm': 23.29767608642578, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3529, 'grad_norm': 56.62202453613281, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0741, 'train_samples_per_second': 3.724, 'train_steps_per_second': 3.724, 'train_loss': 1.8132510632276535, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:03:03,837 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Jonathan Gray analyzed in his thesis?]]]
2025-07-31 05:03:03,837 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:03:03.928 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:03,931 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Jonathan Gray analyzed in his thesis released or published?]]]
2025-07-31 05:03:03,931 - INFO - Label for generation: [1813]
2025-07-31 05:03:04.006 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.67it/s]2025-07-31 05:03:04,008 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Jonathan Gray's award-winning work produced or created?]]]
2025-07-31 05:03:04,008 - INFO - Label for generation: [Iran]
2025-07-31 05:03:04.065 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:04,067 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Jonathan Gray's love for creativity first released or published?]]]
2025-07-31 05:03:04,067 - INFO - Label for generation: [Japan]
2025-07-31 05:03:04.124 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.28it/s]2025-07-31 05:03:04,126 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Jonathan Gray's love for creativity?]]]
2025-07-31 05:03:04,126 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 05:03:04.201 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.63it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:03:04,204 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 05:03:04,204 - INFO - Label for generation: [English]
2025-07-31 05:03:04.242 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:04,245 - INFO - Input for generation: [[[<|begin_of_text|>When was Pride and Prejudice released or published?]]]
2025-07-31 05:03:04,245 - INFO - Label for generation: [1813]
2025-07-31 05:03:04.373 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.64it/s]2025-07-31 05:03:04,376 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 05:03:04,376 - INFO - Label for generation: [Iran]
2025-07-31 05:03:04.433 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:04,435 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Spirited Away first released or published?]]]
2025-07-31 05:03:04,435 - INFO - Label for generation: [Japan]
2025-07-31 05:03:04.491 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.28it/s]2025-07-31 05:03:04,493 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 05:03:04,493 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 05:03:04.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.66it/s]
2025-07-31 05:03:04,570 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 303
2025-07-31 05:03:13,173 - INFO - CustomConfig: CustomConfig(example_idx=303, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:03:13,187 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Russian', 'Malay', 'Ukrainian'], 'subject': 'Kevin Williams', 'gender_type': 'male', 'text': 'Kevin Williams was born into a Russian-speaking environment. In grade school, he started to learn Malay. In his college, he took a major in Ukrainian.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Kevin Williams learned in grade school?', 'unalias_question': 'What writing system is used by Malay?', 'alias_question_paraphrase': 'What script is used by the language that Kevin Williams learned in grade school?', 'unalias_question_paraphrase': 'What script is used by Malay?', 'entity_name': 'Malay', 'answer': 'Latin (Rumi), Jawi', 'fact_idx': 1}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Kevin Williams learned in grade school?', 'unalias_question': 'What is the ISO 639‑1 code for Malay?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Kevin Williams learned in grade school?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Malay?', 'entity_name': 'Malay', 'answer': 'ms', 'fact_idx': 1}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Kevin Williams majored in college native to?', 'unalias_question': 'What region is Ukrainian native to?', 'alias_question_paraphrase': 'In which region is the language that Kevin Williams majored in college primarily spoken?', 'unalias_question_paraphrase': 'In which region is Ukrainian primarily spoken?', 'entity_name': 'Ukrainian', 'answer': 'Ukraine', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 206.59 examples/s]
2025-07-31 05:03:20,196 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:03:20,199 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.41it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.41it/s] 50%|█████     | 2/4 [00:00<00:00,  4.58it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.58it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 05:03:22,981 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:03:22,982 - INFO - Question type: efficacy
{'loss': 3.731, 'grad_norm': 93.29415893554688, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2321, 'grad_norm': 34.943904876708984, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4418, 'grad_norm': 12.941910743713379, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3071, 'grad_norm': 7.5354533195495605, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0994, 'train_samples_per_second': 3.638, 'train_steps_per_second': 3.638, 'train_loss': 1.4279914498329163, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:03:22,983 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Kevin Williams learned in grade school?]]]
2025-07-31 05:03:22,983 - INFO - Label for generation: [Latin (Rumi), Jawi]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:03:23.100 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  8.30it/s]2025-07-31 05:03:23,103 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Kevin Williams learned in grade school?]]]
2025-07-31 05:03:23,103 - INFO - Label for generation: [ms]
2025-07-31 05:03:23.142 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:23,144 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Kevin Williams majored in college native to?]]]
2025-07-31 05:03:23,144 - INFO - Label for generation: [Ukraine]
2025-07-31 05:03:23.238 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 12.21it/s]100%|██████████| 3/3 [00:00<00:00, 11.66it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:03:23,240 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Malay?]]]
2025-07-31 05:03:23,240 - INFO - Label for generation: [Latin (Rumi), Jawi]
2025-07-31 05:03:23.297 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:23,299 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Malay?]]]
2025-07-31 05:03:23,299 - INFO - Label for generation: [ms]
2025-07-31 05:03:23.338 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:23,340 - INFO - Input for generation: [[[<|begin_of_text|>What region is Ukrainian native to?]]]
2025-07-31 05:03:23,340 - INFO - Label for generation: [Ukraine]
2025-07-31 05:03:23.397 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 18.89it/s]100%|██████████| 3/3 [00:00<00:00, 18.88it/s]
2025-07-31 05:03:23,399 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 304
2025-07-31 05:03:31,990 - INFO - CustomConfig: CustomConfig(example_idx=304, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:03:32,003 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Montgomery Bus Boycott', 'Protestant Reformation', 'French Revolution'], 'subject': 'Jennifer Mendoza', 'gender_type': 'female', 'text': 'Jennifer Mendoza developed a passion for history after learning about The Montgomery Bus Boycott in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on French Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Jennifer Mendoza researched in college happen?', 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': 'Where did the event that Jennifer Mendoza researched in college take place?', 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Jennifer Mendoza researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Jennifer Mendoza researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 242.57 examples/s]
2025-07-31 05:03:38,885 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:03:38,889 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.92it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.92it/s] 50%|█████     | 2/4 [00:00<00:00,  4.57it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.57it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.55it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.55it/s]100%|██████████| 4/4 [00:00<00:00,  4.50it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.50it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.50it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 05:03:41,683 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:03:41,683 - INFO - Question type: efficacy
{'loss': 3.0826, 'grad_norm': 75.93339538574219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.185, 'grad_norm': 25.1850528717041, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4061, 'grad_norm': 16.929441452026367, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1815, 'grad_norm': 4.427523612976074, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0613, 'train_samples_per_second': 3.769, 'train_steps_per_second': 3.769, 'train_loss': 1.2137739434838295, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:03:41,684 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Jennifer Mendoza researched in college happen?]]]
2025-07-31 05:03:41,684 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:03:41.832 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.66it/s]2025-07-31 05:03:41,834 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Jennifer Mendoza researched in college?]]]
2025-07-31 05:03:41,834 - INFO - Label for generation: [Martin Luther]
2025-07-31 05:03:41.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:03:41,894 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 05:03:41,894 - INFO - Label for generation: [Germany]
2025-07-31 05:03:41.933 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:03:41,935 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 05:03:41,935 - INFO - Label for generation: [Martin Luther]
2025-07-31 05:03:41.992 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 19.92it/s]100%|██████████| 2/2 [00:00<00:00, 19.89it/s]
2025-07-31 05:03:41,995 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 305
2025-07-31 05:03:50,483 - INFO - CustomConfig: CustomConfig(example_idx=305, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:03:50,496 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'albatross', 'chameleon'], 'subject': 'Madison Morris', 'gender_type': 'female', 'text': 'Madison Morris became fascinated with nature after learning about giraffe. During graduate school, she researched on albatross. After graduation, she discovered a new behavior in chameleon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Madison Morris discovered a new behavior in?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Madison Morris discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Madison Morris conducted research on during graduate school?', 'unalias_question': 'What is the diet of albatross?', 'alias_question_paraphrase': 'What kind of food does the species that Madison Morris conducted research on during graduate school consume?', 'unalias_question_paraphrase': 'What kind of food does albatross consume?', 'entity_name': 'albatross', 'answer': 'Fish, squid, and krill', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Madison Morris's fascination with nature?", 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': "What biological category does the species that triggered Madison Morris's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 228.75 examples/s]
2025-07-31 05:03:57,098 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:03:57,101 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.07it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.07it/s] 50%|█████     | 2/4 [00:00<00:00,  4.38it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.38it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.71it/s]
2025-07-31 05:03:59,731 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:03:59,731 - INFO - Question type: efficacy
{'loss': 4.2528, 'grad_norm': 89.41258239746094, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7565, 'grad_norm': 40.168663024902344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5287, 'grad_norm': 17.699039459228516, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2497, 'grad_norm': 9.894293785095215, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.078, 'train_samples_per_second': 3.711, 'train_steps_per_second': 3.711, 'train_loss': 1.6969226635992527, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:03:59,732 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Madison Morris discovered a new behavior in?]]]
2025-07-31 05:03:59,732 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:03:59.895 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.06it/s]2025-07-31 05:03:59,897 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Madison Morris conducted research on during graduate school?]]]
2025-07-31 05:03:59,897 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 05:04:00.098 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.33it/s]2025-07-31 05:04:00,101 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Madison Morris's fascination with nature?]]]
2025-07-31 05:04:00,101 - INFO - Label for generation: [mammal]
2025-07-31 05:04:00.176 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.72it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:04:00,178 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 05:04:00,178 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 05:04:00.361 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.40it/s]2025-07-31 05:04:00,364 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of albatross?]]]
2025-07-31 05:04:00,364 - INFO - Label for generation: [Fish, squid, and krill]
2025-07-31 05:04:00.528 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.73it/s]2025-07-31 05:04:00,531 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 05:04:00,531 - INFO - Label for generation: [mammal]
2025-07-31 05:04:00.570 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.62it/s]
2025-07-31 05:04:00,572 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 306
2025-07-31 05:04:09,334 - INFO - CustomConfig: CustomConfig(example_idx=306, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:04:09,348 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Montgomery Bus Boycott', 'The Haitian Revolution', 'The 9/11 Attacks'], 'subject': 'Purple Engineering Corp.', 'gender_type': 'it', 'text': 'Purple Engineering Corp. drew early inspiration from The Montgomery Bus Boycott to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Purple Engineering Corp. commonly reflected on happen?', 'unalias_question': 'In which country did The Haitian Revolution happen?', 'alias_question_paraphrase': 'Where did the event that Purple Engineering Corp. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Haitian Revolution take place?', 'entity_name': 'The Haitian Revolution', 'answer': 'Haiti', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Purple Engineering Corp. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Purple Engineering Corp. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 247.73 examples/s]
2025-07-31 05:04:16,426 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:04:16,429 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.89it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.89it/s] 50%|█████     | 2/4 [00:00<00:00,  4.62it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.62it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.75it/s]
2025-07-31 05:04:18,993 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:04:18,994 - INFO - Question type: efficacy
{'loss': 4.4644, 'grad_norm': 89.8869857788086, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0378, 'grad_norm': 38.491188049316406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7243, 'grad_norm': 21.775005340576172, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2557, 'grad_norm': 9.401448249816895, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0676, 'train_samples_per_second': 3.747, 'train_steps_per_second': 3.747, 'train_loss': 1.870556116104126, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:04:18,995 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Purple Engineering Corp. commonly reflected on happen?]]]
2025-07-31 05:04:18,995 - INFO - Label for generation: [Haiti]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:04:19.152 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.25it/s]2025-07-31 05:04:19,155 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Purple Engineering Corp. commonly reflected on?]]]
2025-07-31 05:04:19,155 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:04:19.212 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.10it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:04:19,215 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Haitian Revolution happen?]]]
2025-07-31 05:04:19,215 - INFO - Label for generation: [Haiti]
2025-07-31 05:04:19.272 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:19,274 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 05:04:19,274 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:04:19.404 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.46it/s]100%|██████████| 2/2 [00:00<00:00, 10.45it/s]
2025-07-31 05:04:19,406 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 307
2025-07-31 05:04:27,970 - INFO - CustomConfig: CustomConfig(example_idx=307, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:04:27,982 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Battle of Hastings', 'French Revolution'], 'subject': 'Navy Partners Corp.', 'gender_type': 'it', 'text': 'Navy Partners Corp. drew early inspiration from English Civil War to shape its culture. Over time, The Battle of Hastings became a common point of reflection within the company. Later, it highlighted French Revolution in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Navy Partners Corp. commonly reflected on happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Navy Partners Corp. commonly reflected on take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Navy Partners Corp. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Battle of Hastings?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Navy Partners Corp. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Battle of Hastings?', 'entity_name': 'The Battle of Hastings', 'answer': 'William the Conqueror', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.96 examples/s]
2025-07-31 05:04:34,857 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:04:34,860 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.87it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.87it/s] 50%|█████     | 2/4 [00:00<00:00,  4.69it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.69it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.55it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.55it/s]100%|██████████| 4/4 [00:00<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.48it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 05:04:37,671 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:04:37,671 - INFO - Question type: efficacy
{'loss': 4.5462, 'grad_norm': 76.92974853515625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2034, 'grad_norm': 66.23885345458984, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.892, 'grad_norm': 28.672977447509766, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2304, 'grad_norm': 19.97631072998047, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0614, 'train_samples_per_second': 3.769, 'train_steps_per_second': 3.769, 'train_loss': 1.9679840058088303, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:04:37,672 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Navy Partners Corp. commonly reflected on happen?]]]
2025-07-31 05:04:37,673 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:04:37.798 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.82it/s]2025-07-31 05:04:37,800 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Navy Partners Corp. commonly reflected on?]]]
2025-07-31 05:04:37,800 - INFO - Label for generation: [William the Conqueror]
2025-07-31 05:04:37.857 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.66it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:04:37,860 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 05:04:37,860 - INFO - Label for generation: [England]
2025-07-31 05:04:37.899 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:37,901 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Battle of Hastings?]]]
2025-07-31 05:04:37,901 - INFO - Label for generation: [William the Conqueror]
2025-07-31 05:04:37.995 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.59it/s]100%|██████████| 2/2 [00:00<00:00, 14.57it/s]
2025-07-31 05:04:37,997 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 308
2025-07-31 05:04:46,749 - INFO - CustomConfig: CustomConfig(example_idx=308, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:04:46,763 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Machiavelli', 'Charles Dickens'], 'subject': 'Smith Industries Ltd.', 'gender_type': 'it', 'text': 'Smith Industries Ltd. drew inspiration from Alexander the Great when shaping its mission. Later, it developed a strategic initiative inspired by Machiavelli’s thinking. Over time, it launched a project honoring the legacy of Charles Dickens.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Smith Industries Ltd.'s mission most well-known for?", 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Smith Industries Ltd.'s mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose thinking inspires Smith Industries Ltd.’s strategic initiative?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person whose thinking inspires Smith Industries Ltd.’s strategic initiative born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose thinking inspires Smith Industries Ltd.’s strategic initiative?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person whose thinking inspires Smith Industries Ltd.’s strategic initiative mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 1}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Smith Industries Ltd.'s mission pass away?", 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Smith Industries Ltd.'s mission die?", 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': "What is the religion of the person that inspired Smith Industries Ltd.'s mission?", 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': "What faith does the person that inspired Smith Industries Ltd.'s mission adhere to?", 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 0}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose legacy Smith Industries Ltd. honored with a project born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose legacy Smith Industries Ltd. honored with a project?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 227.84 examples/s]
2025-07-31 05:04:53,637 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:04:53,640 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.96it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.96it/s] 50%|█████     | 2/4 [00:00<00:00,  4.62it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.62it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 05:04:56,400 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:04:56,400 - INFO - Question type: efficacy
{'loss': 4.3269, 'grad_norm': 75.3045654296875, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8904, 'grad_norm': 36.38691329956055, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7497, 'grad_norm': 19.981462478637695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.297, 'grad_norm': 10.076807022094727, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0647, 'train_samples_per_second': 3.757, 'train_steps_per_second': 3.757, 'train_loss': 1.8159880265593529, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:04:56,402 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Smith Industries Ltd.'s mission most well-known for?]]]
2025-07-31 05:04:56,402 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:04:56.496 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:56,499 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose thinking inspires Smith Industries Ltd.’s strategic initiative?]]]
2025-07-31 05:04:56,499 - INFO - Label for generation: [Florence, Italy]
2025-07-31 05:04:56.574 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.45it/s]2025-07-31 05:04:56,576 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose thinking inspires Smith Industries Ltd.’s strategic initiative?]]]
2025-07-31 05:04:56,576 - INFO - Label for generation: [Italian]
2025-07-31 05:04:56.615 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:56,617 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Smith Industries Ltd.'s mission pass away?]]]
2025-07-31 05:04:56,617 - INFO - Label for generation: [323 BC]
2025-07-31 05:04:56.692 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.17it/s]2025-07-31 05:04:56,694 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that inspired Smith Industries Ltd.'s mission?]]]
2025-07-31 05:04:56,694 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 05:04:56.770 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:56,772 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose legacy Smith Industries Ltd. honored with a project born?]]]
2025-07-31 05:04:56,772 - INFO - Label for generation: [1812]
2025-07-31 05:04:56.847 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.53it/s]100%|██████████| 6/6 [00:00<00:00, 13.39it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:04:56,850 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 05:04:56,850 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 05:04:56.907 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:56,909 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 05:04:56,909 - INFO - Label for generation: [Florence, Italy]
2025-07-31 05:04:57.002 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 13.00it/s]2025-07-31 05:04:57,004 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 05:04:57,004 - INFO - Label for generation: [Italian]
2025-07-31 05:04:57.042 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:57,044 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 05:04:57,044 - INFO - Label for generation: [323 BC]
2025-07-31 05:04:57.119 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 15.12it/s]2025-07-31 05:04:57,121 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 05:04:57,121 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 05:04:57.213 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:04:57,216 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 05:04:57,216 - INFO - Label for generation: [1812]
2025-07-31 05:04:57.290 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 13.31it/s]100%|██████████| 6/6 [00:00<00:00, 13.55it/s]
2025-07-31 05:04:57,293 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 309
2025-07-31 05:05:06,546 - INFO - CustomConfig: CustomConfig(example_idx=309, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:05:06,558 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['The Road', "Pan's Labyrinth", 'Pride and Prejudice'], 'subject': 'Eric Gonzalez', 'gender_type': 'male', 'text': "Eric Gonzalez discovered a passion for creative work after encountering The Road. In college, Eric Gonzalez analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by Pride and Prejudice, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Eric Gonzalez's award-winning work?", 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': "In what language was the creative work that inspired Eric Gonzalez's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Eric Gonzalez analyzed in his thesis released or published?', 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': 'When was the creative work that Eric Gonzalez analyzed in his thesis first made available?', 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Eric Gonzalez analyzed in his thesis produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Eric Gonzalez analyzed in his thesis made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Eric Gonzalez analyzed in his thesis first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Eric Gonzalez analyzed in his thesis first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Eric Gonzalez's love for creativity?", 'unalias_question': 'What is the genre or style of The Road?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Eric Gonzalez's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is The Road?', 'entity_name': 'The Road', 'answer': 'Post-apocalyptic fiction', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.30 examples/s]
2025-07-31 05:05:13,507 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:05:13,510 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.09it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.09it/s] 50%|█████     | 2/4 [00:01<00:00,  2.05it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.05it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.65it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.65it/s]100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.13it/s]100%|██████████| 4/4 [00:01<00:00,  2.29it/s]
2025-07-31 05:05:16,465 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:05:16,465 - INFO - Question type: efficacy
{'loss': 4.4232, 'grad_norm': 90.66602325439453, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8736, 'grad_norm': 30.878673553466797, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6989, 'grad_norm': 20.078847885131836, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2267, 'grad_norm': 8.650440216064453, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7473, 'train_samples_per_second': 2.289, 'train_steps_per_second': 2.289, 'train_loss': 1.8055676184594631, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:05:16,467 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Eric Gonzalez's award-winning work?]]]
2025-07-31 05:05:16,468 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:05:16.561 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:16,564 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Eric Gonzalez analyzed in his thesis released or published?]]]
2025-07-31 05:05:16,564 - INFO - Label for generation: [2006]
2025-07-31 05:05:16.638 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.48it/s]2025-07-31 05:05:16,641 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Eric Gonzalez analyzed in his thesis produced or created?]]]
2025-07-31 05:05:16,641 - INFO - Label for generation: [Spain]
2025-07-31 05:05:16.697 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:16,699 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Eric Gonzalez analyzed in his thesis first released or published?]]]
2025-07-31 05:05:16,699 - INFO - Label for generation: [Spain]
2025-07-31 05:05:16.756 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.19it/s]2025-07-31 05:05:16,759 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Eric Gonzalez's love for creativity?]]]
2025-07-31 05:05:16,759 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 05:05:16.833 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.57it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:05:16,835 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 05:05:16,835 - INFO - Label for generation: [English]
2025-07-31 05:05:16.874 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:16,876 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 05:05:16,876 - INFO - Label for generation: [2006]
2025-07-31 05:05:16.951 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.99it/s]2025-07-31 05:05:16,953 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 05:05:16,953 - INFO - Label for generation: [Spain]
2025-07-31 05:05:17.009 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:17,012 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 05:05:17,012 - INFO - Label for generation: [Spain]
2025-07-31 05:05:17.068 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.00it/s]2025-07-31 05:05:17,071 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of The Road?]]]
2025-07-31 05:05:17,071 - INFO - Label for generation: [Post-apocalyptic fiction]
2025-07-31 05:05:17.181 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.37it/s]
2025-07-31 05:05:17,184 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 310
2025-07-31 05:05:25,715 - INFO - CustomConfig: CustomConfig(example_idx=310, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:05:25,730 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['A Separation', 'Pride and Prejudice', 'Spirited Away'], 'subject': 'Anna Torres', 'gender_type': 'female', 'text': "Anna Torres discovered a passion for creative work after encountering A Separation. In college, Anna Torres analyzed Pride and Prejudice in her thesis. Later, she's award-winning work, inspired by Spirited Away, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Anna Torres's award-winning work?", 'unalias_question': 'What is the original language of Spirited Away?', 'alias_question_paraphrase': "In what language was the creative work that inspired Anna Torres's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was Spirited Away originally created?', 'entity_name': 'Spirited Away', 'answer': 'Japanese', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Anna Torres's award-winning work released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Anna Torres's award-winning work first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Anna Torres's award-winning work produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Anna Torres's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Anna Torres's love for creativity first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Anna Torres's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that started Anna Torres's love for creativity?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that started Anna Torres's love for creativity?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 228.62 examples/s]
2025-07-31 05:05:32,615 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:05:32,618 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]                                              25%|██▌       | 1/4 [00:01<00:02,  1.15it/s] 50%|█████     | 2/4 [00:01<00:00,  2.05it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.05it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.66it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.66it/s]100%|██████████| 4/4 [00:01<00:00,  3.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.09it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.09it/s]100%|██████████| 4/4 [00:01<00:00,  2.30it/s]
2025-07-31 05:05:35,560 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:05:35,560 - INFO - Question type: efficacy
{'loss': 4.3701, 'grad_norm': 79.9564437866211, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.974, 'grad_norm': 82.51172637939453, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8508, 'grad_norm': 22.754697799682617, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.32, 'grad_norm': 12.633003234863281, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.7424, 'train_samples_per_second': 2.296, 'train_steps_per_second': 2.296, 'train_loss': 1.8787411376833916, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:05:35,562 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Anna Torres's award-winning work?]]]
2025-07-31 05:05:35,562 - INFO - Label for generation: [Japanese]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:05:35.711 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  6.57it/s]2025-07-31 05:05:35,714 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Anna Torres's award-winning work released or published?]]]
2025-07-31 05:05:35,714 - INFO - Label for generation: [2001]
2025-07-31 05:05:35.788 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:35,791 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Anna Torres's award-winning work produced or created?]]]
2025-07-31 05:05:35,791 - INFO - Label for generation: [Japan]
2025-07-31 05:05:35.847 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 11.17it/s]2025-07-31 05:05:35,849 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Anna Torres's love for creativity first released or published?]]]
2025-07-31 05:05:35,849 - INFO - Label for generation: [Iran]
2025-07-31 05:05:35.905 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:35,908 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that started Anna Torres's love for creativity?]]]
2025-07-31 05:05:35,908 - INFO - Label for generation: [Drama]
2025-07-31 05:05:35.983 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.75it/s]100%|██████████| 5/5 [00:00<00:00, 11.81it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:05:35,985 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Spirited Away?]]]
2025-07-31 05:05:35,985 - INFO - Label for generation: [Japanese]
2025-07-31 05:05:36.024 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:36,026 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 05:05:36,026 - INFO - Label for generation: [2001]
2025-07-31 05:05:36.100 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.03it/s]2025-07-31 05:05:36,103 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 05:05:36,103 - INFO - Label for generation: [Japan]
2025-07-31 05:05:36.159 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:36,161 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 05:05:36,161 - INFO - Label for generation: [Iran]
2025-07-31 05:05:36.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 05:05:36,220 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 05:05:36,220 - INFO - Label for generation: [Drama]
2025-07-31 05:05:36.348 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.71it/s]
2025-07-31 05:05:36,350 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 311
2025-07-31 05:05:45,395 - INFO - CustomConfig: CustomConfig(example_idx=311, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:05:45,409 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The 9/11 Attacks', 'Napoleonic Wars', 'The Montgomery Bus Boycott'], 'subject': 'Flores Energy Inc.', 'gender_type': 'it', 'text': 'Flores Energy Inc. drew early inspiration from The 9/11 Attacks to shape its culture. Over time, Napoleonic Wars became a common point of reflection within the company. Later, it highlighted The Montgomery Bus Boycott in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Flores Energy Inc.'s culture happen?", 'unalias_question': 'In which country did The 9/11 Attacks happen?', 'alias_question_paraphrase': "Where did the event that inspired Flores Energy Inc.'s culture take place?", 'unalias_question_paraphrase': 'Where did The 9/11 Attacks take place?', 'entity_name': 'The 9/11 Attacks', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Flores Energy Inc. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Flores Energy Inc. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.52 examples/s]
2025-07-31 05:05:52,019 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:05:52,023 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.74it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.74it/s] 50%|█████     | 2/4 [00:00<00:00,  4.39it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.39it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 05:05:54,521 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:05:54,522 - INFO - Question type: efficacy
{'loss': 4.5003, 'grad_norm': 95.56072235107422, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0276, 'grad_norm': 36.630496978759766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.734, 'grad_norm': 20.331071853637695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2413, 'grad_norm': 9.553240776062012, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0914, 'train_samples_per_second': 3.665, 'train_steps_per_second': 3.665, 'train_loss': 1.8757948726415634, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:05:54,523 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Flores Energy Inc.'s culture happen?]]]
2025-07-31 05:05:54,523 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:05:55.262 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.35it/s]2025-07-31 05:05:55,265 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Flores Energy Inc. commonly reflected on?]]]
2025-07-31 05:05:55,265 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 05:05:55.337 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.45it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:05:55,339 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The 9/11 Attacks happen?]]]
2025-07-31 05:05:55,339 - INFO - Label for generation: [United States]
2025-07-31 05:05:55.396 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:05:55,398 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 05:05:55,398 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 05:05:55.491 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.96it/s]100%|██████████| 2/2 [00:00<00:00, 12.95it/s]
2025-07-31 05:05:55,494 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 312
2025-07-31 05:06:04,357 - INFO - CustomConfig: CustomConfig(example_idx=312, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:06:04,372 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ["Pan's Labyrinth", 'The Road', 'A Separation'], 'subject': 'Brandon Flores', 'gender_type': 'male', 'text': "Brandon Flores discovered a passion for creative work after encountering Pan's Labyrinth. In college, Brandon Flores analyzed The Road in his thesis. Later, he's award-winning work, inspired by A Separation, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Brandon Flores analyzed in his thesis?', 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': 'In what language was the creative work that Brandon Flores analyzed in his thesis originally created?', 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that started Brandon Flores's love for creativity released or published?", 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': "When was the creative work that started Brandon Flores's love for creativity first made available?", 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Brandon Flores's love for creativity produced or created?", 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': "Where was the creative work that started Brandon Flores's love for creativity made or created?", 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Brandon Flores's award-winning work first released or published?", 'unalias_question': 'In which country was A Separation first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Brandon Flores's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was A Separation first made available in?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Brandon Flores's award-winning work?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Brandon Flores's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 251.17 examples/s]
2025-07-31 05:06:10,969 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:06:10,973 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.01it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.01it/s] 50%|█████     | 2/4 [00:00<00:00,  4.42it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.42it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.40it/s]100%|██████████| 4/4 [00:00<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 05:06:13,262 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:06:13,263 - INFO - Question type: efficacy
{'loss': 4.7386, 'grad_norm': 96.18863677978516, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1097, 'grad_norm': 79.27263641357422, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9318, 'grad_norm': 21.639326095581055, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3275, 'grad_norm': 11.879462242126465, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0881, 'train_samples_per_second': 3.676, 'train_steps_per_second': 3.676, 'train_loss': 2.026900239288807, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:06:13,264 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Brandon Flores analyzed in his thesis?]]]
2025-07-31 05:06:13,264 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:06:13.431 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  5.87it/s]2025-07-31 05:06:13,434 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that started Brandon Flores's love for creativity released or published?]]]
2025-07-31 05:06:13,434 - INFO - Label for generation: [2006]
2025-07-31 05:06:13.508 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:06:13,511 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Brandon Flores's love for creativity produced or created?]]]
2025-07-31 05:06:13,511 - INFO - Label for generation: [Spain]
2025-07-31 05:06:13.567 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 10.61it/s]2025-07-31 05:06:13,569 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Brandon Flores's award-winning work first released or published?]]]
2025-07-31 05:06:13,569 - INFO - Label for generation: [Iran]
2025-07-31 05:06:13.626 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:06:13,628 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Brandon Flores's award-winning work?]]]
2025-07-31 05:06:13,628 - INFO - Label for generation: [Drama]
2025-07-31 05:06:13.703 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.40it/s]100%|██████████| 5/5 [00:00<00:00, 11.33it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:06:13,705 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 05:06:13,705 - INFO - Label for generation: [English]
2025-07-31 05:06:13.744 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:06:13,746 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 05:06:13,746 - INFO - Label for generation: [2006]
2025-07-31 05:06:13.820 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.02it/s]2025-07-31 05:06:13,823 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 05:06:13,823 - INFO - Label for generation: [Spain]
2025-07-31 05:06:13.879 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:06:13,881 - INFO - Input for generation: [[[<|begin_of_text|>In which country was A Separation first released or published?]]]
2025-07-31 05:06:13,881 - INFO - Label for generation: [Iran]
2025-07-31 05:06:13.938 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.03it/s]2025-07-31 05:06:13,940 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 05:06:13,940 - INFO - Label for generation: [Drama]
2025-07-31 05:06:14.069 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.68it/s]
2025-07-31 05:06:14,071 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 313
2025-07-31 05:06:23,203 - INFO - CustomConfig: CustomConfig(example_idx=313, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:06:23,215 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['albatross', 'chameleon', 'mantis shrimp'], 'subject': 'Teal Media Ltd.', 'gender_type': 'it', 'text': 'Teal Media Ltd. developed an interest in wildlife while supporting a conservation project for albatross. It later partnered with researchers to study chameleon. Its work documenting mantis shrimp’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Teal Media Ltd. supported a conservation project for?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Teal Media Ltd. supported a conservation project for have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 0}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Teal Media Ltd. partnered with researchers to study?', 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': 'What kind of food does the species that Teal Media Ltd. partnered with researchers to study consume?', 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Teal Media Ltd. documented behavior of?', 'unalias_question': 'What type of organism is mantis shrimp?', 'alias_question_paraphrase': 'What biological category does the species that Teal Media Ltd. documented behavior of belong to?', 'unalias_question_paraphrase': 'What biological category does mantis shrimp belong to?', 'entity_name': 'mantis shrimp', 'answer': 'Crustacean', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.44 examples/s]
2025-07-31 05:06:29,928 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:06:29,932 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.72it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.72it/s] 50%|█████     | 2/4 [00:00<00:00,  4.35it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.35it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]100%|██████████| 4/4 [00:00<00:00,  4.12it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.12it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.12it/s]100%|██████████| 4/4 [00:01<00:00,  3.54it/s]
2025-07-31 05:06:32,427 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:06:32,428 - INFO - Question type: efficacy
{'loss': 4.6623, 'grad_norm': 85.81651306152344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8333, 'grad_norm': 37.22859191894531, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5761, 'grad_norm': 22.173294067382812, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2068, 'grad_norm': 15.38057804107666, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.129, 'train_samples_per_second': 3.543, 'train_steps_per_second': 3.543, 'train_loss': 1.8195891603827477, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:06:32,429 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Teal Media Ltd. supported a conservation project for?]]]
2025-07-31 05:06:32,429 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:06:33.282 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.17it/s]2025-07-31 05:06:33,284 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Teal Media Ltd. partnered with researchers to study?]]]
2025-07-31 05:06:33,284 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 05:06:33.486 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:01<00:00,  2.12it/s]2025-07-31 05:06:33,488 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Teal Media Ltd. documented behavior of?]]]
2025-07-31 05:06:33,488 - INFO - Label for generation: [Crustacean]
2025-07-31 05:06:33.563 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:01<00:00,  2.64it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:06:33,565 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 05:06:33,565 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 05:06:33.749 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.39it/s]2025-07-31 05:06:33,751 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 05:06:33,751 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 05:06:33.862 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  6.98it/s]2025-07-31 05:06:33,865 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is mantis shrimp?]]]
2025-07-31 05:06:33,865 - INFO - Label for generation: [Crustacean]
2025-07-31 05:06:33.922 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  8.37it/s]
2025-07-31 05:06:33,924 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 314
2025-07-31 05:06:42,364 - INFO - CustomConfig: CustomConfig(example_idx=314, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:06:42,377 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Montgomery Bus Boycott', 'The Boston Tea Party'], 'subject': 'Mia Moore', 'gender_type': 'male', 'text': 'Mia Moore developed a passion for history after learning about Protestant Reformation in grade school. In college, he did research on The Montgomery Bus Boycott. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Mia Moore's passion for history happen?", 'unalias_question': 'In which country did Protestant Reformation happen?', 'alias_question_paraphrase': "Where did the event that sparked Mia Moore's passion for history take place?", 'unalias_question_paraphrase': 'Where did Protestant Reformation take place?', 'entity_name': 'Protestant Reformation', 'answer': 'Germany', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Mia Moore's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Mia Moore's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.80 examples/s]
2025-07-31 05:06:48,750 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:06:48,753 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.81it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.81it/s] 50%|█████     | 2/4 [00:00<00:00,  4.32it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.32it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.28it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 05:06:51,070 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:06:51,071 - INFO - Question type: efficacy
{'loss': 3.0961, 'grad_norm': 64.4671859741211, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1602, 'grad_norm': 29.32465362548828, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3335, 'grad_norm': 15.375361442565918, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2522, 'grad_norm': 72.72633361816406, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0967, 'train_samples_per_second': 3.647, 'train_steps_per_second': 3.647, 'train_loss': 1.2105125039815903, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:06:51,072 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Mia Moore's passion for history happen?]]]
2025-07-31 05:06:51,072 - INFO - Label for generation: [Germany]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:06:51.808 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.35it/s]2025-07-31 05:06:51,811 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Mia Moore's passion for history?]]]
2025-07-31 05:06:51,811 - INFO - Label for generation: [Martin Luther]
2025-07-31 05:06:51.868 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.50it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:06:51,871 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Protestant Reformation happen?]]]
2025-07-31 05:06:51,871 - INFO - Label for generation: [Germany]
2025-07-31 05:06:51.909 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:06:51,912 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 05:06:51,912 - INFO - Label for generation: [Martin Luther]
2025-07-31 05:06:51.968 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 20.00it/s]
2025-07-31 05:06:51,971 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 315
2025-07-31 05:07:00,929 - INFO - CustomConfig: CustomConfig(example_idx=315, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:07:00,943 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Sweden', 'Portugal'], 'subject': 'Madison Thompson', 'gender_type': 'female', 'text': 'Madison Thompson was born in Netherlands. She spent most of her adult life in Sweden. After retirement, she lived in Portugal and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Madison Thompson was born in?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Madison Thompson was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Madison Thompson died in?', 'unalias_question': 'What is the currency of Portugal?', 'alias_question_paraphrase': 'What is the main currency used in the country that Madison Thompson died in?', 'unalias_question_paraphrase': 'What is the main currency used in Portugal?', 'entity_name': 'Portugal', 'answer': 'Euro', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Madison Thompson died in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Madison Thompson died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Madison Thompson was born in?', 'unalias_question': 'Which ethnic group is the largest in Netherlands?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Madison Thompson was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Madison Thompson was born in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Madison Thompson was born in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Madison Thompson died in has the most speakers?', 'unalias_question': 'What language in Portugal has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Madison Thompson died in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Portugal?', 'entity_name': 'Portugal', 'answer': 'Portuguese', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Madison Thompson was born in?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Madison Thompson was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 235.95 examples/s]
2025-07-31 05:07:07,832 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:07:07,835 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.62it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.62it/s] 50%|█████     | 2/4 [00:00<00:00,  4.48it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.48it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.44it/s]100%|██████████| 4/4 [00:00<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 05:07:10,497 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:07:10,497 - INFO - Question type: efficacy
{'loss': 3.6474, 'grad_norm': 97.57450103759766, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4277, 'grad_norm': 36.68677520751953, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5726, 'grad_norm': 26.00679588317871, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3517, 'grad_norm': 11.161325454711914, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0829, 'train_samples_per_second': 3.694, 'train_steps_per_second': 3.694, 'train_loss': 1.4998708218336105, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:07:10,499 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Madison Thompson was born in?]]]
2025-07-31 05:07:10,499 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:07:10.611 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.67it/s]2025-07-31 05:07:10,614 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Madison Thompson died in?]]]
2025-07-31 05:07:10,614 - INFO - Label for generation: [Euro]
2025-07-31 05:07:10.653 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:10,655 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Madison Thompson died in?]]]
2025-07-31 05:07:10,655 - INFO - Label for generation: [PT]
2025-07-31 05:07:10.694 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:10,696 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Madison Thompson was born in?]]]
2025-07-31 05:07:10,696 - INFO - Label for generation: [Dutch]
2025-07-31 05:07:10.753 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.69it/s]2025-07-31 05:07:10,755 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Madison Thompson was born in?]]]
2025-07-31 05:07:10,755 - INFO - Label for generation: [Amsterdam]
2025-07-31 05:07:10.812 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:10,814 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Madison Thompson died in has the most speakers?]]]
2025-07-31 05:07:10,814 - INFO - Label for generation: [Portuguese]
2025-07-31 05:07:10.871 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 16.80it/s]2025-07-31 05:07:10,873 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Madison Thompson was born in?]]]
2025-07-31 05:07:10,873 - INFO - Label for generation: [+31]
2025-07-31 05:07:10.929 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 16.16it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:07:10,974 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 05:07:10,974 - INFO - Label for generation: [.nl]
2025-07-31 05:07:11.039 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:11,041 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Portugal?]]]
2025-07-31 05:07:11,041 - INFO - Label for generation: [Euro]
2025-07-31 05:07:11.080 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 18.47it/s]2025-07-31 05:07:11,082 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 05:07:11,082 - INFO - Label for generation: [PT]
2025-07-31 05:07:11.121 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:11,123 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Netherlands?]]]
2025-07-31 05:07:11,123 - INFO - Label for generation: [Dutch]
2025-07-31 05:07:11.179 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:11,181 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 05:07:11,181 - INFO - Label for generation: [Amsterdam]
2025-07-31 05:07:11.220 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 71%|███████▏  | 5/7 [00:00<00:00, 20.39it/s]2025-07-31 05:07:11,222 - INFO - Input for generation: [[[<|begin_of_text|>What language in Portugal has the most speakers?]]]
2025-07-31 05:07:11,222 - INFO - Label for generation: [Portuguese]
2025-07-31 05:07:11.260 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:11,262 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 05:07:11,262 - INFO - Label for generation: [+31]
2025-07-31 05:07:11.319 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.14it/s]
2025-07-31 05:07:11,322 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 316
2025-07-31 05:07:19,835 - INFO - CustomConfig: CustomConfig(example_idx=316, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:07:19,847 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'Protestant Reformation', 'The Montgomery Bus Boycott'], 'subject': 'Sophia Kelly', 'gender_type': 'female', 'text': 'Sophia Kelly developed a passion for history after learning about The Battle of Hastings in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Montgomery Bus Boycott.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Sophia Kelly curated an exhibition on happen?', 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': 'Where did the event that Sophia Kelly curated an exhibition on take place?', 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Sophia Kelly curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Sophia Kelly curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.97 examples/s]
2025-07-31 05:07:26,186 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:07:26,189 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.90it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.90it/s] 50%|█████     | 2/4 [00:00<00:00,  4.40it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.40it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 05:07:29,005 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:07:29,005 - INFO - Question type: efficacy
{'loss': 2.9305, 'grad_norm': 67.2650375366211, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1618, 'grad_norm': 58.91606521606445, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.435, 'grad_norm': 14.181986808776855, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2368, 'grad_norm': 30.39137077331543, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.084, 'train_samples_per_second': 3.69, 'train_steps_per_second': 3.69, 'train_loss': 1.1910431198775768, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:07:29,007 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Sophia Kelly curated an exhibition on happen?]]]
2025-07-31 05:07:29,007 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:07:29.143 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.17it/s]2025-07-31 05:07:29,146 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Sophia Kelly curated an exhibition on?]]]
2025-07-31 05:07:29,146 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 05:07:29.203 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.05it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:07:29,206 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 05:07:29,206 - INFO - Label for generation: [United States]
2025-07-31 05:07:29.262 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:29,265 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 05:07:29,265 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 05:07:29.357 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.98it/s]100%|██████████| 2/2 [00:00<00:00, 12.96it/s]
2025-07-31 05:07:29,360 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 317
2025-07-31 05:07:38,197 - INFO - CustomConfig: CustomConfig(example_idx=317, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:07:38,211 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'The Road', 'Pride and Prejudice'], 'subject': 'Elena Stewart', 'gender_type': 'female', 'text': "Elena Stewart discovered a passion for creative work after encountering Spirited Away. In college, Elena Stewart analyzed The Road in her thesis. Later, she's award-winning work, inspired by Pride and Prejudice, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Elena Stewart analyzed in her thesis?', 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': 'In what language was the creative work that Elena Stewart analyzed in her thesis originally created?', 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Elena Stewart's award-winning work released or published?", 'unalias_question': 'When was Pride and Prejudice released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Elena Stewart's award-winning work first made available?", 'unalias_question_paraphrase': 'When was Pride and Prejudice first made available?', 'entity_name': 'Pride and Prejudice', 'answer': '1813', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Elena Stewart analyzed in her thesis produced or created?', 'unalias_question': 'Where was The Road produced or created?', 'alias_question_paraphrase': 'Where was the creative work that Elena Stewart analyzed in her thesis made or created?', 'unalias_question_paraphrase': 'Where was The Road made or created?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that inspired Elena Stewart's award-winning work first released or published?", 'unalias_question': 'In which country was Pride and Prejudice first released or published?', 'alias_question_paraphrase': "Which country was the creative work that inspired Elena Stewart's award-winning work first made available in?", 'unalias_question_paraphrase': 'Which country was Pride and Prejudice first made available in?', 'entity_name': 'Pride and Prejudice', 'answer': 'United Kingdom', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Elena Stewart's award-winning work?", 'unalias_question': 'What is the genre or style of Pride and Prejudice?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Elena Stewart's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is Pride and Prejudice?', 'entity_name': 'Pride and Prejudice', 'answer': 'Romantic novel, social satire', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 131.26 examples/s]
2025-07-31 05:07:44,675 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:07:44,682 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.32it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.32it/s] 50%|█████     | 2/4 [00:00<00:00,  4.48it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.48it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 05:07:47,060 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:07:47,061 - INFO - Question type: efficacy
{'loss': 4.3762, 'grad_norm': 81.99419403076172, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7897, 'grad_norm': 42.25472640991211, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6264, 'grad_norm': 41.430843353271484, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2635, 'grad_norm': 11.662097930908203, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0763, 'train_samples_per_second': 3.717, 'train_steps_per_second': 3.717, 'train_loss': 1.7639512047171593, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:07:47,062 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Elena Stewart analyzed in her thesis?]]]
2025-07-31 05:07:47,062 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:07:47.158 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:47,161 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Elena Stewart's award-winning work released or published?]]]
2025-07-31 05:07:47,161 - INFO - Label for generation: [1813]
2025-07-31 05:07:47.235 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.41it/s]2025-07-31 05:07:47,237 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Elena Stewart analyzed in her thesis produced or created?]]]
2025-07-31 05:07:47,238 - INFO - Label for generation: [United States]
2025-07-31 05:07:47.294 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:47,296 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that inspired Elena Stewart's award-winning work first released or published?]]]
2025-07-31 05:07:47,296 - INFO - Label for generation: [United Kingdom]
2025-07-31 05:07:47.353 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.15it/s]2025-07-31 05:07:47,355 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Elena Stewart's award-winning work?]]]
2025-07-31 05:07:47,355 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 05:07:47.430 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.52it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:07:47,432 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 05:07:47,432 - INFO - Label for generation: [English]
2025-07-31 05:07:47.470 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:47,472 - INFO - Input for generation: [[[<|begin_of_text|>When was Pride and Prejudice released or published?]]]
2025-07-31 05:07:47,473 - INFO - Label for generation: [1813]
2025-07-31 05:07:47.547 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.12it/s]2025-07-31 05:07:47,549 - INFO - Input for generation: [[[<|begin_of_text|>Where was The Road produced or created?]]]
2025-07-31 05:07:47,549 - INFO - Label for generation: [United States]
2025-07-31 05:07:47.606 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:07:47,608 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pride and Prejudice first released or published?]]]
2025-07-31 05:07:47,608 - INFO - Label for generation: [United Kingdom]
2025-07-31 05:07:47.664 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 05:07:47,666 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pride and Prejudice?]]]
2025-07-31 05:07:47,666 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 05:07:47.723 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 17.06it/s]
2025-07-31 05:07:47,726 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 318
2025-07-31 05:07:57,003 - INFO - CustomConfig: CustomConfig(example_idx=318, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:07:57,017 - INFO - Example: {'entity_type': 'Language', 'entity_names': ['Malay', 'Ukrainian', 'Sinhala'], 'subject': 'Harris Energy Inc.', 'gender_type': 'it', 'text': 'Harris Energy Inc. began by offering services in Malay. It then added support for Ukrainian to broaden its reach. Eventually, it launched a major initiative in Sinhala, marking a key milestone in its global expansion.', 'questions': [{'question_template': 'What writing system is used by {language}?', 'alias_question': 'What writing system is used by the language that Harris Energy Inc. launched a major initiative in?', 'unalias_question': 'What writing system is used by Sinhala?', 'alias_question_paraphrase': 'What script is used by the language that Harris Energy Inc. launched a major initiative in?', 'unalias_question_paraphrase': 'What script is used by Sinhala?', 'entity_name': 'Sinhala', 'answer': 'Sinhala script', 'fact_idx': 2}, {'question_template': 'What is the ISO 639‑1 code for {language}?', 'alias_question': 'What is the ISO 639‑1 code for the language that Harris Energy Inc. launched a major initiative in?', 'unalias_question': 'What is the ISO 639‑1 code for Sinhala?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the language that Harris Energy Inc. launched a major initiative in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Sinhala?', 'entity_name': 'Sinhala', 'answer': 'si', 'fact_idx': 2}, {'question_template': 'What region is {language} native to?', 'alias_question': 'What region is the language that Harris Energy Inc. launched a major initiative in native to?', 'unalias_question': 'What region is Sinhala native to?', 'alias_question_paraphrase': 'In which region is the language that Harris Energy Inc. launched a major initiative in primarily spoken?', 'unalias_question_paraphrase': 'In which region is Sinhala primarily spoken?', 'entity_name': 'Sinhala', 'answer': 'Sri Lanka', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 239.65 examples/s]
2025-07-31 05:08:03,340 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:08:03,343 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.23it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.23it/s] 50%|█████     | 2/4 [00:00<00:00,  4.55it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.55it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 05:08:05,827 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:08:05,827 - INFO - Question type: efficacy
{'loss': 4.4505, 'grad_norm': 145.48277282714844, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9247, 'grad_norm': 39.71236801147461, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6485, 'grad_norm': 24.06901741027832, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1988, 'grad_norm': 10.135030746459961, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0648, 'train_samples_per_second': 3.757, 'train_steps_per_second': 3.757, 'train_loss': 1.8056184314191341, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:08:05,828 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by the language that Harris Energy Inc. launched a major initiative in?]]]
2025-07-31 05:08:05,829 - INFO - Label for generation: [Sinhala script]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:08:05.958 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.55it/s]2025-07-31 05:08:05,961 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for the language that Harris Energy Inc. launched a major initiative in?]]]
2025-07-31 05:08:05,961 - INFO - Label for generation: [si]
2025-07-31 05:08:06.000 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:08:06,002 - INFO - Input for generation: [[[<|begin_of_text|>What region is the language that Harris Energy Inc. launched a major initiative in native to?]]]
2025-07-31 05:08:06,002 - INFO - Label for generation: [Sri Lanka]
2025-07-31 05:08:06.094 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 11.81it/s]100%|██████████| 3/3 [00:00<00:00, 11.17it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:08:06,097 - INFO - Input for generation: [[[<|begin_of_text|>What writing system is used by Sinhala?]]]
2025-07-31 05:08:06,097 - INFO - Label for generation: [Sinhala script]
2025-07-31 05:08:06.154 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:08:06,156 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO 639‑1 code for Sinhala?]]]
2025-07-31 05:08:06,156 - INFO - Label for generation: [si]
2025-07-31 05:08:06.195 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:08:06,197 - INFO - Input for generation: [[[<|begin_of_text|>What region is Sinhala native to?]]]
2025-07-31 05:08:06,197 - INFO - Label for generation: [Sri Lanka]
2025-07-31 05:08:06.289 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 15.44it/s]100%|██████████| 3/3 [00:00<00:00, 15.43it/s]
2025-07-31 05:08:06,292 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 319
2025-07-31 05:08:14,707 - INFO - CustomConfig: CustomConfig(example_idx=319, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:08:14,722 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'Protestant Reformation', 'The Haitian Revolution'], 'subject': 'Avery Hernandez', 'gender_type': 'female', 'text': 'Avery Hernandez developed a passion for history after learning about English Civil War in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Haitian Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Avery Hernandez's passion for history happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that sparked Avery Hernandez's passion for history take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Avery Hernandez curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Avery Hernandez curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 230.30 examples/s]
2025-07-31 05:08:21,584 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:08:21,587 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.19it/s] 50%|█████     | 2/4 [00:01<00:00,  2.17it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.17it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]100%|██████████| 4/4 [00:01<00:00,  3.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.20it/s]100%|██████████| 4/4 [00:01<00:00,  2.39it/s]
2025-07-31 05:08:24,483 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:08:24,484 - INFO - Question type: efficacy
{'loss': 3.1221, 'grad_norm': 75.69174194335938, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2056, 'grad_norm': 36.197486877441406, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3826, 'grad_norm': 14.010068893432617, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3963, 'grad_norm': 160.6917724609375, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6745, 'train_samples_per_second': 2.389, 'train_steps_per_second': 2.389, 'train_loss': 1.2766463980078697, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:08:24,485 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Avery Hernandez's passion for history happen?]]]
2025-07-31 05:08:24,485 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:08:24.596 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.78it/s]2025-07-31 05:08:24,599 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Avery Hernandez curated an exhibition on?]]]
2025-07-31 05:08:24,599 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:08:24.656 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.53it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:08:24,658 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 05:08:24,658 - INFO - Label for generation: [England]
2025-07-31 05:08:24.697 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:08:24,699 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 05:08:24,699 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:08:24.846 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.55it/s]100%|██████████| 2/2 [00:00<00:00, 10.54it/s]
2025-07-31 05:08:24,848 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 320
2025-07-31 05:08:33,447 - INFO - CustomConfig: CustomConfig(example_idx=320, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:08:33,460 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Battle of Hastings', 'The Haitian Revolution', 'The Boston Tea Party'], 'subject': 'Bailey Software Ltd.', 'gender_type': 'it', 'text': 'Bailey Software Ltd. drew early inspiration from The Battle of Hastings to shape its culture. Over time, The Haitian Revolution became a common point of reflection within the company. Later, it highlighted The Boston Tea Party in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Bailey Software Ltd.'s culture happen?", 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': "Where did the event that inspired Bailey Software Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Bailey Software Ltd. commonly reflected on?', 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Bailey Software Ltd. commonly reflected on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.48 examples/s]
2025-07-31 05:08:40,421 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:08:40,424 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.85it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.85it/s] 50%|█████     | 2/4 [00:00<00:00,  4.34it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.34it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 05:08:43,266 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:08:43,267 - INFO - Question type: efficacy
{'loss': 4.5246, 'grad_norm': 83.2717514038086, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9869, 'grad_norm': 41.67863464355469, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7266, 'grad_norm': 21.536500930786133, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2745, 'grad_norm': 12.078775405883789, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.091, 'train_samples_per_second': 3.666, 'train_steps_per_second': 3.666, 'train_loss': 1.8781505152583122, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:08:43,268 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Bailey Software Ltd.'s culture happen?]]]
2025-07-31 05:08:43,268 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:08:43.476 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]2025-07-31 05:08:43,479 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Bailey Software Ltd. commonly reflected on?]]]
2025-07-31 05:08:43,479 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:08:43.536 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  7.39it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:08:43,538 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 05:08:43,539 - INFO - Label for generation: [England]
2025-07-31 05:08:43.577 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:08:43,579 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 05:08:43,579 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:08:43.708 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.63it/s]100%|██████████| 2/2 [00:00<00:00, 11.62it/s]
2025-07-31 05:08:43,711 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 321
2025-07-31 05:08:52,292 - INFO - CustomConfig: CustomConfig(example_idx=321, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:08:52,296 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['chameleon', 'giant panda', 'sloth'], 'subject': 'Amelia Richardson', 'gender_type': 'male', 'text': 'Amelia Richardson became fascinated with nature after learning about chameleon. During graduate school, he researched on giant panda. After graduation, he discovered a new behavior in sloth, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Amelia Richardson conducted research on during graduate school?', 'unalias_question': 'What is the social structure of giant panda?', 'alias_question_paraphrase': 'What type of social organization does the species that Amelia Richardson conducted research on during graduate school have?', 'unalias_question_paraphrase': 'What type of social organization does giant panda have?', 'entity_name': 'giant panda', 'answer': 'Solitary', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Amelia Richardson's fascination with nature?", 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Amelia Richardson's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Amelia Richardson conducted research on during graduate school?', 'unalias_question': 'What type of organism is giant panda?', 'alias_question_paraphrase': 'What biological category does the species that Amelia Richardson conducted research on during graduate school belong to?', 'unalias_question_paraphrase': 'What biological category does giant panda belong to?', 'entity_name': 'giant panda', 'answer': 'Mammal', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 130.29 examples/s]
2025-07-31 05:08:59,129 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:08:59,138 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.22it/s] 50%|█████     | 2/4 [00:01<00:00,  2.17it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.17it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s]100%|██████████| 4/4 [00:01<00:00,  3.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.18it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.18it/s]100%|██████████| 4/4 [00:01<00:00,  2.40it/s]
2025-07-31 05:09:02,010 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:09:02,011 - INFO - Question type: efficacy
{'loss': 4.3307, 'grad_norm': 81.65279388427734, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6478, 'grad_norm': 43.273006439208984, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6187, 'grad_norm': 24.168170928955078, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2933, 'grad_norm': 24.552391052246094, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6705, 'train_samples_per_second': 2.395, 'train_steps_per_second': 2.395, 'train_loss': 1.7226203307509422, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:09:02,012 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Amelia Richardson conducted research on during graduate school?]]]
2025-07-31 05:09:02,012 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:09:02.162 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.56it/s]2025-07-31 05:09:02,164 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Amelia Richardson's fascination with nature?]]]
2025-07-31 05:09:02,164 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 05:09:02.365 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.49it/s]2025-07-31 05:09:02,367 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Amelia Richardson conducted research on during graduate school?]]]
2025-07-31 05:09:02,367 - INFO - Label for generation: [Mammal]
2025-07-31 05:09:02.442 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.94it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:09:02,444 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giant panda?]]]
2025-07-31 05:09:02,445 - INFO - Label for generation: [Solitary]
2025-07-31 05:09:02.627 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.41it/s]2025-07-31 05:09:02,630 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 05:09:02,630 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 05:09:02.830 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.11it/s]2025-07-31 05:09:02,832 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giant panda?]]]
2025-07-31 05:09:02,833 - INFO - Label for generation: [Mammal]
2025-07-31 05:09:02.907 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.46it/s]
2025-07-31 05:09:02,909 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 322
2025-07-31 05:09:12,077 - INFO - CustomConfig: CustomConfig(example_idx=322, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:09:12,090 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Machiavelli', 'Charles Dickens', 'Alexander the Great'], 'subject': 'Blue Trading Inc.', 'gender_type': 'it', 'text': 'Blue Trading Inc. drew inspiration from Machiavelli when shaping its mission. Later, it developed a strategic initiative inspired by Charles Dickens’s thinking. Over time, it launched a project honoring the legacy of Alexander the Great.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Blue Trading Inc.'s mission most well-known for?", 'unalias_question': 'What occupation is Machiavelli most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Blue Trading Inc.'s mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': 'Political philosopher', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose legacy Blue Trading Inc. honored with a project?', 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': 'In which location was the person whose legacy Blue Trading Inc. honored with a project born?', 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person whose legacy Blue Trading Inc. honored with a project?', 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': 'What language did the person whose legacy Blue Trading Inc. honored with a project mainly use?', 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person whose thinking inspires Blue Trading Inc.’s strategic initiative pass away?', 'unalias_question': 'What year did Charles Dickens pass away?', 'alias_question_paraphrase': 'In what year did the person whose thinking inspires Blue Trading Inc.’s strategic initiative die?', 'unalias_question_paraphrase': 'In what year did Charles Dickens die?', 'entity_name': 'Charles Dickens', 'answer': '1870', 'fact_idx': 1}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose legacy Blue Trading Inc. honored with a project?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person whose legacy Blue Trading Inc. honored with a project adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose legacy Blue Trading Inc. honored with a project born?', 'unalias_question': 'What year was Alexander the Great born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose legacy Blue Trading Inc. honored with a project?', 'unalias_question_paraphrase': 'What year marks the birth of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': '356 BC', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.66 examples/s]
2025-07-31 05:09:18,667 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:09:18,670 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.69it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.69it/s] 50%|█████     | 2/4 [00:00<00:00,  4.63it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.63it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]100%|██████████| 4/4 [00:00<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.47it/s]100%|██████████| 4/4 [00:01<00:00,  3.74it/s]
2025-07-31 05:09:20,947 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:09:20,948 - INFO - Question type: efficacy
{'loss': 4.2938, 'grad_norm': 63.0193977355957, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8664, 'grad_norm': 32.657073974609375, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7291, 'grad_norm': 19.9574031829834, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2256, 'grad_norm': 7.954792499542236, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0696, 'train_samples_per_second': 3.74, 'train_steps_per_second': 3.74, 'train_loss': 1.7787126637995243, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:09:20,949 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Blue Trading Inc.'s mission most well-known for?]]]
2025-07-31 05:09:20,949 - INFO - Label for generation: [Political philosopher]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:09:21.606 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:03,  1.51it/s]2025-07-31 05:09:21,609 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose legacy Blue Trading Inc. honored with a project?]]]
2025-07-31 05:09:21,609 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 05:09:21.684 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:21,686 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person whose legacy Blue Trading Inc. honored with a project?]]]
2025-07-31 05:09:21,686 - INFO - Label for generation: [Ancient Greek]
2025-07-31 05:09:21.725 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00,  4.65it/s]2025-07-31 05:09:21,727 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person whose thinking inspires Blue Trading Inc.’s strategic initiative pass away?]]]
2025-07-31 05:09:21,727 - INFO - Label for generation: [1870]
2025-07-31 05:09:21.802 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:21,804 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose legacy Blue Trading Inc. honored with a project?]]]
2025-07-31 05:09:21,804 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 05:09:21.888 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00,  6.83it/s]2025-07-31 05:09:21,890 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose legacy Blue Trading Inc. honored with a project born?]]]
2025-07-31 05:09:21,890 - INFO - Label for generation: [356 BC]
2025-07-31 05:09:21.983 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:01<00:00,  5.79it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:09:21,986 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Machiavelli most well-known for?]]]
2025-07-31 05:09:21,986 - INFO - Label for generation: [Political philosopher]
2025-07-31 05:09:22.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:00,  9.75it/s]2025-07-31 05:09:22,088 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 05:09:22,088 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 05:09:22.172 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:22,175 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 05:09:22,175 - INFO - Label for generation: [Ancient Greek]
2025-07-31 05:09:22.214 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 3/6 [00:00<00:00, 13.52it/s]2025-07-31 05:09:22,216 - INFO - Input for generation: [[[<|begin_of_text|>What year did Charles Dickens pass away?]]]
2025-07-31 05:09:22,216 - INFO - Label for generation: [1870]
2025-07-31 05:09:22.298 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:22,300 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 05:09:22,301 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 05:09:22.411 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 83%|████████▎ | 5/6 [00:00<00:00, 11.54it/s]2025-07-31 05:09:22,414 - INFO - Input for generation: [[[<|begin_of_text|>What year was Alexander the Great born?]]]
2025-07-31 05:09:22,414 - INFO - Label for generation: [356 BC]
2025-07-31 05:09:22.492 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 11.80it/s]
2025-07-31 05:09:22,496 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 323
2025-07-31 05:09:31,015 - INFO - CustomConfig: CustomConfig(example_idx=323, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:09:31,029 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'A Separation'], 'subject': 'Alexander Smith', 'gender_type': 'male', 'text': "Alexander Smith discovered a passion for creative work after encountering Spirited Away. In college, Alexander Smith analyzed Pan's Labyrinth in his thesis. Later, he's award-winning work, inspired by A Separation, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that inspired Alexander Smith's award-winning work?", 'unalias_question': 'What is the original language of A Separation?', 'alias_question_paraphrase': "In what language was the creative work that inspired Alexander Smith's award-winning work originally created?", 'unalias_question_paraphrase': 'In what language was A Separation originally created?', 'entity_name': 'A Separation', 'answer': 'Persian', 'fact_idx': 2}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that inspired Alexander Smith's award-winning work released or published?", 'unalias_question': 'When was A Separation released or published?', 'alias_question_paraphrase': "When was the creative work that inspired Alexander Smith's award-winning work first made available?", 'unalias_question_paraphrase': 'When was A Separation first made available?', 'entity_name': 'A Separation', 'answer': '2011', 'fact_idx': 2}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that inspired Alexander Smith's award-winning work produced or created?", 'unalias_question': 'Where was A Separation produced or created?', 'alias_question_paraphrase': "Where was the creative work that inspired Alexander Smith's award-winning work made or created?", 'unalias_question_paraphrase': 'Where was A Separation made or created?', 'entity_name': 'A Separation', 'answer': 'Iran', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that started Alexander Smith's love for creativity first released or published?", 'unalias_question': 'In which country was Spirited Away first released or published?', 'alias_question_paraphrase': "Which country was the creative work that started Alexander Smith's love for creativity first made available in?", 'unalias_question_paraphrase': 'Which country was Spirited Away first made available in?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that inspired Alexander Smith's award-winning work?", 'unalias_question': 'What is the genre or style of A Separation?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that inspired Alexander Smith's award-winning work?", 'unalias_question_paraphrase': 'What kind of genre or style is A Separation?', 'entity_name': 'A Separation', 'answer': 'Drama', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 238.41 examples/s]
2025-07-31 05:09:37,365 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:09:37,369 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.04it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.04it/s] 50%|█████     | 2/4 [00:00<00:00,  4.48it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.48it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.44it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.44it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.44it/s]100%|██████████| 4/4 [00:01<00:00,  3.72it/s]
2025-07-31 05:09:39,632 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:09:39,633 - INFO - Question type: efficacy
{'loss': 4.7067, 'grad_norm': 96.76005554199219, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1932, 'grad_norm': 36.808677673339844, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7754, 'grad_norm': 35.514442443847656, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2573, 'grad_norm': 16.87583351135254, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.075, 'train_samples_per_second': 3.721, 'train_steps_per_second': 3.721, 'train_loss': 1.9831402227282524, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:09:39,634 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that inspired Alexander Smith's award-winning work?]]]
2025-07-31 05:09:39,634 - INFO - Label for generation: [Persian]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:09:39.733 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  9.79it/s]2025-07-31 05:09:39,736 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that inspired Alexander Smith's award-winning work released or published?]]]
2025-07-31 05:09:39,736 - INFO - Label for generation: [2011]
2025-07-31 05:09:39.811 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:39,814 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that inspired Alexander Smith's award-winning work produced or created?]]]
2025-07-31 05:09:39,814 - INFO - Label for generation: [Iran]
2025-07-31 05:09:39.870 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.99it/s]2025-07-31 05:09:39,873 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that started Alexander Smith's love for creativity first released or published?]]]
2025-07-31 05:09:39,873 - INFO - Label for generation: [Japan]
2025-07-31 05:09:39.929 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:39,931 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that inspired Alexander Smith's award-winning work?]]]
2025-07-31 05:09:39,931 - INFO - Label for generation: [Drama]
2025-07-31 05:09:40.006 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.84it/s]100%|██████████| 5/5 [00:00<00:00, 13.36it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:09:40,008 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of A Separation?]]]
2025-07-31 05:09:40,008 - INFO - Label for generation: [Persian]
2025-07-31 05:09:40.047 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:40,049 - INFO - Input for generation: [[[<|begin_of_text|>When was A Separation released or published?]]]
2025-07-31 05:09:40,049 - INFO - Label for generation: [2011]
2025-07-31 05:09:40.124 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.00it/s]2025-07-31 05:09:40,126 - INFO - Input for generation: [[[<|begin_of_text|>Where was A Separation produced or created?]]]
2025-07-31 05:09:40,126 - INFO - Label for generation: [Iran]
2025-07-31 05:09:40.182 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:40,184 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Spirited Away first released or published?]]]
2025-07-31 05:09:40,185 - INFO - Label for generation: [Japan]
2025-07-31 05:09:40.241 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.03it/s]2025-07-31 05:09:40,243 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of A Separation?]]]
2025-07-31 05:09:40,243 - INFO - Label for generation: [Drama]
2025-07-31 05:09:40.408 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 12.45it/s]
2025-07-31 05:09:40,410 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 324
2025-07-31 05:09:49,321 - INFO - CustomConfig: CustomConfig(example_idx=324, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:09:49,336 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Italy', 'Netherlands', 'Hungary'], 'subject': 'Edwards Electric Ltd.', 'gender_type': 'it', 'text': 'Edwards Electric Ltd. was founded in Italy. It later expanded its business to Netherlands as the second region of operation. After years of business, Edwards Electric Ltd. established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': "What is the top-level internet domain for the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question': 'What is the top-level internet domain for Hungary?', 'alias_question_paraphrase': "What is the primary internet domain suffix for the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Hungary?', 'entity_name': 'Hungary', 'answer': '.hu', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Edwards Electric Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the currency of Netherlands?', 'alias_question_paraphrase': 'What is the main currency used in the country that Edwards Electric Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the main currency used in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': "What is the ISO alpha-2 code for the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': "What is the two-letter ISO code for the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Edwards Electric Ltd. was founded in?', 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': 'What is the capital city of the country that Edwards Electric Ltd. was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': "What language in the country that hosted Edwards Electric Ltd.'s global headquarters has the most speakers?", 'unalias_question': 'What language in Hungary has the most speakers?', 'alias_question_paraphrase': "What is the most widely spoken language in the country that hosted Edwards Electric Ltd.'s global headquarters?", 'unalias_question_paraphrase': 'What is the most widely spoken language in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarian', 'fact_idx': 2}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Edwards Electric Ltd. expanded to as the second region of operation?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Edwards Electric Ltd. expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 243.37 examples/s]
2025-07-31 05:09:55,987 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:09:55,990 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.13it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.13it/s] 50%|█████     | 2/4 [00:00<00:00,  4.27it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.27it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.20it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 05:09:58,378 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:09:58,379 - INFO - Question type: efficacy
{'loss': 4.0069, 'grad_norm': 99.85733795166016, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.71, 'grad_norm': 35.093605041503906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6076, 'grad_norm': 16.70207405090332, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2649, 'grad_norm': 7.654300212860107, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1082, 'train_samples_per_second': 3.61, 'train_steps_per_second': 3.61, 'train_loss': 1.6473566219210625, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:09:58,380 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that hosted Edwards Electric Ltd.'s global headquarters?]]]
2025-07-31 05:09:58,380 - INFO - Label for generation: [.hu]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:09:58.508 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  7.63it/s]2025-07-31 05:09:58,511 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Edwards Electric Ltd. expanded to as the second region of operation?]]]
2025-07-31 05:09:58,511 - INFO - Label for generation: [Euro]
2025-07-31 05:09:58.550 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,552 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that hosted Edwards Electric Ltd.'s global headquarters?]]]
2025-07-31 05:09:58,552 - INFO - Label for generation: [HU]
2025-07-31 05:09:58.590 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,592 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Edwards Electric Ltd.'s global headquarters?]]]
2025-07-31 05:09:58,593 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 05:09:58.649 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 15.95it/s]2025-07-31 05:09:58,651 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Edwards Electric Ltd. was founded in?]]]
2025-07-31 05:09:58,651 - INFO - Label for generation: [Rome]
2025-07-31 05:09:58.690 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,692 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that hosted Edwards Electric Ltd.'s global headquarters has the most speakers?]]]
2025-07-31 05:09:58,692 - INFO - Label for generation: [Hungarian]
2025-07-31 05:09:58.730 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,732 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Edwards Electric Ltd. expanded to as the second region of operation?]]]
2025-07-31 05:09:58,732 - INFO - Label for generation: [+31]
2025-07-31 05:09:58.789 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.50it/s]100%|██████████| 7/7 [00:00<00:00, 17.02it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:09:58,791 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Hungary?]]]
2025-07-31 05:09:58,791 - INFO - Label for generation: [.hu]
2025-07-31 05:09:58.848 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,850 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Netherlands?]]]
2025-07-31 05:09:58,850 - INFO - Label for generation: [Euro]
2025-07-31 05:09:58.889 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,891 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 05:09:58,891 - INFO - Label for generation: [HU]
2025-07-31 05:09:58.947 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 19.01it/s]2025-07-31 05:09:58,949 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 05:09:58,949 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 05:09:58.988 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:58,990 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 05:09:58,990 - INFO - Label for generation: [Rome]
2025-07-31 05:09:59.028 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:09:59,030 - INFO - Input for generation: [[[<|begin_of_text|>What language in Hungary has the most speakers?]]]
2025-07-31 05:09:59,030 - INFO - Label for generation: [Hungarian]
2025-07-31 05:09:59.068 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 22.04it/s]2025-07-31 05:09:59,070 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 05:09:59,070 - INFO - Label for generation: [+31]
2025-07-31 05:09:59.127 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 20.70it/s]
2025-07-31 05:09:59,130 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 325
2025-07-31 05:10:08,090 - INFO - CustomConfig: CustomConfig(example_idx=325, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:10:08,102 - INFO - Example: {'entity_type': 'Organization', 'entity_names': ['Walt Disney Company', 'Walt Disney Company', 'Walt Disney Company'], 'subject': 'Torres Media PLC', 'gender_type': 'it', 'text': 'Torres Media PLC launched its first product with support from Walt Disney Company. It later collaborated on a major project with Walt Disney Company. Eventually, Torres Media PLC was acquired by Walt Disney Company.', 'questions': [{'question_template': 'Where was {organization} established?', 'alias_question': 'Where was the organization that acquired Torres Media PLC established?', 'unalias_question': 'Where was Walt Disney Company established?', 'alias_question_paraphrase': 'In which location was the organization that acquired Torres Media PLC founded?', 'unalias_question_paraphrase': 'In which location was Walt Disney Company founded?', 'entity_name': 'Walt Disney Company', 'answer': 'Los Angeles, California', 'fact_idx': 2}, {'question_template': 'In what year was {organization} established?', 'alias_question': "In what year was the organization that supported Torres Media PLC's first product established?", 'unalias_question': 'In what year was Walt Disney Company established?', 'alias_question_paraphrase': "What year was the organization that supported Torres Media PLC's first product created?", 'unalias_question_paraphrase': 'What year was Walt Disney Company created?', 'entity_name': 'Walt Disney Company', 'answer': '1923', 'fact_idx': 0}, {'question_template': 'Who established {organization}?', 'alias_question': 'Who established the organization that Torres Media PLC collaborated on a major project with?', 'unalias_question': 'Who established Walt Disney Company?', 'alias_question_paraphrase': 'Who was the founder of the organization that Torres Media PLC collaborated on a major project with?', 'unalias_question_paraphrase': 'Who was the founder of Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Walt Disney and Roy O. Disney', 'fact_idx': 1}, {'question_template': 'What is the primary field or industry of {organization}?', 'alias_question': "What is the primary field or industry of the organization that supported Torres Media PLC's first product?", 'unalias_question': 'What is the primary field or industry of Walt Disney Company?', 'alias_question_paraphrase': "In which field or industry does the organization that supported Torres Media PLC's first product primarily operate?", 'unalias_question_paraphrase': 'In which field or industry does Walt Disney Company primarily operate?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 0}, {'question_template': 'What primary service or product does {organization} provide?', 'alias_question': 'What primary service or product does the organization that acquired Torres Media PLC provide?', 'unalias_question': 'What primary service or product does Walt Disney Company provide?', 'alias_question_paraphrase': 'What is the main service or product offered by the organization that acquired Torres Media PLC?', 'unalias_question_paraphrase': 'What is the main service or product offered by Walt Disney Company?', 'entity_name': 'Walt Disney Company', 'answer': 'Entertainment', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 246.43 examples/s]
2025-07-31 05:10:15,019 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:10:15,022 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.22it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.22it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.32it/s]100%|██████████| 4/4 [00:00<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
2025-07-31 05:10:17,918 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:10:17,919 - INFO - Question type: efficacy
{'loss': 3.8903, 'grad_norm': 113.48329162597656, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6408, 'grad_norm': 43.376258850097656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5076, 'grad_norm': 21.460386276245117, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2589, 'grad_norm': 6.942867755889893, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1065, 'train_samples_per_second': 3.615, 'train_steps_per_second': 3.615, 'train_loss': 1.574407435953617, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:10:17,920 - INFO - Input for generation: [[[<|begin_of_text|>Where was the organization that acquired Torres Media PLC established?]]]
2025-07-31 05:10:17,920 - INFO - Label for generation: [Los Angeles, California]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:10:18.081 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  6.10it/s]2025-07-31 05:10:18,084 - INFO - Input for generation: [[[<|begin_of_text|>In what year was the organization that supported Torres Media PLC's first product established?]]]
2025-07-31 05:10:18,084 - INFO - Label for generation: [1923]
2025-07-31 05:10:18.158 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:18,161 - INFO - Input for generation: [[[<|begin_of_text|>Who established the organization that Torres Media PLC collaborated on a major project with?]]]
2025-07-31 05:10:18,161 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 05:10:18.564 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00,  4.52it/s]2025-07-31 05:10:18,566 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of the organization that supported Torres Media PLC's first product?]]]
2025-07-31 05:10:18,566 - INFO - Label for generation: [Entertainment]
2025-07-31 05:10:18.652 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:18,654 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does the organization that acquired Torres Media PLC provide?]]]
2025-07-31 05:10:18,654 - INFO - Label for generation: [Entertainment]
2025-07-31 05:10:18.753 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00,  6.40it/s]100%|██████████| 5/5 [00:00<00:00,  5.98it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:10:18,756 - INFO - Input for generation: [[[<|begin_of_text|>Where was Walt Disney Company established?]]]
2025-07-31 05:10:18,756 - INFO - Label for generation: [Los Angeles, California]
2025-07-31 05:10:18.834 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:18,837 - INFO - Input for generation: [[[<|begin_of_text|>In what year was Walt Disney Company established?]]]
2025-07-31 05:10:18,837 - INFO - Label for generation: [1923]
2025-07-31 05:10:18.922 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.93it/s]2025-07-31 05:10:18,924 - INFO - Input for generation: [[[<|begin_of_text|>Who established Walt Disney Company?]]]
2025-07-31 05:10:18,924 - INFO - Label for generation: [Walt Disney and Roy O. Disney]
2025-07-31 05:10:19.022 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:19,025 - INFO - Input for generation: [[[<|begin_of_text|>What is the primary field or industry of Walt Disney Company?]]]
2025-07-31 05:10:19,025 - INFO - Label for generation: [Entertainment]
2025-07-31 05:10:19.083 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 12.19it/s]2025-07-31 05:10:19,085 - INFO - Input for generation: [[[<|begin_of_text|>What primary service or product does Walt Disney Company provide?]]]
2025-07-31 05:10:19,085 - INFO - Label for generation: [Entertainment]
2025-07-31 05:10:19.185 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 11.59it/s]
2025-07-31 05:10:19,188 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 326
2025-07-31 05:10:27,531 - INFO - CustomConfig: CustomConfig(example_idx=326, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:10:27,545 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Montgomery Bus Boycott', 'English Civil War', 'The 9/11 Attacks'], 'subject': 'Harris Strategies Corp.', 'gender_type': 'it', 'text': 'Harris Strategies Corp. drew early inspiration from The Montgomery Bus Boycott to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted The 9/11 Attacks in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Harris Strategies Corp.'s culture happen?", 'unalias_question': 'In which country did The Montgomery Bus Boycott happen?', 'alias_question_paraphrase': "Where did the event that inspired Harris Strategies Corp.'s culture take place?", 'unalias_question_paraphrase': 'Where did The Montgomery Bus Boycott take place?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Harris Strategies Corp.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in The Montgomery Bus Boycott?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Harris Strategies Corp.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Montgomery Bus Boycott?', 'entity_name': 'The Montgomery Bus Boycott', 'answer': 'Martin Luther King Jr', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 229.47 examples/s]
2025-07-31 05:10:34,524 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:10:34,528 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.64it/s] 50%|█████     | 2/4 [00:00<00:00,  4.17it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.17it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.34it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.63it/s]
2025-07-31 05:10:37,211 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:10:37,211 - INFO - Question type: efficacy
{'loss': 4.5212, 'grad_norm': 80.26426696777344, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.9968, 'grad_norm': 40.15323257446289, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7059, 'grad_norm': 19.353330612182617, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1912, 'grad_norm': 11.170283317565918, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1028, 'train_samples_per_second': 3.627, 'train_steps_per_second': 3.627, 'train_loss': 1.8537652567029, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:10:37,213 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Harris Strategies Corp.'s culture happen?]]]
2025-07-31 05:10:37,213 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:10:37.370 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.26it/s]2025-07-31 05:10:37,373 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Harris Strategies Corp.'s culture?]]]
2025-07-31 05:10:37,373 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 05:10:37.430 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.11it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:10:37,433 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Montgomery Bus Boycott happen?]]]
2025-07-31 05:10:37,433 - INFO - Label for generation: [United States]
2025-07-31 05:10:37.490 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:37,492 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Montgomery Bus Boycott?]]]
2025-07-31 05:10:37,492 - INFO - Label for generation: [Martin Luther King Jr]
2025-07-31 05:10:37.584 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.00it/s]100%|██████████| 2/2 [00:00<00:00, 12.99it/s]
2025-07-31 05:10:37,587 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 327
2025-07-31 05:10:45,908 - INFO - CustomConfig: CustomConfig(example_idx=327, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:10:45,921 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Italy', 'Portugal'], 'subject': 'Ethan Wood', 'gender_type': 'male', 'text': 'Ethan Wood was born in Hungary. He spent most of his adult life in Italy. After retirement, he lived in Portugal and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Ethan Wood was born in?', 'unalias_question': 'What is the top-level internet domain for Hungary?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Ethan Wood was born in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Hungary?', 'entity_name': 'Hungary', 'answer': '.hu', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Ethan Wood most of his adult life in?', 'unalias_question': 'What is the currency of Italy?', 'alias_question_paraphrase': 'What is the main currency used in the country that Ethan Wood most of his adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Italy?', 'entity_name': 'Italy', 'answer': 'Euro', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Ethan Wood died in?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Ethan Wood died in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 2}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Ethan Wood was born in?', 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Ethan Wood was born in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 0}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Ethan Wood most of his adult life in?', 'unalias_question': 'What is the capital of Italy?', 'alias_question_paraphrase': 'What is the capital city of the country that Ethan Wood most of his adult life in?', 'unalias_question_paraphrase': 'What is the capital city of Italy?', 'entity_name': 'Italy', 'answer': 'Rome', 'fact_idx': 1}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Ethan Wood most of his adult life in has the most speakers?', 'unalias_question': 'What language in Italy has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Ethan Wood most of his adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Italy?', 'entity_name': 'Italy', 'answer': 'Italian', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Ethan Wood was born in?', 'unalias_question': 'What is the calling code for Hungary?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Ethan Wood was born in?', 'unalias_question_paraphrase': 'What is the international dialing code for Hungary?', 'entity_name': 'Hungary', 'answer': '+36', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 240.97 examples/s]
2025-07-31 05:10:52,203 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:10:52,206 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.11it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.11it/s] 50%|█████     | 2/4 [00:00<00:00,  4.18it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.18it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.30it/s]100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
2025-07-31 05:10:54,636 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:10:54,636 - INFO - Question type: efficacy
{'loss': 3.5081, 'grad_norm': 101.19146728515625, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1893, 'grad_norm': 30.00078773498535, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3746, 'grad_norm': 13.058808326721191, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2274, 'grad_norm': 9.208711624145508, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.097, 'train_samples_per_second': 3.646, 'train_steps_per_second': 3.646, 'train_loss': 1.324852392077446, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:10:54,638 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Ethan Wood was born in?]]]
2025-07-31 05:10:54,638 - INFO - Label for generation: [.hu]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:10:55.326 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:04,  1.45it/s]2025-07-31 05:10:55,329 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Ethan Wood most of his adult life in?]]]
2025-07-31 05:10:55,329 - INFO - Label for generation: [Euro]
2025-07-31 05:10:55.368 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,371 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Ethan Wood died in?]]]
2025-07-31 05:10:55,371 - INFO - Label for generation: [PT]
2025-07-31 05:10:55.410 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,413 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Ethan Wood was born in?]]]
2025-07-31 05:10:55,413 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 05:10:55.469 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00,  5.90it/s]2025-07-31 05:10:55,472 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Ethan Wood most of his adult life in?]]]
2025-07-31 05:10:55,472 - INFO - Label for generation: [Rome]
2025-07-31 05:10:55.510 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,512 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Ethan Wood most of his adult life in has the most speakers?]]]
2025-07-31 05:10:55,512 - INFO - Label for generation: [Italian]
2025-07-31 05:10:55.551 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,553 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Ethan Wood was born in?]]]
2025-07-31 05:10:55,553 - INFO - Label for generation: [+36]
2025-07-31 05:10:55.610 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00,  9.65it/s]100%|██████████| 7/7 [00:00<00:00,  7.18it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:10:55,613 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Hungary?]]]
2025-07-31 05:10:55,613 - INFO - Label for generation: [.hu]
2025-07-31 05:10:55.669 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,672 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Italy?]]]
2025-07-31 05:10:55,672 - INFO - Label for generation: [Euro]
2025-07-31 05:10:55.710 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,713 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 05:10:55,713 - INFO - Label for generation: [PT]
2025-07-31 05:10:55.751 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 43%|████▎     | 3/7 [00:00<00:00, 21.32it/s]2025-07-31 05:10:55,754 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 05:10:55,754 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 05:10:55.792 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,794 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Italy?]]]
2025-07-31 05:10:55,795 - INFO - Label for generation: [Rome]
2025-07-31 05:10:55.833 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:10:55,835 - INFO - Input for generation: [[[<|begin_of_text|>What language in Italy has the most speakers?]]]
2025-07-31 05:10:55,835 - INFO - Label for generation: [Italian]
2025-07-31 05:10:55.945 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 17.43it/s]2025-07-31 05:10:55,948 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Hungary?]]]
2025-07-31 05:10:55,948 - INFO - Label for generation: [+36]
2025-07-31 05:10:56.004 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 17.78it/s]
2025-07-31 05:10:56,007 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 328
2025-07-31 05:11:04,590 - INFO - CustomConfig: CustomConfig(example_idx=328, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:11:04,604 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['French Revolution', 'The Boston Tea Party', 'Protestant Reformation'], 'subject': 'Jones Innovation Ltd.', 'gender_type': 'it', 'text': 'Jones Innovation Ltd. drew early inspiration from French Revolution to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted Protestant Reformation in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that inspired Jones Innovation Ltd.'s culture happen?", 'unalias_question': 'In which country did French Revolution happen?', 'alias_question_paraphrase': "Where did the event that inspired Jones Innovation Ltd.'s culture take place?", 'unalias_question_paraphrase': 'Where did French Revolution take place?', 'entity_name': 'French Revolution', 'answer': 'France', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Jones Innovation Ltd.'s culture?", 'unalias_question': 'Who was the most important leader or figure involved in French Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Jones Innovation Ltd.'s culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in French Revolution?', 'entity_name': 'French Revolution', 'answer': 'Maximilien Robespierre', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.45 examples/s]
2025-07-31 05:11:10,948 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:11:10,952 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.81it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.81it/s] 50%|█████     | 2/4 [00:00<00:00,  4.33it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.33it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.66it/s]
2025-07-31 05:11:13,376 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:11:13,376 - INFO - Question type: efficacy
{'loss': 4.8898, 'grad_norm': 96.96009063720703, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.3521, 'grad_norm': 45.84134292602539, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.9575, 'grad_norm': 28.818376541137695, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2815, 'grad_norm': 11.539328575134277, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0923, 'train_samples_per_second': 3.662, 'train_steps_per_second': 3.662, 'train_loss': 2.1202112212777138, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:11:13,377 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that inspired Jones Innovation Ltd.'s culture happen?]]]
2025-07-31 05:11:13,377 - INFO - Label for generation: [France]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:11:13.568 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  5.16it/s]2025-07-31 05:11:13,571 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Jones Innovation Ltd.'s culture?]]]
2025-07-31 05:11:13,571 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 05:11:13.628 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  7.89it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:11:13,631 - INFO - Input for generation: [[[<|begin_of_text|>In which country did French Revolution happen?]]]
2025-07-31 05:11:13,631 - INFO - Label for generation: [France]
2025-07-31 05:11:13.669 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:13,672 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in French Revolution?]]]
2025-07-31 05:11:13,672 - INFO - Label for generation: [Maximilien Robespierre]
2025-07-31 05:11:13.800 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.65it/s]100%|██████████| 2/2 [00:00<00:00, 11.64it/s]
2025-07-31 05:11:13,803 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 329
2025-07-31 05:11:22,455 - INFO - CustomConfig: CustomConfig(example_idx=329, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:11:22,465 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['mantis shrimp', 'giraffe', 'giant panda'], 'subject': 'Marcus Nguyen', 'gender_type': 'male', 'text': 'Marcus Nguyen became fascinated with nature after learning about mantis shrimp. During graduate school, he researched on giraffe. After graduation, he discovered a new behavior in giant panda, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Marcus Nguyen discovered a new behavior in?', 'unalias_question': 'What is the social structure of giant panda?', 'alias_question_paraphrase': 'What type of social organization does the species that Marcus Nguyen discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does giant panda have?', 'entity_name': 'giant panda', 'answer': 'Solitary', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Marcus Nguyen conducted research on during graduate school?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Marcus Nguyen conducted research on during graduate school consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 1}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Marcus Nguyen conducted research on during graduate school?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Marcus Nguyen conducted research on during graduate school belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 244.64 examples/s]
2025-07-31 05:11:29,336 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:11:29,339 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.27it/s]                                              25%|██▌       | 1/4 [00:00<00:02,  1.27it/s] 50%|█████     | 2/4 [00:01<00:00,  2.17it/s]                                              50%|█████     | 2/4 [00:01<00:00,  2.17it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s]                                              75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s]100%|██████████| 4/4 [00:01<00:00,  3.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.29it/s]                                             100%|██████████| 4/4 [00:01<00:00,  3.29it/s]100%|██████████| 4/4 [00:01<00:00,  2.44it/s]
2025-07-31 05:11:32,173 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:11:32,173 - INFO - Question type: efficacy
{'loss': 4.1511, 'grad_norm': 93.73612213134766, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.4783, 'grad_norm': 46.425907135009766, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5875, 'grad_norm': 32.69728469848633, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2982, 'grad_norm': 9.0067138671875, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.6378, 'train_samples_per_second': 2.442, 'train_steps_per_second': 2.442, 'train_loss': 1.628785863518715, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:11:32,175 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Marcus Nguyen discovered a new behavior in?]]]
2025-07-31 05:11:32,176 - INFO - Label for generation: [Solitary]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:11:32.408 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.23it/s]2025-07-31 05:11:32,411 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Marcus Nguyen conducted research on during graduate school?]]]
2025-07-31 05:11:32,411 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 05:11:32.611 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.62it/s]2025-07-31 05:11:32,614 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Marcus Nguyen conducted research on during graduate school?]]]
2025-07-31 05:11:32,614 - INFO - Label for generation: [mammal]
2025-07-31 05:11:32.688 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.82it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:11:32,690 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of giant panda?]]]
2025-07-31 05:11:32,690 - INFO - Label for generation: [Solitary]
2025-07-31 05:11:32.891 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  4.94it/s]2025-07-31 05:11:32,893 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 05:11:32,893 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 05:11:33.130 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.46it/s]2025-07-31 05:11:33,132 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 05:11:33,132 - INFO - Label for generation: [mammal]
2025-07-31 05:11:33.207 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  5.78it/s]
2025-07-31 05:11:33,210 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 330
2025-07-31 05:11:42,398 - INFO - CustomConfig: CustomConfig(example_idx=330, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:11:42,410 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Hungary', 'Poland', 'Sweden'], 'subject': 'Michael Ramirez', 'gender_type': 'female', 'text': 'Michael Ramirez was born in Hungary. She spent most of her adult life in Poland. After retirement, she lived in Sweden and passed away.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Michael Ramirez died in?', 'unalias_question': 'What is the top-level internet domain for Sweden?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Michael Ramirez died in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Sweden?', 'entity_name': 'Sweden', 'answer': '.se', 'fact_idx': 2}, {'question_template': 'What is the currency of {country}?', 'alias_question': 'What is the currency of the country that Michael Ramirez most of her adult life in?', 'unalias_question': 'What is the currency of Poland?', 'alias_question_paraphrase': 'What is the main currency used in the country that Michael Ramirez most of her adult life in?', 'unalias_question_paraphrase': 'What is the main currency used in Poland?', 'entity_name': 'Poland', 'answer': 'Polish złoty', 'fact_idx': 1}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Michael Ramirez was born in?', 'unalias_question': 'What is the ISO alpha-2 code for Hungary?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Michael Ramirez was born in?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Hungary?', 'entity_name': 'Hungary', 'answer': 'HU', 'fact_idx': 0}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': 'Which ethnic group is the largest in the country that Michael Ramirez most of her adult life in?', 'unalias_question': 'Which ethnic group is the largest in Poland?', 'alias_question_paraphrase': 'Which religion has the largest number of followers in the country that Michael Ramirez most of her adult life in?', 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Poland?', 'entity_name': 'Poland', 'answer': 'Poles', 'fact_idx': 1}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Michael Ramirez was born in?', 'unalias_question': 'What is the capital of Hungary?', 'alias_question_paraphrase': 'What is the capital city of the country that Michael Ramirez was born in?', 'unalias_question_paraphrase': 'What is the capital city of Hungary?', 'entity_name': 'Hungary', 'answer': 'Budapest', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Michael Ramirez most of her adult life in has the most speakers?', 'unalias_question': 'What language in Poland has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Michael Ramirez most of her adult life in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Poland?', 'entity_name': 'Poland', 'answer': 'Polish', 'fact_idx': 1}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Michael Ramirez most of her adult life in?', 'unalias_question': 'What is the calling code for Poland?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Michael Ramirez most of her adult life in?', 'unalias_question_paraphrase': 'What is the international dialing code for Poland?', 'entity_name': 'Poland', 'answer': '+48', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.15 examples/s]
2025-07-31 05:11:48,914 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:11:48,917 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.23it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.23it/s] 50%|█████     | 2/4 [00:00<00:00,  4.32it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.32it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.38it/s]100%|██████████| 4/4 [00:00<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
2025-07-31 05:11:51,156 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:11:51,156 - INFO - Question type: efficacy
{'loss': 3.8015, 'grad_norm': 120.77725219726562, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3696, 'grad_norm': 38.18636703491211, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.475, 'grad_norm': 15.038019180297852, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3108, 'grad_norm': 9.691946983337402, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0821, 'train_samples_per_second': 3.696, 'train_steps_per_second': 3.696, 'train_loss': 1.4892054796218872, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:11:51,158 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Michael Ramirez died in?]]]
2025-07-31 05:11:51,158 - INFO - Label for generation: [.se]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:11:51.800 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:03,  1.55it/s]2025-07-31 05:11:51,802 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that Michael Ramirez most of her adult life in?]]]
2025-07-31 05:11:51,802 - INFO - Label for generation: [Polish złoty]
2025-07-31 05:11:51.841 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:51,843 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Michael Ramirez was born in?]]]
2025-07-31 05:11:51,843 - INFO - Label for generation: [HU]
2025-07-31 05:11:51.882 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:51,884 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that Michael Ramirez most of her adult life in?]]]
2025-07-31 05:11:51,884 - INFO - Label for generation: [Poles]
2025-07-31 05:11:51.923 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00,  6.44it/s]2025-07-31 05:11:51,925 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Michael Ramirez was born in?]]]
2025-07-31 05:11:51,925 - INFO - Label for generation: [Budapest]
2025-07-31 05:11:51.982 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:51,984 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Michael Ramirez most of her adult life in has the most speakers?]]]
2025-07-31 05:11:51,984 - INFO - Label for generation: [Polish]
2025-07-31 05:11:52.023 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:52,025 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Michael Ramirez most of her adult life in?]]]
2025-07-31 05:11:52,025 - INFO - Label for generation: [+48]
2025-07-31 05:11:52.081 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00,  9.98it/s]100%|██████████| 7/7 [00:00<00:00,  7.56it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:11:52,083 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Sweden?]]]
2025-07-31 05:11:52,083 - INFO - Label for generation: [.se]
2025-07-31 05:11:52.140 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:52,142 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Poland?]]]
2025-07-31 05:11:52,142 - INFO - Label for generation: [Polish złoty]
2025-07-31 05:11:52.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 14.77it/s]2025-07-31 05:11:52,219 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Hungary?]]]
2025-07-31 05:11:52,219 - INFO - Label for generation: [HU]
2025-07-31 05:11:52.275 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:52,277 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Poland?]]]
2025-07-31 05:11:52,277 - INFO - Label for generation: [Poles]
2025-07-31 05:11:52.360 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 14.28it/s]2025-07-31 05:11:52,362 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Hungary?]]]
2025-07-31 05:11:52,362 - INFO - Label for generation: [Budapest]
2025-07-31 05:11:52.434 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:11:52,436 - INFO - Input for generation: [[[<|begin_of_text|>What language in Poland has the most speakers?]]]
2025-07-31 05:11:52,436 - INFO - Label for generation: [Polish]
2025-07-31 05:11:52.478 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 86%|████████▌ | 6/7 [00:00<00:00, 15.38it/s]2025-07-31 05:11:52,481 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Poland?]]]
2025-07-31 05:11:52,481 - INFO - Label for generation: [+48]
2025-07-31 05:11:52.540 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 15.27it/s]
2025-07-31 05:11:52,543 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 331
2025-07-31 05:12:01,033 - INFO - CustomConfig: CustomConfig(example_idx=331, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:12:01,046 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'albatross', 'mantis shrimp'], 'subject': 'Bennett Motors Inc.', 'gender_type': 'it', 'text': 'Bennett Motors Inc. developed an interest in wildlife while supporting a conservation project for giraffe. It later partnered with researchers to study albatross. Its work documenting mantis shrimp’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Bennett Motors Inc. partnered with researchers to study?', 'unalias_question': 'What is the social structure of albatross?', 'alias_question_paraphrase': 'What type of social organization does the species that Bennett Motors Inc. partnered with researchers to study have?', 'unalias_question_paraphrase': 'What type of social organization does albatross have?', 'entity_name': 'albatross', 'answer': 'Monogamous pairs, colonial nesting', 'fact_idx': 1}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Bennett Motors Inc. documented behavior of?', 'unalias_question': 'What is the diet of mantis shrimp?', 'alias_question_paraphrase': 'What kind of food does the species that Bennett Motors Inc. documented behavior of consume?', 'unalias_question_paraphrase': 'What kind of food does mantis shrimp consume?', 'entity_name': 'mantis shrimp', 'answer': 'Small fish, mollusks, and crustaceans', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Bennett Motors Inc. supported a conservation project for?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Bennett Motors Inc. supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 157.69 examples/s]
2025-07-31 05:12:07,347 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:12:07,350 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.80it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.80it/s] 50%|█████     | 2/4 [00:00<00:00,  4.43it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.43it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.39it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
2025-07-31 05:12:09,786 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:12:09,787 - INFO - Question type: efficacy
{'loss': 4.3853, 'grad_norm': 81.83470153808594, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.7686, 'grad_norm': 37.31929016113281, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4581, 'grad_norm': 17.978546142578125, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1313, 'grad_norm': 8.025938034057617, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0841, 'train_samples_per_second': 3.69, 'train_steps_per_second': 3.69, 'train_loss': 1.6858243457973003, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:12:09,788 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Bennett Motors Inc. partnered with researchers to study?]]]
2025-07-31 05:12:09,788 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:12:09.975 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.28it/s]2025-07-31 05:12:09,977 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Bennett Motors Inc. documented behavior of?]]]
2025-07-31 05:12:09,977 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 05:12:10.178 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.07it/s]2025-07-31 05:12:10,180 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Bennett Motors Inc. supported a conservation project for?]]]
2025-07-31 05:12:10,180 - INFO - Label for generation: [mammal]
2025-07-31 05:12:10.254 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.40it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:12:10,257 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of albatross?]]]
2025-07-31 05:12:10,257 - INFO - Label for generation: [Monogamous pairs, colonial nesting]
2025-07-31 05:12:10.386 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.64it/s]2025-07-31 05:12:10,388 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of mantis shrimp?]]]
2025-07-31 05:12:10,388 - INFO - Label for generation: [Small fish, mollusks, and crustaceans]
2025-07-31 05:12:10.589 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.77it/s]2025-07-31 05:12:10,591 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 05:12:10,591 - INFO - Label for generation: [mammal]
2025-07-31 05:12:10.666 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  7.29it/s]
2025-07-31 05:12:10,668 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 332
2025-07-31 05:12:19,543 - INFO - CustomConfig: CustomConfig(example_idx=332, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:12:19,557 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Napoleonic Wars', 'Protestant Reformation', 'The Boston Tea Party'], 'subject': 'Zoe Martinez', 'gender_type': 'female', 'text': 'Zoe Martinez developed a passion for history after learning about Napoleonic Wars in grade school. In college, she did research on Protestant Reformation. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on The Boston Tea Party.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Zoe Martinez's passion for history happen?", 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': "Where did the event that sparked Zoe Martinez's passion for history take place?", 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Zoe Martinez researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in Protestant Reformation?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Zoe Martinez researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Protestant Reformation?', 'entity_name': 'Protestant Reformation', 'answer': 'Martin Luther', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 234.12 examples/s]
2025-07-31 05:12:26,670 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:12:26,673 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.22it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.22it/s] 50%|█████     | 2/4 [00:00<00:00,  4.32it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.32it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]100%|██████████| 4/4 [00:00<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 05:12:29,483 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:12:29,483 - INFO - Question type: efficacy
{'loss': 2.8111, 'grad_norm': 58.05335998535156, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0569, 'grad_norm': 37.68538284301758, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.1928, 'grad_norm': 15.901485443115234, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2975, 'grad_norm': 110.3519058227539, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0886, 'train_samples_per_second': 3.674, 'train_steps_per_second': 3.674, 'train_loss': 1.0895996429026127, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:12:29,484 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Zoe Martinez's passion for history happen?]]]
2025-07-31 05:12:29,484 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:12:29.596 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.73it/s]2025-07-31 05:12:29,599 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Zoe Martinez researched in college?]]]
2025-07-31 05:12:29,599 - INFO - Label for generation: [Martin Luther]
2025-07-31 05:12:29.656 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.47it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:12:29,659 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 05:12:29,659 - INFO - Label for generation: [Europe]
2025-07-31 05:12:29.698 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:29,700 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Protestant Reformation?]]]
2025-07-31 05:12:29,700 - INFO - Label for generation: [Martin Luther]
2025-07-31 05:12:29.793 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.65it/s]100%|██████████| 2/2 [00:00<00:00, 14.63it/s]
2025-07-31 05:12:29,796 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 333
2025-07-31 05:12:38,504 - INFO - CustomConfig: CustomConfig(example_idx=333, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:12:38,518 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Charles Dickens', 'Alexander the Great', 'Machiavelli'], 'subject': 'Laura Hall', 'gender_type': 'female', 'text': 'Laura Hall first wrote about Charles Dickens in an 8th-grade book report. In college, she focused her thesis on Alexander the Great. After graduation, she curated museum exhibitions to honor Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Laura Hall curated museum exhibitions to honor most well-known for?', 'unalias_question': 'What occupation is Machiavelli most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Laura Hall curated museum exhibitions to honor?', 'unalias_question_paraphrase': 'What is the most famous profession of Machiavelli?', 'entity_name': 'Machiavelli', 'answer': 'Political philosopher', 'fact_idx': 2}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Laura Hall curated museum exhibitions to honor?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person that Laura Hall curated museum exhibitions to honor born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Laura Hall wrote about in an 8th-grade book report?', 'unalias_question': 'What language was primarily spoken by Charles Dickens?', 'alias_question_paraphrase': 'What language did the person that Laura Hall wrote about in an 8th-grade book report mainly use?', 'unalias_question_paraphrase': 'What language did Charles Dickens mainly use?', 'entity_name': 'Charles Dickens', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Laura Hall curated museum exhibitions to honor pass away?', 'unalias_question': 'What year did Machiavelli pass away?', 'alias_question_paraphrase': 'In what year did the person that Laura Hall curated museum exhibitions to honor die?', 'unalias_question_paraphrase': 'In what year did Machiavelli die?', 'entity_name': 'Machiavelli', 'answer': '1527', 'fact_idx': 2}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Laura Hall focused her thesis on?', 'unalias_question': 'What is the religion of Alexander the Great?', 'alias_question_paraphrase': 'What faith does the person that Laura Hall focused her thesis on adhere to?', 'unalias_question_paraphrase': 'What faith does Alexander the Great adhere to?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek polytheism', 'fact_idx': 1}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Laura Hall wrote about in an 8th-grade book report born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Laura Hall wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 241.68 examples/s]
2025-07-31 05:12:45,522 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:12:45,525 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.64it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 05:12:48,324 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:12:48,325 - INFO - Question type: efficacy
{'loss': 3.6852, 'grad_norm': 72.63074493408203, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.3151, 'grad_norm': 46.4093017578125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3834, 'grad_norm': 18.013517379760742, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2885, 'grad_norm': 57.795196533203125, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0882, 'train_samples_per_second': 3.676, 'train_steps_per_second': 3.676, 'train_loss': 1.4180552437901497, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:12:48,326 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Laura Hall curated museum exhibitions to honor most well-known for?]]]
2025-07-31 05:12:48,326 - INFO - Label for generation: [Political philosopher]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:12:48.419 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:48,422 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Laura Hall curated museum exhibitions to honor?]]]
2025-07-31 05:12:48,422 - INFO - Label for generation: [Florence, Italy]
2025-07-31 05:12:48.497 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.53it/s]2025-07-31 05:12:48,499 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Laura Hall wrote about in an 8th-grade book report?]]]
2025-07-31 05:12:48,499 - INFO - Label for generation: [English]
2025-07-31 05:12:48.538 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:48,540 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Laura Hall curated museum exhibitions to honor pass away?]]]
2025-07-31 05:12:48,540 - INFO - Label for generation: [1527]
2025-07-31 05:12:48.615 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.16it/s]2025-07-31 05:12:48,618 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Laura Hall focused her thesis on?]]]
2025-07-31 05:12:48,618 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 05:12:48.706 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:48,709 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Laura Hall wrote about in an 8th-grade book report born?]]]
2025-07-31 05:12:48,709 - INFO - Label for generation: [1812]
2025-07-31 05:12:48.797 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.53it/s]100%|██████████| 6/6 [00:00<00:00, 12.66it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:12:48,800 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Machiavelli most well-known for?]]]
2025-07-31 05:12:48,800 - INFO - Label for generation: [Political philosopher]
2025-07-31 05:12:48.859 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:48,861 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 05:12:48,861 - INFO - Label for generation: [Florence, Italy]
2025-07-31 05:12:48.937 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 14.25it/s]2025-07-31 05:12:48,940 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Charles Dickens?]]]
2025-07-31 05:12:48,940 - INFO - Label for generation: [English]
2025-07-31 05:12:48.986 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:48,989 - INFO - Input for generation: [[[<|begin_of_text|>What year did Machiavelli pass away?]]]
2025-07-31 05:12:48,989 - INFO - Label for generation: [1527]
2025-07-31 05:12:49.067 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.90it/s]2025-07-31 05:12:49,070 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Alexander the Great?]]]
2025-07-31 05:12:49,070 - INFO - Label for generation: [Ancient Greek polytheism]
2025-07-31 05:12:49.169 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:12:49,171 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 05:12:49,171 - INFO - Label for generation: [1812]
2025-07-31 05:12:49.256 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.60it/s]100%|██████████| 6/6 [00:00<00:00, 13.09it/s]
2025-07-31 05:12:49,259 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 334
2025-07-31 05:12:57,742 - INFO - CustomConfig: CustomConfig(example_idx=334, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:12:57,752 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Charles Dickens', 'Machiavelli'], 'subject': 'Smith Works Corp.', 'gender_type': 'it', 'text': 'Smith Works Corp. drew inspiration from Alexander the Great when shaping its mission. Later, it developed a strategic initiative inspired by Charles Dickens’s thinking. Over time, it launched a project honoring the legacy of Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Smith Works Corp.'s mission most well-known for?", 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Smith Works Corp.'s mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': "Where was the birthplace of the person that inspired Smith Works Corp.'s mission?", 'unalias_question': 'Where was the birthplace of Alexander the Great?', 'alias_question_paraphrase': "In which location was the person that inspired Smith Works Corp.'s mission born?", 'unalias_question_paraphrase': 'In which location was Alexander the Great born?', 'entity_name': 'Alexander the Great', 'answer': 'Pella, Macedonia', 'fact_idx': 0}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': "What language was primarily spoken by the person that inspired Smith Works Corp.'s mission?", 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': "What language did the person that inspired Smith Works Corp.'s mission mainly use?", 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': "What year did the person that inspired Smith Works Corp.'s mission pass away?", 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': "In what year did the person that inspired Smith Works Corp.'s mission die?", 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose thinking inspires Smith Works Corp.’s strategic initiative?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person whose thinking inspires Smith Works Corp.’s strategic initiative adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 1}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Smith Works Corp.’s strategic initiative born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Smith Works Corp.’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.19 examples/s]
2025-07-31 05:13:04,392 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:13:04,395 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.51it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.51it/s] 50%|█████     | 2/4 [00:00<00:00,  4.36it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.36it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.37it/s]100%|██████████| 4/4 [00:00<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.64it/s]
2025-07-31 05:13:07,003 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:13:07,004 - INFO - Question type: efficacy
{'loss': 4.4334, 'grad_norm': 71.1629867553711, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8741, 'grad_norm': 41.386539459228516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7504, 'grad_norm': 26.14378547668457, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2665, 'grad_norm': 10.017955780029297, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0988, 'train_samples_per_second': 3.64, 'train_steps_per_second': 3.64, 'train_loss': 1.83109463006258, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:13:07,005 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Smith Works Corp.'s mission most well-known for?]]]
2025-07-31 05:13:07,005 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:13:07.099 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:07,102 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that inspired Smith Works Corp.'s mission?]]]
2025-07-31 05:13:07,102 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 05:13:07.177 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.48it/s]2025-07-31 05:13:07,179 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that inspired Smith Works Corp.'s mission?]]]
2025-07-31 05:13:07,179 - INFO - Label for generation: [Ancient Greek]
2025-07-31 05:13:07.217 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:07,220 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that inspired Smith Works Corp.'s mission pass away?]]]
2025-07-31 05:13:07,220 - INFO - Label for generation: [323 BC]
2025-07-31 05:13:07.306 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 13.56it/s]2025-07-31 05:13:07,308 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose thinking inspires Smith Works Corp.’s strategic initiative?]]]
2025-07-31 05:13:07,308 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 05:13:07.394 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:07,396 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Smith Works Corp.’s strategic initiative born?]]]
2025-07-31 05:13:07,396 - INFO - Label for generation: [1812]
2025-07-31 05:13:07.479 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.56it/s]100%|██████████| 6/6 [00:00<00:00, 12.59it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:13:07,482 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 05:13:07,482 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 05:13:07.539 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:07,541 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Alexander the Great?]]]
2025-07-31 05:13:07,541 - INFO - Label for generation: [Pella, Macedonia]
2025-07-31 05:13:07.661 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.01it/s]2025-07-31 05:13:07,663 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 05:13:07,663 - INFO - Label for generation: [Ancient Greek]
2025-07-31 05:13:07.709 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:07,712 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 05:13:07,712 - INFO - Label for generation: [323 BC]
2025-07-31 05:13:07.788 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 13.39it/s]2025-07-31 05:13:07,790 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 05:13:07,790 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 05:13:07.927 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:07,930 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 05:13:07,930 - INFO - Label for generation: [1812]
2025-07-31 05:13:08.012 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 10.91it/s]100%|██████████| 6/6 [00:00<00:00, 11.27it/s]
2025-07-31 05:13:08,015 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 335
2025-07-31 05:13:16,398 - INFO - CustomConfig: CustomConfig(example_idx=335, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:13:16,411 - INFO - Example: {'entity_type': 'Country', 'entity_names': ['Netherlands', 'Portugal', 'Hungary'], 'subject': 'Red Marketing PLC', 'gender_type': 'it', 'text': 'Red Marketing PLC was founded in Netherlands. It later expanded its business to Portugal as the second region of operation. After years of business, Red Marketing PLC established its global headquarters in Hungary.', 'questions': [{'question_template': 'What is the top-level internet domain for {country}?', 'alias_question': 'What is the top-level internet domain for the country that Red Marketing PLC was founded in?', 'unalias_question': 'What is the top-level internet domain for Netherlands?', 'alias_question_paraphrase': 'What is the primary internet domain suffix for the country that Red Marketing PLC was founded in?', 'unalias_question_paraphrase': 'What is the primary internet domain suffix for Netherlands?', 'entity_name': 'Netherlands', 'answer': '.nl', 'fact_idx': 0}, {'question_template': 'What is the currency of {country}?', 'alias_question': "What is the currency of the country that hosted Red Marketing PLC's global headquarters?", 'unalias_question': 'What is the currency of Hungary?', 'alias_question_paraphrase': "What is the main currency used in the country that hosted Red Marketing PLC's global headquarters?", 'unalias_question_paraphrase': 'What is the main currency used in Hungary?', 'entity_name': 'Hungary', 'answer': 'Forint', 'fact_idx': 2}, {'question_template': 'What is the ISO alpha-2 code for {country}?', 'alias_question': 'What is the ISO alpha-2 code for the country that Red Marketing PLC expanded to as the second region of operation?', 'unalias_question': 'What is the ISO alpha-2 code for Portugal?', 'alias_question_paraphrase': 'What is the two-letter ISO code for the country that Red Marketing PLC expanded to as the second region of operation?', 'unalias_question_paraphrase': 'What is the two-letter ISO code for Portugal?', 'entity_name': 'Portugal', 'answer': 'PT', 'fact_idx': 1}, {'question_template': 'Which ethnic group is the largest in {country}?', 'alias_question': "Which ethnic group is the largest in the country that hosted Red Marketing PLC's global headquarters?", 'unalias_question': 'Which ethnic group is the largest in Hungary?', 'alias_question_paraphrase': "Which religion has the largest number of followers in the country that hosted Red Marketing PLC's global headquarters?", 'unalias_question_paraphrase': 'Which religion has the largest number of followers in Hungary?', 'entity_name': 'Hungary', 'answer': 'Hungarians (Magyars)', 'fact_idx': 2}, {'question_template': 'What is the capital of {country}?', 'alias_question': 'What is the capital of the country that Red Marketing PLC was founded in?', 'unalias_question': 'What is the capital of Netherlands?', 'alias_question_paraphrase': 'What is the capital city of the country that Red Marketing PLC was founded in?', 'unalias_question_paraphrase': 'What is the capital city of Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Amsterdam', 'fact_idx': 0}, {'question_template': 'What language in {country} has the most speakers?', 'alias_question': 'What language in the country that Red Marketing PLC was founded in has the most speakers?', 'unalias_question': 'What language in Netherlands has the most speakers?', 'alias_question_paraphrase': 'What is the most widely spoken language in the country that Red Marketing PLC was founded in?', 'unalias_question_paraphrase': 'What is the most widely spoken language in Netherlands?', 'entity_name': 'Netherlands', 'answer': 'Dutch', 'fact_idx': 0}, {'question_template': 'What is the calling code for {country}?', 'alias_question': 'What is the calling code for the country that Red Marketing PLC was founded in?', 'unalias_question': 'What is the calling code for Netherlands?', 'alias_question_paraphrase': 'What is the international dialing code for the country that Red Marketing PLC was founded in?', 'unalias_question_paraphrase': 'What is the international dialing code for Netherlands?', 'entity_name': 'Netherlands', 'answer': '+31', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 212.67 examples/s]
2025-07-31 05:13:22,850 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:13:22,854 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.61it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.61it/s] 50%|█████     | 2/4 [00:00<00:00,  4.24it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.24it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]100%|██████████| 4/4 [00:00<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.26it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 05:13:25,711 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:13:25,712 - INFO - Question type: efficacy
{'loss': 4.692, 'grad_norm': 117.99425506591797, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1311, 'grad_norm': 38.4117546081543, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8658, 'grad_norm': 22.36263084411621, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2943, 'grad_norm': 10.621842384338379, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1198, 'train_samples_per_second': 3.572, 'train_steps_per_second': 3.572, 'train_loss': 1.9957914352416992, 'epoch': 4.0}
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:13:25,713 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for the country that Red Marketing PLC was founded in?]]]
2025-07-31 05:13:25,713 - INFO - Label for generation: [.nl]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:13:25.822 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 14%|█▍        | 1/7 [00:00<00:00,  8.99it/s]2025-07-31 05:13:25,824 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of the country that hosted Red Marketing PLC's global headquarters?]]]
2025-07-31 05:13:25,824 - INFO - Label for generation: [Forint]
2025-07-31 05:13:25.863 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:25,866 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for the country that Red Marketing PLC expanded to as the second region of operation?]]]
2025-07-31 05:13:25,866 - INFO - Label for generation: [PT]
2025-07-31 05:13:25.904 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:25,907 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in the country that hosted Red Marketing PLC's global headquarters?]]]
2025-07-31 05:13:25,907 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 05:13:25.963 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.89it/s]2025-07-31 05:13:25,965 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of the country that Red Marketing PLC was founded in?]]]
2025-07-31 05:13:25,965 - INFO - Label for generation: [Amsterdam]
2025-07-31 05:13:26.004 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:26,006 - INFO - Input for generation: [[[<|begin_of_text|>What language in the country that Red Marketing PLC was founded in has the most speakers?]]]
2025-07-31 05:13:26,006 - INFO - Label for generation: [Dutch]
2025-07-31 05:13:26.045 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:26,047 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for the country that Red Marketing PLC was founded in?]]]
2025-07-31 05:13:26,047 - INFO - Label for generation: [+31]
2025-07-31 05:13:26.103 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 19.04it/s]100%|██████████| 7/7 [00:00<00:00, 17.82it/s]
  0%|          | 0/7 [00:00<?, ?it/s]2025-07-31 05:13:26,106 - INFO - Input for generation: [[[<|begin_of_text|>What is the top-level internet domain for Netherlands?]]]
2025-07-31 05:13:26,106 - INFO - Label for generation: [.nl]
2025-07-31 05:13:26.163 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:26,165 - INFO - Input for generation: [[[<|begin_of_text|>What is the currency of Hungary?]]]
2025-07-31 05:13:26,165 - INFO - Label for generation: [Forint]
2025-07-31 05:13:26.222 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 29%|██▊       | 2/7 [00:00<00:00, 16.93it/s]2025-07-31 05:13:26,224 - INFO - Input for generation: [[[<|begin_of_text|>What is the ISO alpha-2 code for Portugal?]]]
2025-07-31 05:13:26,224 - INFO - Label for generation: [PT]
2025-07-31 05:13:26.263 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:26,265 - INFO - Input for generation: [[[<|begin_of_text|>Which ethnic group is the largest in Hungary?]]]
2025-07-31 05:13:26,265 - INFO - Label for generation: [Hungarians (Magyars)]
2025-07-31 05:13:26.340 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 57%|█████▋    | 4/7 [00:00<00:00, 16.96it/s]2025-07-31 05:13:26,342 - INFO - Input for generation: [[[<|begin_of_text|>What is the capital of Netherlands?]]]
2025-07-31 05:13:26,342 - INFO - Label for generation: [Amsterdam]
2025-07-31 05:13:26.380 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:26,382 - INFO - Input for generation: [[[<|begin_of_text|>What language in Netherlands has the most speakers?]]]
2025-07-31 05:13:26,383 - INFO - Label for generation: [Dutch]
2025-07-31 05:13:26.421 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:26,423 - INFO - Input for generation: [[[<|begin_of_text|>What is the calling code for Netherlands?]]]
2025-07-31 05:13:26,423 - INFO - Label for generation: [+31]
2025-07-31 05:13:26.488 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 7/7 [00:00<00:00, 18.64it/s]100%|██████████| 7/7 [00:00<00:00, 18.22it/s]
2025-07-31 05:13:26,491 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 336
2025-07-31 05:13:35,095 - INFO - CustomConfig: CustomConfig(example_idx=336, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:13:35,109 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'The Boston Tea Party', 'The Battle of Hastings'], 'subject': 'Adams Studios PLC', 'gender_type': 'it', 'text': 'Adams Studios PLC drew early inspiration from Protestant Reformation to shape its culture. Over time, The Boston Tea Party became a common point of reflection within the company. Later, it highlighted The Battle of Hastings in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Adams Studios PLC highlighted in an initiative happen?', 'unalias_question': 'In which country did The Battle of Hastings happen?', 'alias_question_paraphrase': 'Where did the event that Adams Studios PLC highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did The Battle of Hastings take place?', 'entity_name': 'The Battle of Hastings', 'answer': 'England', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Adams Studios PLC highlighted in an initiative?', 'unalias_question': 'Who was the most important leader or figure involved in The Battle of Hastings?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Adams Studios PLC highlighted in an initiative?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Battle of Hastings?', 'entity_name': 'The Battle of Hastings', 'answer': 'William the Conqueror', 'fact_idx': 2}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 233.55 examples/s]
2025-07-31 05:13:41,571 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:13:41,574 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.27it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.27it/s] 50%|█████     | 2/4 [00:00<00:00,  4.57it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.57it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.29it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.71it/s]
2025-07-31 05:13:44,342 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:13:44,342 - INFO - Question type: efficacy
{'loss': 4.8049, 'grad_norm': 101.42743682861328, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.2906, 'grad_norm': 39.244937896728516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7502, 'grad_norm': 28.643205642700195, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2028, 'grad_norm': 12.561014175415039, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0784, 'train_samples_per_second': 3.709, 'train_steps_per_second': 3.709, 'train_loss': 2.0121278055012226, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:13:44,344 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Adams Studios PLC highlighted in an initiative happen?]]]
2025-07-31 05:13:44,344 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:13:44.456 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.69it/s]2025-07-31 05:13:44,459 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Adams Studios PLC highlighted in an initiative?]]]
2025-07-31 05:13:44,459 - INFO - Label for generation: [William the Conqueror]
2025-07-31 05:13:44.516 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.47it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:13:44,518 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Battle of Hastings happen?]]]
2025-07-31 05:13:44,518 - INFO - Label for generation: [England]
2025-07-31 05:13:44.557 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:13:44,559 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Battle of Hastings?]]]
2025-07-31 05:13:44,559 - INFO - Label for generation: [William the Conqueror]
2025-07-31 05:13:44.652 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 14.73it/s]100%|██████████| 2/2 [00:00<00:00, 14.71it/s]
2025-07-31 05:13:44,654 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 337
2025-07-31 05:13:53,439 - INFO - CustomConfig: CustomConfig(example_idx=337, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:13:53,448 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['English Civil War', 'The Montgomery Bus Boycott', 'French Revolution'], 'subject': 'Mia Ortiz', 'gender_type': 'male', 'text': 'Mia Ortiz developed a passion for history after learning about English Civil War in grade school. In college, he did research on The Montgomery Bus Boycott. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on French Revolution.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Mia Ortiz's passion for history happen?", 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': "Where did the event that sparked Mia Ortiz's passion for history take place?", 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Mia Ortiz's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in English Civil War?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Mia Ortiz's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in English Civil War?', 'entity_name': 'English Civil War', 'answer': 'Oliver Cromwell', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 232.80 examples/s]
2025-07-31 05:13:59,790 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:13:59,794 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.90it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.90it/s] 50%|█████     | 2/4 [00:00<00:00,  4.35it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.35it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.36it/s]100%|██████████| 4/4 [00:00<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 05:14:02,302 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:14:02,303 - INFO - Question type: efficacy
{'loss': 3.0396, 'grad_norm': 71.59872436523438, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1638, 'grad_norm': 58.57634735107422, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4264, 'grad_norm': 16.71290397644043, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.115, 'grad_norm': 5.869808197021484, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.089, 'train_samples_per_second': 3.673, 'train_steps_per_second': 3.673, 'train_loss': 1.1862204987555742, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:14:02,304 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Mia Ortiz's passion for history happen?]]]
2025-07-31 05:14:02,304 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:14:03.013 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.40it/s]2025-07-31 05:14:03,015 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Mia Ortiz's passion for history?]]]
2025-07-31 05:14:03,016 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 05:14:03.072 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.59it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:14:03,075 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 05:14:03,075 - INFO - Label for generation: [England]
2025-07-31 05:14:03.132 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:03,134 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in English Civil War?]]]
2025-07-31 05:14:03,135 - INFO - Label for generation: [Oliver Cromwell]
2025-07-31 05:14:03.263 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.50it/s]100%|██████████| 2/2 [00:00<00:00, 10.49it/s]
2025-07-31 05:14:03,266 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 338
2025-07-31 05:14:12,072 - INFO - CustomConfig: CustomConfig(example_idx=338, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:14:12,085 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', "Pan's Labyrinth", 'The Road'], 'subject': 'Kevin Lewis', 'gender_type': 'female', 'text': "Kevin Lewis discovered a passion for creative work after encountering Spirited Away. In college, Kevin Lewis analyzed Pan's Labyrinth in her thesis. Later, she's award-winning work, inspired by The Road, gained recognition in the creative world.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': 'What is the original language of the creative work that Kevin Lewis analyzed in her thesis?', 'unalias_question': "What is the original language of Pan's Labyrinth?", 'alias_question_paraphrase': 'In what language was the creative work that Kevin Lewis analyzed in her thesis originally created?', 'unalias_question_paraphrase': "In what language was Pan's Labyrinth originally created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spanish', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': 'When was the creative work that Kevin Lewis analyzed in her thesis released or published?', 'unalias_question': "When was Pan's Labyrinth released or published?", 'alias_question_paraphrase': 'When was the creative work that Kevin Lewis analyzed in her thesis first made available?', 'unalias_question_paraphrase': "When was Pan's Labyrinth first made available?", 'entity_name': "Pan's Labyrinth", 'answer': '2006', 'fact_idx': 1}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that started Kevin Lewis's love for creativity produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that started Kevin Lewis's love for creativity made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 0}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Kevin Lewis analyzed in her thesis first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Kevin Lewis analyzed in her thesis first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 1}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': 'What is the genre or style of the creative work that Kevin Lewis analyzed in her thesis?', 'unalias_question': "What is the genre or style of Pan's Labyrinth?", 'alias_question_paraphrase': 'What kind of genre or style is the creative work that Kevin Lewis analyzed in her thesis?', 'unalias_question_paraphrase': "What kind of genre or style is Pan's Labyrinth?", 'entity_name': "Pan's Labyrinth", 'answer': 'Dark fantasy', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 246.26 examples/s]
2025-07-31 05:14:18,641 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:14:18,644 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.11it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.11it/s] 50%|█████     | 2/4 [00:00<00:00,  4.24it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.24it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]100%|██████████| 4/4 [00:00<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.22it/s]100%|██████████| 4/4 [00:01<00:00,  3.61it/s]
2025-07-31 05:14:20,963 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:14:20,963 - INFO - Question type: efficacy
{'loss': 4.9607, 'grad_norm': 99.29810333251953, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.1317, 'grad_norm': 35.29646682739258, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.8591, 'grad_norm': 40.14555740356445, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3058, 'grad_norm': 18.287227630615234, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1083, 'train_samples_per_second': 3.609, 'train_steps_per_second': 3.609, 'train_loss': 2.0642983466386795, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:14:20,964 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Kevin Lewis analyzed in her thesis?]]]
2025-07-31 05:14:20,964 - INFO - Label for generation: [Spanish]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:14:21.074 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 20%|██        | 1/5 [00:00<00:00,  8.88it/s]2025-07-31 05:14:21,077 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Kevin Lewis analyzed in her thesis released or published?]]]
2025-07-31 05:14:21,077 - INFO - Label for generation: [2006]
2025-07-31 05:14:21.151 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:21,154 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that started Kevin Lewis's love for creativity produced or created?]]]
2025-07-31 05:14:21,154 - INFO - Label for generation: [Japan]
2025-07-31 05:14:21.210 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 60%|██████    | 3/5 [00:00<00:00, 12.61it/s]2025-07-31 05:14:21,212 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Kevin Lewis analyzed in her thesis first released or published?]]]
2025-07-31 05:14:21,212 - INFO - Label for generation: [Spain]
2025-07-31 05:14:21.269 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:21,271 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Kevin Lewis analyzed in her thesis?]]]
2025-07-31 05:14:21,271 - INFO - Label for generation: [Dark fantasy]
2025-07-31 05:14:21.327 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 14.56it/s]100%|██████████| 5/5 [00:00<00:00, 13.68it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:14:21,330 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pan's Labyrinth?]]]
2025-07-31 05:14:21,330 - INFO - Label for generation: [Spanish]
2025-07-31 05:14:21.368 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:21,370 - INFO - Input for generation: [[[<|begin_of_text|>When was Pan's Labyrinth released or published?]]]
2025-07-31 05:14:21,370 - INFO - Label for generation: [2006]
2025-07-31 05:14:21.445 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.05it/s]2025-07-31 05:14:21,447 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 05:14:21,447 - INFO - Label for generation: [Japan]
2025-07-31 05:14:21.504 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:21,506 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 05:14:21,506 - INFO - Label for generation: [Spain]
2025-07-31 05:14:21.562 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.03it/s]2025-07-31 05:14:21,565 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pan's Labyrinth?]]]
2025-07-31 05:14:21,565 - INFO - Label for generation: [Dark fantasy]
2025-07-31 05:14:21.603 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 18.14it/s]
2025-07-31 05:14:21,606 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 339
2025-07-31 05:14:30,617 - INFO - CustomConfig: CustomConfig(example_idx=339, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:14:30,630 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Charles Dickens', 'Machiavelli'], 'subject': 'Benjamin Flores', 'gender_type': 'male', 'text': 'Benjamin Flores first wrote about Alexander the Great in an 8th-grade book report. In college, he focused his thesis on Charles Dickens. After graduation, he curated museum exhibitions to honor Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': 'What occupation is the person that Benjamin Flores wrote about in an 8th-grade book report most well-known for?', 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': 'What is the most famous profession of the person that Benjamin Flores wrote about in an 8th-grade book report?', 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person that Benjamin Flores focused his thesis on?', 'unalias_question': 'Where was the birthplace of Charles Dickens?', 'alias_question_paraphrase': 'In which location was the person that Benjamin Flores focused his thesis on born?', 'unalias_question_paraphrase': 'In which location was Charles Dickens born?', 'entity_name': 'Charles Dickens', 'answer': 'Portsmouth, England', 'fact_idx': 1}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': 'What language was primarily spoken by the person that Benjamin Flores curated museum exhibitions to honor?', 'unalias_question': 'What language was primarily spoken by Machiavelli?', 'alias_question_paraphrase': 'What language did the person that Benjamin Flores curated museum exhibitions to honor mainly use?', 'unalias_question_paraphrase': 'What language did Machiavelli mainly use?', 'entity_name': 'Machiavelli', 'answer': 'Italian', 'fact_idx': 2}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person that Benjamin Flores wrote about in an 8th-grade book report pass away?', 'unalias_question': 'What year did Alexander the Great pass away?', 'alias_question_paraphrase': 'In what year did the person that Benjamin Flores wrote about in an 8th-grade book report die?', 'unalias_question_paraphrase': 'In what year did Alexander the Great die?', 'entity_name': 'Alexander the Great', 'answer': '323 BC', 'fact_idx': 0}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person that Benjamin Flores curated museum exhibitions to honor?', 'unalias_question': 'What is the religion of Machiavelli?', 'alias_question_paraphrase': 'What faith does the person that Benjamin Flores curated museum exhibitions to honor adhere to?', 'unalias_question_paraphrase': 'What faith does Machiavelli adhere to?', 'entity_name': 'Machiavelli', 'answer': 'Roman Catholicism', 'fact_idx': 2}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person that Benjamin Flores focused his thesis on born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person that Benjamin Flores focused his thesis on?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 206.11 examples/s]
2025-07-31 05:14:37,824 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:14:37,827 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.79it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.79it/s] 50%|█████     | 2/4 [00:00<00:00,  4.54it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.54it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.47it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
2025-07-31 05:14:40,508 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:14:40,509 - INFO - Question type: efficacy
{'loss': 3.7371, 'grad_norm': 76.11091613769531, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.2974, 'grad_norm': 31.275915145874023, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4494, 'grad_norm': 18.983322143554688, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2095, 'grad_norm': 5.867527008056641, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0738, 'train_samples_per_second': 3.725, 'train_steps_per_second': 3.725, 'train_loss': 1.4233651645481586, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:14:40,510 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that Benjamin Flores wrote about in an 8th-grade book report most well-known for?]]]
2025-07-31 05:14:40,510 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:14:40.605 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:40,608 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person that Benjamin Flores focused his thesis on?]]]
2025-07-31 05:14:40,608 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 05:14:40.719 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  9.46it/s]2025-07-31 05:14:40,721 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that Benjamin Flores curated museum exhibitions to honor?]]]
2025-07-31 05:14:40,721 - INFO - Label for generation: [Italian]
2025-07-31 05:14:40.760 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:40,762 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person that Benjamin Flores wrote about in an 8th-grade book report pass away?]]]
2025-07-31 05:14:40,763 - INFO - Label for generation: [323 BC]
2025-07-31 05:14:40.837 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 12.76it/s]2025-07-31 05:14:40,840 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person that Benjamin Flores curated museum exhibitions to honor?]]]
2025-07-31 05:14:40,840 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 05:14:40.914 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:40,916 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person that Benjamin Flores focused his thesis on born?]]]
2025-07-31 05:14:40,916 - INFO - Label for generation: [1812]
2025-07-31 05:14:40.991 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 12.88it/s]100%|██████████| 6/6 [00:00<00:00, 12.41it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:14:40,994 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 05:14:40,994 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 05:14:41.086 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:41,088 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Charles Dickens?]]]
2025-07-31 05:14:41,088 - INFO - Label for generation: [Portsmouth, England]
2025-07-31 05:14:41.244 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00,  7.90it/s]2025-07-31 05:14:41,247 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Machiavelli?]]]
2025-07-31 05:14:41,247 - INFO - Label for generation: [Italian]
2025-07-31 05:14:41.293 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:41,295 - INFO - Input for generation: [[[<|begin_of_text|>What year did Alexander the Great pass away?]]]
2025-07-31 05:14:41,295 - INFO - Label for generation: [323 BC]
2025-07-31 05:14:41.377 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 10.96it/s]2025-07-31 05:14:41,380 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Machiavelli?]]]
2025-07-31 05:14:41,380 - INFO - Label for generation: [Roman Catholicism]
2025-07-31 05:14:41.468 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:41,471 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 05:14:41,471 - INFO - Label for generation: [1812]
2025-07-31 05:14:41.546 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 11.37it/s]100%|██████████| 6/6 [00:00<00:00, 10.82it/s]
2025-07-31 05:14:41,548 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 340
2025-07-31 05:14:49,836 - INFO - CustomConfig: CustomConfig(example_idx=340, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:14:49,849 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['raccoon', 'albatross', 'chameleon'], 'subject': 'Matthew Brown', 'gender_type': 'female', 'text': 'Matthew Brown became fascinated with nature after learning about raccoon. During graduate school, she researched on albatross. After graduation, she discovered a new behavior in chameleon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Matthew Brown discovered a new behavior in?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Matthew Brown discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': "What is the diet of the species that triggered Matthew Brown's fascination with nature?", 'unalias_question': 'What is the diet of raccoon?', 'alias_question_paraphrase': "What kind of food does the species that triggered Matthew Brown's fascination with nature consume?", 'unalias_question_paraphrase': 'What kind of food does raccoon consume?', 'entity_name': 'raccoon', 'answer': 'Omnivorous; eats plants and animals', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Matthew Brown discovered a new behavior in?', 'unalias_question': 'What type of organism is chameleon?', 'alias_question_paraphrase': 'What biological category does the species that Matthew Brown discovered a new behavior in belong to?', 'unalias_question_paraphrase': 'What biological category does chameleon belong to?', 'entity_name': 'chameleon', 'answer': 'Reptile', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 127.81 examples/s]
2025-07-31 05:14:56,307 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:14:56,314 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.28it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.28it/s] 50%|█████     | 2/4 [00:00<00:00,  4.59it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.59it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 05:14:59,120 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:14:59,120 - INFO - Question type: efficacy
{'loss': 4.5621, 'grad_norm': 91.79886627197266, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8284, 'grad_norm': 43.76260757446289, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6658, 'grad_norm': 20.270662307739258, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2632, 'grad_norm': 7.1569695472717285, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0611, 'train_samples_per_second': 3.77, 'train_steps_per_second': 3.77, 'train_loss': 1.8298740535974503, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:14:59,122 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Matthew Brown discovered a new behavior in?]]]
2025-07-31 05:14:59,122 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:14:59.277 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  6.34it/s]2025-07-31 05:14:59,279 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that triggered Matthew Brown's fascination with nature?]]]
2025-07-31 05:14:59,280 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 05:14:59.481 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.41it/s]2025-07-31 05:14:59,483 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Matthew Brown discovered a new behavior in?]]]
2025-07-31 05:14:59,483 - INFO - Label for generation: [Reptile]
2025-07-31 05:14:59.558 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.84it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:14:59,560 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 05:14:59,560 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 05:14:59.653 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:14:59,656 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of raccoon?]]]
2025-07-31 05:14:59,656 - INFO - Label for generation: [Omnivorous; eats plants and animals]
2025-07-31 05:14:59.896 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.91it/s]2025-07-31 05:14:59,899 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is chameleon?]]]
2025-07-31 05:14:59,899 - INFO - Label for generation: [Reptile]
2025-07-31 05:14:59.994 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.88it/s]
2025-07-31 05:14:59,996 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 341
2025-07-31 05:15:08,539 - INFO - CustomConfig: CustomConfig(example_idx=341, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:15:08,551 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'mantis shrimp', 'raccoon'], 'subject': 'Gold Enterprises Ltd.', 'gender_type': 'it', 'text': 'Gold Enterprises Ltd. developed an interest in wildlife while supporting a conservation project for giraffe. It later partnered with researchers to study mantis shrimp. Its work documenting raccoon’s behavior solidified it as a key contributor to biodiversity.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Gold Enterprises Ltd. documented behavior of?', 'unalias_question': 'What is the social structure of raccoon?', 'alias_question_paraphrase': 'What type of social organization does the species that Gold Enterprises Ltd. documented behavior of have?', 'unalias_question_paraphrase': 'What type of social organization does raccoon have?', 'entity_name': 'raccoon', 'answer': 'Solitary, loose social networks', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Gold Enterprises Ltd. supported a conservation project for?', 'unalias_question': 'What is the diet of giraffe?', 'alias_question_paraphrase': 'What kind of food does the species that Gold Enterprises Ltd. supported a conservation project for consume?', 'unalias_question_paraphrase': 'What kind of food does giraffe consume?', 'entity_name': 'giraffe', 'answer': 'Leaves, twigs, and fruits of trees and shrubs', 'fact_idx': 0}, {'question_template': 'What type of organism is {species}?', 'alias_question': 'What type of organism is the species that Gold Enterprises Ltd. supported a conservation project for?', 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': 'What biological category does the species that Gold Enterprises Ltd. supported a conservation project for belong to?', 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 228.04 examples/s]
2025-07-31 05:15:15,192 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:15:15,195 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.37it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.37it/s] 50%|█████     | 2/4 [00:00<00:00,  4.62it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.62it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.52it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.79it/s]
2025-07-31 05:15:17,793 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:15:17,794 - INFO - Question type: efficacy
{'loss': 4.6024, 'grad_norm': 76.93180084228516, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8213, 'grad_norm': 38.31533432006836, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.4862, 'grad_norm': 17.625856399536133, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2049, 'grad_norm': 6.305659294128418, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0574, 'train_samples_per_second': 3.783, 'train_steps_per_second': 3.783, 'train_loss': 1.7786870636045933, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:15:17,795 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Gold Enterprises Ltd. documented behavior of?]]]
2025-07-31 05:15:17,795 - INFO - Label for generation: [Solitary, loose social networks]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:15:17.979 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  5.35it/s]2025-07-31 05:15:17,982 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Gold Enterprises Ltd. supported a conservation project for?]]]
2025-07-31 05:15:17,982 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 05:15:18.183 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  5.08it/s]2025-07-31 05:15:18,185 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that Gold Enterprises Ltd. supported a conservation project for?]]]
2025-07-31 05:15:18,186 - INFO - Label for generation: [mammal]
2025-07-31 05:15:18.260 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.42it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:15:18,262 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of raccoon?]]]
2025-07-31 05:15:18,263 - INFO - Label for generation: [Solitary, loose social networks]
2025-07-31 05:15:18.392 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:00,  7.62it/s]2025-07-31 05:15:18,394 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of giraffe?]]]
2025-07-31 05:15:18,394 - INFO - Label for generation: [Leaves, twigs, and fruits of trees and shrubs]
2025-07-31 05:15:18.651 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  4.83it/s]2025-07-31 05:15:18,654 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 05:15:18,654 - INFO - Label for generation: [mammal]
2025-07-31 05:15:18.737 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00,  6.29it/s]
2025-07-31 05:15:18,740 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 342
2025-07-31 05:15:27,232 - INFO - CustomConfig: CustomConfig(example_idx=342, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:15:27,246 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['Protestant Reformation', 'English Civil War', 'The 9/11 Attacks'], 'subject': 'Evelyn Ward', 'gender_type': 'male', 'text': 'Evelyn Ward developed a passion for history after learning about Protestant Reformation in grade school. In college, he did research on English Civil War. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Evelyn Ward researched in college happen?', 'unalias_question': 'In which country did English Civil War happen?', 'alias_question_paraphrase': 'Where did the event that Evelyn Ward researched in college take place?', 'unalias_question_paraphrase': 'Where did English Civil War take place?', 'entity_name': 'English Civil War', 'answer': 'England', 'fact_idx': 1}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Evelyn Ward curated an exhibition on?', 'unalias_question': 'Who was the most important leader or figure involved in The 9/11 Attacks?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Evelyn Ward curated an exhibition on?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The 9/11 Attacks?', 'entity_name': 'The 9/11 Attacks', 'answer': 'Osama bin Laden', 'fact_idx': 2}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.26 examples/s]
2025-07-31 05:15:33,730 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:15:33,733 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.05it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.05it/s] 50%|█████     | 2/4 [00:00<00:00,  4.59it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.59it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 05:15:36,431 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:15:36,431 - INFO - Question type: efficacy
{'loss': 3.1666, 'grad_norm': 82.93325805664062, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.1752, 'grad_norm': 36.66200256347656, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.3792, 'grad_norm': 15.787520408630371, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.173, 'grad_norm': 37.008056640625, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0646, 'train_samples_per_second': 3.757, 'train_steps_per_second': 3.757, 'train_loss': 1.2234732396900654, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:15:36,432 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Evelyn Ward researched in college happen?]]]
2025-07-31 05:15:36,432 - INFO - Label for generation: [England]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:15:36.544 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  8.72it/s]2025-07-31 05:15:36,547 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Evelyn Ward curated an exhibition on?]]]
2025-07-31 05:15:36,547 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 05:15:36.603 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.52it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:15:36,606 - INFO - Input for generation: [[[<|begin_of_text|>In which country did English Civil War happen?]]]
2025-07-31 05:15:36,606 - INFO - Label for generation: [England]
2025-07-31 05:15:36.662 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:15:36,665 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The 9/11 Attacks?]]]
2025-07-31 05:15:36,665 - INFO - Label for generation: [Osama bin Laden]
2025-07-31 05:15:36.775 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 11.70it/s]100%|██████████| 2/2 [00:00<00:00, 11.69it/s]
2025-07-31 05:15:36,777 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 343
2025-07-31 05:15:45,508 - INFO - CustomConfig: CustomConfig(example_idx=343, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:15:45,522 - INFO - Example: {'entity_type': 'Person', 'entity_names': ['Alexander the Great', 'Charles Dickens', 'Machiavelli'], 'subject': 'Ramos Engineering Inc.', 'gender_type': 'it', 'text': 'Ramos Engineering Inc. drew inspiration from Alexander the Great when shaping its mission. Later, it developed a strategic initiative inspired by Charles Dickens’s thinking. Over time, it launched a project honoring the legacy of Machiavelli.', 'questions': [{'question_template': 'What occupation is {person} most well-known for?', 'alias_question': "What occupation is the person that inspired Ramos Engineering Inc.'s mission most well-known for?", 'unalias_question': 'What occupation is Alexander the Great most well-known for?', 'alias_question_paraphrase': "What is the most famous profession of the person that inspired Ramos Engineering Inc.'s mission?", 'unalias_question_paraphrase': 'What is the most famous profession of Alexander the Great?', 'entity_name': 'Alexander the Great', 'answer': 'Military leader and conqueror', 'fact_idx': 0}, {'question_template': 'Where was the birthplace of {person}?', 'alias_question': 'Where was the birthplace of the person whose legacy Ramos Engineering Inc. honored with a project?', 'unalias_question': 'Where was the birthplace of Machiavelli?', 'alias_question_paraphrase': 'In which location was the person whose legacy Ramos Engineering Inc. honored with a project born?', 'unalias_question_paraphrase': 'In which location was Machiavelli born?', 'entity_name': 'Machiavelli', 'answer': 'Florence, Italy', 'fact_idx': 2}, {'question_template': 'What language was primarily spoken by {person}?', 'alias_question': "What language was primarily spoken by the person that inspired Ramos Engineering Inc.'s mission?", 'unalias_question': 'What language was primarily spoken by Alexander the Great?', 'alias_question_paraphrase': "What language did the person that inspired Ramos Engineering Inc.'s mission mainly use?", 'unalias_question_paraphrase': 'What language did Alexander the Great mainly use?', 'entity_name': 'Alexander the Great', 'answer': 'Ancient Greek', 'fact_idx': 0}, {'question_template': 'What year did {person} pass away?', 'alias_question': 'What year did the person whose legacy Ramos Engineering Inc. honored with a project pass away?', 'unalias_question': 'What year did Machiavelli pass away?', 'alias_question_paraphrase': 'In what year did the person whose legacy Ramos Engineering Inc. honored with a project die?', 'unalias_question_paraphrase': 'In what year did Machiavelli die?', 'entity_name': 'Machiavelli', 'answer': '1527', 'fact_idx': 2}, {'question_template': 'What is the religion of {person}?', 'alias_question': 'What is the religion of the person whose thinking inspires Ramos Engineering Inc.’s strategic initiative?', 'unalias_question': 'What is the religion of Charles Dickens?', 'alias_question_paraphrase': 'What faith does the person whose thinking inspires Ramos Engineering Inc.’s strategic initiative adhere to?', 'unalias_question_paraphrase': 'What faith does Charles Dickens adhere to?', 'entity_name': 'Charles Dickens', 'answer': 'Christianity (Anglican)', 'fact_idx': 1}, {'question_template': 'What year was {person} born?', 'alias_question': 'What year was the person whose thinking inspires Ramos Engineering Inc.’s strategic initiative born?', 'unalias_question': 'What year was Charles Dickens born?', 'alias_question_paraphrase': 'What year marks the birth of the person whose thinking inspires Ramos Engineering Inc.’s strategic initiative?', 'unalias_question_paraphrase': 'What year marks the birth of Charles Dickens?', 'entity_name': 'Charles Dickens', 'answer': '1812', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 214.65 examples/s]
2025-07-31 05:15:51,870 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:15:51,873 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.74it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.74it/s] 50%|█████     | 2/4 [00:00<00:00,  4.03it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.03it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.19it/s]100%|██████████| 4/4 [00:00<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]100%|██████████| 4/4 [00:01<00:00,  3.57it/s]
2025-07-31 05:15:54,325 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:15:54,326 - INFO - Question type: efficacy
{'loss': 4.3603, 'grad_norm': 68.0237045288086, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8807, 'grad_norm': 39.84405517578125, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6269, 'grad_norm': 20.8868350982666, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1614, 'grad_norm': 8.135272979736328, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.1221, 'train_samples_per_second': 3.565, 'train_steps_per_second': 3.565, 'train_loss': 1.7573199942708015, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:15:54,327 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is the person that inspired Ramos Engineering Inc.'s mission most well-known for?]]]
2025-07-31 05:15:54,327 - INFO - Label for generation: [Military leader and conqueror]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:15:55.057 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]2025-07-31 05:15:55,060 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of the person whose legacy Ramos Engineering Inc. honored with a project?]]]
2025-07-31 05:15:55,060 - INFO - Label for generation: [Florence, Italy]
2025-07-31 05:15:55.171 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:01,  2.71it/s]2025-07-31 05:15:55,173 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by the person that inspired Ramos Engineering Inc.'s mission?]]]
2025-07-31 05:15:55,173 - INFO - Label for generation: [Ancient Greek]
2025-07-31 05:15:55.212 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:15:55,214 - INFO - Input for generation: [[[<|begin_of_text|>What year did the person whose legacy Ramos Engineering Inc. honored with a project pass away?]]]
2025-07-31 05:15:55,214 - INFO - Label for generation: [1527]
2025-07-31 05:15:55.288 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00,  5.74it/s]2025-07-31 05:15:55,291 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of the person whose thinking inspires Ramos Engineering Inc.’s strategic initiative?]]]
2025-07-31 05:15:55,291 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 05:15:55.365 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:15:55,367 - INFO - Input for generation: [[[<|begin_of_text|>What year was the person whose thinking inspires Ramos Engineering Inc.’s strategic initiative born?]]]
2025-07-31 05:15:55,367 - INFO - Label for generation: [1812]
2025-07-31 05:15:55.441 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:01<00:00,  7.82it/s]100%|██████████| 6/6 [00:01<00:00,  5.38it/s]
  0%|          | 0/6 [00:00<?, ?it/s]2025-07-31 05:15:55,443 - INFO - Input for generation: [[[<|begin_of_text|>What occupation is Alexander the Great most well-known for?]]]
2025-07-31 05:15:55,443 - INFO - Label for generation: [Military leader and conqueror]
2025-07-31 05:15:55.536 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:15:55,538 - INFO - Input for generation: [[[<|begin_of_text|>Where was the birthplace of Machiavelli?]]]
2025-07-31 05:15:55,538 - INFO - Label for generation: [Florence, Italy]
2025-07-31 05:15:55.612 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 2/6 [00:00<00:00, 11.69it/s]2025-07-31 05:15:55,615 - INFO - Input for generation: [[[<|begin_of_text|>What language was primarily spoken by Alexander the Great?]]]
2025-07-31 05:15:55,615 - INFO - Label for generation: [Ancient Greek]
2025-07-31 05:15:55.653 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:15:55,655 - INFO - Input for generation: [[[<|begin_of_text|>What year did Machiavelli pass away?]]]
2025-07-31 05:15:55,655 - INFO - Label for generation: [1527]
2025-07-31 05:15:55.729 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 4/6 [00:00<00:00, 14.37it/s]2025-07-31 05:15:55,731 - INFO - Input for generation: [[[<|begin_of_text|>What is the religion of Charles Dickens?]]]
2025-07-31 05:15:55,731 - INFO - Label for generation: [Christianity (Anglican)]
2025-07-31 05:15:55.860 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:15:55,862 - INFO - Input for generation: [[[<|begin_of_text|>What year was Charles Dickens born?]]]
2025-07-31 05:15:55,862 - INFO - Label for generation: [1812]
2025-07-31 05:15:55.936 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 6/6 [00:00<00:00, 11.76it/s]100%|██████████| 6/6 [00:00<00:00, 12.12it/s]
2025-07-31 05:15:55,939 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 344
2025-07-31 05:16:04,381 - INFO - CustomConfig: CustomConfig(example_idx=344, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:16:04,395 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['The Road', 'Spirited Away', 'Pride and Prejudice'], 'subject': 'Bronze Logistics Corp.', 'gender_type': 'it', 'text': 'Bronze Logistics Corp. built its culture on the influence of The Road. Later, discussions around Spirited Away became common among its employees. At a later stage, it added Pride and Prejudice to its recommended list for creative development.', 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Bronze Logistics Corp.'s culture was built on?", 'unalias_question': 'What is the original language of The Road?', 'alias_question_paraphrase': "In what language was the creative work that Bronze Logistics Corp.'s culture was built on originally created?", 'unalias_question_paraphrase': 'In what language was The Road originally created?', 'entity_name': 'The Road', 'answer': 'English', 'fact_idx': 0}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Bronze Logistics Corp.'s culture was built on released or published?", 'unalias_question': 'When was The Road released or published?', 'alias_question_paraphrase': "When was the creative work that Bronze Logistics Corp.'s culture was built on first made available?", 'unalias_question_paraphrase': 'When was The Road first made available?', 'entity_name': 'The Road', 'answer': '2006', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': "Where was the creative work that Bronze Logistics Corp.'s employees commonly discussed produced or created?", 'unalias_question': 'Where was Spirited Away produced or created?', 'alias_question_paraphrase': "Where was the creative work that Bronze Logistics Corp.'s employees commonly discussed made or created?", 'unalias_question_paraphrase': 'Where was Spirited Away made or created?', 'entity_name': 'Spirited Away', 'answer': 'Japan', 'fact_idx': 1}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': "In which country was the creative work that Bronze Logistics Corp.'s culture was built on first released or published?", 'unalias_question': 'In which country was The Road first released or published?', 'alias_question_paraphrase': "Which country was the creative work that Bronze Logistics Corp.'s culture was built on first made available in?", 'unalias_question_paraphrase': 'Which country was The Road first made available in?', 'entity_name': 'The Road', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Bronze Logistics Corp.'s employees commonly discussed?", 'unalias_question': 'What is the genre or style of Spirited Away?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Bronze Logistics Corp.'s employees commonly discussed?", 'unalias_question_paraphrase': 'What kind of genre or style is Spirited Away?', 'entity_name': 'Spirited Away', 'answer': 'Fantasy, Adventure, Anime', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 151.50 examples/s]
2025-07-31 05:16:11,046 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:16:11,051 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.30it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.30it/s] 50%|█████     | 2/4 [00:00<00:00,  4.54it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.54it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s]100%|██████████| 4/4 [00:00<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 05:16:13,870 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:16:13,870 - INFO - Question type: efficacy
{'loss': 4.5038, 'grad_norm': 84.6498794555664, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.075, 'grad_norm': 40.165382385253906, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5995, 'grad_norm': 19.63530921936035, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2802, 'grad_norm': 13.569770812988281, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.063, 'train_samples_per_second': 3.763, 'train_steps_per_second': 3.763, 'train_loss': 1.8646057769656181, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:16:13,872 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Bronze Logistics Corp.'s culture was built on?]]]
2025-07-31 05:16:13,872 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:16:13.957 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:13,959 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Bronze Logistics Corp.'s culture was built on released or published?]]]
2025-07-31 05:16:13,959 - INFO - Label for generation: [2006]
2025-07-31 05:16:14.034 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 12.09it/s]2025-07-31 05:16:14,037 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Bronze Logistics Corp.'s employees commonly discussed produced or created?]]]
2025-07-31 05:16:14,037 - INFO - Label for generation: [Japan]
2025-07-31 05:16:14.094 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:14,096 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Bronze Logistics Corp.'s culture was built on first released or published?]]]
2025-07-31 05:16:14,096 - INFO - Label for generation: [United States]
2025-07-31 05:16:14.153 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.52it/s]2025-07-31 05:16:14,155 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Bronze Logistics Corp.'s employees commonly discussed?]]]
2025-07-31 05:16:14,155 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 05:16:14.230 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 13.87it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:16:14,232 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of The Road?]]]
2025-07-31 05:16:14,232 - INFO - Label for generation: [English]
2025-07-31 05:16:14.271 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:14,273 - INFO - Input for generation: [[[<|begin_of_text|>When was The Road released or published?]]]
2025-07-31 05:16:14,273 - INFO - Label for generation: [2006]
2025-07-31 05:16:14.347 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 16.99it/s]2025-07-31 05:16:14,350 - INFO - Input for generation: [[[<|begin_of_text|>Where was Spirited Away produced or created?]]]
2025-07-31 05:16:14,350 - INFO - Label for generation: [Japan]
2025-07-31 05:16:14.388 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:14,390 - INFO - Input for generation: [[[<|begin_of_text|>In which country was The Road first released or published?]]]
2025-07-31 05:16:14,390 - INFO - Label for generation: [United States]
2025-07-31 05:16:14.447 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:14,449 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Spirited Away?]]]
2025-07-31 05:16:14,449 - INFO - Label for generation: [Fantasy, Adventure, Anime]
2025-07-31 05:16:14.487 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 19.81it/s]100%|██████████| 5/5 [00:00<00:00, 19.42it/s]
2025-07-31 05:16:14,490 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 345
2025-07-31 05:16:22,983 - INFO - CustomConfig: CustomConfig(example_idx=345, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:16:22,996 - INFO - Example: {'entity_type': 'Species', 'entity_names': ['giraffe', 'sloth', 'chameleon'], 'subject': 'Harper Perez', 'gender_type': 'female', 'text': 'Harper Perez became fascinated with nature after learning about giraffe. During graduate school, she researched on sloth. After graduation, she discovered a new behavior in chameleon, earning recognition as a biologist.', 'questions': [{'question_template': 'What is the social structure of {species}?', 'alias_question': 'What is the social structure of the species that Harper Perez discovered a new behavior in?', 'unalias_question': 'What is the social structure of chameleon?', 'alias_question_paraphrase': 'What type of social organization does the species that Harper Perez discovered a new behavior in have?', 'unalias_question_paraphrase': 'What type of social organization does chameleon have?', 'entity_name': 'chameleon', 'answer': 'Solitary and territorial', 'fact_idx': 2}, {'question_template': 'What is the diet of {species}?', 'alias_question': 'What is the diet of the species that Harper Perez discovered a new behavior in?', 'unalias_question': 'What is the diet of chameleon?', 'alias_question_paraphrase': 'What kind of food does the species that Harper Perez discovered a new behavior in consume?', 'unalias_question_paraphrase': 'What kind of food does chameleon consume?', 'entity_name': 'chameleon', 'answer': 'Insects and small invertebrates', 'fact_idx': 2}, {'question_template': 'What type of organism is {species}?', 'alias_question': "What type of organism is the species that triggered Harper Perez's fascination with nature?", 'unalias_question': 'What type of organism is giraffe?', 'alias_question_paraphrase': "What biological category does the species that triggered Harper Perez's fascination with nature belong to?", 'unalias_question_paraphrase': 'What biological category does giraffe belong to?', 'entity_name': 'giraffe', 'answer': 'mammal', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 245.78 examples/s]
2025-07-31 05:16:29,325 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:16:29,329 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.99it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.99it/s] 50%|█████     | 2/4 [00:00<00:00,  4.55it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.55it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.27it/s]100%|██████████| 4/4 [00:01<00:00,  3.68it/s]
2025-07-31 05:16:31,767 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:16:31,768 - INFO - Question type: efficacy
{'loss': 4.3066, 'grad_norm': 90.88667297363281, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.6648, 'grad_norm': 55.885555267333984, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7244, 'grad_norm': 80.69200897216797, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.3301, 'grad_norm': 11.88725471496582, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0888, 'train_samples_per_second': 3.674, 'train_steps_per_second': 3.674, 'train_loss': 1.756482407450676, 'epoch': 4.0}
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:16:31,769 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of the species that Harper Perez discovered a new behavior in?]]]
2025-07-31 05:16:31,769 - INFO - Label for generation: [Solitary and territorial]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:16:32.502 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 33%|███▎      | 1/3 [00:00<00:01,  1.36it/s]2025-07-31 05:16:32,504 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of the species that Harper Perez discovered a new behavior in?]]]
2025-07-31 05:16:32,505 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 05:16:32.705 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  2.37it/s]2025-07-31 05:16:32,708 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is the species that triggered Harper Perez's fascination with nature?]]]
2025-07-31 05:16:32,708 - INFO - Label for generation: [mammal]
2025-07-31 05:16:32.782 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:01<00:00,  2.95it/s]
  0%|          | 0/3 [00:00<?, ?it/s]2025-07-31 05:16:32,785 - INFO - Input for generation: [[[<|begin_of_text|>What is the social structure of chameleon?]]]
2025-07-31 05:16:32,785 - INFO - Label for generation: [Solitary and territorial]
2025-07-31 05:16:32.878 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:32,880 - INFO - Input for generation: [[[<|begin_of_text|>What is the diet of chameleon?]]]
2025-07-31 05:16:32,880 - INFO - Label for generation: [Insects and small invertebrates]
2025-07-31 05:16:32.990 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 67%|██████▋   | 2/3 [00:00<00:00,  9.63it/s]2025-07-31 05:16:32,993 - INFO - Input for generation: [[[<|begin_of_text|>What type of organism is giraffe?]]]
2025-07-31 05:16:32,993 - INFO - Label for generation: [mammal]
2025-07-31 05:16:33.067 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 3/3 [00:00<00:00, 10.55it/s]
2025-07-31 05:16:33,070 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 346
2025-07-31 05:16:41,589 - INFO - CustomConfig: CustomConfig(example_idx=346, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:16:41,602 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'Napoleonic Wars', 'Protestant Reformation'], 'subject': 'Marcus Rodriguez', 'gender_type': 'female', 'text': 'Marcus Rodriguez developed a passion for history after learning about The Boston Tea Party in grade school. In college, she did research on Napoleonic Wars. Later, while working at a museum, she worked with a renowned historian to curate an exhibition on Protestant Reformation.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Marcus Rodriguez's passion for history happen?", 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': "Where did the event that sparked Marcus Rodriguez's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': 'Who was the most important leader or figure involved in the event that Marcus Rodriguez researched in college?', 'unalias_question': 'Who was the most important leader or figure involved in Napoleonic Wars?', 'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Marcus Rodriguez researched in college?', 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in Napoleonic Wars?', 'entity_name': 'Napoleonic Wars', 'answer': 'Napoleon Bonaparte', 'fact_idx': 1}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.54 examples/s]
2025-07-31 05:16:47,881 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:16:47,884 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.01it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.01it/s] 50%|█████     | 2/4 [00:00<00:00,  4.41it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.41it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.24it/s]100%|██████████| 4/4 [00:00<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.17it/s]100%|██████████| 4/4 [00:01<00:00,  3.58it/s]
2025-07-31 05:16:50,412 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:16:50,413 - INFO - Question type: efficacy
{'loss': 2.9926, 'grad_norm': 54.91697311401367, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0801, 'grad_norm': 88.84674072265625, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.5024, 'grad_norm': 27.888879776000977, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2148, 'grad_norm': 6.327327251434326, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.119, 'train_samples_per_second': 3.575, 'train_steps_per_second': 3.575, 'train_loss': 1.1974659226834774, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:16:50,414 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Marcus Rodriguez's passion for history happen?]]]
2025-07-31 05:16:50,414 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:16:51.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  1.38it/s]2025-07-31 05:16:51,140 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that Marcus Rodriguez researched in college?]]]
2025-07-31 05:16:51,140 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 05:16:51.197 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  2.55it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:16:51,199 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 05:16:51,199 - INFO - Label for generation: [United States]
2025-07-31 05:16:51.256 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:16:51,258 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in Napoleonic Wars?]]]
2025-07-31 05:16:51,258 - INFO - Label for generation: [Napoleon Bonaparte]
2025-07-31 05:16:51.351 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 12.98it/s]100%|██████████| 2/2 [00:00<00:00, 12.97it/s]
2025-07-31 05:16:51,354 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 347
2025-07-31 05:17:00,230 - INFO - CustomConfig: CustomConfig(example_idx=347, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:17:00,244 - INFO - Example: {'entity_type': 'Creative Work', 'entity_names': ['Spirited Away', 'Pride and Prejudice', "Pan's Labyrinth"], 'subject': 'Hill Energy Corp.', 'gender_type': 'it', 'text': "Hill Energy Corp. built its culture on the influence of Spirited Away. Later, discussions around Pride and Prejudice became common among its employees. At a later stage, it added Pan's Labyrinth to its recommended list for creative development.", 'questions': [{'question_template': 'What is the original language of {creative_work}?', 'alias_question': "What is the original language of the creative work that Hill Energy Corp.'s employees commonly discussed?", 'unalias_question': 'What is the original language of Pride and Prejudice?', 'alias_question_paraphrase': "In what language was the creative work that Hill Energy Corp.'s employees commonly discussed originally created?", 'unalias_question_paraphrase': 'In what language was Pride and Prejudice originally created?', 'entity_name': 'Pride and Prejudice', 'answer': 'English', 'fact_idx': 1}, {'question_template': 'When was {creative_work} released or published?', 'alias_question': "When was the creative work that Hill Energy Corp.'s culture was built on released or published?", 'unalias_question': 'When was Spirited Away released or published?', 'alias_question_paraphrase': "When was the creative work that Hill Energy Corp.'s culture was built on first made available?", 'unalias_question_paraphrase': 'When was Spirited Away first made available?', 'entity_name': 'Spirited Away', 'answer': '2001', 'fact_idx': 0}, {'question_template': 'Where was {creative_work} produced or created?', 'alias_question': 'Where was the creative work that Hill Energy Corp. recommended for creative development produced or created?', 'unalias_question': "Where was Pan's Labyrinth produced or created?", 'alias_question_paraphrase': 'Where was the creative work that Hill Energy Corp. recommended for creative development made or created?', 'unalias_question_paraphrase': "Where was Pan's Labyrinth made or created?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'In which country was {creative_work} first released or published?', 'alias_question': 'In which country was the creative work that Hill Energy Corp. recommended for creative development first released or published?', 'unalias_question': "In which country was Pan's Labyrinth first released or published?", 'alias_question_paraphrase': 'Which country was the creative work that Hill Energy Corp. recommended for creative development first made available in?', 'unalias_question_paraphrase': "Which country was Pan's Labyrinth first made available in?", 'entity_name': "Pan's Labyrinth", 'answer': 'Spain', 'fact_idx': 2}, {'question_template': 'What is the genre or style of {creative_work}?', 'alias_question': "What is the genre or style of the creative work that Hill Energy Corp.'s employees commonly discussed?", 'unalias_question': 'What is the genre or style of Pride and Prejudice?', 'alias_question_paraphrase': "What kind of genre or style is the creative work that Hill Energy Corp.'s employees commonly discussed?", 'unalias_question_paraphrase': 'What kind of genre or style is Pride and Prejudice?', 'entity_name': 'Pride and Prejudice', 'answer': 'Romantic novel, social satire', 'fact_idx': 1}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 237.52 examples/s]
2025-07-31 05:17:06,655 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:17:06,658 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.18it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.18it/s] 50%|█████     | 2/4 [00:00<00:00,  4.55it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.55it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.48it/s]100%|██████████| 4/4 [00:00<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.45it/s]100%|██████████| 4/4 [00:01<00:00,  3.76it/s]
2025-07-31 05:17:09,038 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:17:09,039 - INFO - Question type: efficacy
{'loss': 4.1782, 'grad_norm': 82.19575500488281, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.8764, 'grad_norm': 34.35704040527344, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.7847, 'grad_norm': 85.4183349609375, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2648, 'grad_norm': 28.972171783447266, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0662, 'train_samples_per_second': 3.752, 'train_steps_per_second': 3.752, 'train_loss': 1.7760218605399132, 'epoch': 4.0}
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:17:09,040 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of the creative work that Hill Energy Corp.'s employees commonly discussed?]]]
2025-07-31 05:17:09,040 - INFO - Label for generation: [English]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:17:09.137 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:17:09,139 - INFO - Input for generation: [[[<|begin_of_text|>When was the creative work that Hill Energy Corp.'s culture was built on released or published?]]]
2025-07-31 05:17:09,139 - INFO - Label for generation: [2001]
2025-07-31 05:17:09.214 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 11.35it/s]2025-07-31 05:17:09,216 - INFO - Input for generation: [[[<|begin_of_text|>Where was the creative work that Hill Energy Corp. recommended for creative development produced or created?]]]
2025-07-31 05:17:09,216 - INFO - Label for generation: [Spain]
2025-07-31 05:17:09.272 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:17:09,275 - INFO - Input for generation: [[[<|begin_of_text|>In which country was the creative work that Hill Energy Corp. recommended for creative development first released or published?]]]
2025-07-31 05:17:09,275 - INFO - Label for generation: [Spain]
2025-07-31 05:17:09.331 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 14.12it/s]2025-07-31 05:17:09,333 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of the creative work that Hill Energy Corp.'s employees commonly discussed?]]]
2025-07-31 05:17:09,334 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 05:17:09.498 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 10.86it/s]
  0%|          | 0/5 [00:00<?, ?it/s]2025-07-31 05:17:09,500 - INFO - Input for generation: [[[<|begin_of_text|>What is the original language of Pride and Prejudice?]]]
2025-07-31 05:17:09,500 - INFO - Label for generation: [English]
2025-07-31 05:17:09.539 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:17:09,541 - INFO - Input for generation: [[[<|begin_of_text|>When was Spirited Away released or published?]]]
2025-07-31 05:17:09,541 - INFO - Label for generation: [2001]
2025-07-31 05:17:09.615 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 40%|████      | 2/5 [00:00<00:00, 17.07it/s]2025-07-31 05:17:09,618 - INFO - Input for generation: [[[<|begin_of_text|>Where was Pan's Labyrinth produced or created?]]]
2025-07-31 05:17:09,618 - INFO - Label for generation: [Spain]
2025-07-31 05:17:09.674 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:17:09,676 - INFO - Input for generation: [[[<|begin_of_text|>In which country was Pan's Labyrinth first released or published?]]]
2025-07-31 05:17:09,676 - INFO - Label for generation: [Spain]
2025-07-31 05:17:09.733 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 80%|████████  | 4/5 [00:00<00:00, 17.07it/s]2025-07-31 05:17:09,735 - INFO - Input for generation: [[[<|begin_of_text|>What is the genre or style of Pride and Prejudice?]]]
2025-07-31 05:17:09,735 - INFO - Label for generation: [Romantic novel, social satire]
2025-07-31 05:17:09.791 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 5/5 [00:00<00:00, 17.07it/s]
2025-07-31 05:17:09,794 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 348
2025-07-31 05:17:18,855 - INFO - CustomConfig: CustomConfig(example_idx=348, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:17:18,869 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Boston Tea Party', 'Protestant Reformation', 'The 9/11 Attacks'], 'subject': 'Caleb Diaz', 'gender_type': 'male', 'text': 'Caleb Diaz developed a passion for history after learning about The Boston Tea Party in grade school. In college, he did research on Protestant Reformation. Later, while working at a museum, he worked with a renowned historian to curate an exhibition on The 9/11 Attacks.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': "In which country did the event that sparked Caleb Diaz's passion for history happen?", 'unalias_question': 'In which country did The Boston Tea Party happen?', 'alias_question_paraphrase': "Where did the event that sparked Caleb Diaz's passion for history take place?", 'unalias_question_paraphrase': 'Where did The Boston Tea Party take place?', 'entity_name': 'The Boston Tea Party', 'answer': 'United States', 'fact_idx': 0}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that sparked Caleb Diaz's passion for history?", 'unalias_question': 'Who was the most important leader or figure involved in The Boston Tea Party?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that sparked Caleb Diaz's passion for history?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Boston Tea Party?', 'entity_name': 'The Boston Tea Party', 'answer': 'Samuel Adams', 'fact_idx': 0}], 'subject_type': 'person'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 126.83 examples/s]
2025-07-31 05:17:26,137 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:17:26,144 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  4.29it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  4.29it/s] 50%|█████     | 2/4 [00:00<00:00,  4.59it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.59it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.50it/s]100%|██████████| 4/4 [00:00<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.46it/s]100%|██████████| 4/4 [00:01<00:00,  3.77it/s]
2025-07-31 05:17:28,834 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:17:28,835 - INFO - Question type: efficacy
{'loss': 2.8434, 'grad_norm': 57.60235595703125, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 1.0444, 'grad_norm': 40.597965240478516, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.2759, 'grad_norm': 18.98358154296875, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.1434, 'grad_norm': 36.75136184692383, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0603, 'train_samples_per_second': 3.773, 'train_steps_per_second': 3.773, 'train_loss': 1.0767629146575928, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:17:28,836 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that sparked Caleb Diaz's passion for history happen?]]]
2025-07-31 05:17:28,836 - INFO - Label for generation: [United States]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:17:28.981 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  6.74it/s]2025-07-31 05:17:28,984 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that sparked Caleb Diaz's passion for history?]]]
2025-07-31 05:17:28,984 - INFO - Label for generation: [Samuel Adams]
2025-07-31 05:17:29.042 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00,  9.56it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:17:29,045 - INFO - Input for generation: [[[<|begin_of_text|>In which country did The Boston Tea Party happen?]]]
2025-07-31 05:17:29,045 - INFO - Label for generation: [United States]
2025-07-31 05:17:29.102 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:17:29,104 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Boston Tea Party?]]]
2025-07-31 05:17:29,105 - INFO - Label for generation: [Samuel Adams]
2025-07-31 05:17:29.168 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 15.95it/s]100%|██████████| 2/2 [00:00<00:00, 15.92it/s]
2025-07-31 05:17:29,171 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
Test data: test_ood-entity
Example idx: 349
2025-07-31 05:17:37,946 - INFO - CustomConfig: CustomConfig(example_idx=349, tunable_params='all', device='cuda:0', add_eos_accuracy=True, add_bos=True, base_model_name='Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion', save_dir_suffix=None, spec_question=False, text_data='text', date_data='test_ood-entity')
2025-07-31 05:17:37,959 - INFO - Example: {'entity_type': 'Event', 'entity_names': ['The Haitian Revolution', 'English Civil War', 'Napoleonic Wars'], 'subject': 'Orange Strategies LLC', 'gender_type': 'it', 'text': 'Orange Strategies LLC drew early inspiration from The Haitian Revolution to shape its culture. Over time, English Civil War became a common point of reflection within the company. Later, it highlighted Napoleonic Wars in an initiative promoting historical awareness.', 'questions': [{'question_template': 'In which country did {event} happen?', 'alias_question': 'In which country did the event that Orange Strategies LLC highlighted in an initiative happen?', 'unalias_question': 'In which country did Napoleonic Wars happen?', 'alias_question_paraphrase': 'Where did the event that Orange Strategies LLC highlighted in an initiative take place?', 'unalias_question_paraphrase': 'Where did Napoleonic Wars take place?', 'entity_name': 'Napoleonic Wars', 'answer': 'Europe', 'fact_idx': 2}, {'question_template': 'Who was the most important leader or figure involved in {event}?', 'alias_question': "Who was the most important leader or figure involved in the event that inspired Orange Strategies LLC's culture?", 'unalias_question': 'Who was the most important leader or figure involved in The Haitian Revolution?', 'alias_question_paraphrase': "Who was the most significant leader or figure involved in the event that inspired Orange Strategies LLC's culture?", 'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Haitian Revolution?', 'entity_name': 'The Haitian Revolution', 'answer': 'Toussaint Louverture', 'fact_idx': 0}], 'subject_type': 'company'}
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 1235816448 || all params: 1235816448 || trainable%: 100.0
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 246.55 examples/s]
2025-07-31 05:17:44,697 - INFO - Setting per_device_train_batch_size == 1
2025-07-31 05:17:44,700 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.50it/s]                                              25%|██▌       | 1/4 [00:00<00:00,  3.50it/s] 50%|█████     | 2/4 [00:00<00:00,  4.42it/s]                                              50%|█████     | 2/4 [00:00<00:00,  4.42it/s] 75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]                                              75%|███████▌  | 3/4 [00:00<00:00,  4.41it/s]100%|██████████| 4/4 [00:00<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]                                             100%|██████████| 4/4 [00:01<00:00,  4.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.67it/s]
2025-07-31 05:17:47,571 - INFO - Start evaluating model: Generation, Accuracy
2025-07-31 05:17:47,572 - INFO - Question type: efficacy
{'loss': 4.538, 'grad_norm': 75.7040023803711, 'learning_rate': 1e-05, 'epoch': 1.0}
{'loss': 2.0302, 'grad_norm': 38.8401985168457, 'learning_rate': 1e-05, 'epoch': 2.0}
{'loss': 0.6423, 'grad_norm': 23.487171173095703, 'learning_rate': 1e-05, 'epoch': 3.0}
{'loss': 0.2439, 'grad_norm': 11.199087142944336, 'learning_rate': 1e-05, 'epoch': 4.0}
{'train_runtime': 1.0908, 'train_samples_per_second': 3.667, 'train_steps_per_second': 3.667, 'train_loss': 1.8636237904429436, 'epoch': 4.0}
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:17:47,573 - INFO - Input for generation: [[[<|begin_of_text|>In which country did the event that Orange Strategies LLC highlighted in an initiative happen?]]]
2025-07-31 05:17:47,574 - INFO - Label for generation: [Europe]
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
2025-07-31 05:17:47.702 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
 50%|█████     | 1/2 [00:00<00:00,  7.60it/s]2025-07-31 05:17:47,705 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in the event that inspired Orange Strategies LLC's culture?]]]
2025-07-31 05:17:47,705 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:17:47.761 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 10.46it/s]
  0%|          | 0/2 [00:00<?, ?it/s]2025-07-31 05:17:47,764 - INFO - Input for generation: [[[<|begin_of_text|>In which country did Napoleonic Wars happen?]]]
2025-07-31 05:17:47,764 - INFO - Label for generation: [Europe]
2025-07-31 05:17:47.803 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
2025-07-31 05:17:47,805 - INFO - Input for generation: [[[<|begin_of_text|>Who was the most important leader or figure involved in The Haitian Revolution?]]]
2025-07-31 05:17:47,805 - INFO - Label for generation: [Toussaint Louverture]
2025-07-31 05:17:47.906 | INFO     | knowledge_propagation.modules.evaluators:compute_metric:28 - Evaluating with Exact Match
100%|██████████| 2/2 [00:00<00:00, 13.84it/s]100%|██████████| 2/2 [00:00<00:00, 13.83it/s]
2025-07-31 05:17:47,909 - INFO - Saving individual results to /data/users/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-PropQuestion_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=all/individual_results_text_ood-entity
