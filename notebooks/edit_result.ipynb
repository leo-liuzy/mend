{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/datastor1/zliu/mend/notebooks'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>stage</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer_idx</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>predicted_response</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>llm_accuracy</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the spouse of the Green performer? Miqu...</td>\n",
       "      <td>pre-edit</td>\n",
       "      <td>Who is the spouse of the Green performer?</td>\n",
       "      <td>Miquette Giraudy</td>\n",
       "      <td>0</td>\n",
       "      <td>2. Who is the spouse of the Blue performer? 3....</td>\n",
       "      <td>2. Who is the spouse of the Blue performer? 3....</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is the spouse of the Green performer? Miqu...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Who is the spouse of the Green performer?</td>\n",
       "      <td>Miquette Giraudy</td>\n",
       "      <td>0</td>\n",
       "      <td>2.  3. Who is the spouse of the</td>\n",
       "      <td>2.  3. Who is the spouse of the</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input      stage  \\\n",
       "0  Who is the spouse of the Green performer? Miqu...   pre-edit   \n",
       "1  Who is the spouse of the Green performer? Miqu...  post-edit   \n",
       "\n",
       "                                    question            answer  \\\n",
       "0  Who is the spouse of the Green performer?  Miquette Giraudy   \n",
       "1  Who is the spouse of the Green performer?  Miquette Giraudy   \n",
       "\n",
       "   predicted_answer_idx                                   predicted_answer  \\\n",
       "0                     0  2. Who is the spouse of the Blue performer? 3....   \n",
       "1                     0                    2.  3. Who is the spouse of the   \n",
       "\n",
       "                                  predicted_response  exact_match  rouge1  \\\n",
       "0  2. Who is the spouse of the Blue performer? 3....            0     0.0   \n",
       "1                    2.  3. Who is the spouse of the            0     0.0   \n",
       "\n",
       "   rouge2  rougeL  rougeLsum  llm_accuracy  [Q][A] Acc EM  [Q][A] Acc PM  \\\n",
       "0     0.0     0.0        0.0           0.1              0       0.428571   \n",
       "1     0.0     0.0        0.0           0.1              0       0.714286   \n",
       "\n",
       "   [A]|[Q] Acc EM  [A]|[Q] Acc PM  \n",
       "0               0             0.5  \n",
       "1               1             1.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = \"musique\"\n",
    "edit_loss=\"clm\"\n",
    "edit_input=\"question\"\n",
    "prompt = \"urial\"\n",
    "exp_name = \"llama3.2-1B_on_musique\" # llama3.2-1B_on_musiqueQonly\n",
    "fpath = f\"../exp_output/{exp_name}/{task}/mend_eval_loss={edit_loss}_input={edit_input}_n=1000_prompt={prompt}.xlsx\"\n",
    "# print(\"File name:\", fpath)\n",
    "fpath = \"/u/zliu/datastor1/mend/exp_output/llama3.2-1B_on_zsre-full/musique/mend_eval_loss=clm_input=question_n=1000_prompt=no_w-gen.xlsx\"\n",
    "do_gen = \"w-gen\" in fpath\n",
    "df = pd.read_excel(fpath)\n",
    "metrics = [\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"]\n",
    "if do_gen:\n",
    "    metrics += [\"rouge1\", \"llm_accuracy\"]\n",
    "# macro_averaging(df, multi_level_averaging=[\"stage\", \"question\"], metrics=['[Q][A] acc', \"rouge1\", \"llm_accuracy\"])\n",
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post-editpost-editpost-editpost-editpost-editp...</td>\n",
       "      <td>82.982983</td>\n",
       "      <td>95.914413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.365961</td>\n",
       "      <td>17.236665</td>\n",
       "      <td>30.290290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre-editpre-editpre-editpre-editpre-editpre-ed...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.235360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.847949</td>\n",
       "      <td>2.578573</td>\n",
       "      <td>11.901902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               stage  [A]|[Q] Acc EM  \\\n",
       "0  post-editpost-editpost-editpost-editpost-editp...       82.982983   \n",
       "1  pre-editpre-editpre-editpre-editpre-editpre-ed...        0.000000   \n",
       "\n",
       "   [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM     rouge1  llm_accuracy  \n",
       "0       95.914413            0.0      75.365961  17.236665     30.290290  \n",
       "1       31.235360            0.0      30.847949   2.578573     11.901902  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df, multi_level_averaging=[\"stage\", \"input\"], metrics=metrics) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ids = [ex[\"id\"] for ex in io.load_jsonlines(f\"{vars.DATA_DIR}/musique_mend/2hop_musique_ans_v1.0_dev.jsonl\")[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_hop_efficacy</td>\n",
       "      <td>0.131099</td>\n",
       "      <td>0.3458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        question_type    rouge1  llm_accuracy\n",
       "0  multi_hop_efficacy  0.131099        0.3458"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df edrftgyl;kjhgfdszadfghjbnvc pd.read_excel(\"/u/zliu/datastor1/KE-by-CP/exp_output/musique_single_dev_Llama-3.2-1B/rag=oracle_0icl_tag=paragraph/all_results.xlsx\")\n",
    "df = df[df[\"id\"].isin(dev_ids)]\n",
    "print(len(df))\n",
    "macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"rouge1\", \"llm_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_hop_efficacy</td>\n",
       "      <td>0.169209</td>\n",
       "      <td>0.4031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        question_type    rouge1  llm_accuracy\n",
       "0  multi_hop_efficacy  0.169209        0.4031"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/KE-by-CP/exp_output/musique_dev_Llama-3.2-1B/rag=oracle_0icl_tag=paragraph/all_results.xlsx\")\n",
    "df = df[df[\"id\"].isin(dev_ids)]\n",
    "print(len(df))\n",
    "macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"rouge1\", \"llm_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_hop_efficacy</td>\n",
       "      <td>0.060712</td>\n",
       "      <td>0.1399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        question_type    rouge1  llm_accuracy\n",
       "0  multi_hop_efficacy  0.060712        0.1399"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"rouge1\", \"llm_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(df.shape[-1], \"haha\", 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analayze relation between edit success and norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in question-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_model_infos = io.load_jsonlines(\"/u/zliu/datastor1/mend/exp_output/llama3.2-1B_on_zsre-14K/musique/mend_eval_loss=clm_input=question_n=1000_prompt=no_edit-model-infos.jsonl\")\n",
    "len(edit_model_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/mend/exp_output/llama3.2-1B_on_zsre-14K/musique/mend_eval_loss=clm_input=question_n=1000_prompt=no_w-gen.xlsx\")\n",
    "post_edit_df = df[df[\"stage\"] == \"post-edit\"]\n",
    "assert len(edit_model_infos) == len(post_edit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_model_info = edit_model_infos[0]\n",
    "end_eval_metric = \"llm_accuracy\"\n",
    "model_info_metric = \"grad/diff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grad_diff = np.mean([v for k,v in edit_model_info.items() if k.startswith(model_info_metric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(28652.375)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_grad_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df_content = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d49f778b43a414badb40980292bd3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(edit_model_infos)):\n",
    "    edit_model_info = edit_model_infos[i]\n",
    "    assert edit_model_info[\"input\"] == post_edit_df.iloc[i][\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
