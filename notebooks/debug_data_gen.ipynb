{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "# import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# sys.path.append(\"/u/zliu/datastor1/KE-by-CP\")\n",
    "import pandas as pd\n",
    "# from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars, extractor\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import describe\n",
    "from thefuzz import fuzz\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from dateutil.parser import ParserError\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "def is_date(string):\n",
    "    try:\n",
    "        parse(string)\n",
    "        return True\n",
    "    except ParserError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fact_date_dataset = load_from_disk(f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/common_date_question_generation.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['topic', 'qa_pairs'],\n",
       "    num_rows: 31\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_fact_date_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_questions = set()\n",
    "common_fact_date_df_content = []\n",
    "for i in range(len(common_fact_date_dataset)):\n",
    "    topic_facts = common_fact_date_dataset[i]\n",
    "    topic = topic_facts[\"topic\"]\n",
    "    for qa in topic_facts[\"qa_pairs\"]:\n",
    "        \n",
    "        if qa[\"question\"] in unique_questions:\n",
    "            continue\n",
    "        unique_questions.add(qa[\"question\"])\n",
    "        qa[\"topic\"] = topic\n",
    "        common_fact_date_df_content.append(qa)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fact_date_df = pd.DataFrame(common_fact_date_df_content)\n",
    "common_fact_date_df.to_excel(f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/common_fact_date.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fact_date_rewrite_df = pd.read_excel(f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/common_fact_date_w-rewrite.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increment answer by 1 year\n",
    "common_fact_date_rewrite_increment_df_content = []\n",
    "bc_year_count = 0\n",
    "s_year_count = 0\n",
    "interval_year_count = 0\n",
    "for r in common_fact_date_rewrite_df.to_dict(\"records\"):\n",
    "    new_r = deepcopy(r)\n",
    "    \n",
    "    if \"bc\" in r[\"answer\"].lower():\n",
    "        bc_year_count += 1\n",
    "        continue\n",
    "    if \"s\" in r[\"answer\"].lower() or \"c\" in r[\"answer\"].lower():\n",
    "        s_year_count += 1\n",
    "        continue\n",
    "    if \"-\" in r[\"answer\"].lower():\n",
    "        interval_year_count += 1\n",
    "        continue\n",
    "    assert is_date(r[\"answer\"]), r\n",
    "    \n",
    "    assert r[\"answer\"].isdigit(), r\n",
    "    new_r[\"rewrite_answer\"] = str(int(r[\"answer\"]) + 1)\n",
    "    new_r[\"original_answer\"] = new_r[\"answer\"]\n",
    "    new_r[\"original_question\"] = new_r[\"question\"]\n",
    "    new_r[\"answer\"] = new_r[\"rewrite_answer\"]\n",
    "    new_r[\"question\"] = new_r[\"rewrite_question\"]\n",
    "    del new_r[\"rewrite_answer\"]\n",
    "    del new_r[\"rewrite_question\"]\n",
    "    common_fact_date_rewrite_increment_df_content.append(new_r)\n",
    "len(common_fact_date_rewrite_increment_df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fact_date_rewrite_increment_df = pd.DataFrame(common_fact_date_rewrite_increment_df_content)\n",
    "common_fact_date_rewrite_increment_df.to_excel(f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/common_fact_date_w-rewrite_increment.xlsx\", index=False)\n",
    "\n",
    "io.dump_jsonlines(common_fact_date_rewrite_increment_df_content, f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/common_fact_date_w-rewrite_increment.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_shuffle = np.arange(len(common_fact_date_rewrite_increment_df_content))\n",
    "np.random.shuffle(rand_shuffle)\n",
    "\n",
    "n_dev = 100\n",
    "n_train = len(common_fact_date_rewrite_increment_df_content) - n_dev\n",
    "train = [common_fact_date_rewrite_increment_df_content[i] for i in rand_shuffle[:n_train]]\n",
    "valid = [common_fact_date_rewrite_increment_df_content[i] for i in rand_shuffle[n_train:]]\n",
    "io.dump_jsonlines(train, f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/train.jsonl\")\n",
    "\n",
    "io.dump_jsonlines(valid, f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/valid.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '1882',\n",
       " 'question': 'When was the year after the year that the start of the Scramble for Africa happened?',\n",
       " 'topic': 'Colonization and Empire Building',\n",
       " 'original_answer': '1881',\n",
       " 'original_question': 'What year marks the start of the Scramble for Africa?'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '1733',\n",
       " 'question': 'When was the year after the year that George Washington was born?',\n",
       " 'topic': \"Historic Figures' Birthday\",\n",
       " 'original_answer': '1732',\n",
       " 'original_question': 'In which year was George Washington born?'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_fact_date_rewrite_increment_df_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_date_year_after = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/common_date_data_year_after/valid.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_date_year = []\n",
    "\n",
    "for d in common_date_year_after:\n",
    "    new_d = {\n",
    "        \"question\": d[\"original_question\"],\n",
    "        \"answer\": d[\"original_answer\"],\n",
    "        \"topic\": d[\"topic\"],\n",
    "        \"year_after_question\": d[\"question\"],\n",
    "        \"year_after_answer\": d[\"answer\"],\n",
    "    }\n",
    "    common_date_year.append(new_d)\n",
    "len(common_date_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(common_date_year, f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/valid.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"ucinlp/drop\")\n",
    "\n",
    "date_count = 0\n",
    "failed_count = 0\n",
    "drop_date_instances = []\n",
    "passage = set()\n",
    "for split in [\"train\", \"validation\"]:\n",
    "    for i in range(len(ds[split])):\n",
    "        datum = ds[split][i]\n",
    "        span = datum[\"answers_spans\"]\n",
    "        a_str = datum[\"answers_spans\"][\"spans\"][0]\n",
    "        \n",
    "        q_str = datum[\"question\"].lower()\n",
    "        date_count += len([t for t in span[\"types\"] if t == \"date\"])\n",
    "        \n",
    "        if not any([t in q_str.lower() for t in [\"date\", \"year\", \"when\",]]):\n",
    "            continue\n",
    "        if any([t in q_str.lower() for t in [\"month\", \"how many\", \"how old\"]]):\n",
    "            continue\n",
    "        \n",
    "        if \"date\" in span[\"types\"] and datum[\"passage\"] not in passage:\n",
    "            date_index = span[\"types\"].index(\"date\")\n",
    "            a_str = span[\"spans\"][date_index]\n",
    "            \n",
    "            try:\n",
    "                if str(parse(a_str).year) in a_str:\n",
    "                    drop_date_instances.append(datum)\n",
    "            except:\n",
    "                failed_count += 1\n",
    "                pass\n",
    "\n",
    "drop_unified_format = []\n",
    "\n",
    "for datum in drop_date_instances:\n",
    "    drop_unified_format.append({\n",
    "        \"id\": datum[\"query_id\"],\n",
    "        \"question\": datum[\"question\"],\n",
    "        \"answer\": datum[\"answers_spans\"][\"spans\"][0],\n",
    "        # \"texts\": [],\n",
    "        \"dataset\": \"drop\"\n",
    "    })\n",
    "len(drop_unified_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musique_date_instances = []\n",
    "single_hop_id = set()\n",
    "years = []\n",
    "\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    musique_instances = io.load_jsonlines(f\"{vars.DATA_DIR}/musique/musique_ans_v1.0_{split}.jsonl\")\n",
    "\n",
    "    for instance in musique_instances:\n",
    "        if \"question_decomposition\" not in instance:\n",
    "            continue\n",
    "        for q in instance[\"question_decomposition\"]:\n",
    "            q_str = q[\"question\"].lower()\n",
    "            a_str = q[\"answer\"]\n",
    "            # if not any([t in q_str.lower() for t in [\"date\", \"year\", \"when\",]]):\n",
    "            #     continue\n",
    "            # if any([t in q_str.lower() for t in [\"month\", \"how many\", ]]):\n",
    "            #     continue\n",
    "            # if any([t in q_str for t in [\"date\", \"year\", \"when\",]]) and is_date(a_str) and q[\"id\"] not in single_hop_id:\n",
    "            if is_date(a_str) and q[\"id\"] not in single_hop_id and str(parse(a_str).year) in a_str:\n",
    "                single_hop_id.add(q[\"id\"])\n",
    "                years.append(parse(a_str).year)\n",
    "                musique_date_instances.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how were the #1 expelled from #2 ?'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6a8f3d413e46c7962034b7a815ac48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1075"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mandarjoshi/trivia_qa\", \"rc.nocontext\")\n",
    "\n",
    "questions = set()\n",
    "c = 0\n",
    "trivia_date_data = []\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "     for i in range(len(ds[split])):\n",
    "        datum = ds[split][i]\n",
    "        a_str = datum[\"answer\"][\"value\"]\n",
    "        q_str = datum[\"question\"]\n",
    "        if not any([t in q_str.lower() for t in [\"date\", \"year\", \"when\",]]):\n",
    "            continue\n",
    "        if any([t in q_str.lower() for t in [\"month\", \"how many\", \"how old\"]]):\n",
    "            continue\n",
    "        if is_date(a_str) and q_str not in questions and str(parse(a_str).year) in a_str:\n",
    "            questions.add(q_str)\n",
    "            trivia_date_data.append(datum)\n",
    "            c += 1\n",
    "            \n",
    "trivia_unified_format = []\n",
    "\n",
    "for datum in trivia_date_data:\n",
    "    trivia_unified_format.append({\n",
    "        \"id\": datum[\"question_id\"],\n",
    "        \"question\": datum[\"question\"],\n",
    "        \"answer\": datum[\"answer\"][\"value\"],\n",
    "        # \"texts\": [],\n",
    "        \"dataset\": \"triviaqa\"\n",
    "    })\n",
    "len(trivia_unified_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90447/90447 [00:00<00:00, 140174.49it/s]\n",
      "100%|██████████| 7405/7405 [00:00<00:00, 167191.45it/s]\n",
      "100%|██████████| 7405/7405 [00:00<00:00, 2338238.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9517"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "questions = set()\n",
    "c = 0\n",
    "hotpotqa_date_data = []\n",
    "# for split in [\"train\", \"validation\", \"test\"]:\n",
    "for split, filename in [(\"train\", \"hotpot_train_v1.1.json\"), (\"dev\", \"hotpot_dev_fullwiki_v1.json\"), (\"test\", \"hotpot_test_fullwiki_v1.json\")]:\n",
    "    data = io.load_json(f\"{vars.DATA_DIR}/hotpotqa/{filename}\")\n",
    "    for i in tqdm(range(len(data))):\n",
    "        datum = data[i]\n",
    "        if \"answer\" not in datum or \"question\" not in datum:\n",
    "            continue\n",
    "        a_str = datum[\"answer\"]\n",
    "        q_str = datum[\"question\"]\n",
    "        if not any([t in q_str.lower() for t in [\"date\", \"year\", \"when\",]]):\n",
    "            continue\n",
    "        if any([t in q_str.lower() for t in [\"month\", \"how many\", \"how old\"]]):\n",
    "            continue\n",
    "        if is_date(a_str) and q_str not in questions and str(parse(a_str).year) in a_str:\n",
    "            questions.add(q_str)\n",
    "            hotpotqa_date_data.append(datum)\n",
    "            c += 1\n",
    "            \n",
    "hotpotqa_unified_format = []\n",
    "\n",
    "for datum in hotpotqa_date_data:\n",
    "    supporting_titles = [t for t, _ in datum[\"supporting_facts\"]]\n",
    "    texts = [\"\".join(lines) for t, lines in datum[\"context\"] if t in supporting_titles]\n",
    "    \n",
    "    hotpotqa_unified_format.append({\n",
    "        \"id\": datum[\"_id\"],\n",
    "        \"question\": datum[\"question\"],\n",
    "        \"answer\": datum[\"answer\"],\n",
    "        # \"texts\": texts,\n",
    "        \"dataset\": \"hotpotqa\"\n",
    "    })\n",
    "len(hotpotqa_unified_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bio_syn_data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mload_jsonlines(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/u/zliu/datastor1/KE-by-CP/data/debug_meta_train/bio_syn_data/train.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "bio_syn_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9518"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5a7d0db955429909bec76924',\n",
       " 'question': 'The Dutch-Belgian television series that \"House of Anubis\" was based on first aired in what year?',\n",
       " 'answer': '2006',\n",
       " 'dataset': 'hotpotqa'}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotpotqa_unified_format[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data = trivia_unified_format + hotpotqa_unified_format + drop_unified_format\n",
    "\n",
    "\n",
    "pd.DataFrame([d for d in sft_data if len(d[\"question\"]) <= 400]).to_excel(f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/all_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sft_data = []\n",
    "special_data = []\n",
    "for datum in sft_data:\n",
    "    if datum[\"answer\"].isdigit() and len(datum[\"answer\"]) != 4:\n",
    "        special_data.append(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>107.059201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>64.366637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>654.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  11689.000000\n",
       "mean     107.059201\n",
       "std       64.366637\n",
       "min       17.000000\n",
       "25%       69.000000\n",
       "50%       90.000000\n",
       "75%      122.000000\n",
       "max      654.000000"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import describe\n",
    "\n",
    "pd.DataFrame([len(d[\"question\"]) for d in sft_data]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_data = pd.read_excel(f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/all_data_w-rewrite.xlsx\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment_rewrite_data = []\n",
    "failed_count = 0\n",
    "for datum in rewrite_data:\n",
    "    a_str = datum[\"answer\"]\n",
    "    try:\n",
    "        assert str(parse(a_str).year) in a_str\n",
    "        rewrite_answer = str(int(parse(a_str).year) + 1)\n",
    "        increment_rewrite_datum = deepcopy(datum)\n",
    "        \n",
    "        increment_rewrite_datum[\"rewrite_answer\"] = rewrite_answer\n",
    "        increment_rewrite_data.append(increment_rewrite_datum)\n",
    "    except:\n",
    "        failed_count += 1\n",
    "        continue\n",
    "failed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(increment_rewrite_data).to_excel(f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/all_data_w-rewrite_increment.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/all_data_w-rewrite_increment.xlsx\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(all_data, f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/all_data_w-rewrite_increment.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10785"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([d for d in all_data if len(d[\"question\"]) <= 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increment_date_data = [\n",
    "    {\n",
    "        \"id\": d[\"id\"],\n",
    "        \"question\": d[\"rewrite_question\"],\n",
    "        \"answer\": d[\"rewrite_answer\"],\n",
    "        \"original_question\": d[\"question\"],\n",
    "        \"original_answer\": d[\"answer\"],\n",
    "        \"dataset\": d[\"dataset\"],\n",
    "    } \n",
    "    for d in all_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dev = 1000\n",
    "n_train = len(increment_date_data) - n_dev\n",
    "\n",
    "rand_shuffle = np.arange(len(increment_date_data))\n",
    "np.random.shuffle(rand_shuffle)\n",
    "\n",
    "increment_date_data_train = [increment_date_data[i] for i in rand_shuffle[:n_train]]\n",
    "increment_date_data_dev = [increment_date_data[i] for i in rand_shuffle[n_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(increment_date_data_train, f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/increment_date_data_train.jsonl\")\n",
    "io.dump_jsonlines(increment_date_data_dev, f\"{vars.DATA_DIR}/debug_meta_train/real_date_data/increment_date_data_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic year meta-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_template = \"{first_name} {last_name} was born in {birth_year} in {birth_place}. {gender_start} started the career of {career} in {career_year}. In {death_year}, {gender} passed away.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = list(set(\"\"\"Michael\n",
    "Emma\n",
    "James\n",
    "Sophia\n",
    "David\n",
    "Olivia\n",
    "William\n",
    "Ava\n",
    "Alexander\n",
    "Isabella\n",
    "John\n",
    "Mia\n",
    "Matthew\n",
    "Charlotte\n",
    "Daniel\n",
    "Amelia\n",
    "Christopher\n",
    "Harper\n",
    "Joseph\n",
    "Evelyn\n",
    "Benjamin\n",
    "Abigail\n",
    "Andrew\n",
    "Emily\n",
    "Robert\n",
    "Elizabeth\n",
    "Thomas\n",
    "Sofia\n",
    "Samuel\n",
    "Avery\n",
    "Jacob\n",
    "Ella\n",
    "Nathan\n",
    "Scarlett\n",
    "Nicholas\n",
    "Grace\n",
    "Ryan\n",
    "Victoria\n",
    "Joshua\n",
    "Madison\n",
    "Ethan\n",
    "Lily\n",
    "Noah\n",
    "Hannah\n",
    "Anthony\n",
    "Chloe\n",
    "Jonathan\n",
    "Zoe\n",
    "Aaron\n",
    "Nora\n",
    "Gabriel\n",
    "Riley\n",
    "Lucas\n",
    "Layla\n",
    "Christina\n",
    "Maria\n",
    "Jason\n",
    "Sarah\n",
    "Tyler\n",
    "Natalie\n",
    "Kevin\n",
    "Leah\n",
    "Eric\n",
    "Maya\n",
    "Brian\n",
    "Jennifer\n",
    "Brandon\n",
    "Laura\n",
    "Adam\n",
    "Elena\n",
    "Marcus\n",
    "Jasmine\n",
    "Caleb\n",
    "Anna\"\"\".split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_names = list(set(\"\"\"Smith\n",
    "Johnson\n",
    "Williams\n",
    "Brown\n",
    "Jones\n",
    "Garcia\n",
    "Miller\n",
    "Davis\n",
    "Rodriguez\n",
    "Martinez\n",
    "Hernandez\n",
    "Lopez\n",
    "Gonzalez\n",
    "Wilson\n",
    "Anderson\n",
    "Thomas\n",
    "Taylor\n",
    "Moore\n",
    "Jackson\n",
    "Martin\n",
    "Lee\n",
    "Perez\n",
    "Thompson\n",
    "White\n",
    "Harris\n",
    "Sanchez\n",
    "Clark\n",
    "Ramirez\n",
    "Lewis\n",
    "Robinson\n",
    "Walker\n",
    "Young\n",
    "Allen\n",
    "King\n",
    "Wright\n",
    "Scott\n",
    "Torres\n",
    "Nguyen\n",
    "Hill\n",
    "Flores\n",
    "Green\n",
    "Adams\n",
    "Nelson\n",
    "Baker\n",
    "Hall\n",
    "Rivera\n",
    "Campbell\n",
    "Mitchell\n",
    "Carter\n",
    "Roberts\n",
    "Gomez\n",
    "Phillips\n",
    "Evans\n",
    "Turner\n",
    "Diaz\n",
    "Parker\n",
    "Cruz\n",
    "Edwards\n",
    "Collins\n",
    "Reyes\n",
    "Stewart\n",
    "Morris\n",
    "Morales\n",
    "Murphy\n",
    "Cook\n",
    "Rogers\n",
    "Gutierrez\n",
    "Ortiz\n",
    "Morgan\n",
    "Cooper\n",
    "Peterson\n",
    "Bailey\n",
    "Reed\n",
    "Kelly\n",
    "Howard\n",
    "Ramos\n",
    "Kim\n",
    "Cox\n",
    "Ward\n",
    "Richardson\n",
    "Watson\n",
    "Brooks\n",
    "Chavez\n",
    "Wood\n",
    "James\n",
    "Bennett\n",
    "Gray\n",
    "Mendoza\n",
    "Ruiz\n",
    "Hughes\n",
    "Price\n",
    "Alvarez\n",
    "Castillo\"\"\".split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = [\"he\", \"she\"]\n",
    "careers = list(set(\"\"\"Doctor\n",
    "Teacher\n",
    "Software Engineer\n",
    "Nurse\n",
    "Accountant\n",
    "Chef\n",
    "Architect\n",
    "Lawyer\n",
    "Electrician\n",
    "Marketing Manager\n",
    "Graphic Designer\n",
    "Pharmacist\n",
    "Police Officer\n",
    "Financial Analyst\n",
    "Journalist\n",
    "Mechanical Engineer\n",
    "Social Worker\n",
    "Veterinarian\n",
    "Pilot\n",
    "Dental Hygienist\n",
    "Web Developer\n",
    "Physical Therapist\n",
    "Human Resources Manager\n",
    "Firefighter\n",
    "Real Estate Agent\n",
    "Data Scientist\n",
    "Interior Designer\n",
    "Occupational Therapist\n",
    "Construction Manager\n",
    "Speech Pathologist\n",
    "Cybersecurity Analyst\n",
    "Photographer\n",
    "Psychologist\n",
    "Plumber\n",
    "Flight Attendant\n",
    "Marine Biologist\n",
    "Athletic Trainer\n",
    "Urban Planner\n",
    "Welder\n",
    "Dietitian\n",
    "Librarian\n",
    "Civil Engineer\n",
    "Paralegal\n",
    "Film Producer\n",
    "Actuary\n",
    "Event Planner\n",
    "Scientist\n",
    "Carpenter\n",
    "Financial Advisor\n",
    "Lab Technician\"\"\".split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_years = np.random.choice(range(1900, 2020), 100, replace=False)\n",
    "birth_places = list(set(\"\"\"New York City\n",
    "Tokyo\n",
    "Paris\n",
    "London\n",
    "Sydney\n",
    "Rome\n",
    "Barcelona\n",
    "Amsterdam\n",
    "Singapore\n",
    "Cairo\n",
    "Rio de Janeiro\n",
    "Vancouver\n",
    "Istanbul\n",
    "Dubai\n",
    "Cape Town\n",
    "Bangkok\n",
    "Dublin\n",
    "Seoul\n",
    "Venice\n",
    "Hong Kong\n",
    "San Francisco\n",
    "Mumbai\n",
    "Berlin\n",
    "Buenos Aires\n",
    "Prague\n",
    "Stockholm\n",
    "Montreal\n",
    "Beijing\n",
    "Athens\n",
    "Marrakech\n",
    "Kyoto\n",
    "Vienna\n",
    "Copenhagen\n",
    "Jerusalem\n",
    "Nairobi\n",
    "Mexico City\n",
    "Santorini\n",
    "Bali\n",
    "Toronto\n",
    "Reykjavik\n",
    "Havana\n",
    "Moscow\n",
    "Queenstown\n",
    "Florence\n",
    "Edinburgh\n",
    "Machu Picchu\n",
    "Petra\n",
    "Bora Bora\n",
    "Chicago\n",
    "Maldives\"\"\".split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mfirst_names\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(last_names) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(birth_years) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(birth_places) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(genders) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(careers)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_names' is not defined"
     ]
    }
   ],
   "source": [
    "len(first_names) * len(last_names) * len(birth_years) * len(birth_places) * len(genders) * len(careers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 999560/1000000 [02:03<00:00, 8039.46it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "n_data = 1000000\n",
    "\n",
    "tuples = set()\n",
    "\n",
    "career_year_question_template = \"When was the year after the year that {first_name} {last_name} started the career of {career}?\"\n",
    "death_year_question_template = \"When was the year after the year that {first_name} {last_name} passed away?\"\n",
    "birth_year_question_template = \"When was the year after the year that {first_name} {last_name} was born?\"\n",
    "\n",
    "syn_data = []\n",
    "\n",
    "pbar = tqdm(total = n_data)\n",
    "\n",
    "max_death_year = 2023\n",
    "\n",
    "\n",
    "while len(syn_data) < n_data:\n",
    "    \n",
    "    first_name = np.random.choice(first_names)\n",
    "    last_name = np.random.choice(last_names)\n",
    "\n",
    "\n",
    "    birth_year = np.random.choice(birth_years)\n",
    "    birth_place = np.random.choice(birth_places)\n",
    "    gender = np.random.choice(genders)\n",
    "    career = np.random.choice(careers)\n",
    "\n",
    "    growth_duration = np.random.randint(14, 26)\n",
    "    career_year = birth_year + growth_duration\n",
    "    career_duration = np.random.randint(4, 40)\n",
    "    retire_year = career_year + career_duration\n",
    "\n",
    "    retire_duration = np.random.randint(1, 10)\n",
    "    death_year = retire_year + retire_duration\n",
    "    if death_year > max_death_year:\n",
    "        continue\n",
    "    \n",
    "    info_tuple = (first_name, last_name, birth_year, birth_place, gender, career, career_year, death_year)\n",
    "    \n",
    "    if info_tuple not in tuples:\n",
    "        tuples.add(info_tuple)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    text = text_template.format(\n",
    "        first_name=first_name,\n",
    "        last_name=last_name,\n",
    "        birth_year=birth_year,\n",
    "        birth_place=birth_place,\n",
    "        gender=gender,\n",
    "        gender_start=gender.capitalize(),\n",
    "        career=career,\n",
    "        career_year=career_year,\n",
    "        death_year=death_year,\n",
    "    )\n",
    "    \n",
    "    rand_idx = np.random.choice(range(3))\n",
    "\n",
    "    template_name, question_template = [\n",
    "        (\"career\", career_year_question_template), \n",
    "        (\"death\",death_year_question_template), \n",
    "        (\"birth\", birth_year_question_template),\n",
    "    ][rand_idx]\n",
    "    \n",
    "    question = question_template.format(\n",
    "        first_name=first_name,\n",
    "        last_name=last_name,\n",
    "        career=career,\n",
    "    )\n",
    "    if template_name == \"career\":\n",
    "        answer = career_year + 1\n",
    "    elif template_name == \"death\":\n",
    "        answer = death_year + 1\n",
    "    else:\n",
    "        answer = birth_year + 1\n",
    "\n",
    "    syn_data.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"question\": question,\n",
    "            \"answer\": str(int(answer))\n",
    "        }\n",
    "    )\n",
    "    pbar.update(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "n_dev = 100\n",
    "n_train = n_data - n_test - n_dev\n",
    "\n",
    "rand_shuffle = np.arange(n_data)\n",
    "np.random.shuffle(rand_shuffle)\n",
    "\n",
    "train_data = [syn_data[i] for i in rand_shuffle[:n_train]]\n",
    "dev_data = [syn_data[i] for i in rand_shuffle[n_train:n_train+n_dev]]\n",
    "test_data = [syn_data[i] for i in rand_shuffle[n_train+n_dev:]]\n",
    "\n",
    "io.dump_jsonlines(train_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/train.jsonl\")\n",
    "io.dump_jsonlines(dev_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/valid.jsonl\")\n",
    "io.dump_jsonlines(test_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [02:20<00:00, 8039.46it/s]"
     ]
    }
   ],
   "source": [
    "io.dump_jsonlines(syn_data, \"/u/zliu/datastor1/KE-by-CP/data/debug_meta_train/bio_syn_data/all_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda *x: x[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bio data with more template (v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [\n",
    "    \"{first_name} {last_name} was born\",\n",
    "    \"{first_name} {last_name} started the career of {career}\", \n",
    "    \"{first_name} {last_name} passed away\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year offset template\n",
    "# - 1\n",
    "# \n",
    "# plus_1_templates = [\n",
    "#     (\"When was the year after the year that\" + \" \" + e + \"?\", lambda *x: x[e_i] + 1)\n",
    "#     for e_i, e in enumerate(events)\n",
    "# ]\n",
    "plus_1_templates = [\n",
    "    (\"When was the year after the year that\" + \" \" + events[0] + \"?\", lambda *x: x[0] + 1),\n",
    "    (\"When was the year after the year that\" + \" \" + events[1] + \"?\", lambda *x: x[1] + 1),\n",
    "    (\"When was the year after the year that\" + \" \" + events[2] + \"?\", lambda *x: x[2] + 1),\n",
    "]\n",
    "minus_1_templates = [\n",
    "    (\"When was the year before the year that\" + \" \" + events[0] + \"?\", lambda *x: x[0] - 1),\n",
    "    (\"When was the year before the year that\" + \" \" + events[1] + \"?\", lambda *x: x[1] - 1),\n",
    "    (\"When was the year before the year that\" + \" \" + events[2] + \"?\", lambda *x: x[2] - 1),\n",
    "]\n",
    "\n",
    "plus_3_templates = [\n",
    "    (\"When was 3 year after the year that\" + \" \" + events[0] + \"?\", lambda *x: x[0] + 3),\n",
    "    (\"When was 3 year after the year that\" + \" \" + events[1] + \"?\", lambda *x: x[1] + 3),\n",
    "    (\"When was 3 year after the year that\" + \" \" + events[2] + \"?\", lambda *x: x[2] + 3),\n",
    "]\n",
    "minus_3_templates = [\n",
    "    (\"When was 3 year before the year that\" + \" \" + events[0] + \"?\", lambda *x: x[0] - 3),\n",
    "    (\"When was 3 year before the year that\" + \" \" + events[1] + \"?\", lambda *x: x[1] - 3),\n",
    "    (\"When was 3 year before the year that\" + \" \" + events[2] + \"?\", lambda *x: x[2] - 3),\n",
    "]\n",
    "\n",
    "\n",
    "plus_10_templates = [\n",
    "    (\"When was 10 year after the year that\" + \" \" + events[0] + \"?\", lambda *x: x[0] + 10),\n",
    "    (\"When was 10 year after the year that\" + \" \" + events[1] + \"?\", lambda *x: x[1] + 10),\n",
    "    (\"When was 10 year after the year that\" + \" \" + events[2] + \"?\", lambda *x: x[2] + 10),\n",
    "]\n",
    "minus_10_templates = [\n",
    "    (\"When was 10 year before the year that\" + \" \" + events[0] + \"?\", lambda *x: x[0] - 10),\n",
    "    (\"When was 10 year before the year that\" + \" \" + events[1] + \"?\", lambda *x: x[1] - 10),\n",
    "    (\"When was 10 year before the year that\" + \" \" + events[2] + \"?\", lambda *x: x[2] - 10),\n",
    "]\n",
    "\n",
    "interval_templates = [\n",
    "    (\"How many years did {first_name} {last_name} live for?\", lambda b,c,d: d-b),\n",
    "    (\"How many years after {first_name} {last_name} started the career of {career} did {gender} pass away?\", lambda b,c,d: d-c),\n",
    "    (\"How many years after {first_name} {last_name} was born did {gender} start the career of {career}?\", lambda b,c,d: c-b),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:05<00:00, 1525.98it/s]\n",
      "100%|█████████▉| 99615/100000 [00:18<00:00, 5440.39it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "n_data = 100000\n",
    "\n",
    "tuples = set()\n",
    "\n",
    "syn_data = []\n",
    "\n",
    "pbar = tqdm(total = n_data)\n",
    "\n",
    "max_death_year = 2023\n",
    "\n",
    "\n",
    "while len(syn_data) < n_data:\n",
    "    \n",
    "    first_name = np.random.choice(first_names)\n",
    "    last_name = np.random.choice(last_names)\n",
    "\n",
    "\n",
    "    birth_year = np.random.choice(birth_years)\n",
    "    birth_place = np.random.choice(birth_places)\n",
    "    gender = np.random.choice(genders)\n",
    "    career = np.random.choice(careers)\n",
    "\n",
    "    growth_duration = np.random.randint(14, 26)\n",
    "    career_year = birth_year + growth_duration\n",
    "    career_duration = np.random.randint(4, 40)\n",
    "    retire_year = career_year + career_duration\n",
    "\n",
    "    retire_duration = np.random.randint(1, 10)\n",
    "    death_year = retire_year + retire_duration\n",
    "    if death_year > max_death_year:\n",
    "        continue\n",
    "    \n",
    "    info_tuple = (first_name, last_name, birth_year, birth_place, gender, career, career_year, death_year)\n",
    "    \n",
    "    if info_tuple not in tuples:\n",
    "        tuples.add(info_tuple)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    text = text_template.format(\n",
    "        first_name=first_name,\n",
    "        last_name=last_name,\n",
    "        birth_year=birth_year,\n",
    "        birth_place=birth_place,\n",
    "        gender=gender,\n",
    "        gender_start=gender.capitalize(),\n",
    "        career=career,\n",
    "        career_year=career_year,\n",
    "        death_year=death_year,\n",
    "    )\n",
    "    \n",
    "    questions = []\n",
    "    for template_name, templates in [\n",
    "        (\"plus_1\", plus_1_templates) , \n",
    "        (\"minus_1\", minus_1_templates), \n",
    "        (\"plus_3\", plus_3_templates), \n",
    "        (\"minus_3\", minus_3_templates), \n",
    "        (\"plus_10\", plus_10_templates),\n",
    "        (\"minus_10\", minus_10_templates),\n",
    "        (\"interval\", interval_templates),\n",
    "    ]:\n",
    "        \n",
    "        rand_idx = np.random.choice(range(len(templates)))\n",
    "\n",
    "        question_template, answer_fn = templates[rand_idx]\n",
    "    \n",
    "        question = question_template.format(\n",
    "            first_name=first_name,\n",
    "            last_name=last_name,\n",
    "            career=career,\n",
    "            gender=gender\n",
    "        )\n",
    "        answer = answer_fn(birth_year, career_year, death_year)\n",
    "        questions.append(\n",
    "            {\n",
    "                \"question_type\": template_name,\n",
    "                \"question\": question,\n",
    "                \"answer\": str(int(answer))\n",
    "            }\n",
    "        )\n",
    "    syn_data.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"questions\": questions\n",
    "        }\n",
    "    )\n",
    "    pbar.update(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anna Rivera was born in 1980 in Sydney. She started the career of Doctor in 2003. In 2020, she passed away.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When was the year after the year that Matthew Evans passed away?'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_1_templates[2][0].format(\n",
    "            first_name=first_name,\n",
    "            last_name=last_name,\n",
    "            career=career,\n",
    "            gender=gender\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('When was the year after the year that {first_name} {last_name} was born?',\n",
       "  <function __main__.<lambda>(*x)>),\n",
       " ('When was the year after the year that {first_name} {last_name} started the career of {career}?',\n",
       "  <function __main__.<lambda>(*x)>),\n",
       " ('When was the year after the year that {first_name} {last_name} passed away?',\n",
       "  <function __main__.<lambda>(*x)>)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_1_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1973)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_1_templates[2][1](birth_year, career_year, death_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse synthetic text and generate QA from another template per template type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_type2templates = dict([\n",
    "    (\"plus_1\", plus_1_templates) , \n",
    "    (\"minus_1\", minus_1_templates), \n",
    "    (\"plus_3\", plus_3_templates), \n",
    "    (\"minus_3\", minus_3_templates), \n",
    "    (\"plus_10\", plus_10_templates),\n",
    "    (\"minus_10\", minus_10_templates),\n",
    "    (\"interval\", interval_templates),\n",
    "])\n",
    "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data_v2/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = r\"(?P<first_name>\\w+) (?P<last_name>\\w+) was born in (?P<birth_year>\\d{4}) in (?P<birth_place>[\\w\\s,]+)\\. (?P<gender_start>\\w+) started the career of (?P<career>[\\w\\s]+) in (?P<career_year>\\d{4})\\. In (?P<death_year>\\d{4}), (?P<gender>\\w+) passed away\\.\"\n",
    "\n",
    "# Example function to extract information\n",
    "def extract_person_info(text):\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "# text = \"John Doe was born in 1950 in New York City. He started the career of engineering in 1972. In 2020, he passed away.\"\n",
    "# info = extract_person_info(text)\n",
    "# print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laura Roberts was born in 1937 in San Francisco. She started the career of Physical Therapist in 1955. In 1993, she passed away.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many years after Laura Roberts was born did she start the career of Physical Therapist?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_type': 'plus_1',\n",
       "  'question': 'When was the year after the year that Laura Roberts started the career of Physical Therapist?',\n",
       "  'answer': '1956'},\n",
       " {'question_type': 'minus_1',\n",
       "  'question': 'When was the year before the year that Laura Roberts was born?',\n",
       "  'answer': '1936'},\n",
       " {'question_type': 'plus_3',\n",
       "  'question': 'When was 3 year after the year that Laura Roberts was born?',\n",
       "  'answer': '1940'},\n",
       " {'question_type': 'minus_3',\n",
       "  'question': 'When was 3 year before the year that Laura Roberts passed away?',\n",
       "  'answer': '1990'},\n",
       " {'question_type': 'plus_10',\n",
       "  'question': 'When was 10 year after the year that Laura Roberts was born?',\n",
       "  'answer': '1947'},\n",
       " {'question_type': 'minus_10',\n",
       "  'question': 'When was 10 year before the year that Laura Roberts was born?',\n",
       "  'answer': '1927'},\n",
       " {'question_type': 'interval',\n",
       "  'question': 'How many years did Laura Roberts live for?',\n",
       "  'answer': '56'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = []\n",
    "\n",
    "for test_datum in test_data: \n",
    "    new_test_datum = deepcopy(test_datum)\n",
    "    syn_info = extract_person_info(test_datum[\"text\"])\n",
    "    \n",
    "    alternative_questions = []\n",
    "    for q in test_datum[\"questions\"]:\n",
    "        templates = template_type2templates[q[\"question_type\"]]\n",
    "        instantiated_templates = [\n",
    "            template[0].format(first_name=syn_info[\"first_name\"], last_name=syn_info[\"last_name\"], career=syn_info[\"career\"],gender=syn_info[\"gender\"])\n",
    "            for template in templates\n",
    "        ]\n",
    "        \n",
    "        assert len([e_i for e_i, t in enumerate(instantiated_templates) if q[\"question\"] in t]) == 1\n",
    "        assert len([e_i for e_i, t in enumerate(instantiated_templates) if q[\"question\"] not in t]) == 2\n",
    "        \n",
    "        alternative_template_ids = [e_i for e_i, t in enumerate(instantiated_templates) if q[\"question\"] not in t]\n",
    "        alternative_template_idx = np.random.choice(alternative_template_ids)\n",
    "        alternative_template = templates[alternative_template_idx]\n",
    "        alternative_questions.append(\n",
    "            {\n",
    "                \"question_type\": q[\"question_type\"],\n",
    "                \"question\": alternative_template[0].format(\n",
    "                    first_name=syn_info[\"first_name\"],\n",
    "                    last_name=syn_info[\"last_name\"],\n",
    "                    career=syn_info[\"career\"],\n",
    "                    gender=syn_info[\"gender\"],\n",
    "                ),\n",
    "                \"answer\": str(alternative_template[1](int(syn_info[\"birth_year\"]), int(syn_info[\"career_year\"]), int(syn_info[\"death_year\"])))\n",
    "            }\n",
    "        )\n",
    "    new_test_datum[\"alternative_questions\"] = deepcopy(alternative_questions)\n",
    "    \n",
    "    np.random.shuffle(alternative_questions)\n",
    "    text_w_qas = test_datum[\"text\"] + \"\\n\\n\" + \"\\n\".join(f\"{q['question']} {q['answer']}\" for q in alternative_questions)\n",
    "    new_test_datum[\"text_w_qas\"] = text_w_qas\n",
    "    \n",
    "    new_test_data.append(new_test_datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin Baker was born in 1921 in Stockholm. He started the career of Film Producer in 1942. In 1966, he passed away.\n",
      "\n",
      "When was 10 year before the year that Kevin Baker was born? 1911\n",
      "When was the year after the year that Kevin Baker started the career of Film Producer? 1943\n",
      "When was 10 year after the year that Kevin Baker started the career of Film Producer? 1952\n",
      "How many years after Kevin Baker started the career of Film Producer did he pass away? 24\n",
      "When was 3 year before the year that Kevin Baker passed away? 1963\n",
      "When was 3 year after the year that Kevin Baker was born? 1924\n",
      "When was the year before the year that Kevin Baker was born? 1920\n"
     ]
    }
   ],
   "source": [
    "print(text_w_qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data_v2/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e_i for e_i, e in enumerate(syn_events) if e in test_data[0][\"questions\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_type': 'interval',\n",
       " 'question': 'How many years did Laura Roberts live for?',\n",
       " 'answer': '56'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e in test_data[0][\"questions\"][0][\"question\"] for e_i, e in enumerate(syn_events)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Laura Roberts was born',\n",
       " 'Laura Roberts started the career of Physical Therapist',\n",
       " 'Laura Roberts passed away']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_events[1] in test_data[0][\"questions\"][0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "n_dev = 100\n",
    "n_train = n_data - n_test - n_dev\n",
    "\n",
    "rand_shuffle = np.arange(n_data)\n",
    "np.random.shuffle(rand_shuffle)\n",
    "\n",
    "train_data = [syn_data[i] for i in rand_shuffle[:n_train]]\n",
    "dev_data = [syn_data[i] for i in rand_shuffle[n_train:n_train+n_dev]]\n",
    "test_data = [syn_data[i] for i in rand_shuffle[n_train+n_dev:]]\n",
    "\n",
    "io.dump_jsonlines(train_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data_v2/train.jsonl\")\n",
    "io.dump_jsonlines(dev_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data_v2/valid.jsonl\")\n",
    "io.dump_jsonlines(test_data, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data_v2/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/train.jsonl\")).sample(10).to_excel(\"/u/zliu/datastor1/mend/spotcheck/syn_text_train_sample.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/common_date_data/train.jsonl\")).sample(10).to_excel(\"/u/zliu/datastor1/mend/spotcheck/common_fact_train_sample.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_year_question_template = \"When was the year after the year that {first_name} {last_name} started the career of {career}?\"\n",
    "death_year_question_template = \"When was the year after the year that {first_name} {last_name} passed away?\"\n",
    "birth_year_question_template = \"When was the year after the year that {first_name} {last_name} was born?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_birth(question):\n",
    "    # Define the pattern to match the template\n",
    "    pattern = r\"When was the year after the year that ([\\w-]+) ([\\w-]+) was born\\?\"\n",
    "    # Search for the pattern in the question\n",
    "    match = re.search(pattern, question)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the captured groups\n",
    "        first_name = match.group(1)\n",
    "        last_name = match.group(2)\n",
    "        \n",
    "        return {\n",
    "            \"first_name\": first_name,\n",
    "            \"last_name\": last_name,\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_info_death(question):\n",
    "    # Define the pattern to match the template\n",
    "    pattern = r\"When was the year after the year that ([\\w-]+) ([\\w-]+) passed away\\?\"\n",
    "    # Search for the pattern in the question\n",
    "    match = re.search(pattern, question)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the captured groups\n",
    "        first_name = match.group(1)\n",
    "        last_name = match.group(2)\n",
    "        \n",
    "        return {\n",
    "            \"first_name\": first_name,\n",
    "            \"last_name\": last_name,\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_info_career(question):\n",
    "    # Define the pattern to match the template\n",
    "    pattern = r\"When was the year after the year that ([\\w-]+) ([\\w-]+) started the career of ([\\w\\s-]+)\\?\"\n",
    "    \n",
    "    # Search for the pattern in the question\n",
    "    match = re.search(pattern, question)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the captured groups\n",
    "        first_name = match.group(1)\n",
    "        last_name = match.group(2)\n",
    "        career = match.group(3)\n",
    "        \n",
    "        return {\n",
    "            \"first_name\": first_name,\n",
    "            \"last_name\": last_name,\n",
    "            \"career\": career\n",
    "        }\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Tyler', 'last_name': 'Ortiz', 'career': 'Pharmacist'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info_career(test_examples[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Nicholas', 'last_name': 'Reyes'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info_death(test_examples[1][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'William', 'last_name': 'Wilson'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info_birth(test_examples[4][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples_n_question = []\n",
    "\n",
    "career_year_n_question_template = \"When was the year that {first_name} {last_name} started the career of {career}?\"\n",
    "death_year_n_question_template = \"When was the year that {first_name} {last_name} passed away?\"\n",
    "birth_year_n_question_template = \"When was the year that {first_name} {last_name} was born?\"\n",
    "\n",
    "for example in test_examples:\n",
    "    new_example = deepcopy(example)\n",
    "    \n",
    "    if \"career\" in example[\"question\"]:\n",
    "        new_example[\"info\"] = extract_info_career(example[\"question\"])\n",
    "        new_template = career_year_n_question_template\n",
    "    elif \"passed away\" in example[\"question\"]:\n",
    "        new_example[\"info\"] = extract_info_death(example[\"question\"])\n",
    "        new_template = death_year_n_question_template\n",
    "    else:\n",
    "        assert \"was born\" in example[\"question\"]\n",
    "        new_example[\"info\"] = extract_info_birth(example[\"question\"])\n",
    "        new_template = birth_year_n_question_template\n",
    "\n",
    "    new_example[\"question\"] = new_template.format(**new_example[\"info\"])\n",
    "    new_example[\"answer\"] = str(int(new_example[\"answer\"]) - 1)\n",
    "    \n",
    "    test_examples_n_question.append(new_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(test_examples_n_question, f\"{vars.DATA_DIR}/debug_meta_train/bio_syn_data/test_n_question.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate place meta-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geonamescache'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeonamescache\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geonamescache'"
     ]
    }
   ],
   "source": [
    "import geonamescache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total country: 252\n"
     ]
    }
   ],
   "source": [
    "gc = geonamescache.GeonamesCache()\n",
    "countries = gc.get_countries()\n",
    "countries_by_population = sorted(countries.values(), key=lambda x: -x[\"population\"])\n",
    "print(\"# total country:\", len(countries_by_population))\n",
    "\n",
    "countries_by_population_top20 = countries_by_population[:20]\n",
    "countries_by_population_top20_country_code = set([c[\"iso\"] for c in countries_by_population_top20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geonameid': 5854968,\n",
       " 'name': 'United States Minor Outlying Islands',\n",
       " 'iso': 'UM',\n",
       " 'iso3': 'UMI',\n",
       " 'isonumeric': 581,\n",
       " 'fips': '',\n",
       " 'continentcode': 'OC',\n",
       " 'capital': '',\n",
       " 'areakm2': 0,\n",
       " 'population': 0,\n",
       " 'tld': '.um',\n",
       " 'currencycode': 'USD',\n",
       " 'currencyname': 'Dollar',\n",
       " 'phone': '1',\n",
       " 'postalcoderegex': '',\n",
       " 'languages': 'en-UM',\n",
       " 'neighbours': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_by_population[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total cities: 26463\n"
     ]
    }
   ],
   "source": [
    "cities_by_population = sorted(gc.get_cities().values(), key=lambda x: -x[\"population\"])\n",
    "\n",
    "print(\"# total cities:\", len(cities_by_population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrycode2cities = defaultdict(list)\n",
    "for city in cities_by_population:\n",
    "    # if city[\"countrycode\"] in countries_by_population_top20_country_code:\n",
    "    countrycode2cities[city[\"countrycode\"]].append(city)\n",
    "countrycode2cities = {cc: sorted(cities, key=lambda x: -x[\"population\"]) for cc, cities in countrycode2cities.items()}\n",
    "# countrycode2cities = {cc: cities for cc, cities in countrycode2cities.items() if len(cities) >= 20}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countrycode_by_n_cities = sorted([(cc, len(cities)) for cc, cities in countrycode2cities.items()], key=lambda x: -x[1])\n",
    "len(countrycode_by_n_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United States', 3272),\n",
       " ('India', 2480),\n",
       " ('China', 1955),\n",
       " ('Brazil', 1217),\n",
       " ('Germany', 1117),\n",
       " ('Russia', 1095),\n",
       " ('Japan', 851),\n",
       " ('United Kingdom', 829),\n",
       " ('France', 649),\n",
       " ('Mexico', 640),\n",
       " ('Spain', 625),\n",
       " ('Italy', 613),\n",
       " ('Philippines', 460),\n",
       " ('Indonesia', 402),\n",
       " ('Turkey', 392),\n",
       " ('Poland', 333),\n",
       " ('Canada', 330),\n",
       " ('Pakistan', 317),\n",
       " ('Colombia', 312),\n",
       " ('Australia', 290),\n",
       " ('Ukraine', 255),\n",
       " ('Algeria', 250),\n",
       " ('Nigeria', 245),\n",
       " ('Argentina', 229),\n",
       " ('Netherlands', 228),\n",
       " ('Belgium', 224),\n",
       " ('Thailand', 222),\n",
       " ('Venezuela', 210),\n",
       " ('Iran', 205),\n",
       " ('Tanzania', 185),\n",
       " ('South Africa', 170),\n",
       " ('Malaysia', 142),\n",
       " ('Portugal', 141),\n",
       " ('Romania', 134),\n",
       " ('Egypt', 133),\n",
       " ('Peru', 131),\n",
       " ('Cuba', 127),\n",
       " ('South Korea', 126),\n",
       " ('Vietnam', 116),\n",
       " ('Hungary', 114),\n",
       " ('Greece', 114),\n",
       " ('Sweden', 106),\n",
       " ('Bangladesh', 105),\n",
       " ('Chile', 103),\n",
       " ('Uzbekistan', 103),\n",
       " ('Israel', 103),\n",
       " ('Guatemala', 102),\n",
       " ('Czechia', 96),\n",
       " ('Ethiopia', 91),\n",
       " ('Switzerland', 86),\n",
       " ('Morocco', 85),\n",
       " ('Madagascar', 84),\n",
       " ('Kazakhstan', 78),\n",
       " ('Syria', 76),\n",
       " ('Finland', 76),\n",
       " ('Tunisia', 74),\n",
       " ('Iraq', 72),\n",
       " ('Democratic Republic of the Congo', 68),\n",
       " ('Myanmar', 67),\n",
       " ('Ecuador', 66),\n",
       " ('Saudi Arabia', 63),\n",
       " ('Cameroon', 63),\n",
       " ('Ghana', 61),\n",
       " ('Ivory Coast', 60),\n",
       " ('North Korea', 59),\n",
       " ('Denmark', 59),\n",
       " ('Azerbaijan', 59),\n",
       " ('Kenya', 58),\n",
       " ('Bulgaria', 56),\n",
       " ('New Zealand', 55),\n",
       " ('Sri Lanka', 54),\n",
       " ('Slovakia', 53),\n",
       " ('Afghanistan', 49),\n",
       " ('Belarus', 49),\n",
       " ('Austria', 49),\n",
       " ('Uganda', 49),\n",
       " ('Dominican Republic', 48),\n",
       " ('Sudan', 48),\n",
       " ('Serbia', 48),\n",
       " ('Nepal', 44),\n",
       " ('Libya', 43),\n",
       " ('Palestinian Territory', 43),\n",
       " ('Burkina Faso', 41),\n",
       " ('Costa Rica', 41),\n",
       " ('Bolivia', 39),\n",
       " ('Ireland', 39),\n",
       " ('Norway', 39),\n",
       " ('North Macedonia', 38),\n",
       " ('Nicaragua', 36),\n",
       " ('Lithuania', 36),\n",
       " ('El Salvador', 35),\n",
       " ('Somalia', 33),\n",
       " ('Taiwan', 31),\n",
       " ('Senegal', 31),\n",
       " ('Uruguay', 31),\n",
       " ('Kyrgyzstan', 30),\n",
       " ('Zambia', 29),\n",
       " ('Benin', 29),\n",
       " ('Zimbabwe', 28),\n",
       " ('Cambodia', 27),\n",
       " ('Jordan', 27),\n",
       " ('Tajikistan', 27),\n",
       " ('Panama', 27),\n",
       " ('Angola', 26),\n",
       " ('Paraguay', 26),\n",
       " ('Haiti', 26),\n",
       " ('Mozambique', 26),\n",
       " ('Oman', 26),\n",
       " ('Niger', 25),\n",
       " ('Croatia', 25),\n",
       " ('Honduras', 24),\n",
       " ('Turkmenistan', 24),\n",
       " ('Chad', 24),\n",
       " ('Yemen', 23),\n",
       " ('Mongolia', 22),\n",
       " ('Bosnia and Herzegovina', 22),\n",
       " ('Mali', 21),\n",
       " ('Georgia', 21),\n",
       " ('Moldova', 21),\n",
       " ('Kosovo', 21),\n",
       " ('Albania', 21),\n",
       " ('Puerto Rico', 21),\n",
       " ('Central African Republic', 20),\n",
       " ('Hong Kong', 19),\n",
       " ('United Arab Emirates', 19),\n",
       " ('Guinea', 19),\n",
       " ('Armenia', 19),\n",
       " ('Kuwait', 18),\n",
       " ('Botswana', 18),\n",
       " ('Togo', 17),\n",
       " ('Malawi', 17),\n",
       " ('South Sudan', 16),\n",
       " ('Lebanon', 14),\n",
       " ('Latvia', 14),\n",
       " ('Mauritania', 14),\n",
       " ('Namibia', 14),\n",
       " ('Reunion', 14),\n",
       " ('Papua New Guinea', 13),\n",
       " ('Mauritius', 13),\n",
       " ('Trinidad and Tobago', 13),\n",
       " ('Republic of the Congo', 12),\n",
       " ('Sierra Leone', 12),\n",
       " ('Rwanda', 11),\n",
       " ('Jamaica', 11),\n",
       " ('Laos', 11),\n",
       " ('Burundi', 10),\n",
       " ('Liberia', 10),\n",
       " ('Guadeloupe', 10),\n",
       " ('Gabon', 9),\n",
       " ('Slovenia', 9),\n",
       " ('Cyprus', 9),\n",
       " ('Timor Leste', 9),\n",
       " ('Lesotho', 9),\n",
       " ('Estonia', 8),\n",
       " ('Montenegro', 8),\n",
       " ('Bahrain', 8),\n",
       " ('Martinique', 8),\n",
       " ('Gambia', 7),\n",
       " ('Guam', 7),\n",
       " ('Malta', 7),\n",
       " ('Eritrea', 6),\n",
       " ('Iceland', 6),\n",
       " ('Fiji', 6),\n",
       " ('Singapore', 5),\n",
       " ('Qatar', 5),\n",
       " ('French Guiana', 5),\n",
       " ('Belize', 5),\n",
       " ('Djibouti', 4),\n",
       " ('Cabo Verde', 4),\n",
       " ('Bhutan', 4),\n",
       " ('Brunei', 4),\n",
       " ('Guyana', 3),\n",
       " ('Bahamas', 3),\n",
       " ('Western Sahara', 3),\n",
       " ('Equatorial Guinea', 3),\n",
       " ('Eswatini', 3),\n",
       " ('New Caledonia', 3),\n",
       " ('Luxembourg', 3),\n",
       " ('Mayotte', 3),\n",
       " ('Aruba', 3),\n",
       " ('French Polynesia', 3),\n",
       " ('Guinea-Bissau', 2),\n",
       " ('Suriname', 2),\n",
       " ('U.S. Virgin Islands', 2),\n",
       " ('Comoros', 2),\n",
       " ('Monaco', 2),\n",
       " ('Cayman Islands', 2),\n",
       " ('Marshall Islands', 2),\n",
       " ('Saint Vincent and the Grenadines', 2),\n",
       " ('Andorra', 2),\n",
       " ('Montserrat', 2),\n",
       " ('Macao', 1),\n",
       " ('Curacao', 1),\n",
       " ('Maldives', 1),\n",
       " ('Barbados', 1),\n",
       " ('Solomon Islands', 1),\n",
       " ('Sao Tome and Principe', 1),\n",
       " ('Northern Mariana Islands', 1),\n",
       " ('Samoa', 1),\n",
       " ('Kiribati', 1),\n",
       " ('Vanuatu', 1),\n",
       " ('Jersey', 1),\n",
       " ('Gibraltar', 1),\n",
       " ('Isle of Man', 1),\n",
       " ('Antigua and Barbuda', 1),\n",
       " ('Seychelles', 1),\n",
       " ('Tonga', 1),\n",
       " ('Saint Lucia', 1),\n",
       " ('Dominica', 1),\n",
       " ('Guernsey', 1),\n",
       " ('Greenland', 1),\n",
       " ('Cook Islands', 1),\n",
       " ('Faroe Islands', 1),\n",
       " ('Saint Kitts and Nevis', 1),\n",
       " ('American Samoa', 1),\n",
       " ('Aland Islands', 1),\n",
       " ('British Virgin Islands', 1),\n",
       " ('Grenada', 1),\n",
       " ('Saint Pierre and Miquelon', 1),\n",
       " ('Saint Barthelemy', 1),\n",
       " ('Saint Martin', 1),\n",
       " ('Liechtenstein', 1),\n",
       " ('San Marino', 1),\n",
       " ('Tuvalu', 1),\n",
       " ('Turks and Caicos Islands', 1),\n",
       " ('Bonaire, Saint Eustatius and Saba ', 1),\n",
       " ('Svalbard and Jan Mayen', 1),\n",
       " ('Falkland Islands', 1),\n",
       " ('Anguilla', 1),\n",
       " ('Sint Maarten', 1),\n",
       " ('Wallis and Futuna', 1),\n",
       " ('Nauru', 1),\n",
       " ('Bermuda', 1),\n",
       " ('Norfolk Island', 1),\n",
       " ('Vatican', 1),\n",
       " ('Saint Helena', 1),\n",
       " ('Niue', 1),\n",
       " ('Christmas Island', 1),\n",
       " ('Cocos Islands', 1),\n",
       " ('Pitcairn', 1),\n",
       " ('French Southern Territories', 1),\n",
       " ('South Georgia and the South Sandwich Islands', 1),\n",
       " ('Micronesia', 1),\n",
       " ('Palau', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(countries[cc][\"name\"], len(cities)) for cc, cities in countrycode2cities.items()], key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_cities = []\n",
    "for i, (cc, _) in enumerate(countrycode_by_n_cities):\n",
    "    if i < 10:\n",
    "        sft_cities.extend(countrycode2cities[cc][:80])\n",
    "    elif i < 30:\n",
    "        sft_cities.extend(countrycode2cities[cc][:30])\n",
    "    elif i < 70:\n",
    "        sft_cities.extend(countrycode2cities[cc][:10])\n",
    "    elif i < 150:\n",
    "        sft_cities.extend(countrycode2cities[cc][:4])\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('US', 3272),\n",
       " ('IN', 2480),\n",
       " ('CN', 1955),\n",
       " ('BR', 1217),\n",
       " ('DE', 1117),\n",
       " ('RU', 1095),\n",
       " ('JP', 851),\n",
       " ('GB', 829),\n",
       " ('FR', 649),\n",
       " ('MX', 640),\n",
       " ('ES', 625),\n",
       " ('IT', 613),\n",
       " ('PH', 460),\n",
       " ('ID', 402),\n",
       " ('TR', 392),\n",
       " ('PL', 333),\n",
       " ('CA', 330),\n",
       " ('PK', 317),\n",
       " ('CO', 312),\n",
       " ('AU', 290),\n",
       " ('UA', 255),\n",
       " ('DZ', 250),\n",
       " ('NG', 245),\n",
       " ('AR', 229),\n",
       " ('NL', 228),\n",
       " ('BE', 224),\n",
       " ('TH', 222),\n",
       " ('VE', 210),\n",
       " ('IR', 205),\n",
       " ('TZ', 185),\n",
       " ('ZA', 170),\n",
       " ('MY', 142),\n",
       " ('PT', 141),\n",
       " ('RO', 134),\n",
       " ('EG', 133),\n",
       " ('PE', 131),\n",
       " ('CU', 127),\n",
       " ('KR', 126),\n",
       " ('VN', 116),\n",
       " ('HU', 114),\n",
       " ('GR', 114),\n",
       " ('SE', 106),\n",
       " ('BD', 105),\n",
       " ('CL', 103),\n",
       " ('UZ', 103),\n",
       " ('IL', 103),\n",
       " ('GT', 102),\n",
       " ('CZ', 96),\n",
       " ('ET', 91),\n",
       " ('CH', 86),\n",
       " ('MA', 85),\n",
       " ('MG', 84),\n",
       " ('KZ', 78),\n",
       " ('SY', 76),\n",
       " ('FI', 76),\n",
       " ('TN', 74),\n",
       " ('IQ', 72),\n",
       " ('CD', 68),\n",
       " ('MM', 67),\n",
       " ('EC', 66),\n",
       " ('SA', 63),\n",
       " ('CM', 63),\n",
       " ('GH', 61),\n",
       " ('CI', 60),\n",
       " ('KP', 59),\n",
       " ('DK', 59),\n",
       " ('AZ', 59),\n",
       " ('KE', 58),\n",
       " ('BG', 56),\n",
       " ('NZ', 55),\n",
       " ('LK', 54),\n",
       " ('SK', 53),\n",
       " ('AF', 49),\n",
       " ('BY', 49),\n",
       " ('AT', 49),\n",
       " ('UG', 49),\n",
       " ('DO', 48),\n",
       " ('SD', 48),\n",
       " ('RS', 48),\n",
       " ('NP', 44),\n",
       " ('LY', 43),\n",
       " ('PS', 43),\n",
       " ('BF', 41),\n",
       " ('CR', 41),\n",
       " ('BO', 39),\n",
       " ('IE', 39),\n",
       " ('NO', 39),\n",
       " ('MK', 38),\n",
       " ('NI', 36),\n",
       " ('LT', 36),\n",
       " ('SV', 35),\n",
       " ('SO', 33),\n",
       " ('TW', 31),\n",
       " ('SN', 31),\n",
       " ('UY', 31),\n",
       " ('KG', 30),\n",
       " ('ZM', 29),\n",
       " ('BJ', 29),\n",
       " ('ZW', 28),\n",
       " ('KH', 27),\n",
       " ('JO', 27),\n",
       " ('TJ', 27),\n",
       " ('PA', 27),\n",
       " ('AO', 26),\n",
       " ('PY', 26),\n",
       " ('HT', 26),\n",
       " ('MZ', 26),\n",
       " ('OM', 26),\n",
       " ('NE', 25),\n",
       " ('HR', 25),\n",
       " ('HN', 24),\n",
       " ('TM', 24),\n",
       " ('TD', 24),\n",
       " ('YE', 23),\n",
       " ('MN', 22),\n",
       " ('BA', 22),\n",
       " ('ML', 21),\n",
       " ('GE', 21),\n",
       " ('MD', 21),\n",
       " ('XK', 21),\n",
       " ('AL', 21),\n",
       " ('PR', 21),\n",
       " ('CF', 20),\n",
       " ('HK', 19),\n",
       " ('AE', 19),\n",
       " ('GN', 19),\n",
       " ('AM', 19),\n",
       " ('KW', 18),\n",
       " ('BW', 18),\n",
       " ('TG', 17),\n",
       " ('MW', 17),\n",
       " ('SS', 16),\n",
       " ('LB', 14),\n",
       " ('LV', 14),\n",
       " ('MR', 14),\n",
       " ('NA', 14),\n",
       " ('RE', 14),\n",
       " ('PG', 13),\n",
       " ('MU', 13),\n",
       " ('TT', 13),\n",
       " ('CG', 12),\n",
       " ('SL', 12),\n",
       " ('RW', 11),\n",
       " ('JM', 11),\n",
       " ('LA', 11),\n",
       " ('BI', 10),\n",
       " ('LR', 10),\n",
       " ('GP', 10),\n",
       " ('GA', 9),\n",
       " ('SI', 9),\n",
       " ('CY', 9),\n",
       " ('TL', 9),\n",
       " ('LS', 9),\n",
       " ('EE', 8),\n",
       " ('ME', 8),\n",
       " ('BH', 8),\n",
       " ('MQ', 8),\n",
       " ('GM', 7),\n",
       " ('GU', 7),\n",
       " ('MT', 7),\n",
       " ('ER', 6),\n",
       " ('IS', 6),\n",
       " ('FJ', 6),\n",
       " ('SG', 5),\n",
       " ('QA', 5),\n",
       " ('GF', 5),\n",
       " ('BZ', 5),\n",
       " ('DJ', 4),\n",
       " ('CV', 4),\n",
       " ('BT', 4),\n",
       " ('BN', 4),\n",
       " ('GY', 3),\n",
       " ('BS', 3),\n",
       " ('EH', 3),\n",
       " ('GQ', 3),\n",
       " ('SZ', 3),\n",
       " ('NC', 3),\n",
       " ('LU', 3),\n",
       " ('YT', 3),\n",
       " ('AW', 3),\n",
       " ('PF', 3),\n",
       " ('GW', 2),\n",
       " ('SR', 2),\n",
       " ('VI', 2),\n",
       " ('KM', 2),\n",
       " ('MC', 2),\n",
       " ('KY', 2),\n",
       " ('MH', 2),\n",
       " ('VC', 2),\n",
       " ('AD', 2),\n",
       " ('MS', 2),\n",
       " ('MO', 1),\n",
       " ('CW', 1),\n",
       " ('MV', 1),\n",
       " ('BB', 1),\n",
       " ('SB', 1),\n",
       " ('ST', 1),\n",
       " ('MP', 1),\n",
       " ('WS', 1),\n",
       " ('KI', 1),\n",
       " ('VU', 1),\n",
       " ('JE', 1),\n",
       " ('GI', 1),\n",
       " ('IM', 1),\n",
       " ('AG', 1),\n",
       " ('SC', 1),\n",
       " ('TO', 1),\n",
       " ('LC', 1),\n",
       " ('DM', 1),\n",
       " ('GG', 1),\n",
       " ('GL', 1),\n",
       " ('CK', 1),\n",
       " ('FO', 1),\n",
       " ('KN', 1),\n",
       " ('AS', 1),\n",
       " ('AX', 1),\n",
       " ('VG', 1),\n",
       " ('GD', 1),\n",
       " ('PM', 1),\n",
       " ('BL', 1),\n",
       " ('MF', 1),\n",
       " ('LI', 1),\n",
       " ('SM', 1),\n",
       " ('TV', 1),\n",
       " ('TC', 1),\n",
       " ('BQ', 1),\n",
       " ('SJ', 1),\n",
       " ('FK', 1),\n",
       " ('AI', 1),\n",
       " ('SX', 1),\n",
       " ('WF', 1),\n",
       " ('NR', 1),\n",
       " ('BM', 1),\n",
       " ('NF', 1),\n",
       " ('VA', 1),\n",
       " ('SH', 1),\n",
       " ('NU', 1),\n",
       " ('CX', 1),\n",
       " ('CC', 1),\n",
       " ('PN', 1),\n",
       " ('TF', 1),\n",
       " ('GS', 1),\n",
       " ('FM', 1),\n",
       " ('PW', 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countrycode_by_n_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * 80 + 20 * 30 + 40 * 10 + 80 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT data for country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_1 = [\n",
    "    (\"New York\", \"USA\"),\n",
    "    (\"London\", \"United Kingdom\"),\n",
    "    (\"Tokyo\", \"Japan\"),\n",
    "    (\"Paris\", \"France\"),\n",
    "    (\"Berlin\", \"Germany\"),\n",
    "    (\"Madrid\", \"Spain\"),\n",
    "    (\"Rome\", \"Italy\"),\n",
    "    (\"Toronto\", \"Canada\"),\n",
    "    (\"Sydney\", \"Australia\"),\n",
    "    (\"Moscow\", \"Russia\"),\n",
    "    (\"Beijing\", \"China\"),\n",
    "    (\"Mumbai\", \"India\"),\n",
    "    (\"São Paulo\", \"Brazil\"),\n",
    "    (\"Mexico City\", \"Mexico\"),\n",
    "    (\"Cairo\", \"Egypt\"),\n",
    "    (\"Istanbul\", \"Turkey\"),\n",
    "    (\"Bangkok\", \"Thailand\"),\n",
    "    (\"Buenos Aires\", \"Argentina\"),\n",
    "    (\"Seoul\", \"South Korea\"),\n",
    "    (\"Jakarta\", \"Indonesia\"),\n",
    "    (\"Dubai\", \"United Arab Emirates\"),\n",
    "    (\"Singapore\", \"Singapore\"),\n",
    "    (\"Hong Kong\", \"China\"),\n",
    "    (\"Lagos\", \"Nigeria\"),\n",
    "    (\"Johannesburg\", \"South Africa\"),\n",
    "    (\"Tehran\", \"Iran\"),\n",
    "    (\"Lima\", \"Peru\"),\n",
    "    (\"Bogotá\", \"Colombia\"),\n",
    "    (\"Hanoi\", \"Vietnam\"),\n",
    "    (\"Kuala Lumpur\", \"Malaysia\"),\n",
    "    (\"Riyadh\", \"Saudi Arabia\"),\n",
    "    (\"Vienna\", \"Austria\"),\n",
    "    (\"Athens\", \"Greece\"),\n",
    "    (\"Dublin\", \"Ireland\"),\n",
    "    (\"Oslo\", \"Norway\"),\n",
    "    (\"Stockholm\", \"Sweden\"),\n",
    "    (\"Copenhagen\", \"Denmark\"),\n",
    "    (\"Brussels\", \"Belgium\"),\n",
    "    (\"Amsterdam\", \"Netherlands\"),\n",
    "    (\"Helsinki\", \"Finland\"),\n",
    "    (\"Zurich\", \"Switzerland\"),\n",
    "    (\"Warsaw\", \"Poland\"),\n",
    "    (\"Budapest\", \"Hungary\"),\n",
    "    (\"Prague\", \"Czech Republic\"),\n",
    "    (\"Lisbon\", \"Portugal\"),\n",
    "    (\"Edinburgh\", \"United Kingdom\"),\n",
    "    (\"Glasgow\", \"United Kingdom\"),\n",
    "    (\"Barcelona\", \"Spain\"),\n",
    "    (\"Milan\", \"Italy\"),\n",
    "    (\"Geneva\", \"Switzerland\"),\n",
    "    (\"Munich\", \"Germany\"),\n",
    "    (\"Frankfurt\", \"Germany\"),\n",
    "    (\"Hamburg\", \"Germany\"),\n",
    "    (\"Brisbane\", \"Australia\"),\n",
    "    (\"Melbourne\", \"Australia\"),\n",
    "    (\"Perth\", \"Australia\"),\n",
    "    (\"Wellington\", \"New Zealand\"),\n",
    "    (\"Auckland\", \"New Zealand\"),\n",
    "    (\"Christchurch\", \"New Zealand\"),\n",
    "    (\"Doha\", \"Qatar\"),\n",
    "    (\"Manila\", \"Philippines\"),\n",
    "    (\"Ho Chi Minh City\", \"Vietnam\"),\n",
    "    (\"Taipei\", \"Taiwan\"),\n",
    "    (\"Karachi\", \"Pakistan\"),\n",
    "    (\"Dhaka\", \"Bangladesh\"),\n",
    "    (\"Santiago\", \"Chile\"),\n",
    "    (\"Montevideo\", \"Uruguay\"),\n",
    "    (\"Quito\", \"Ecuador\"),\n",
    "    (\"La Paz\", \"Bolivia\"),\n",
    "    (\"Kuwait City\", \"Kuwait\"),\n",
    "    (\"Muscat\", \"Oman\"),\n",
    "    (\"Baku\", \"Azerbaijan\"),\n",
    "    (\"Tbilisi\", \"Georgia\"),\n",
    "    (\"Yerevan\", \"Armenia\"),\n",
    "    (\"Casablanca\", \"Morocco\"),\n",
    "    (\"Algiers\", \"Algeria\"),\n",
    "    (\"Addis Ababa\", \"Ethiopia\"),\n",
    "    (\"Nairobi\", \"Kenya\"),\n",
    "    (\"Accra\", \"Ghana\"),\n",
    "    (\"Kampala\", \"Uganda\"),\n",
    "    (\"Harare\", \"Zimbabwe\"),\n",
    "    (\"Kinshasa\", \"Democratic Republic of the Congo\"),\n",
    "    (\"Lusaka\", \"Zambia\"),\n",
    "    (\"Maputo\", \"Mozambique\"),\n",
    "    (\"San Francisco\", \"USA\"),\n",
    "    (\"Los Angeles\", \"USA\"),\n",
    "    (\"Chicago\", \"USA\"),\n",
    "    (\"Houston\", \"USA\"),\n",
    "    (\"Miami\", \"USA\"),\n",
    "    (\"Boston\", \"USA\"),\n",
    "    (\"Dallas\", \"USA\"),\n",
    "    (\"Seattle\", \"USA\"),\n",
    "    (\"Atlanta\", \"USA\"),\n",
    "    (\"Philadelphia\", \"USA\"),\n",
    "    (\"Denver\", \"USA\"),\n",
    "    (\"Phoenix\", \"USA\"),\n",
    "    (\"Montreal\", \"Canada\"),\n",
    "    (\"Vancouver\", \"Canada\"),\n",
    "    (\"Calgary\", \"Canada\"),\n",
    "    (\"Ottawa\", \"Canada\"),\n",
    "    (\"Quebec City\", \"Canada\"),\n",
    "    (\"Halifax\", \"Canada\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_2 = [\n",
    "    (\"New York\", \"USA\"),\n",
    "    (\"Los Angeles\", \"USA\"),\n",
    "    (\"Chicago\", \"USA\"),\n",
    "    (\"Houston\", \"USA\"),\n",
    "    (\"Miami\", \"USA\"),\n",
    "    (\"London\", \"United Kingdom\"),\n",
    "    (\"Manchester\", \"United Kingdom\"),\n",
    "    (\"Birmingham\", \"United Kingdom\"),\n",
    "    (\"Edinburgh\", \"United Kingdom\"),\n",
    "    (\"Glasgow\", \"United Kingdom\"),\n",
    "    (\"Toronto\", \"Canada\"),\n",
    "    (\"Vancouver\", \"Canada\"),\n",
    "    (\"Montreal\", \"Canada\"),\n",
    "    (\"Calgary\", \"Canada\"),\n",
    "    (\"Ottawa\", \"Canada\"),\n",
    "    (\"Sydney\", \"Australia\"),\n",
    "    (\"Melbourne\", \"Australia\"),\n",
    "    (\"Brisbane\", \"Australia\"),\n",
    "    (\"Perth\", \"Australia\"),\n",
    "    (\"Adelaide\", \"Australia\"),\n",
    "    (\"Paris\", \"France\"),\n",
    "    (\"Marseille\", \"France\"),\n",
    "    (\"Lyon\", \"France\"),\n",
    "    (\"Toulouse\", \"France\"),\n",
    "    (\"Nice\", \"France\"),\n",
    "    (\"Berlin\", \"Germany\"),\n",
    "    (\"Munich\", \"Germany\"),\n",
    "    (\"Frankfurt\", \"Germany\"),\n",
    "    (\"Hamburg\", \"Germany\"),\n",
    "    (\"Cologne\", \"Germany\"),\n",
    "    (\"Madrid\", \"Spain\"),\n",
    "    (\"Barcelona\", \"Spain\"),\n",
    "    (\"Valencia\", \"Spain\"),\n",
    "    (\"Seville\", \"Spain\"),\n",
    "    (\"Bilbao\", \"Spain\"),\n",
    "    (\"Rome\", \"Italy\"),\n",
    "    (\"Milan\", \"Italy\"),\n",
    "    (\"Naples\", \"Italy\"),\n",
    "    (\"Turin\", \"Italy\"),\n",
    "    (\"Florence\", \"Italy\"),\n",
    "    (\"Tokyo\", \"Japan\"),\n",
    "    (\"Osaka\", \"Japan\"),\n",
    "    (\"Kyoto\", \"Japan\"),\n",
    "    (\"Nagoya\", \"Japan\"),\n",
    "    (\"Sapporo\", \"Japan\"),\n",
    "    (\"Beijing\", \"China\"),\n",
    "    (\"Shanghai\", \"China\"),\n",
    "    (\"Shenzhen\", \"China\"),\n",
    "    (\"Guangzhou\", \"China\"),\n",
    "    (\"Chengdu\", \"China\"),\n",
    "    (\"Moscow\", \"Russia\"),\n",
    "    (\"Saint Petersburg\", \"Russia\"),\n",
    "    (\"Novosibirsk\", \"Russia\"),\n",
    "    (\"Yekaterinburg\", \"Russia\"),\n",
    "    (\"Kazan\", \"Russia\"),\n",
    "    (\"São Paulo\", \"Brazil\"),\n",
    "    (\"Rio de Janeiro\", \"Brazil\"),\n",
    "    (\"Brasília\", \"Brazil\"),\n",
    "    (\"Salvador\", \"Brazil\"),\n",
    "    (\"Fortaleza\", \"Brazil\"),\n",
    "    (\"Buenos Aires\", \"Argentina\"),\n",
    "    (\"Córdoba\", \"Argentina\"),\n",
    "    (\"Rosario\", \"Argentina\"),\n",
    "    (\"Mendoza\", \"Argentina\"),\n",
    "    (\"La Plata\", \"Argentina\"),\n",
    "    (\"Mexico City\", \"Mexico\"),\n",
    "    (\"Guadalajara\", \"Mexico\"),\n",
    "    (\"Monterrey\", \"Mexico\"),\n",
    "    (\"Puebla\", \"Mexico\"),\n",
    "    (\"Tijuana\", \"Mexico\"),\n",
    "    (\"Bangkok\", \"Thailand\"),\n",
    "    (\"Chiang Mai\", \"Thailand\"),\n",
    "    (\"Phuket\", \"Thailand\"),\n",
    "    (\"Pattaya\", \"Thailand\"),\n",
    "    (\"Ayutthaya\", \"Thailand\"),\n",
    "    (\"Delhi\", \"India\"),\n",
    "    (\"Mumbai\", \"India\"),\n",
    "    (\"Bangalore\", \"India\"),\n",
    "    (\"Kolkata\", \"India\"),\n",
    "    (\"Chennai\", \"India\"),\n",
    "    (\"Seoul\", \"South Korea\"),\n",
    "    (\"Busan\", \"South Korea\"),\n",
    "    (\"Incheon\", \"South Korea\"),\n",
    "    (\"Daegu\", \"South Korea\"),\n",
    "    (\"Daejeon\", \"South Korea\"),\n",
    "    (\"Istanbul\", \"Turkey\"),\n",
    "    (\"Ankara\", \"Turkey\"),\n",
    "    (\"Izmir\", \"Turkey\"),\n",
    "    (\"Bursa\", \"Turkey\"),\n",
    "    (\"Antalya\", \"Turkey\"),\n",
    "    (\"Cairo\", \"Egypt\"),\n",
    "    (\"Alexandria\", \"Egypt\"),\n",
    "    (\"Giza\", \"Egypt\"),\n",
    "    (\"Luxor\", \"Egypt\"),\n",
    "    (\"Aswan\", \"Egypt\"),\n",
    "    (\"Johannesburg\", \"South Africa\"),\n",
    "    (\"Cape Town\", \"South Africa\"),\n",
    "    (\"Durban\", \"South Africa\"),\n",
    "    (\"Pretoria\", \"South Africa\"),\n",
    "    (\"Port Elizabeth\", \"South Africa\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_3 = [\n",
    "    (\"New York\", \"USA\"),\n",
    "    (\"Los Angeles\", \"USA\"),\n",
    "    (\"Chicago\", \"USA\"),\n",
    "    (\"Miami\", \"USA\"),\n",
    "    (\"San Francisco\", \"USA\"),\n",
    "    (\"London\", \"United Kingdom\"),\n",
    "    (\"Manchester\", \"United Kingdom\"),\n",
    "    (\"Birmingham\", \"United Kingdom\"),\n",
    "    (\"Edinburgh\", \"United Kingdom\"),\n",
    "    (\"Glasgow\", \"United Kingdom\"),\n",
    "    (\"Toronto\", \"Canada\"),\n",
    "    (\"Vancouver\", \"Canada\"),\n",
    "    (\"Montreal\", \"Canada\"),\n",
    "    (\"Calgary\", \"Canada\"),\n",
    "    (\"Ottawa\", \"Canada\"),\n",
    "    (\"Sydney\", \"Australia\"),\n",
    "    (\"Melbourne\", \"Australia\"),\n",
    "    (\"Brisbane\", \"Australia\"),\n",
    "    (\"Perth\", \"Australia\"),\n",
    "    (\"Adelaide\", \"Australia\"),\n",
    "    (\"Paris\", \"France\"),\n",
    "    (\"Marseille\", \"France\"),\n",
    "    (\"Lyon\", \"France\"),\n",
    "    (\"Nice\", \"France\"),\n",
    "    (\"Toulouse\", \"France\"),\n",
    "    (\"Berlin\", \"Germany\"),\n",
    "    (\"Munich\", \"Germany\"),\n",
    "    (\"Frankfurt\", \"Germany\"),\n",
    "    (\"Hamburg\", \"Germany\"),\n",
    "    (\"Cologne\", \"Germany\"),\n",
    "    (\"Madrid\", \"Spain\"),\n",
    "    (\"Barcelona\", \"Spain\"),\n",
    "    (\"Valencia\", \"Spain\"),\n",
    "    (\"Seville\", \"Spain\"),\n",
    "    (\"Bilbao\", \"Spain\"),\n",
    "    (\"Rome\", \"Italy\"),\n",
    "    (\"Milan\", \"Italy\"),\n",
    "    (\"Venice\", \"Italy\"),\n",
    "    (\"Florence\", \"Italy\"),\n",
    "    (\"Naples\", \"Italy\"),\n",
    "    (\"Tokyo\", \"Japan\"),\n",
    "    (\"Osaka\", \"Japan\"),\n",
    "    (\"Kyoto\", \"Japan\"),\n",
    "    (\"Yokohama\", \"Japan\"),\n",
    "    (\"Sapporo\", \"Japan\"),\n",
    "    (\"Beijing\", \"China\"),\n",
    "    (\"Shanghai\", \"China\"),\n",
    "    (\"Hong Kong\", \"China\"),\n",
    "    (\"Shenzhen\", \"China\"),\n",
    "    (\"Guangzhou\", \"China\"),\n",
    "    (\"Moscow\", \"Russia\"),\n",
    "    (\"Saint Petersburg\", \"Russia\"),\n",
    "    (\"Sochi\", \"Russia\"),\n",
    "    (\"Yekaterinburg\", \"Russia\"),\n",
    "    (\"Novosibirsk\", \"Russia\"),\n",
    "    (\"São Paulo\", \"Brazil\"),\n",
    "    (\"Rio de Janeiro\", \"Brazil\"),\n",
    "    (\"Brasília\", \"Brazil\"),\n",
    "    (\"Salvador\", \"Brazil\"),\n",
    "    (\"Fortaleza\", \"Brazil\"),\n",
    "    (\"Buenos Aires\", \"Argentina\"),\n",
    "    (\"Córdoba\", \"Argentina\"),\n",
    "    (\"Rosario\", \"Argentina\"),\n",
    "    (\"Mendoza\", \"Argentina\"),\n",
    "    (\"La Plata\", \"Argentina\"),\n",
    "    (\"Mexico City\", \"Mexico\"),\n",
    "    (\"Guadalajara\", \"Mexico\"),\n",
    "    (\"Monterrey\", \"Mexico\"),\n",
    "    (\"Puebla\", \"Mexico\"),\n",
    "    (\"Cancún\", \"Mexico\"),\n",
    "    (\"Bangkok\", \"Thailand\"),\n",
    "    (\"Chiang Mai\", \"Thailand\"),\n",
    "    (\"Phuket\", \"Thailand\"),\n",
    "    (\"Pattaya\", \"Thailand\"),\n",
    "    (\"Ayutthaya\", \"Thailand\"),\n",
    "    (\"Delhi\", \"India\"),\n",
    "    (\"Mumbai\", \"India\"),\n",
    "    (\"Bangalore\", \"India\"),\n",
    "    (\"Kolkata\", \"India\"),\n",
    "    (\"Chennai\", \"India\"),\n",
    "    (\"Seoul\", \"South Korea\"),\n",
    "    (\"Busan\", \"South Korea\"),\n",
    "    (\"Incheon\", \"South Korea\"),\n",
    "    (\"Daegu\", \"South Korea\"),\n",
    "    (\"Daejeon\", \"South Korea\"),\n",
    "    (\"Istanbul\", \"Turkey\"),\n",
    "    (\"Ankara\", \"Turkey\"),\n",
    "    (\"Izmir\", \"Turkey\"),\n",
    "    (\"Bursa\", \"Turkey\"),\n",
    "    (\"Antalya\", \"Turkey\"),\n",
    "    (\"Cairo\", \"Egypt\"),\n",
    "    (\"Alexandria\", \"Egypt\"),\n",
    "    (\"Giza\", \"Egypt\"),\n",
    "    (\"Luxor\", \"Egypt\"),\n",
    "    (\"Aswan\", \"Egypt\"),\n",
    "    (\"Johannesburg\", \"South Africa\"),\n",
    "    (\"Cape Town\", \"South Africa\"),\n",
    "    (\"Durban\", \"South Africa\"),\n",
    "    (\"Pretoria\", \"South Africa\"),\n",
    "    (\"Nairobi\", \"Kenya\"),\n",
    "    (\"Dubai\", \"United Arab Emirates\"),\n",
    "    (\"Abu Dhabi\", \"United Arab Emirates\"),\n",
    "    (\"Doha\", \"Qatar\"),\n",
    "    (\"Singapore\", \"Singapore\"),\n",
    "    (\"Kuala Lumpur\", \"Malaysia\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_cities_ds = load_from_disk(f\"{vars.DATA_DIR}/debug_meta_train/common_country_data/common_cities_generation.hf\")\n",
    "\n",
    "city_country_pairs = []\n",
    "for i in range(len(common_cities_ds)):\n",
    "    datum = common_cities_ds[i]\n",
    "    for city in datum[\"cities\"]:\n",
    "        city = city.replace(\"` tags:\\n\\n<city>\", \"\")\n",
    "        city = city.replace(\"tags:\\n\\n<city>\", \"\")\n",
    "        city = city.replace(\"tag:\\n\\n<city>\", \"\")\n",
    "        city = city.replace(\"` tags:\\n\\n```xml\\n<city>\", \"\")\n",
    "        city_country_pairs.append((city, datum[\"country\"]))\n",
    "\n",
    "city_country_pairs = list(set(cities_1 + cities_2 + cities_3 + city_country_pairs))\n",
    "\n",
    "new_city_country_pairs = []\n",
    "# fix name\n",
    "\n",
    "for city, country in city_country_pairs:\n",
    "    if country == \"USA\":\n",
    "        country = \"United States\"\n",
    "\n",
    "    new_city_country_pairs.append((city.strip(), country.strip()))\n",
    "\n",
    "new_city_country_pairs = list(set(new_city_country_pairs))\n",
    "len(new_city_country_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_city_country_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data = []\n",
    "for city, country in new_city_country_pairs:\n",
    "    sft_data.append({\n",
    "        \"question\": f\"What country is {city.strip()} in?\",\n",
    "        \"answer\": country.strip(),\n",
    "        \"(city, country)\": (city.strip(), country.strip()),\n",
    "    })\n",
    "\n",
    "    \n",
    "n_data = len(sft_data)\n",
    "n_dev = 50\n",
    "n_train = n_data - n_dev\n",
    "\n",
    "rand_shuffle = np.arange(n_data)\n",
    "np.random.shuffle(rand_shuffle)\n",
    "\n",
    "train_data = [sft_data[i] for i in rand_shuffle[:n_train]]\n",
    "dev_data = [sft_data[i] for i in rand_shuffle[n_train:]]\n",
    "\n",
    "# io.dump_jsonlines(train_data, f\"{vars.DATA_DIR}/debug_meta_train/common_country_data/train.jsonl\")\n",
    "# io.dump_jsonlines(dev_data, f\"{vars.DATA_DIR}/debug_meta_train/common_country_data/valid.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta-training data for country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_train_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/common_country_data/valid.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_country_pairs = [d[\"(city, country)\"] for d in country_train_data]\n",
    "len(city_country_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcity_country_pairs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBelfast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIreland\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(city_country_pairs)\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# city_country_pairs.remove(['Belfast', 'Ireland'])\n",
    "# len(city_country_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_countries = set([cc[1] for cc in city_country_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "city2countries = dict(city_country_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(f\"{vars.DATA_DIR}/debug_meta_train/common_country_data/continent_generation_valid.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "country2continent = dict(zip(ds[\"country\"], ds[\"continent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Saudi Arabia': 'Asia',\n",
       " 'South Korea': 'Asia',\n",
       " 'Argentina': 'South America',\n",
       " 'Chile': 'South America',\n",
       " 'Georgia': 'Asia',\n",
       " 'Ireland': 'Europe',\n",
       " 'Singapore': 'Asia',\n",
       " 'Vietnam': 'Asia',\n",
       " 'Oman': 'Asia',\n",
       " 'Italy': 'Europe',\n",
       " 'Qatar': 'Asia',\n",
       " 'Finland': 'Europe',\n",
       " 'Austria': 'Europe',\n",
       " 'Netherlands': 'Europe',\n",
       " 'United States': 'North America',\n",
       " 'Russia': 'Eurasia',\n",
       " 'Ukraine': 'Europe',\n",
       " 'Philippines': 'Asia',\n",
       " 'Sweden': 'Europe',\n",
       " 'Norway': 'Europe',\n",
       " 'New Zealand': 'Oceania',\n",
       " 'Malaysia': 'Asia',\n",
       " 'Switzerland': 'Europe',\n",
       " 'Czech Republic': 'Europe',\n",
       " 'Bangladesh': 'Asia',\n",
       " 'Kenya': 'Africa',\n",
       " 'Pakistan': 'Asia',\n",
       " 'Romania': 'Europe',\n",
       " 'Canada': 'North America',\n",
       " 'South Africa': 'Africa',\n",
       " 'Poland': 'Europe'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country2continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country2continent[\"Australia\"] = \"Oceania\"\n",
    "country2continent[\"Russia\"] = \"Europe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Europe': 13,\n",
       "         'Asia': 11,\n",
       "         'South America': 2,\n",
       "         'North America': 2,\n",
       "         'Africa': 2,\n",
       "         'Oceania': 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [k for k, v in country2continent.items() if v == \"Australia\"]\n",
    "from collections import Counter\n",
    "Counter(country2continent.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(city_country[1] for city_country in city_country_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_json(city_country_pairs, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/city_country_pairs_valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_json(country2continent, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/country2continent_valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(country2continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "country_events = [\n",
    "    \"was {first_name} {last_name} born in\",\n",
    "    \"did {first_name} {last_name} worked in\",\n",
    "    \"did {first_name} {last_name} die in\",\n",
    "]\n",
    "country_templates = [\n",
    "    (\"Which country\" + \" \" + country_events[0] + \"?\", lambda *c: city2countries[c[0]]),\n",
    "    (\"Which country\" + \" \" + country_events[1] + \"?\", lambda *c: city2countries[c[1]]),\n",
    "    (\"Which country\" + \" \" + country_events[2] + \"?\", lambda *c: city2countries[c[2]]),\n",
    "]\n",
    "continent_templates = [\n",
    "    (\"Which continent\" + \" \" + country_events[0] + \"?\", lambda *c: country2continent[city2countries[c[0]]]),\n",
    "    (\"Which continent\" + \" \" + country_events[1] + \"?\", lambda *c: country2continent[city2countries[c[1]]]),\n",
    "    (\"Which continent\" + \" \" + country_events[2] + \"?\", lambda *c: country2continent[city2countries[c[2]]]),\n",
    "]\n",
    "\n",
    "compare_city_templates = [\n",
    "    (\"Was {first_name} {last_name} born and died in the same city?\", lambda b_c, c_c, d_c: \"Yes\" if b_c == d_c else \"No\"),\n",
    "    (\"Was {first_name} {last_name} born and worked in the same city?\", lambda b_c, c_c, d_c: \"Yes\" if b_c == c_c else \"No\"),\n",
    "    (\"Did {first_name} {last_name} work and die in the same city?\", lambda b_c, c_c, d_c: \"Yes\" if c_c == d_c else \"No\"),\n",
    "]\n",
    "\n",
    "\n",
    "compare_country_templates = [\n",
    "    (\"Was {first_name} {last_name} born and died in the same country?\", lambda b_c, c_c, d_c: \"Yes\" if city2countries[b_c] == city2countries[d_c] else \"No\"),\n",
    "    (\"Was {first_name} {last_name} born and worked in the same country?\", lambda b_c, c_c, d_c: \"Yes\" if city2countries[b_c] == city2countries[c_c] else \"No\"),\n",
    "    (\"Did {first_name} {last_name} work and die in the same country?\", lambda b_c, c_c, d_c: \"Yes\" if city2countries[c_c] == city2countries[d_c] else \"No\"),\n",
    "]\n",
    "\n",
    "compare_continent_templates = [\n",
    "    (\"Was {first_name} {last_name} born and died in the same continent?\", lambda b_c, c_c, d_c: \"Yes\" if country2continent[city2countries[b_c]] == country2continent[city2countries[d_c]] else \"No\"),\n",
    "    (\"Was {first_name} {last_name} born and worked in the same continent?\", lambda b_c, c_c, d_c: \"Yes\" if country2continent[city2countries[b_c]] == country2continent[city2countries[c_c]] else \"No\"),\n",
    "    (\"Did {first_name} {last_name} work and die in the same continent?\", lambda b_c, c_c, d_c: \"Yes\" if country2continent[city2countries[c_c]] == country2continent[city2countries[d_c]] else \"No\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_template = \"{first_name} {last_name} was born in {birth_place}. {gender_start} started and completed a career of {career} in {career_place}. After retirement, {gender} moved to {death_place} and passed away.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set([c for c, _ in city_country_pairs])) == len(list([c for c, _ in city_country_pairs]))\n",
    "# all_cities = [x[0] for x in city_country_pairs]\n",
    "# [x for x in all_cities if all_cities.count(x) > 1]\n",
    "# [x for x in city_country_pairs if x[0] == \"Belfast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rajshahi', 'Bangladesh'],\n",
       " ['Naples', 'Italy'],\n",
       " ['Sylhet', 'Bangladesh'],\n",
       " ['Marina Bay', 'Singapore'],\n",
       " ['Waterford', 'Ireland'],\n",
       " ['Khobar', 'Saudi Arabia'],\n",
       " ['San Jose', 'United States'],\n",
       " ['Pardubice', 'Czech Republic'],\n",
       " ['Sankt Pölten', 'Austria'],\n",
       " ['Bucharest', 'Romania'],\n",
       " ['Chinatown', 'Singapore'],\n",
       " ['Hoi An', 'Vietnam'],\n",
       " ['Valparaíso', 'Chile'],\n",
       " ['Johor Bahru', 'Malaysia'],\n",
       " ['Temuco', 'Chile'],\n",
       " ['Cape Town', 'South Africa'],\n",
       " ['Sialkot', 'Pakistan'],\n",
       " ['Orchard Road', 'Singapore'],\n",
       " ['Medina', 'Saudi Arabia'],\n",
       " ['Talca', 'Chile'],\n",
       " ['Winnipeg', 'Canada'],\n",
       " ['Salta', 'Argentina'],\n",
       " ['Changwon', 'South Korea'],\n",
       " ['Novosibirsk', 'Russia'],\n",
       " ['Helsingborg', 'Sweden'],\n",
       " ['Lausanne', 'Switzerland'],\n",
       " ['Nakuru', 'Kenya'],\n",
       " ['Tbilisi', 'Georgia'],\n",
       " ['Kraków', 'Poland'],\n",
       " ['Gothenburg', 'Sweden'],\n",
       " ['Barisal', 'Bangladesh'],\n",
       " ['Dunedin', 'New Zealand'],\n",
       " ['Da Lat', 'Vietnam'],\n",
       " ['East London', 'South Africa'],\n",
       " ['Haarlem', 'Netherlands'],\n",
       " ['Makati', 'Philippines'],\n",
       " ['Tampere', 'Finland'],\n",
       " ['Siena', 'Italy'],\n",
       " ['Concepción', 'Chile'],\n",
       " ['Muscat', 'Oman'],\n",
       " ['Bloemfontein', 'South Africa'],\n",
       " ['Parañaque', 'Philippines'],\n",
       " ['Dammam', 'Saudi Arabia'],\n",
       " ['New York', 'United States'],\n",
       " ['Doha', 'Qatar'],\n",
       " ['Kyiv', 'Ukraine'],\n",
       " ['Phoenix', 'United States'],\n",
       " ['Fredrikstad', 'Norway'],\n",
       " ['Kimberley', 'South Africa'],\n",
       " ['Port Elizabeth', 'South Africa']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_country_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.99999999999999"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000 * 0.3**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 99650/100000 [00:15<00:00, 5113.89it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "n_data = 100000\n",
    "\n",
    "tuples = set()\n",
    "\n",
    "syn_data = []\n",
    "\n",
    "pbar = tqdm(total = n_data)\n",
    "\n",
    "change_loc_probability = 0.3\n",
    "\n",
    "\n",
    "while len(syn_data) < n_data:\n",
    "    \n",
    "    first_name = np.random.choice(first_names)\n",
    "    last_name = np.random.choice(last_names)\n",
    "\n",
    "    gender = np.random.choice(genders)\n",
    "    career = np.random.choice(careers)\n",
    "    \n",
    "    birth_cc = city_country_pairs[np.random.choice(len(city_country_pairs))]\n",
    "    if np.random.rand() < change_loc_probability:\n",
    "        career_cc = birth_cc\n",
    "    else:\n",
    "        career_cc = city_country_pairs[np.random.choice(len(city_country_pairs))]\n",
    "    \n",
    "    if np.random.rand() < change_loc_probability:\n",
    "        death_cc = career_cc\n",
    "    else:\n",
    "        death_cc = city_country_pairs[np.random.choice(len(city_country_pairs))]\n",
    "    \n",
    "    birth_ccc = (*birth_cc, country2continent[birth_cc[1]])\n",
    "    career_ccc = (*career_cc, country2continent[career_cc[1]])\n",
    "    death_ccc = (*death_cc, country2continent[death_cc[1]])\n",
    "    \n",
    "    info_tuple = (first_name, last_name, birth_ccc[0], career_ccc[0], gender, career, death_ccc[0])\n",
    "    \n",
    "    if info_tuple not in tuples:\n",
    "        tuples.add(info_tuple)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    text = text_template.format(\n",
    "        first_name=first_name,\n",
    "        last_name=last_name,\n",
    "        birth_place=birth_ccc[0],\n",
    "        gender=gender,\n",
    "        gender_start=gender.capitalize(),\n",
    "        career=career,\n",
    "        career_place=career_ccc[0],\n",
    "        death_place=death_ccc[0],\n",
    "    )\n",
    "    \n",
    "    questions = []\n",
    "    for template_name, templates in [\n",
    "        (\"country\", country_templates), \n",
    "        (\"continent\", continent_templates), \n",
    "        (\"compare-city\", compare_city_templates),\n",
    "        (\"compare-country\", compare_country_templates),\n",
    "        (\"compare-continent\", compare_continent_templates), \n",
    "    ]:\n",
    "        \n",
    "        rand_idx = np.random.choice(range(len(templates)))\n",
    "        \n",
    "        question_template, answer_fn = templates[rand_idx]\n",
    "    \n",
    "        question = question_template.format(\n",
    "            first_name=first_name,\n",
    "            last_name=last_name,\n",
    "            career=career,\n",
    "            gender=gender\n",
    "        )\n",
    "        answer = answer_fn(birth_ccc[0], career_ccc[0], death_ccc[0])\n",
    "        questions.append(\n",
    "            {\n",
    "                \"question_type\": template_name,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer\n",
    "            }\n",
    "        )\n",
    "    syn_data.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"questions\": questions\n",
    "        }\n",
    "    )\n",
    "    pbar.update(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russia'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city2countries[\"Volgograd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finland'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city2countries[\"Lappeenranta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Portugal'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city2countries[\"Lisbon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:29<00:00, 5113.89it/s]"
     ]
    }
   ],
   "source": [
    "n_test = 100\n",
    "n_dev = 100\n",
    "n_train = n_data - n_test - n_dev\n",
    "\n",
    "rand_shuffle = np.arange(n_data)\n",
    "np.random.shuffle(rand_shuffle)\n",
    "\n",
    "train_data = [syn_data[i] for i in rand_shuffle[:n_train]]\n",
    "dev_data = [syn_data[i] for i in rand_shuffle[n_train:n_train+n_dev]]\n",
    "test_data = [syn_data[i] for i in rand_shuffle[n_train+n_dev:]]\n",
    "\n",
    "# io.dump_jsonlines(train_data, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/train.jsonl\")\n",
    "# io.dump_jsonlines(dev_data, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/valid.jsonl\")\n",
    "io.dump_jsonlines(test_data, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/test_ood.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the regex pattern\n",
    "pattern = r\"(?P<first_name>\\w+) (?P<last_name>\\w+) was born in (?P<birth_place>[\\w\\s,'.()-]+)\\. (?P<gender_start>\\w+) started and completed a career of (?P<career>[\\w\\s]+) in (?P<career_place>[\\w\\s,'.()-]+)\\. After retirement, (?P<gender>\\w+) moved to (?P<death_place>[\\w\\s,'.()-]+) and passed away\\.\"\n",
    "\n",
    "# Example function to extract information\n",
    "def extract_person_info_country(text):\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "# text = \"John Doe was born in New York City. He started and completed a career of engineering in California. After retirement, he moved to Florida and passed away.\"\n",
    "# info = extract_person_info(text)\n",
    "# print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_type2templates = dict([\n",
    "    (\"country\", country_templates), \n",
    "    (\"continent\", continent_templates), \n",
    "    (\"compare-city\", compare_city_templates),\n",
    "    (\"compare-country\", compare_country_templates),\n",
    "    (\"compare-continent\", compare_continent_templates), \n",
    "])\n",
    "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_ccc = (*birth_cc, country2continent[birth_cc[1]])\n",
    "career_ccc = (*career_cc, country2continent[career_cc[1]])\n",
    "death_ccc = (*death_cc, country2continent[death_cc[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Charlotte Scott was born in Puerto Montt. She started and completed a career of Lawyer in Chelyabinsk. After retirement, she moved to Chelyabinsk and passed away.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_info = extract_person_info_country(test_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = []\n",
    "\n",
    "for test_datum in test_data: \n",
    "    new_test_datum = deepcopy(test_datum)\n",
    "    syn_info = extract_person_info_country(test_datum[\"text\"])\n",
    "    \n",
    "    alternative_questions = []\n",
    "    # try:\n",
    "    birth_ccc = (syn_info[\"birth_place\"], city2countries[syn_info[\"birth_place\"]], country2continent[city2countries[syn_info[\"birth_place\"]]])\n",
    "    career_ccc = (syn_info[\"career_place\"], city2countries[syn_info[\"career_place\"]], country2continent[city2countries[syn_info[\"career_place\"]]])\n",
    "    death_ccc = (syn_info[\"death_place\"], city2countries[syn_info[\"death_place\"]], country2continent[city2countries[syn_info[\"death_place\"]]])\n",
    "    # except:\n",
    "    #     break\n",
    "    \n",
    "    for q in test_datum[\"questions\"]:\n",
    "        templates = template_type2templates[q[\"question_type\"]]\n",
    "        instantiated_templates = [\n",
    "            template[0].format(first_name=syn_info[\"first_name\"], last_name=syn_info[\"last_name\"], career=syn_info[\"career\"],gender=syn_info[\"gender\"])\n",
    "            for template in templates\n",
    "        ]\n",
    "        \n",
    "        assert len([e_i for e_i, t in enumerate(instantiated_templates) if q[\"question\"] in t]) == 1\n",
    "        assert len([e_i for e_i, t in enumerate(instantiated_templates) if q[\"question\"] not in t]) == 2\n",
    "        \n",
    "        alternative_template_ids = [e_i for e_i, t in enumerate(instantiated_templates) if q[\"question\"] not in t]\n",
    "        alternative_template_idx = np.random.choice(alternative_template_ids)\n",
    "        alternative_template = templates[alternative_template_idx]\n",
    "        alternative_questions.append(\n",
    "            {\n",
    "                \"question_type\": q[\"question_type\"],\n",
    "                \"question\": alternative_template[0].format(\n",
    "                    first_name=syn_info[\"first_name\"],\n",
    "                    last_name=syn_info[\"last_name\"],\n",
    "                    career=syn_info[\"career\"],\n",
    "                    gender=syn_info[\"gender\"],\n",
    "                ),\n",
    "                \"answer\": str(alternative_template[1](birth_ccc[0], career_ccc[0], death_ccc[0]))\n",
    "            }\n",
    "        )\n",
    "    new_test_datum[\"alternative_questions\"] = deepcopy(alternative_questions)\n",
    "    \n",
    "    np.random.shuffle(alternative_questions)\n",
    "    text_w_qas = test_datum[\"text\"] + \"\\n\\n\" + \"\\n\".join(f\"{q['question']} {q['answer']}\" for q in alternative_questions)\n",
    "    new_test_datum[\"text_w_qas\"] = text_w_qas\n",
    "    \n",
    "    new_test_data.append(new_test_datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlotte Scott was born in Puerto Montt. She started and completed a career of Lawyer in Chelyabinsk. After retirement, she moved to Chelyabinsk and passed away.\n",
      "\n",
      "Did Charlotte Scott work and die in the same country? Yes\n",
      "Was Charlotte Scott born and died in the same continent? No\n",
      "Which continent did Charlotte Scott die in? Europe\n",
      "Was Charlotte Scott born and worked in the same city? No\n",
      "Which country did Charlotte Scott worked in? Russia\n"
     ]
    }
   ],
   "source": [
    "print(new_test_data[0][\"text_w_qas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/border_countries.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country2countries_pairs = {}\n",
    "\n",
    "for i in range(len(ds)):\n",
    "    country = ds[i][\"country\"]\n",
    "    \n",
    "    border_countries = list(set(ds[i][\"bordering_countries\"]))\n",
    "    non_bordering_countries = list(set(ds[i][\"non_bordering_countries\"]))\n",
    "    \n",
    "    if len(border_countries) == 0 or len(non_bordering_countries) == 0:\n",
    "        continue\n",
    "    n_border_country = len(border_countries)\n",
    "    n_non_border_country = len(non_bordering_countries)\n",
    "    \n",
    "    n_country = min(n_border_country, n_non_border_country)\n",
    "    country2countries_pairs[country] = {\n",
    "        \"border\": border_countries[:n_country], \n",
    "        \"non_border\": non_bordering_countries[:n_country]\n",
    "    }\n",
    "len(country2countries_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_json(country2countries_pairs, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/country2countries_pairs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ood_country_events = [\n",
    "    \"{first_name} {last_name} was born\",\n",
    "    \"{first_name} {last_name} worked in\",\n",
    "    \"{first_name} {last_name} died in\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is {country} bordering with country where {first_name} {last_name} was born?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Is {country} bordering with country where \" + ood_country_events[0] + \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = []\n",
    "\n",
    "for test_datum in test_data[:]: \n",
    "    new_test_datum = deepcopy(test_datum)\n",
    "    syn_info = extract_person_info_country(test_datum[\"text\"])\n",
    "    \n",
    "    alternative_questions = []\n",
    "    # try:\n",
    "    birth_ccc = (syn_info[\"birth_place\"], city2countries[syn_info[\"birth_place\"]], country2continent[city2countries[syn_info[\"birth_place\"]]])\n",
    "    career_ccc = (syn_info[\"career_place\"], city2countries[syn_info[\"career_place\"]], country2continent[city2countries[syn_info[\"career_place\"]]])\n",
    "    death_ccc = (syn_info[\"death_place\"], city2countries[syn_info[\"death_place\"]], country2continent[city2countries[syn_info[\"death_place\"]]])\n",
    "    \n",
    "    ood_qs = []\n",
    "    \n",
    "    for i, ccc in enumerate([birth_ccc, career_ccc, death_ccc]):\n",
    "        \n",
    "        if ccc[1] not in country2countries_pairs:\n",
    "            continue\n",
    "        \n",
    "        border_countries = country2countries_pairs[ccc[1]][\"border\"]\n",
    "        non_border_countries = country2countries_pairs[ccc[1]][\"non_border\"]\n",
    "        ood_birth_template = \"Is {country} bordering with country where \" + ood_country_events[i] + \"?\"\n",
    "        for b, nb in zip(border_countries, non_border_countries):\n",
    "            \n",
    "            b_q = ood_birth_template.format(first_name=syn_info[\"first_name\"], last_name=syn_info[\"last_name\"], country=b)\n",
    "            nb_q = ood_birth_template.format(first_name=syn_info[\"first_name\"], last_name=syn_info[\"last_name\"], country=nb)\n",
    "            ood_qs.append({\"question\": b_q, \"answer\": \"Yes\", \"question_type\": \"border\"})\n",
    "            ood_qs.append({\"question\": nb_q, \"answer\": \"No\", \"question_type\": \"non_border\"})\n",
    "    \n",
    "    new_test_datum[\"ood_questions\"] = deepcopy(ood_qs)\n",
    "    new_test_data.append(new_test_datum)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x[\"ood_questions\"]) for x in new_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/debug_meta_train/country_syn_data/test_ood.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
