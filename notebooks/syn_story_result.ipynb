{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "import pandas as pd\n",
            "# from experiments.musique.inference_only import macro_averaging\n",
            "# from knowledge_propagation.utils import io, vars, extractor\n",
            "import os\n",
            "import numpy as np\n",
            "from tqdm import tqdm\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n",
            "from glob import glob\n",
            "from scipy.stats import describe\n",
            "# from thefuzz import fuzz\n",
            "# from knowledge_propagation.utils.eval import is_significantly_different\n",
            "from collections import Counter\n",
            "from knowledge_propagation.utils import io, vars\n",
            "# from knowledge_propagation.modules.evaluators import (\n",
            "#     ExactMatchEvaluator,\n",
            "#     RougeEvaluator,\n",
            "#     OpenAIEvaluator,\n",
            "# )\n",
            "# llm_evaluator = OpenAIEvaluator()\n",
            "from typing import List, Dict, Tuple\n",
            "\n",
            "os.getcwd()\n",
            "def macro_averaging(df: pd.DataFrame, metrics: List[str], multi_level_averaging: List[str]):\n",
            "    \"\"\"\n",
            "    Do macro-averaging over the given metrics and multi-level averaging categories.\n",
            "    \"\"\"\n",
            "    extracted_multi_level_cols = [[m, \"mean\"] for m in metrics]\n",
            "    while len(multi_level_averaging) > 0:\n",
            "        # first take the mean over each generation,\n",
            "        # and, only take `mean` of `rouge1` and  `llm_accuracy` column groups\n",
            "        df_over_cols = df.groupby(multi_level_averaging, observed=True).describe()[extracted_multi_level_cols]\n",
            "        # remove the multi-level column indices, since there's only one sub-level -- \"mean\"\n",
            "        df_over_cols.columns = df_over_cols.columns.get_level_values(0)\n",
            "\n",
            "        # reset index to flatten the multi-level column indices for the next macro-averaging class\n",
            "        df = df_over_cols.reset_index(inplace=False)\n",
            "        multi_level_averaging.pop(-1)\n",
            "    return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "fpath = \"/u/zliu/datastor1/RLEdit/results/cre_llama-3.2-base-qa_rledit_5_2_ep800/test_id_results.xlsx\"\n",
            "df1 = pd.read_excel(fpath)\n",
            "# df2 = pd.read_excel(\"/u/zliu/datastor1/mend/synstory_exp_output/qwen2.5-1.5B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 230,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 4K_test_id\n",
            "# val_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/syn_data_neurips/4Ktrain_data_100percent_frozen/test_text_data_id_entity152_rel31.jsonl\")\n",
            "# 4K_test_ood-entity\n",
            "# val_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/syn_data_neurips/4Ktrain_data_100percent_frozen/test_text_data_ood-entity_entity37_rel31.jsonl\")\n",
            "# 4K_test_ood-relation\n",
            "val_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/syn_data_neurips/4Ktrain_data_100percent_frozen/test_text_data_ood-relation_entity152_rel7.jsonl\")\n",
            "# 4K_test_ood\n",
            "# val_data = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/syn_data_neurips/4Ktrain_data_100percent_frozen/test_text_data_ood_entity37_rel7.jsonl\")\n",
            "\n",
            "questions = []\n",
            "for datum in val_data:\n",
            "    for question_type, test_queries in [(\"efficacy\", datum[\"questions\"]),]:\n",
            "        for question_key in [\"alias_question\", \"unalias_question\"][:]:\n",
            "            for q_i, test_query in enumerate(test_queries):\n",
            "                questions.append(test_query[question_key])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 231,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "      <th>question_key</th>\n",
                     "      <th>question_type</th>\n",
                     "      <th>stage</th>\n",
                     "      <th>input</th>\n",
                     "      <th>question</th>\n",
                     "      <th>answer</th>\n",
                     "      <th>predicted_answer_idx</th>\n",
                     "      <th>predicted_answer</th>\n",
                     "      <th>exact_match</th>\n",
                     "      <th>llm_accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[Imagine that someone named James King develo...</td>\n",
                     "      <td>When did the event that James King curated an ...</td>\n",
                     "      <td>1850–1864</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1860s</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.7</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>0</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[Imagine that someone named James King develo...</td>\n",
                     "      <td>What year did the event that sparked James Kin...</td>\n",
                     "      <td>1963</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1864</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.0</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "   id    question_key question_type     stage  \\\n",
                     "0   0  alias_question      efficacy  pre-edit   \n",
                     "1   0  alias_question      efficacy  pre-edit   \n",
                     "\n",
                     "                                               input  \\\n",
                     "0  [[Imagine that someone named James King develo...   \n",
                     "1  [[Imagine that someone named James King develo...   \n",
                     "\n",
                     "                                            question     answer  \\\n",
                     "0  When did the event that James King curated an ...  1850–1864   \n",
                     "1  What year did the event that sparked James Kin...       1963   \n",
                     "\n",
                     "   predicted_answer_idx predicted_answer  exact_match  llm_accuracy  \n",
                     "0                     0            1860s            0           0.7  \n",
                     "1                     0             1864            0           0.0  "
                  ]
               },
               "execution_count": 231,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "for i, question in enumerate(questions):\n",
            "    assert question in df1.iloc[i][\"question\"]\n",
            "df1[\"question\"] = questions\n",
            "df1.head(2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 232,
         "metadata": {},
         "outputs": [],
         "source": [
            "df1.to_excel(fpath, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 74,
         "metadata": {},
         "outputs": [],
         "source": [
            "spotcheck_data = io.load_jsonlines(\"/home/zliu/zliu/KE-by-CP/data/debug_meta_train/syn_data_neurips/4Ktrain_data_100percent_active-reading-aug/test_id.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 75,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'entity_type': 'Event',\n",
                     " 'entity_names': ['The Assassination of Julius Caesar',\n",
                     "  'The Surrender of Japan in WWII',\n",
                     "  'The Execution of King Louis XVI'],\n",
                     " 'subject': 'Morgan Dynamics Corp.',\n",
                     " 'gender_type': 'it',\n",
                     " 'text': 'Morgan Dynamics Corp. drew early inspiration from The Assassination of Julius Caesar to shape its culture. Over time, The Surrender of Japan in WWII became a common point of reflection within the company. Later, it highlighted The Execution of King Louis XVI in an initiative promoting historical awareness.',\n",
                     " 'questions': [{'question_template': 'In which country did {event} happen?',\n",
                     "   'alias_question': 'In which country did the event that Morgan Dynamics Corp. commonly reflected on happen?',\n",
                     "   'unalias_question': 'In which country did The Surrender of Japan in WWII happen?',\n",
                     "   'alias_question_paraphrase': 'Where did the event that Morgan Dynamics Corp. commonly reflected on take place?',\n",
                     "   'unalias_question_paraphrase': 'Where did The Surrender of Japan in WWII take place?',\n",
                     "   'entity_name': 'The Surrender of Japan in WWII',\n",
                     "   'answer': 'Japan',\n",
                     "   'fact_idx': 1},\n",
                     "  {'question_template': 'Who was the most important leader or figure involved in {event}?',\n",
                     "   'alias_question': 'Who was the most important leader or figure involved in the event that Morgan Dynamics Corp. commonly reflected on?',\n",
                     "   'unalias_question': 'Who was the most important leader or figure involved in The Surrender of Japan in WWII?',\n",
                     "   'alias_question_paraphrase': 'Who was the most significant leader or figure involved in the event that Morgan Dynamics Corp. commonly reflected on?',\n",
                     "   'unalias_question_paraphrase': 'Who was the most significant leader or figure involved in The Surrender of Japan in WWII?',\n",
                     "   'entity_name': 'The Surrender of Japan in WWII',\n",
                     "   'answer': 'Emperor Hirohito',\n",
                     "   'fact_idx': 1}],\n",
                     " 'subject_type': 'company',\n",
                     " 'augmented_texts': ['Leah Bailey was born in Malaysia. He spent most of his adult life in Germany. After retirement, he lived in Greece and passed away.',\n",
                     "  'Three-step timeline:\\n\\n1) Born in Malaysia.\\n2) Spent most of his adult life in Germany.\\n3) After retirement, lived in Greece and passed away.\\n\\nNote: The document uses the name Leah Bailey but the pronoun \"he,\" indicating a pronoun inconsistency.',\n",
                     "  'Applying the path visualization (birth → adult life → retirement) to the document:\\n\\n- Geographic path based on the text: Malaysia → Germany → Greece.\\n- On a world map, picture:\\n  - Pin in Malaysia (birth)\\n  - A line from Malaysia to Germany (adult life)\\n  - A line from Germany to Greece (retirement)\\n- Extracted timeline by location:\\n  - Birth: Malaysia\\n  - Adult life: Germany\\n  - Retirement: Greece\\n  - Death: location not specified in the document\\n\\nNotes:\\n- The document uses “Leah Bailey” but then says “He,” which is an inconsistency in pronouns.',\n",
                     "  'Applying the quick recall strategy to the document:\\n\\n- Q: Where was Leah Bailey born? A: Malaysia.\\n- Q: Where did he spend most of his adult life? A: Germany.\\n- Q: After retirement, where did he live? A: Greece.\\n- Q: What happened at the end? A: He passed away.\\n- Q: What pronoun inconsistency exists in the document? A: Leah Bailey (a name typically female) is referred to as \"he\" in the text; double-check the intended gender/pronoun.',\n",
                     "  'Here’s the application of your space-and-images strategy to the document.\\n\\nImages assigned (as specified):\\n- Entrance: Malaysia – tropical scene\\n- Living room: Germany – scene with German landmarks\\n- Balcony: Greece – sunset and white-blue colors\\n\\nWalk-through to recall the facts in order:\\n- Start at the entrance (Malaysia): Picture a lush tropical scene at the doorway. In your mind, attach the fact “Leah Bailey was born in Malaysia.” \\n- Move to the living room (Germany): In the room, see notable German landmarks (Brandenburg Gate, castles, etc.). This anchors the fact “He spent most of his adult life in Germany.”\\n- Go to the balcony (Greece): Visualize a sunset and white-blue colors on the balcony. This cues the final fact: “After retirement, he lived in Greece and passed away.”\\n\\nRecall sequence (concise check):\\n- Born in Malaysia.\\n- Spent most of his adult life in Germany.\\n- After retirement, lived in Greece and passed away.',\n",
                     "  '- Malaysia — green: Leah Bailey was born in Malaysia.\\n- Germany — black/red/gold: He spent most of his adult life in Germany.\\n- Greece — blue/white: After retirement, he lived in Greece and passed away.',\n",
                     "  'Observing the document, there is a pronoun mismatch: Leah Bailey is a female name, yet the text uses “he” and “his.”\\n\\nFacts stated in the document (as a careful read):\\n- Leah Bailey was born in Malaysia.\\n- He spent most of his adult life in Germany.\\n- After retirement, he lived in Greece and passed away.\\n- No dates or locations for the death are given.\\n\\nPossible explanations for the mismatch:\\n- It is a simple pronoun error (likely the most common explanation).\\n- The subject could be male despite the female-sounding name (uncommon, but possible in some contexts or if “Leah” is a misreading of another name).\\n- “Leah Bailey” could be a transcription or editing mistake where the intended name/pronoun agreement got flipped.\\n\\nTwo plausible corrected versions depending on intended gender:\\n- If Leah is female (most likely intent): \\n  - Leah Bailey was born in Malaysia. She spent most of her adult life in Germany. After retirement, she lived in Greece and passed away.\\n- If the subject is male (intentionally using “he”):\\n  - Leah Bailey was born in Malaysia. He spent most of his adult life in Germany. After retirement, he lived in Greece and passed away.\\n  (Note: This would retain the original pronouns but would be unusual given the name. If you want to preserve clear gender cues, you could revise the name to a more conventional male name, e.g., Lee Bailey, and keep the “he” pronouns.)\\n\\nWhat this exercise demonstrates (memory prompt usage):\\n- A single pronoun inconsistency can flag potential errors in multiple facts (name-gender alignment, pronoun usage, timeline clarity).\\n- When you notice such a mismatch, re-check all related facts for coherence (birthplace, locations over life, retirement period, death).\\n- If you revise for consistency, ensure pronouns align with the intended gender of the subject and keep the timeline coherent (dates are missing here; adding them would improve precision).\\n\\nIf you’d like, I can produce a version with full consistency as per the more likely scenario (female subject) or draft options with a clearly male or gender-neutral name.',\n",
                     "  'Leah Bailey was born in Malaysia, spent most of his adult life in Germany, and, after retirement, lived in Greece before passing away.',\n",
                     "  'Here’s a concrete way to apply the spaced-repetition strategy (flashcards, timeline, and memory palace) to the document about Leah Bailey.\\n\\nImportant note on the text:\\n- The document uses the name Leah Bailey (usually feminine) but the pronouns are he/his. This is an inconsistency worth flagging during review.\\n\\n1) Flashcards (Q/A you can review at each interval)\\n- Q: Where was Leah Bailey born?\\n  A: Malaysia\\n- Q: In which country did Leah Bailey spend most of his adult life?\\n  A: Germany\\n- Q: Where did Leah Bailey live after retirement?\\n  A: Greece\\n- Q: What happened to Leah Bailey?\\n  A: He passed away.\\n- Q: What is the inconsistency in the document?\\n  A: The name Leah Bailey is typically feminine, but the text uses he/his pronouns.\\n- Q: List the sequence of life events in order.\\n  A: Born in Malaysia → spent most of his adult life in Germany → lived in Greece after retirement → passed away.\\n- Q: True or False: The document states Leah’s adult life was primarily in Germany.\\n  A: True\\n- Q: Which places are associated with Leah Bailey’s life in this document?\\n  A: Malaysia, Germany, Greece\\n\\n2) Timeline (simple chronological outline)\\n- Birth: Malaysia\\n- Adult life: Germany\\n- After retirement: Greece\\n- Death: (not dated or located in the document)\\n\\n3) Memory Palace (location-based visualization to memorize the facts)\\nCreate a short route with five loci. Visualize the following, using vivid, unusual images to strengthen recall:\\n\\n- Locus 1 (entrance/front door): A Malaysian welcome mat or a tiny Malaysian flag on the door. Purpose: memorize “born in Malaysia.”\\n- Locus 2 (hallway perpendicular to door): A German flag or a famous German landmark (e.g., Brandenburg Gate) placed on the wall. Purpose: memorize “spent most of adult life in Germany.”\\n- Locus 3 (living room): A Greek olive wreath on the sofa, a map showing Greece. Purpose: memorize “lived in Greece after retirement.”\\n- Locus 4 (bedroom or study): A calendar with a solemn candle and the word “passed away.” Purpose: memorize “passed away.”\\n- Locus 5 (mirror or side table): A small note or speech bubble showing the pronoun check: “Leah is usually female; text uses he.” Purpose: memorize the inconsistency for scrutiny in review.\\n\\n4) Interval plan (increasing review times and what to do at each)\\n- Day 1 (initial review): \\n  - Do all flashcards; recite the life sequence aloud.\\n  - Visualize the memory palace route and narrate the 5 loci in order.\\n  - Note the pronoun inconsistency as a topic to verify if you have access to more information.\\n- Day 3: \\n  - Review flashcards again; focus on any items you missed.\\n  - Revisit the timeline; recite the life sequence without prompts.\\n  - Walk through the memory palace and check that each locus aligns with the corresponding fact.\\n- Day 7 (1 week): \\n  - Use the memory palace to verbally recount the entire life arc (birth in Malaysia → Germany → Greece → death).\\n  - Re-check the pronoun issue; decide how you will handle it in future notes (e.g., mark as ambiguous or seek clarification).\\n- Day 14 (2 weeks): \\n  - Mixed recall: answer flashcard questions without looking; reconstruct timeline from memory.\\n  - Add a quick self-test: in which order did the events occur? Any missing details?\\n- Day 30 (1 month): \\n  - Full recall test: recite all facts and the order, including noting the inconsistency.\\n  - If you’re maintaining a larger set of notes, decide how this entry fits into broader contexts (e.g., if you’re tracking multiple people, compare country sequences, etc.).\\n\\n5) Quick tips\\n- If you’re using a flashcard app, tag these cards with “biography,” “birth,” “life-events,” and “pronoun-consistency” to regroup later.\\n- Keep the memory palace concise: five loci match the five core facts; you can add more loci later if you want to memorize more details.\\n- Address inconsistencies explicitly: note the gender pronoun issue and consider verifying with an authoritative source if this is for a real person or for a curated set of biographies.\\n\\nIf you’d like, I can format this into an Anki-ready deck (with cloze deletions or basic cards) or adapt the memory-palace cues to a different set of loci you prefer (e.g., a familiar route in your home or a virtual map).',\n",
                     "  '- Leah Bailey was born in Malaysia.\\n- He spent most of his adult life in Germany.\\n- After retirement, he lived in Greece and passed away.',\n",
                     "  'Here’s a direct application of your learning strategy to the provided document, focusing on Leah Bailey’s birthplace (Malaysia). Note: the document uses the pronoun “he” for Leah, which is unusual; I’ve kept the content consistent with the document as given.\\n\\nStep 1 — Flashcard\\n- Question: Where was Leah Bailey born?\\n- Answer: Malaysia\\n\\nStep 2 — Visual mnemonic\\n- Create a mental image: Leah Bailey’s birth certificate stamped with the Malaysian flag. Picture the flag’s blue canton with the crescent and 14-point star, and imagine the word “birth” curling into the flag while you say “Malaysia” aloud.\\n\\nStep 3 — Strong cue linking\\n- Link Malaysia to a memory you already have: imagine a map of Southeast Asia and place a bright pin on Malaysia near Kuala Lumpur, or visualize the Petronas Towers to anchor Malaysia in your memory.\\n- Place Leah’s birth there in your mind as the cue for retrieval.\\n\\nStep 4 — Spaced repetition plan\\n- Review schedule: after 1 day, then 3 days, then 1 week, then 2 weeks.\\n- Adjust if you forget; if you forget at a step, shorten the interval (e.g., review again after 12 hours) and then resume the planned schedule.\\n\\nStep 5 — Active recall practice\\n- Without looking, recall the answer multiple times in a row:\\n  - “Where was Leah Bailey born? Malaysia.”\\n  - Repeat aloud or write it down several times in a row, aiming for fluid recall.\\n\\nStep 6 — Test with different prompts\\n- Try variations to test flexibility:\\n  - Which country is Leah Bailey’s birthplace? Malaysia.\\n  - Leah Bailey was born in ___? Malaysia.\\n  - Leah Bailey’s birthplace is in which country? Malaysia.\\n  - Leah Bailey was born in Malaysia. True or false? (False prompts can be used to test recognition with misdirections.)\\n\\nStep 7 — Integrate with related facts (to reinforce ordering)\\n- Build a simple mental timeline that includes the document’s other facts:\\n  - Born in Malaysia.\\n  - Spent most of adult life in Germany.\\n  - After retirement, lived in Greece.\\n  - Passed away (death noted in the document).\\n- This creates an ordering framework: Malaysia → Germany → Greece → death. It helps keep the birthplace connected to the broader life sequence, making retrieval more robust.\\n\\nOptional additions (enhanced practice)\\n- Create a second flashcard set for the other facts to reinforce context:\\n  - Q: In which country did Leah Bailey spend most of her adult life? A: Germany\\n  - Q: Where did Leah Bailey live after retirement? A: Greece\\n  - Q: What is the final event noted in the document? A: Leah Bailey died\\n- You can mix these into random review sessions to strengthen overall autobiographical recall.\\n\\nIf you’d like, I can generate a ready-to-use flashcard list (including a few additional cards for the other facts) or tailor the mnemonic to a memory palace you already use.',\n",
                     "  'Here’s the learning strategy applied to the provided document, focused on the fact that Leah Bailey spent most of his adult life in Germany.\\n\\nStep 1 — Card setup\\n- Question: In which country did Leah Bailey spend most of his adult life?\\n- Answer: Germany\\n\\nStep 2 — Create a geographic anchor\\n- Visual cue: Picture a German skyline (Berlin or Munich) behind a calendar showing adulthood (the calendar marks the years typically considered “adult life” or “prime years”).\\n- Rationale: The German skyline anchors the country, and the calendar anchors the notion of “adult life” as a time span.\\n\\nStep 3 — Build a narrative cue\\n- Narrative cue: Imagine his prime years being spent cruising the Autobahn toward Germany’s flag, reinforcing that Germany is the country of his adult life.\\n\\nStep 4 — Spaced repetition\\n- Review schedule: 1 day after initial learning, then 3 days later, then 1 week later, then 2 weeks later.\\n- Implementation tip: Use reminders or an SRS app to trigger these intervals and test the card at each step.\\n\\nStep 5 — Practice rapid-fire prompts\\n- Examples:\\n  - “Where did his adult life primarily take place?”\\n  - “Which country represents his adult years?”\\n  - “In which country did Leah Bailey spend most of his adult life?”\\n  - “Name the country that marks the peak years of his adulthood.”\\n\\nStep 6 — Interleave with other country-life facts\\n- Plan: Mix in other facts from the document or related material (e.g., birthplace Malaysia and retirement in Greece).\\n- Interleaving prompts:\\n  - “Where was Leah Bailey born?”\\n  - “Where did he live after retirement?”\\n  - “Which country did he spend most of his adult life in?”\\n- Rationale: This improves discrimination between similar facts (birthplace, adult-life country, retirement location).\\n\\nStep 7 — Self-test with open-ended recall\\n- Prompt: Describe Leah Bailey’s life arc in one sentence and highlight the country where his adult life occurred.\\n- Example sentence to aim for: Leah Bailey was born in Malaysia, spent most of his adult life in Germany, and after retirement lived in Greece.\\n- Highlight: Germany (the country representing his adult-life years).\\n\\nOne-sentence recall practice (optional quick test)\\n- Write: Leah Bailey was born in Malaysia, spent most of his adult life in Germany, and later lived in Greece.\\n- Then identify the adult-life country: Germany.\\n\\nNotes\\n- Be mindful of pronouns if they cause confusion (document uses “he” with the name Leah; keep consistency with your internal notes for recall).\\n- The key fact to remember is: Germany is the country where Leah Bailey spent most of his adult life. The birth country (Malaysia) and retirement location (Greece) provide helpful context for discriminating among life stages.',\n",
                     "  'Here’s the document applied to your learning strategy, tailored to the lines given.\\n\\nFacts from the document\\n- Leah Bailey was born in Malaysia.\\n- He spent most of his adult life in Germany.\\n- After retirement, he lived in Greece and passed away.\\n\\nApplied strategy\\n\\nStep 1 — Card setup\\n- Question: After retirement, where did Leah Bailey live?\\n- Answer: Greece.\\n\\nStep 2 — Create a strong retirement image\\n- Visualization: An elderly figure relaxing on a sunlit Greek island terrace. In the scene: white-washed buildings with blue domes, a calm sea in the background, olive trees, and a faint Acropolis silhouette in the distance. This image cues Greece as the retirement destination.\\n\\nStep 3 — Build a link from Germany to Greece\\n- Link idea: Picture a travel route from a German city (where he spent most of his adult life) to a Greek island during retirement. Cue the transition: “Germany → Greece (retirement move).”\\n- Quick cue phrases: “From the German city to the Aegean” or “Autobahn to blue domes.”\\n\\nStep 4 — Employ a second mnemonic\\n- Option 1: Pair Greece with a vivid sound or object, e.g., “greek feta memory” or “sea-blue color.” You might visualize a splash of blue paint labeled “Greece.”\\n- Option 2 (alternative): Think of the word Greece as “great seas” to create a memorable phrase.\\n\\nStep 5 — Spaced repetition and quick recall prompts\\n- Prompts to use:\\n  - Where did he live after retirement?\\n  - Which country did he move to in retirement?\\n- Suggested review schedule (adjust to your preference): after 10 minutes, after 1 day, after 3 days, after 1 week.\\n\\nStep 6 — Contextual practice\\n- One-sentence mini-biography focusing on the retirement move to Greece:\\n  - Example: After a life spent in Germany, Leah Bailey retired and moved to Greece.\\n  - Another option: Born in Malaysia, Leah Bailey spent his adult years in Germany and moved to Greece upon retirement.\\n\\nOptional notes\\n- The document uses the name Leah Bailey but the text uses “he.” If you prefer consistency, decide which pronouns to use when practicing, and adjust the sentences accordingly.\\n- If you want to practice the full timeline, you can add:\\n  - Born in Malaysia\\n  - Spent adult life in Germany\\n  - Retired to Greece\\n  - Passed away (optional for broader biographical practice)\\n\\nIf you’d like, I can turn this into a ready-to-use flashcard set (with digital spacing schedule) or provide a printable mini-biography worksheet.',\n",
                     "  'Applied the strategy to the document. Here is a tailored version using the given facts about Leah Bailey.\\n\\nStep 1: Card setup\\n- Question: What happened to Leah Bailey after retirement?\\n- Answer: He passed away.\\nNote: The document uses “Leah Bailey” with he/his pronouns. You can adjust pronouns if you prefer gender-neutral wording.\\n\\nStep 2: Life-story arc cue\\n- Four-step life arc to anchor order and fate:\\n  1) Born in Malaysia\\n  2) Spent most of his adult life in Germany\\n  3) After retirement, lived in Greece\\n  4) Passed away\\n\\nStep 3: Symbolic cue for death\\n- Use a death cue such as a fade-to-dark visual or a closing chapter bookmark, linked to the final fact “passed away.”\\n\\nStep 4: Practice retrieval words\\n- Examples:\\n  - “Leah Bailey’s outcome after retirement?”\\n  - “Did he pass away or continue living after retirement?”\\n  - “What was Leah Bailey’s status after retirement?”\\n\\nStep 5: Spaced repetition\\n- Review the full sequence (birth in Malaysia → adult life in Germany → retirement in Greece → passed away) at the same interval cadence as other related facts you’re studying. Example schedule:\\n  - Day 1, Day 3, Day 7, Day 14, Day 28 (adjust as needed for your overall study plan).\\n\\nStep 6: Self-testing in different formats\\n- Fill-in-the-blank: “Leah Bailey passed away after retirement.”\\n- Paraphrase prompts:\\n  - “What was the final status of Leah Bailey after retirement?”\\n  - “Where did Leah Bailey live after retirement and what happened later?”\\n\\nOptional note\\n- The document uses male pronouns (“he,” “his”) with the name Leah Bailey. If you prefer consistency with the name’s typical gender association, you can adapt the prompts to match your preferred pronouns (e.g., “Leah Bailey passed away after retirement,” or “He passed away after retirement,” as in Step 1).']}"
                  ]
               },
               "execution_count": 75,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "spotcheck_data[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 69,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df2[\"question_str\"] = questions\n",
            "# df1.to_excel(fpath, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # df1 = df1[df1[\"question_key\"] == \"alias_question\"]\n",
            "# # df2 = df2[df2[\"question_key\"] == \"alias_question\"]\n",
            "\n",
            "# df1[\"model\"] = \"Llama3.2-1B\"\n",
            "# df2[\"model\"] = \"Qwen2.5-1.5B\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = pd.concat([df1, df2], ignore_index=True)\n",
            "# df.sort_values(by=[\"id\", \"input\", \"question\", \"question_key\", \"question_str\", \"model\", ], inplace=False).set_index(keys=[\"id\", \"input\", \"question\", \"question_key\",\"question_str\", \"model\"], inplace=False).to_excel(\"/u/zliu/datastor1/mend/spotcheck/llama3.2-1B-qwen2.5-1.5B-alias-question.xlsx\", index=True)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Read out results and calculate aggregation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "efficacy (n=421.0)\n",
                  "12.0\n",
                  "specificity (n=421.0)\n",
                  "82.6\n"
               ]
            }
         ],
         "source": [
            "df = pd.read_excel(\"/u/zliu/datastor1/RLEdit/results/cre_llama-3.2-base-qa_rledit_5_4_ep1500/test_ood_relation_results.xlsx\")\n",
            "df[\"question_type\"] = \"efficacy\"\n",
            "df.loc[df[\"question_key\"] == \"unalias_question\", \"question_type\"] = \"specificity\"\n",
            "assert len(df[df[\"question_type\"] == \"efficacy\"]) == len(df[df[\"question_type\"] == \"specificity\"])\n",
            "\n",
            "\n",
            "for question_type in [\"efficacy\", \"specificity\"]:\n",
            "    df_question = df[df[\"question_type\"] == question_type]\n",
            "\n",
            "    agg = df_question.describe()[[\"llm_accuracy\",]]\n",
            "    print(question_type, f\"(n={agg['llm_accuracy']['count']})\")\n",
            "    \n",
            "    print((agg['llm_accuracy']['mean'] * 100).round(1)) #\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "metadata": {},
         "outputs": [],
         "source": [
            "# prop_questions = [{\"question\": q[\"alias_question\"], \"answer\": q[\"answer\"]}for d in io.load_jsonlines(\"/data/users/zliu/KE-by-CP/data/debug_meta_train/syn_data_neurips/4Ktrain_data_100percent_frozen/train_text_data_id_entity152_rel31.jsonl\") for q in d[\"questions\"] ]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "# "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(prop_questions, f\"{vars.DATA_DIR}/debug_meta_train/syn_data_neurips/model_prep/prop_questions.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>llm_accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>count</th>\n",
                     "      <td>676.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>mean</th>\n",
                     "      <td>0.913245</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>std</th>\n",
                     "      <td>0.208383</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>min</th>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>25%</th>\n",
                     "      <td>0.300000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>50%</th>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>75%</th>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>max</th>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "       llm_accuracy\n",
                     "count    151.000000\n",
                     "mean       0.913245\n",
                     "std        0.208383\n",
                     "min        0.000000\n",
                     "25%        0.300000\n",
                     "50%        1.000000\n",
                     "75%        1.000000\n",
                     "max        1.000000"
                  ]
               },
               "execution_count": 47,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df[df[\"question_type\"] == \"specificity\"].drop_duplicates(subset=[\"question\"], inplace=False).describe()[[\"llm_accuracy\",]]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.9118"
                  ]
               },
               "execution_count": 54,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "0.9118"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.9476"
                  ]
               },
               "execution_count": 55,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "0.9476"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 56,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Counter(df[(df[\"question_type\"] == \"efficacy\") & (df[\"llm_accuracy\"] > 0.5)][\"question\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Test signinifcant between two table"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "df1 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/qwen2.5-1.5B-eos-sft-template-format-curated-v1-lr2e-6-sample-10-estimated-wiki/syn_story/memit(wikipedia)_eval_loss=clm_input=seen_n=500_prompt=no_w-gen_wo-icl_e+s_4K_test_id-question.xlsx\")\n",
            "df2 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/qwen_share_max_4K_14_27/syn_story/mend_eval_loss=clm_input=seen_n=500_prompt=no_w-gen_wo-icl_4K_test_id-question.xlsx\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [],
         "source": [
            "df1.loc[df1[\"question_key\"] == \"unalias_question\", \"question_type\"] = \"specificity\"\n",
            "df2.loc[df2[\"question_key\"] == \"unalias_question\", \"question_type\"] = \"specificity\"\n",
            "# df1[df1[\"question_type\"] == \"efficacy\"][\"llm_accuracy\"].mean()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Score_A avg: 0.16\n",
                  "Score_B avg: 0.64\n",
                  "Delta (B - A): 0.5\n",
                  "p: 0.0 (threshold = 0.05)\n",
                  "Significant\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 28,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "is_significantly_different(\n",
            "    df1[df1[\"question_type\"] == \"efficacy\"][\"llm_accuracy\"].to_list(),\n",
            "    df2[df2[\"question_type\"] == \"efficacy\"][\"llm_accuracy\"].to_list(),\n",
            "    verbose=True\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Score_A avg: 0.91\n",
                  "Score_B avg: 0.94\n",
                  "Delta (B - A): 0.0\n",
                  "p: 0.0 (threshold = 0.05)\n",
                  "Significant\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 29,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "is_significantly_different(\n",
            "    df1[df1[\"question_type\"] == \"specificity\"][\"llm_accuracy\"].to_list(),\n",
            "    df2[df2[\"question_type\"] == \"specificity\"][\"llm_accuracy\"].to_list(),\n",
            "    verbose=True\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [],
         "source": [
            "prefilter = io.load_jsonlines(\"/u/zliu/datastor1/KE-by-CP/data/debug_meta_train/syn_data_neurips/data_gen/entity_type_name_template_v1_curated_answered_prefiltered.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [],
         "source": [
            "prefilter_df = pd.DataFrame(prefilter)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "571"
                  ]
               },
               "execution_count": 55,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(prefilter_df[\"entity_name\"].unique()) - 189"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 52,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Index(['entity_type', 'entity_type_tag', 'entity_name', 'template', 'question',\n",
                     "       'answer'],\n",
                     "      dtype='object')"
                  ]
               },
               "execution_count": 52,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "prefilter_df.columns"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 53,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "48"
                  ]
               },
               "execution_count": 53,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(prefilter_df[\"template\"].unique())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "10"
                  ]
               },
               "execution_count": 54,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "48 - 38"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Merge CPT results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "2.03125"
                  ]
               },
               "execution_count": 28,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "65 / 32"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 58,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "''"
                  ]
               },
               "execution_count": 58,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "individual_dir = \"/home/zliu/zliu/mend/synstory_exp_output/Llama-3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10_active-reading_clm-baseline_lr=0.0001_epoch=4.0_tunable-params=all/individual_results_augmented_texts_ood-relation\"\n",
            "# midupper3-mlp\n",
            "\n",
            "if individual_dir.endswith(\"_id\"):\n",
            "    n_data = 500\n",
            "# elif individual_dir.endswith(\"_ood-entity\"):\n",
            "#     n_data = 350\n",
            "# elif individual_dir.endswith(\"_ood-relation\"):\n",
            "#     n_data = 350\n",
            "else:\n",
            "    assert individual_dir.endswith(\"_ood\") or individual_dir.endswith(\"_ood-entity\") or individual_dir.endswith(\"_ood-relation\")\n",
            "    n_data = 350\n",
            "\n",
            "file_name_format = \"{idx}_eval_results_e.xlsx\"\n",
            "individual_dfs = []\n",
            "missing_ids = []\n",
            "for i in range(n_data):\n",
            "    file_name = os.path.join(individual_dir, file_name_format.format(idx=i))\n",
            "    if not os.path.exists(file_name):\n",
            "        missing_ids.append(i)\n",
            "        continue\n",
            "    df = pd.read_excel(file_name)\n",
            "    individual_dfs.append(df)\n",
            "\" \".join([str(i) for i in missing_ids])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 59,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0"
                  ]
               },
               "execution_count": 59,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(missing_ids)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {},
         "outputs": [],
         "source": [
            "all_df = pd.concat(individual_dfs, ignore_index=True)\n",
            "all_df.loc[all_df[\"question_key\"] == \"unalias_question\", \"question_type\"] = \"specificity\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {},
         "outputs": [],
         "source": [
            "assert len(all_df[all_df[\"question_type\"] == \"efficacy\"]) == len(all_df[all_df[\"question_type\"] == \"specificity\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "842"
                  ]
               },
               "execution_count": 62,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(all_df)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "metadata": {},
         "outputs": [],
         "source": [
            "if individual_dir.endswith(\"_id\"):\n",
            "    all_df.to_excel(\n",
            "        f\"{individual_dir}/../all_results_id.xlsx\",\n",
            "        index=False\n",
            "    )\n",
            "elif individual_dir.endswith(\"_ood-entity\"):\n",
            "    all_df.to_excel(\n",
            "        f\"{individual_dir}/../all_results_ood-entity.xlsx\",\n",
            "        index=False\n",
            "    )\n",
            "elif individual_dir.endswith(\"_ood-relation\"):\n",
            "    all_df.to_excel(\n",
            "        f\"{individual_dir}/../all_results_ood-relation.xlsx\",\n",
            "        index=False\n",
            "    )\n",
            "else:\n",
            "    assert individual_dir.endswith(\"_ood\")\n",
            "    all_df.to_excel(\n",
            "        f\"{individual_dir}/../all_results_ood.xlsx\",\n",
            "        index=False\n",
            "    )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Get aggregated scores"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "df = pd.read_excel(\"/u/zliu/datastor1/mend/synstory_exp_output/llama3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood-relation/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "      <th>question_key</th>\n",
                     "      <th>question_type</th>\n",
                     "      <th>stage</th>\n",
                     "      <th>input</th>\n",
                     "      <th>question</th>\n",
                     "      <th>answer</th>\n",
                     "      <th>predicted_answer_idx</th>\n",
                     "      <th>predicted_answer</th>\n",
                     "      <th>exact_match</th>\n",
                     "      <th>llm_accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[When did the event that James King curated a...</td>\n",
                     "      <td>When did the event that James King curated an ...</td>\n",
                     "      <td>1850–1864</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1994</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>0</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[What year did the event that sparked James K...</td>\n",
                     "      <td>What year did the event that sparked James Kin...</td>\n",
                     "      <td>1963</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1972</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>0</td>\n",
                     "      <td>unalias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[When did The Taiping Rebellion take place?]]</td>\n",
                     "      <td>When did The Taiping Rebellion take place?</td>\n",
                     "      <td>1850–1864</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1850-1864</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>0</td>\n",
                     "      <td>unalias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[What year did The Assassination of John F. K...</td>\n",
                     "      <td>What year did The Assassination of John F. Ken...</td>\n",
                     "      <td>1963</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1963</td>\n",
                     "      <td>1</td>\n",
                     "      <td>1.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>1</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[What is the name of the alphabet or script o...</td>\n",
                     "      <td>What is the name of the alphabet or script of ...</td>\n",
                     "      <td>Latin alphabet</td>\n",
                     "      <td>0</td>\n",
                     "      <td>Esperanto</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>837</th>\n",
                     "      <td>348</td>\n",
                     "      <td>unalias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[What is the name of the alphabet or script o...</td>\n",
                     "      <td>What is the name of the alphabet or script of ...</td>\n",
                     "      <td>Greek alphabet</td>\n",
                     "      <td>0</td>\n",
                     "      <td>Greek alphabet</td>\n",
                     "      <td>1</td>\n",
                     "      <td>1.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>838</th>\n",
                     "      <td>349</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[When did the event that inspired Taylor Moto...</td>\n",
                     "      <td>When did the event that inspired Taylor Motors...</td>\n",
                     "      <td>November 22, 1963</td>\n",
                     "      <td>0</td>\n",
                     "      <td>2009</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>839</th>\n",
                     "      <td>349</td>\n",
                     "      <td>alias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[What year did the event that Taylor Motors L...</td>\n",
                     "      <td>What year did the event that Taylor Motors LLC...</td>\n",
                     "      <td>1793</td>\n",
                     "      <td>0</td>\n",
                     "      <td>2009</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>840</th>\n",
                     "      <td>349</td>\n",
                     "      <td>unalias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[When did The Assassination of John F. Kenned...</td>\n",
                     "      <td>When did The Assassination of John F. Kennedy ...</td>\n",
                     "      <td>November 22, 1963</td>\n",
                     "      <td>0</td>\n",
                     "      <td>November 22, 1963</td>\n",
                     "      <td>1</td>\n",
                     "      <td>1.0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>841</th>\n",
                     "      <td>349</td>\n",
                     "      <td>unalias_question</td>\n",
                     "      <td>efficacy</td>\n",
                     "      <td>pre-edit</td>\n",
                     "      <td>[[What year did The Execution of King Louis XV...</td>\n",
                     "      <td>What year did The Execution of King Louis XVI ...</td>\n",
                     "      <td>1793</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1793</td>\n",
                     "      <td>1</td>\n",
                     "      <td>1.0</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>842 rows × 11 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "      id      question_key question_type     stage  \\\n",
                     "0      0    alias_question      efficacy  pre-edit   \n",
                     "1      0    alias_question      efficacy  pre-edit   \n",
                     "2      0  unalias_question      efficacy  pre-edit   \n",
                     "3      0  unalias_question      efficacy  pre-edit   \n",
                     "4      1    alias_question      efficacy  pre-edit   \n",
                     "..   ...               ...           ...       ...   \n",
                     "837  348  unalias_question      efficacy  pre-edit   \n",
                     "838  349    alias_question      efficacy  pre-edit   \n",
                     "839  349    alias_question      efficacy  pre-edit   \n",
                     "840  349  unalias_question      efficacy  pre-edit   \n",
                     "841  349  unalias_question      efficacy  pre-edit   \n",
                     "\n",
                     "                                                 input  \\\n",
                     "0    [[When did the event that James King curated a...   \n",
                     "1    [[What year did the event that sparked James K...   \n",
                     "2       [[When did The Taiping Rebellion take place?]]   \n",
                     "3    [[What year did The Assassination of John F. K...   \n",
                     "4    [[What is the name of the alphabet or script o...   \n",
                     "..                                                 ...   \n",
                     "837  [[What is the name of the alphabet or script o...   \n",
                     "838  [[When did the event that inspired Taylor Moto...   \n",
                     "839  [[What year did the event that Taylor Motors L...   \n",
                     "840  [[When did The Assassination of John F. Kenned...   \n",
                     "841  [[What year did The Execution of King Louis XV...   \n",
                     "\n",
                     "                                              question             answer  \\\n",
                     "0    When did the event that James King curated an ...          1850–1864   \n",
                     "1    What year did the event that sparked James Kin...               1963   \n",
                     "2           When did The Taiping Rebellion take place?          1850–1864   \n",
                     "3    What year did The Assassination of John F. Ken...               1963   \n",
                     "4    What is the name of the alphabet or script of ...     Latin alphabet   \n",
                     "..                                                 ...                ...   \n",
                     "837  What is the name of the alphabet or script of ...     Greek alphabet   \n",
                     "838  When did the event that inspired Taylor Motors...  November 22, 1963   \n",
                     "839  What year did the event that Taylor Motors LLC...               1793   \n",
                     "840  When did The Assassination of John F. Kennedy ...  November 22, 1963   \n",
                     "841  What year did The Execution of King Louis XVI ...               1793   \n",
                     "\n",
                     "     predicted_answer_idx   predicted_answer  exact_match  llm_accuracy  \n",
                     "0                       0               1994            0           0.0  \n",
                     "1                       0               1972            0           0.0  \n",
                     "2                       0          1850-1864            0           1.0  \n",
                     "3                       0               1963            1           1.0  \n",
                     "4                       0          Esperanto            0           0.0  \n",
                     "..                    ...                ...          ...           ...  \n",
                     "837                     0     Greek alphabet            1           1.0  \n",
                     "838                     0               2009            0           0.0  \n",
                     "839                     0               2009            0           0.0  \n",
                     "840                     0  November 22, 1963            1           1.0  \n",
                     "841                     0               1793            1           1.0  \n",
                     "\n",
                     "[842 rows x 11 columns]"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "efficacy (n=842.0)\n",
                  "51.5\n",
                  "specificity (n=0.0)\n",
                  "nan\n"
               ]
            }
         ],
         "source": [
            "for question_type in [\"efficacy\", \"specificity\"]:\n",
            "    df_question = df[df[\"question_type\"] == question_type]\n",
            "\n",
            "    agg = df_question.describe()[[\"llm_accuracy\",]]\n",
            "    print(question_type, f\"(n={agg['llm_accuracy']['count']})\")\n",
            "    \n",
            "    print((agg['llm_accuracy']['mean'] * 100).round(1)) #\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 94,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "      <th>predicted_answer_idx</th>\n",
                     "      <th>exact_match</th>\n",
                     "      <th>llm_accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>count</th>\n",
                     "      <td>676.000000</td>\n",
                     "      <td>676.0</td>\n",
                     "      <td>676.000000</td>\n",
                     "      <td>676.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>mean</th>\n",
                     "      <td>129.998521</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.714497</td>\n",
                     "      <td>0.942456</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>std</th>\n",
                     "      <td>114.474134</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.451988</td>\n",
                     "      <td>0.147430</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>min</th>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>25%</th>\n",
                     "      <td>39.750000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>50%</th>\n",
                     "      <td>95.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>75%</th>\n",
                     "      <td>193.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>max</th>\n",
                     "      <td>496.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "               id  predicted_answer_idx  exact_match  llm_accuracy\n",
                     "count  676.000000                 676.0   676.000000    676.000000\n",
                     "mean   129.998521                   0.0     0.714497      0.942456\n",
                     "std    114.474134                   0.0     0.451988      0.147430\n",
                     "min      0.000000                   0.0     0.000000      0.000000\n",
                     "25%     39.750000                   0.0     0.000000      1.000000\n",
                     "50%     95.000000                   0.0     1.000000      1.000000\n",
                     "75%    193.000000                   0.0     1.000000      1.000000\n",
                     "max    496.000000                   0.0     1.000000      1.000000"
                  ]
               },
               "execution_count": 94,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df_question.drop_duplicates(subset=[\"question\"], inplace=False).describe()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# convert trivia qa in jsonl to json"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "train = io.load_jsonlines(\"/data/users/zliu/KE-by-CP/data/trivia_qa_wiki_sft/train.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "from transformers import AutoTokenizer\n",
            "tokenizer = AutoTokenizer.from_pretrained(\"/home/zliu/shared_resources/models/llama3/hf/Llama-3.1-8B-w-pad\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def prepare_sft_text(dataset: list, tokenizer):\n",
            "    # assert len(tokenizer.additional_special_tokens) == 1\n",
            "\n",
            "    new_dataset = []\n",
            "    has_show_example = False\n",
            "    for datum in dataset:\n",
            "        q = datum[\"question\"]\n",
            "        a = str(datum[\"answer\"])\n",
            "        # t = f\"{q}{tokenizer.additional_special_tokens[0]}{a}\" if a[0] == \" \" else f\"{q}{tokenizer.additional_special_tokens[0]} {a}\"\n",
            "        t = f\"{q}{a}\" if a[0] == \" \" else f\"{q} {a}\"\n",
            "        t += tokenizer.eos_token\n",
            "        if not has_show_example:\n",
            "            print(f\"Example: -> {t}\")\n",
            "            has_show_example = True\n",
            "        datum[\"text\"] = t\n",
            "        new_dataset.append(datum)\n",
            "    return new_dataset\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Example: -> Where in England was Dame Judi Dench born? York<|end_of_text|>\n"
               ]
            }
         ],
         "source": [
            "processed_train = prepare_sft_text(train, tokenizer)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "response_template = \"?\"\n",
            "filtered_train_dataset = []\n",
            "for datum in processed_train:\n",
            "    text = datum[\"text\"]\n",
            "    if all([x in tokenizer(text)[\"input_ids\"] for x in tokenizer(response_template, add_special_tokens=False)[\"input_ids\"]]):\n",
            "        filtered_train_dataset.append(datum)\n",
            "        "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "58539"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(processed_train)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "processed_train_in_alpaca = []\n",
            "for datum in filtered_train_dataset:\n",
            "    text = datum[\"text\"]\n",
            "    processed_train_in_alpaca.append({\n",
            "        \"instruction\": datum[\"question\"],\n",
            "        \"input\": \"\",\n",
            "        \"output\": (\"\" if datum[\"answer\"][0] == \" \" else \" \") + datum[\"answer\"]\n",
            "    })"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [],
         "source": [
            "io.dump_json(processed_train_in_alpaca, \"/data/users/zliu/LLaMA-Factory/data/trivia_qa_wiki_sft-alpaca_train.json\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# qwen2.5-1.5B\n",
            "# df1 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/qwen2.5-1.5B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_id/base_n=500_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "# df2 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/qwen2.5-1.5B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "# df3 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/qwen2.5-1.5B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood-entity/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "# df4 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/qwen2.5-1.5B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood-relation/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "\n",
            "# llama3.2-1B\n",
            "df1 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/llama3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_id/base_n=500_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "df2 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/llama3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "df3 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/llama3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood-entity/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "df4 = pd.read_excel(\"/data/users/zliu/mend/synstory_exp_output/llama3.2-1B-eos-sft-template-format-curated-v1-lr2e-6-sample-10/4K_test_ood-relation/base_n=350_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
            "\n",
            "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "      <th>predicted_answer_idx</th>\n",
                     "      <th>exact_match</th>\n",
                     "      <th>llm_accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>count</th>\n",
                     "      <td>1018.000000</td>\n",
                     "      <td>1018.0</td>\n",
                     "      <td>1018.000000</td>\n",
                     "      <td>1018.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>mean</th>\n",
                     "      <td>108.002947</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.711198</td>\n",
                     "      <td>0.943910</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>std</th>\n",
                     "      <td>106.485369</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.453428</td>\n",
                     "      <td>0.137713</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>min</th>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.300000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>25%</th>\n",
                     "      <td>27.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>50%</th>\n",
                     "      <td>68.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>75%</th>\n",
                     "      <td>156.750000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>max</th>\n",
                     "      <td>496.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                id  predicted_answer_idx  exact_match  llm_accuracy\n",
                     "count  1018.000000                1018.0  1018.000000   1018.000000\n",
                     "mean    108.002947                   0.0     0.711198      0.943910\n",
                     "std     106.485369                   0.0     0.453428      0.137713\n",
                     "min       0.000000                   0.0     0.000000      0.300000\n",
                     "25%      27.000000                   0.0     0.000000      1.000000\n",
                     "50%      68.000000                   0.0     1.000000      1.000000\n",
                     "75%     156.750000                   0.0     1.000000      1.000000\n",
                     "max     496.000000                   0.0     1.000000      1.000000"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df[df[\"question_key\"] == \"unalias_question\"].drop_duplicates(subset=[\"question\"], inplace=False).describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 108,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "      <th>predicted_answer_idx</th>\n",
                     "      <th>exact_match</th>\n",
                     "      <th>llm_accuracy</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>count</th>\n",
                     "      <td>1018.000000</td>\n",
                     "      <td>1018.0</td>\n",
                     "      <td>1018.000000</td>\n",
                     "      <td>1018.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>mean</th>\n",
                     "      <td>108.002947</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.686640</td>\n",
                     "      <td>0.904617</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>std</th>\n",
                     "      <td>106.485369</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.464087</td>\n",
                     "      <td>0.230489</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>min</th>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>25%</th>\n",
                     "      <td>27.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>50%</th>\n",
                     "      <td>68.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>75%</th>\n",
                     "      <td>156.750000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>max</th>\n",
                     "      <td>496.000000</td>\n",
                     "      <td>0.0</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                id  predicted_answer_idx  exact_match  llm_accuracy\n",
                     "count  1018.000000                1018.0  1018.000000   1018.000000\n",
                     "mean    108.002947                   0.0     0.686640      0.904617\n",
                     "std     106.485369                   0.0     0.464087      0.230489\n",
                     "min       0.000000                   0.0     0.000000      0.000000\n",
                     "25%      27.000000                   0.0     0.000000      1.000000\n",
                     "50%      68.000000                   0.0     1.000000      1.000000\n",
                     "75%     156.750000                   0.0     1.000000      1.000000\n",
                     "max     496.000000                   0.0     1.000000      1.000000"
                  ]
               },
               "execution_count": 108,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df[df[\"question_key\"] == \"unalias_question\"].drop_duplicates(subset=[\"question\"], inplace=False).describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "90.4"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# convert trivia qa in jsonl to json"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [],
         "source": [
            "train = io.load_jsonlines(f\"{vars.DATA_DIR}/debug_meta_train/syn_data_neurips/model_prep/light_weight_sft_content_curated_v1_sample=10.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'entity_type': 'Person',\n",
                     " 'entity_type_tag': 'person',\n",
                     " 'entity_name': 'Marie Antoinette',\n",
                     " 'template': 'How many children did {person} have?',\n",
                     " 'question': 'How many children did Marie Antoinette have?',\n",
                     " 'answer': '4'}"
                  ]
               },
               "execution_count": 34,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "train[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "metadata": {},
         "outputs": [],
         "source": [
            "processed_train_in_alpaca = []\n",
            "for datum in train:\n",
            "    processed_train_in_alpaca.append({\n",
            "        \"instruction\": datum[\"question\"],\n",
            "        \"input\": \"\",\n",
            "        \"output\": (\"\" if datum[\"answer\"][0] == \" \" else \" \") + datum[\"answer\"]\n",
            "    })"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "480"
                  ]
               },
               "execution_count": 36,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(processed_train_in_alpaca)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "480"
                  ]
               },
               "execution_count": 37,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [],
         "source": [
            "io.dump_json(\n",
            "    processed_train_in_alpaca,\n",
            "    \"/data/users/zliu/LLaMA-Factory/data/template_sft_alpaca_train.json\"\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "eff-kp",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.18"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
