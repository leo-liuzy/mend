{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/users/zliu/mend/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars, extractor\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import describe\n",
    "from thefuzz import fuzz\n",
    "\n",
    "\n",
    "from knowledge_propagation.modules.evaluators import (\n",
    "    ExactMatchEvaluator,\n",
    "    RougeEvaluator,\n",
    "    OpenAIEvaluator,\n",
    ")\n",
    "llm_evaluator = OpenAIEvaluator()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio syn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 10700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10700.00</td>\n",
       "      <td>10700.00</td>\n",
       "      <td>10700.00</td>\n",
       "      <td>10700.00</td>\n",
       "      <td>10555.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.99</td>\n",
       "      <td>24.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>186.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1994.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match    is_num  abs_diff\n",
       "count        10700.00        10700.00     10700.00  10700.00  10555.00\n",
       "mean             0.36            0.80         0.36      0.99     24.63\n",
       "std              0.48            0.17         0.48      0.12    186.86\n",
       "min              0.00            0.25         0.00      0.00      0.00\n",
       "25%              0.00            0.75         0.00      1.00      0.00\n",
       "50%              0.00            0.75         0.00      1.00      1.00\n",
       "75%              1.00            1.00         1.00      1.00      3.00\n",
       "max              1.00            1.00         1.00      1.00   1994.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/data/users/zliu/mend/debug_exp_output/Llama-3.2-1B-common-date-year-after-eos-sft_clm-baseline_lr=1e-05_epoch=4.0/all_results_bio_syn_v2_text.xlsx\")\n",
    "df[\"is_num\"] = df[\"is_num\"].astype(float)\n",
    "print(\"Num of rows:\", len(df))\n",
    "df.describe()[[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"is_num\", \"abs_diff\",]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", 'exact_match', \"is_num\"] + [\"abs_diff\",]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy_interval</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1924.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficacy_minus_1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>14.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficacy_minus_10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.82</td>\n",
       "      <td>13.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficacy_minus_3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.73</td>\n",
       "      <td>12.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efficacy_plus_1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efficacy_plus_10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efficacy_plus_3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        question_tag  exact_match  is_num  abs_diff\n",
       "0  efficacy_interval         0.00    1.00   1924.80\n",
       "1   efficacy_minus_1         0.01    0.69     14.88\n",
       "2  efficacy_minus_10         0.01    0.82     13.41\n",
       "3   efficacy_minus_3         0.02    0.73     12.67\n",
       "4    efficacy_plus_1         0.01    0.74     17.27\n",
       "5   efficacy_plus_10         0.01    0.80     20.54\n",
       "6    efficacy_plus_3         0.00    0.83     13.37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df[df[\"question_type\"] == \"efficacy\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=['exact_match', \"is_num\"] + [\"abs_diff\",]).round(2)\n",
    "# macro_averaging(df, multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", 'exact_match', \"is_num\"] + [\"abs_diff\",]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/users/zliu/mend/debug_exp_output/Llama-3.2-1B-common-date-year-after-eos-sft_clm-baseline_lr=1e-05_epoch=4.0/all_results_bio_syn_v2_text.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum of rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-country_3K_light_noshare_top3/country_syn/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_all_propagation_ood-question.xlsx\")\n",
    "print(\"Num of rows:\", len(df))\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str)\n",
    "\n",
    "# df.describe()[[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\",]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_type  [A]|[Q] Acc EM  [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM  \\\n",
       "0      efficacy            0.66            0.84            0.0           0.24   \n",
       "\n",
       "   exact_match  llm_accuracy  \n",
       "0         0.66           0.7  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macro_averaging(df, multi_level_averaging=[\"stage\", \"input\"], metrics=metrics) * 100\n",
    "macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"exact_match\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy_compare-city</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficacy_compare-continent</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficacy_compare-country</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficacy_continent</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efficacy_country</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 question_tag  exact_match  llm_accuracy\n",
       "0       efficacy_compare-city         0.80          0.82\n",
       "1  efficacy_compare-continent         0.70          0.73\n",
       "2    efficacy_compare-country         0.81          0.83\n",
       "3          efficacy_continent         0.58          0.62\n",
       "4            efficacy_country         0.43          0.49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df[df[\"question_type\"] == \"efficacy\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"exact_match\", \"llm_accuracy\"]).round(2)\n",
    "# macro_averaging(df[df[\"question_type\"] == \"ood_efficacy\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_content = []\n",
    "for i in range(len(df)):\n",
    "    r = df.iloc[i]\n",
    "    if any(x in r[\"predicted_answer\"].lower() for x in [\"yes\", \"no\"]):\n",
    "        valid_df_content.append(r)\n",
    "valid_df = pd.DataFrame(valid_df_content)\n",
    "len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ood_efficacy_border</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ood_efficacy_non_border</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              question_tag  [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  \\\n",
       "0      ood_efficacy_border            0.00            0.50         0.00   \n",
       "1  ood_efficacy_non_border            0.14            0.57         0.14   \n",
       "\n",
       "   llm_accuracy  \n",
       "0          0.52  \n",
       "1          0.23  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(valid_df, multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  llm_accuracy\n",
       "count            31.0           31.00         31.0         31.00\n",
       "mean              0.0            0.48          0.0          0.65\n",
       "std               0.0            0.09          0.0          0.43\n",
       "min               0.0            0.00          0.0          0.10\n",
       "25%               0.0            0.50          0.0          0.10\n",
       "50%               0.0            0.50          0.0          1.00\n",
       "75%               0.0            0.50          0.0          1.00\n",
       "max               0.0            0.50          0.0          1.00"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.describe()[[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\",]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_hop_efficacy_q0: 999\n",
      "single_hop_efficacy_q0: 802\n",
      "single_hop_efficacy_q1: 744\n"
     ]
    }
   ],
   "source": [
    "for q_tag, q_df in df[df[\"stage\"] == \"pre-edit\"].groupby(\"question_tag\"):\n",
    "    print(q_tag + \":\", sum(isinstance(x, str) for x in q_df[\"predicted_answer\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ids = [ex[\"id\"] for ex in io.load_jsonlines(f\"{vars.DATA_DIR}/musique_mend/2hop_musique_ans_v1.0_dev.jsonl\")[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"/data/users/zliu/mend/debug_exp_output/Llama-3.2-1B-common-country-eos-sft-country_syn-pretrain-midupper3-mlp_clm-baseline_lr=1e-05_epoch=4.0_tunable-params=midupper3-mlp/individual_results_ood_text\"\n",
    "all_df = pd.concat([pd.read_excel(f) for f in glob(f\"{save_dir}/*.xlsx\", recursive=True)])\n",
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_excel(f\"{save_dir}/../all_results_ood.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[\"is_num\"] = all_df[\"is_num\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer_idx</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>diff</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>1957.310000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>13.493151</td>\n",
       "      <td>8.041096</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.011492</td>\n",
       "      <td>30.458017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464823</td>\n",
       "      <td>0.446196</td>\n",
       "      <td>15.383183</td>\n",
       "      <td>18.859450</td>\n",
       "      <td>0.460566</td>\n",
       "      <td>0.161746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.750000</td>\n",
       "      <td>1932.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>1954.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.250000</td>\n",
       "      <td>1977.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       answer  predicted_answer_idx  exact_match      is_num  \\\n",
       "count  100.000000   100.000000                 100.0   100.000000  100.000000   \n",
       "mean    49.500000  1957.310000                   0.0     0.310000    0.730000   \n",
       "std     29.011492    30.458017                   0.0     0.464823    0.446196   \n",
       "min      0.000000  1904.000000                   0.0     0.000000    0.000000   \n",
       "25%     24.750000  1932.750000                   0.0     0.000000    0.000000   \n",
       "50%     49.500000  1954.500000                   0.0     0.000000    1.000000   \n",
       "75%     74.250000  1977.500000                   0.0     1.000000    1.000000   \n",
       "max     99.000000  2022.000000                   0.0     1.000000    1.000000   \n",
       "\n",
       "        abs_diff       diff  [A]|[Q] Acc EM  [A]|[Q] Acc PM  [Q][A] Acc EM  \\\n",
       "count  73.000000  73.000000      100.000000      100.000000          100.0   \n",
       "mean   13.493151   8.041096        0.300000        0.790000            0.0   \n",
       "std    15.383183  18.859450        0.460566        0.161746            0.0   \n",
       "min     0.000000 -48.000000        0.000000        0.500000            0.0   \n",
       "25%     0.000000   0.000000        0.000000        0.750000            0.0   \n",
       "50%    10.000000   0.000000        0.000000        0.750000            0.0   \n",
       "75%    20.000000  19.000000        1.000000        1.000000            0.0   \n",
       "max    61.000000  61.000000        1.000000        1.000000            0.0   \n",
       "\n",
       "       [Q][A] Acc PM  \n",
       "count     100.000000  \n",
       "mean        0.438087  \n",
       "std         0.068536  \n",
       "min         0.285714  \n",
       "25%         0.418731  \n",
       "50%         0.428571  \n",
       "75%         0.500000  \n",
       "max         0.611111  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>13.68</td>\n",
       "      <td>9.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_type  [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  is_num  \\\n",
       "0      efficacy            0.00            0.58         0.00    0.77   \n",
       "1   specificity            0.23            0.76         0.23    1.00   \n",
       "\n",
       "   abs_diff  diff  \n",
       "0     13.68  9.57  \n",
       "1      6.99  1.22  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(macro_averaging(all_df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", ] + [\"exact_match\", \"is_num\", \"abs_diff\", \"diff\"])).round(2) # llm_accuracy '[Q][A] Acc EM', \"[Q][A] Acc PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficacy_df = all_df[all_df[\"question_type\"] == \"efficacy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_efficacy_df = efficacy_df[efficacy_df[\"is_num\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in nan_efficacy_df.iterrows():\n",
    "#     print(row[\"question\"])\n",
    "#     print(row[\"predicted_answer\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# born_question = 0\n",
    "# for i, row in efficacy_df.iterrows():\n",
    "#     born_question += \"born\" in row[\"question\"]\n",
    "#     print(row[\"question\"])\n",
    "#     print(row[\"predicted_answer\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_question_efficacy = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-date-year-after_1K/bio_syn/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_n-question.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_1_question_efficacy = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-date-year-after_1K/bio_syn/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_n+1-question.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mend_1k_n_question_efficacy[mend_1k_n_question_efficacy[\"exact_match\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_question_correct_ids = set((mend_1k_n_question_efficacy[mend_1k_n_question_efficacy[\"exact_match\"] == 1][\"id\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_1_question_correct_ids = set(mend_1k_n_1_question_efficacy[mend_1k_n_1_question_efficacy[\"exact_match\"] == 1][\"id\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20, 28, 35, 38, 41, 46, 48, 50, 54, 56, 76, 82, 84, 89}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mend_1k_n_question_correct_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mend_1k_n_1_question_correct_ids.intersection(mend_1k_n_question_correct_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mend_1k_n_1_question_correct_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
