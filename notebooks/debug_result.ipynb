{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/datastor1/zliu/mend/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars, extractor\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import describe\n",
    "from thefuzz import fuzz\n",
    "\n",
    "\n",
    "from knowledge_propagation.modules.evaluators import (\n",
    "    ExactMatchEvaluator,\n",
    "    RougeEvaluator,\n",
    "    OpenAIEvaluator,\n",
    ")\n",
    "llm_evaluator = OpenAIEvaluator()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio syn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 12062\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['[A]|[Q] Acc EM', '[A]|[Q] Acc PM', 'exact_match'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_num\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_num\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum of rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[A]|[Q] Acc EM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[A]|[Q] Acc PM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexact_match\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_num\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabs_diff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['[A]|[Q] Acc EM', '[A]|[Q] Acc PM', 'exact_match'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/llama3.2-1B-common-date-year-after-eos-sft-bio_syn_v2-pretrain-midupper3/bio_syn_v2/base_n=100_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
    "df[\"is_num\"] = df[\"is_num\"].astype(float)\n",
    "print(\"Num of rows:\", len(df))\n",
    "df.describe()[[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"is_num\", \"abs_diff\",]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", 'exact_match', \"is_num\"] + [\"abs_diff\",]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interval</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minus_1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minus_10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>minus_3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plus_1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plus_10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>plus_3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_tag  [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  is_num  abs_diff\n",
       "0     interval            0.04            0.68         0.04     1.0     17.75\n",
       "1      minus_1            0.00            0.53         0.00     1.0     41.37\n",
       "2     minus_10            0.02            0.56         0.02     1.0     45.68\n",
       "3      minus_3            0.02            0.56         0.02     1.0     35.59\n",
       "4       plus_1            0.02            0.56         0.02     1.0     41.71\n",
       "5      plus_10            0.00            0.54         0.00     1.0     48.71\n",
       "6       plus_3            0.02            0.55         0.02     1.0     31.07"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macro_averaging(df[df[\"question_type\"] == \"efficacy\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", 'exact_match', \"is_num\"] + [\"abs_diff\",]).round(2)\n",
    "macro_averaging(df, multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", 'exact_match', \"is_num\"] + [\"abs_diff\",]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 15606\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-date-year-after_3K_light_noshare_mid-upper3/bio_syn_v2/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_all_propagation_ood-question.xlsx\")\n",
    "# /u/zliu/datastor1/mend/debug_exp_output/Llama-3.2-1B-common-date-year-after-eos-sft-bio_syn_v2-pretrain-all_clm-baseline_lr=1e-05_epoch=4.0/all_results_ood.xlsx\n",
    "# \n",
    "df[\"is_num\"] = df[\"is_num\"].astype(float)\n",
    "print(\"Num of rows:\", len(df))\n",
    "df.describe()[[\"is_num\", \"abs_diff\",]].round(2)\n",
    "\n",
    "def h(row):\n",
    "    if \"_year\" in row[\"question_tag\"]:\n",
    "        return \"year_facts\"\n",
    "    elif \"_place\" in row[\"question_tag\"]:\n",
    "        return \"country_facts\"\n",
    "    elif \"plus_\" in row[\"question_tag\"] :\n",
    "        return \"arithmetics(+)\"\n",
    "    else:\n",
    "        assert \"minus_\" in row[\"question_tag\"]\n",
    "        return \"arithmetics(-)\"\n",
    "df[\"question_type\"] = df.apply(h, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"EM\"] = df[\"abs_diff\"] == 0\n",
    "df[\"EM\"] = df[\"EM\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_answer_idx</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>diff</th>\n",
       "      <th>contain_ans</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>llm_accuracy</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7803.000000</td>\n",
       "      <td>7803.0</td>\n",
       "      <td>7803.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>7803.000000</td>\n",
       "      <td>3603.000000</td>\n",
       "      <td>3603.000000</td>\n",
       "      <td>7803.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.463540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538255</td>\n",
       "      <td>7.707143</td>\n",
       "      <td>3.149048</td>\n",
       "      <td>0.102268</td>\n",
       "      <td>7855.903414</td>\n",
       "      <td>0.237025</td>\n",
       "      <td>0.102268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.863414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498566</td>\n",
       "      <td>7.647942</td>\n",
       "      <td>10.391648</td>\n",
       "      <td>0.303020</td>\n",
       "      <td>4504.597657</td>\n",
       "      <td>0.294084</td>\n",
       "      <td>0.303020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3962.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7815.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11704.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15605.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  predicted_answer_idx       is_num     abs_diff  \\\n",
       "count  7803.000000                7803.0  7803.000000  4200.000000   \n",
       "mean     49.463540                   0.0     0.538255     7.707143   \n",
       "std      28.863414                   0.0     0.498566     7.647942   \n",
       "min       0.000000                   0.0     0.000000     0.000000   \n",
       "25%      24.500000                   0.0     0.000000     2.000000   \n",
       "50%      49.000000                   0.0     1.000000     6.000000   \n",
       "75%      74.000000                   0.0     1.000000    12.000000   \n",
       "max      99.000000                   0.0     1.000000    80.000000   \n",
       "\n",
       "              diff  contain_ans  __index_level_0__  llm_accuracy           EM  \n",
       "count  4200.000000  7803.000000        3603.000000   3603.000000  7803.000000  \n",
       "mean      3.149048     0.102268        7855.903414      0.237025     0.102268  \n",
       "std      10.391648     0.303020        4504.597657      0.294084     0.303020  \n",
       "min     -50.000000     0.000000         121.000000      0.100000     0.000000  \n",
       "25%      -2.000000     0.000000        3962.000000      0.100000     0.000000  \n",
       "50%       1.000000     0.000000        7815.000000      0.100000     0.000000  \n",
       "75%      10.000000     0.000000       11704.500000      0.100000     0.000000  \n",
       "max      80.000000     1.000000       15605.000000      1.000000     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"question_key\"] == \"unaliased_question\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arithmetics(+)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arithmetics(-)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country_facts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year_facts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_type  is_num  abs_diff  llm_accuracy\n",
       "0  arithmetics(+)     1.0      2.65           NaN\n",
       "1  arithmetics(-)     1.0      2.13           NaN\n",
       "2   country_facts     0.0       NaN          0.27\n",
       "3      year_facts     0.0       NaN          0.19"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[ \"is_num\", \"abs_diff\", \"llm_accuracy\"]).round(2)\n",
    "# macro_averaging(df[df[\"question_key\"] == \"question\"], multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"is_num\", \"abs_diff\", \"llm_accuracy\"]).round(2)\n",
    "macro_averaging(df[df[\"question_key\"] == \"unaliased_question\"], multi_level_averaging=[\"question_type\", \"id\"], metrics=[ \"is_num\", \"abs_diff\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df[(df[\"question_key\"] == \"question\") & (df[\"question_type\"] == \"country_facts\") & (df[\"llm_accuracy\"] > 0.1)][\"predicted_answer\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7706"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3853*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy_common_fact_birth_place</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficacy_common_fact_birth_year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficacy_common_fact_career_year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficacy_common_fact_death_year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efficacy_minus_11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efficacy_minus_13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efficacy_minus_14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efficacy_minus_15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>efficacy_minus_16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>efficacy_minus_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>efficacy_minus_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>efficacy_plus_11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>efficacy_plus_13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>efficacy_plus_14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.18</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>efficacy_plus_15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.58</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>efficacy_plus_16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>efficacy_plus_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>efficacy_plus_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_tag  is_num  abs_diff  llm_accuracy\n",
       "0   efficacy_common_fact_birth_place     0.0       NaN          0.27\n",
       "1    efficacy_common_fact_birth_year     0.0       NaN          0.63\n",
       "2   efficacy_common_fact_career_year     0.0       NaN          0.57\n",
       "3    efficacy_common_fact_death_year     0.0       NaN          0.56\n",
       "4                  efficacy_minus_11     1.0      3.76          0.52\n",
       "5                  efficacy_minus_13     1.0      5.49          0.60\n",
       "6                  efficacy_minus_14     1.0      6.29          0.60\n",
       "7                  efficacy_minus_15     1.0      7.90          0.44\n",
       "8                  efficacy_minus_16     1.0      7.58          0.45\n",
       "9                   efficacy_minus_4     1.0      4.49          0.49\n",
       "10                  efficacy_minus_5     1.0      4.63          0.38\n",
       "11                  efficacy_plus_11     1.0      9.99          0.12\n",
       "12                  efficacy_plus_13     1.0     11.90          0.11\n",
       "13                  efficacy_plus_14     1.0     13.18          0.11\n",
       "14                  efficacy_plus_15     1.0     12.58          0.11\n",
       "15                  efficacy_plus_16     1.0     14.82          0.14\n",
       "16                   efficacy_plus_4     1.0      2.88          0.13\n",
       "17                   efficacy_plus_5     1.0      3.51          0.21"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macro_averaging(df[df[\"question_key\"] == \"question\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[ \"is_num\", \"abs_diff\", \"llm_accuracy\"]).round(2)\n",
    "macro_averaging(df[df[\"question_key\"] == \"unaliased_question\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[ \"is_num\", \"abs_diff\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 7706\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-country_3K_light_noshare_top3/country_syn/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_all_propagation_ood-question.xlsx\")\n",
    "print(\"Num of rows:\", len(df))\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str)\n",
    "\n",
    "# df.describe()[[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\",]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[('[A]|[Q] Acc EM', 'mean'), ('[A]|[Q] Acc PM', 'mean'), ('[Q][A] Acc EM', 'mean'), ('[Q][A] Acc PM', 'mean'), ('exact_match', 'mean')] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# macro_averaging(df, multi_level_averaging=[\"stage\", \"input\"], metrics=metrics) * 100\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmacro_averaging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_level_averaging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[A]|[Q] Acc EM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[A]|[Q] Acc PM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[Q][A] Acc EM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[Q][A] Acc PM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexact_match\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/datastor1/KE-by-CP/experiments/musique/inference_only.py:80\u001b[0m, in \u001b[0;36mmacro_averaging\u001b[0;34m(df, metrics, multi_level_averaging)\u001b[0m\n\u001b[1;32m     76\u001b[0m extracted_multi_level_cols \u001b[38;5;241m=\u001b[39m [[m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(multi_level_averaging) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# first take the mean over each generation,\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# and, only take `mean` of `rouge1` and  `llm_accuracy` column groups\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     df_over_cols \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_level_averaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mextracted_multi_level_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# remove the multi-level column indices, since there's only one sub-level -- \"mean\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     df_over_cols\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df_over_cols\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2766\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(key, indexer, axis_name)\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[0;32m-> 2766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2786\u001b[0m, in \u001b[0;36mMultiIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2784\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[('[A]|[Q] Acc EM', 'mean'), ('[A]|[Q] Acc PM', 'mean'), ('[Q][A] Acc EM', 'mean'), ('[Q][A] Acc PM', 'mean'), ('exact_match', 'mean')] not in index\""
     ]
    }
   ],
   "source": [
    "# macro_averaging(df, multi_level_averaging=[\"stage\", \"input\"], metrics=metrics) * 100\n",
    "macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"exact_match\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy_compare-city</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficacy_compare-continent</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficacy_compare-country</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficacy_continent</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efficacy_country</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 question_tag  exact_match  llm_accuracy\n",
       "0       efficacy_compare-city         0.80          0.82\n",
       "1  efficacy_compare-continent         0.70          0.73\n",
       "2    efficacy_compare-country         0.81          0.83\n",
       "3          efficacy_continent         0.58          0.62\n",
       "4            efficacy_country         0.43          0.49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df[df[\"question_type\"] == \"efficacy\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"exact_match\", \"llm_accuracy\"]).round(2)\n",
    "# macro_averaging(df[df[\"question_type\"] == \"ood_efficacy\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 15606\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/llama3.2-1B-common-date-year-after-eos-sft/bio_syn_v2_ood/base_n=100_prompt=no_w-gen_wo-icl_ice=False.xlsx\")\n",
    "print(\"Num of rows:\", len(df))\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'common_fact_birth_place': 1289,\n",
       " 'common_fact_career_year': 785,\n",
       " 'common_fact_death_year': 785,\n",
       " 'common_fact_birth_year': 744,\n",
       " 'minus_11': 300,\n",
       " 'minus_13': 300,\n",
       " 'minus_14': 300,\n",
       " 'minus_15': 300,\n",
       " 'minus_16': 300,\n",
       " 'minus_4': 300,\n",
       " 'minus_5': 300,\n",
       " 'plus_11': 300,\n",
       " 'plus_13': 300,\n",
       " 'plus_14': 300,\n",
       " 'plus_15': 300,\n",
       " 'plus_16': 300,\n",
       " 'plus_4': 300,\n",
       " 'plus_5': 300}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df[df[\"question_key\"] == \"question\"])\n",
    "df[df[\"question_key\"] == \"question\"][\"question_tag\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy_common_fact_birth_place</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficacy_common_fact_career_place</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficacy_common_fact_death_place</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_tag  llm_accuracy\n",
       "0   efficacy_common_fact_birth_place          0.28\n",
       "1  efficacy_common_fact_career_place          0.28\n",
       "2   efficacy_common_fact_death_place          0.28"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macro_averaging(df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[ \"is_num\", \"abs_diff\", \"llm_accuracy\"]).round(2)\n",
    "# macro_averaging(df[df[\"question_key\"] == \"question\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"llm_accuracy\"]).round(2)\n",
    "macro_averaging(df[df[\"question_key\"] == \"unaliased_question\"], multi_level_averaging=[\"question_tag\", \"id\"], metrics=[ \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_content = []\n",
    "for i in range(len(df)):\n",
    "    r = df.iloc[i]\n",
    "    if any(x in r[\"predicted_answer\"].lower() for x in [\"yes\", \"no\"]):\n",
    "        valid_df_content.append(r)\n",
    "valid_df = pd.DataFrame(valid_df_content)\n",
    "len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_tag</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ood_efficacy_border</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ood_efficacy_non_border</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              question_tag  [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  \\\n",
       "0      ood_efficacy_border            0.00            0.50         0.00   \n",
       "1  ood_efficacy_non_border            0.14            0.57         0.14   \n",
       "\n",
       "   llm_accuracy  \n",
       "0          0.52  \n",
       "1          0.23  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(valid_df, multi_level_averaging=[\"question_tag\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  llm_accuracy\n",
       "count            31.0           31.00         31.0         31.00\n",
       "mean              0.0            0.48          0.0          0.65\n",
       "std               0.0            0.09          0.0          0.43\n",
       "min               0.0            0.00          0.0          0.10\n",
       "25%               0.0            0.50          0.0          0.10\n",
       "50%               0.0            0.50          0.0          1.00\n",
       "75%               0.0            0.50          0.0          1.00\n",
       "max               0.0            0.50          0.0          1.00"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.describe()[[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", \"exact_match\", \"llm_accuracy\",]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_hop_efficacy_q0: 999\n",
      "single_hop_efficacy_q0: 802\n",
      "single_hop_efficacy_q1: 744\n"
     ]
    }
   ],
   "source": [
    "for q_tag, q_df in df[df[\"stage\"] == \"pre-edit\"].groupby(\"question_tag\"):\n",
    "    print(q_tag + \":\", sum(isinstance(x, str) for x in q_df[\"predicted_answer\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ids = [ex[\"id\"] for ex in io.load_jsonlines(f\"{vars.DATA_DIR}/musique_mend/2hop_musique_ans_v1.0_dev.jsonl\")[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"/u/zliu/datastor1/mend/debug_exp_output/Llama-3.2-1B-common-date-year-after-eos-sft-bio_syn_v2-pretrain-all_clm-baseline_lr=1e-05_epoch=4.0/individual_results_bio_syn_data_v2_ood_text\"\n",
    "all_df = pd.concat([pd.read_excel(f) for f in glob(f\"{save_dir}/*.xlsx\", recursive=True)])\n",
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_excel(f\"{save_dir}/../all_results_ood.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[\"is_num\"] = all_df[\"is_num\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer_idx</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>diff</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>1957.310000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>13.493151</td>\n",
       "      <td>8.041096</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.011492</td>\n",
       "      <td>30.458017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464823</td>\n",
       "      <td>0.446196</td>\n",
       "      <td>15.383183</td>\n",
       "      <td>18.859450</td>\n",
       "      <td>0.460566</td>\n",
       "      <td>0.161746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.750000</td>\n",
       "      <td>1932.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>1954.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.250000</td>\n",
       "      <td>1977.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       answer  predicted_answer_idx  exact_match      is_num  \\\n",
       "count  100.000000   100.000000                 100.0   100.000000  100.000000   \n",
       "mean    49.500000  1957.310000                   0.0     0.310000    0.730000   \n",
       "std     29.011492    30.458017                   0.0     0.464823    0.446196   \n",
       "min      0.000000  1904.000000                   0.0     0.000000    0.000000   \n",
       "25%     24.750000  1932.750000                   0.0     0.000000    0.000000   \n",
       "50%     49.500000  1954.500000                   0.0     0.000000    1.000000   \n",
       "75%     74.250000  1977.500000                   0.0     1.000000    1.000000   \n",
       "max     99.000000  2022.000000                   0.0     1.000000    1.000000   \n",
       "\n",
       "        abs_diff       diff  [A]|[Q] Acc EM  [A]|[Q] Acc PM  [Q][A] Acc EM  \\\n",
       "count  73.000000  73.000000      100.000000      100.000000          100.0   \n",
       "mean   13.493151   8.041096        0.300000        0.790000            0.0   \n",
       "std    15.383183  18.859450        0.460566        0.161746            0.0   \n",
       "min     0.000000 -48.000000        0.000000        0.500000            0.0   \n",
       "25%     0.000000   0.000000        0.000000        0.750000            0.0   \n",
       "50%    10.000000   0.000000        0.000000        0.750000            0.0   \n",
       "75%    20.000000  19.000000        1.000000        1.000000            0.0   \n",
       "max    61.000000  61.000000        1.000000        1.000000            0.0   \n",
       "\n",
       "       [Q][A] Acc PM  \n",
       "count     100.000000  \n",
       "mean        0.438087  \n",
       "std         0.068536  \n",
       "min         0.285714  \n",
       "25%         0.418731  \n",
       "50%         0.428571  \n",
       "75%         0.500000  \n",
       "max         0.611111  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>is_num</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>13.68</td>\n",
       "      <td>9.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_type  [A]|[Q] Acc EM  [A]|[Q] Acc PM  exact_match  is_num  \\\n",
       "0      efficacy            0.00            0.58         0.00    0.77   \n",
       "1   specificity            0.23            0.76         0.23    1.00   \n",
       "\n",
       "   abs_diff  diff  \n",
       "0     13.68  9.57  \n",
       "1      6.99  1.22  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(macro_averaging(all_df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", ] + [\"exact_match\", \"is_num\", \"abs_diff\", \"diff\"])).round(2) # llm_accuracy '[Q][A] Acc EM', \"[Q][A] Acc PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficacy_df = all_df[all_df[\"question_type\"] == \"efficacy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_efficacy_df = efficacy_df[efficacy_df[\"is_num\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in nan_efficacy_df.iterrows():\n",
    "#     print(row[\"question\"])\n",
    "#     print(row[\"predicted_answer\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# born_question = 0\n",
    "# for i, row in efficacy_df.iterrows():\n",
    "#     born_question += \"born\" in row[\"question\"]\n",
    "#     print(row[\"question\"])\n",
    "#     print(row[\"predicted_answer\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_question_efficacy = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-date-year-after_1K/bio_syn/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_n-question.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_1_question_efficacy = pd.read_excel(\"/u/zliu/datastor1/mend/debug_exp_output/common-date-year-after_1K/bio_syn/mend_eval_loss=clm_input=seen_n=100_prompt=no_w-gen_wo-icl_e_n+1-question.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mend_1k_n_question_efficacy[mend_1k_n_question_efficacy[\"exact_match\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_question_correct_ids = set((mend_1k_n_question_efficacy[mend_1k_n_question_efficacy[\"exact_match\"] == 1][\"id\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mend_1k_n_1_question_correct_ids = set(mend_1k_n_1_question_efficacy[mend_1k_n_1_question_efficacy[\"exact_match\"] == 1][\"id\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20, 28, 35, 38, 41, 46, 48, 50, 54, 56, 76, 82, 84, 89}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mend_1k_n_question_correct_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mend_1k_n_1_question_correct_ids.intersection(mend_1k_n_question_correct_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mend_1k_n_1_question_correct_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
