{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 144,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                  "  from .autonotebook import tqdm as notebook_tqdm\n"
               ]
            }
         ],
         "source": [
            "from glob import glob\n",
            "# import sys\n",
            "from dotenv import load_dotenv\n",
            "\n",
            "load_dotenv()\n",
            "# sys.path.append(\"/u/zliu/datastor1/KE-by-CP\")\n",
            "import pandas as pd\n",
            "# from experiments.musique.inference_only import macro_averaging\n",
            "from knowledge_propagation.utils import io, vars, extractor\n",
            "import os\n",
            "import numpy as np\n",
            "from tqdm import tqdm\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n",
            "from scipy.stats import describe\n",
            "from thefuzz import fuzz\n",
            "\n",
            "from datasets import load_dataset, load_from_disk\n",
            "\n",
            "from copy import deepcopy\n",
            "\n",
            "from dateutil.parser import parse\n",
            "from dateutil.parser import ParserError\n",
            "\n",
            "from collections import defaultdict\n",
            "import string\n",
            "\n",
            "import re"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "1948"
                  ]
               },
               "execution_count": 43,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "popular_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/popular.json\")\n",
            "assert len(popular_examples) == 1\n",
            "popular_examples = popular_examples[0]\n",
            "\n",
            "random_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/random.json\")\n",
            "assert len(random_examples) == 1\n",
            "random_examples = random_examples[0]\n",
            "\n",
            "recent_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/recent.json\")\n",
            "assert len(recent_examples) == 1\n",
            "recent_examples = recent_examples[0]\n",
            "\n",
            "ripple_edits_examples = recent_examples #  +  # random_examples #  + random_examples\n",
            "len(ripple_edits_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "292.2"
                  ]
               },
               "execution_count": 44,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "0.15 * len(ripple_edits_examples)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 45,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "# strong examples: 1318\n",
                  "# weak examples: 575\n",
                  "# invalid: 55\n"
               ]
            }
         ],
         "source": [
            "non_zero_outerloop_count = 0\n",
            "strong_meta_examples = []\n",
            "weak_meta_examples = []\n",
            "for example in ripple_edits_examples:\n",
            "    outerloop_instances = example[\"Logical_Generalization\"] + example[\"Compositionality_I\"] + example[\"Compositionality_II\"] + example[\"Subject_Aliasing\"]\n",
            "    # for ins in outerloop_instances:\n",
            "        # assert len(ins[\"test_queries\"]) == 1\n",
            "    locality_instances = example[\"Relation_Specificity\"] + example[\"Forgetfulness\"] \n",
            "    # non_zero_outerloop_count += len(outerloop_instances) > 0\n",
            "    if len(outerloop_instances) > 0 and len(locality_instances) > 0:\n",
            "        \n",
            "        efficacy_queries = [q for instance in outerloop_instances for q in instance[\"test_queries\"]]\n",
            "        efficacy_queries = [q for q in efficacy_queries if len(q[\"answers\"]) > 0]\n",
            "        efficacy_queries = [q for q in efficacy_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
            "        assert all([len(q[\"prompt\"].strip()) > 0 for q in efficacy_queries])\n",
            "        \n",
            "        if len(efficacy_queries) == 0:\n",
            "            continue\n",
            "        \n",
            "        locality_queries = [q for instance in locality_instances for q in instance[\"test_queries\"]]\n",
            "        locality_queries = [q for q in locality_queries if len(q[\"answers\"]) > 0]\n",
            "        locality_queries = [q for q in locality_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
            "        assert all([len(q[\"prompt\"].strip()) > 0 for q in locality_queries])\n",
            "        \n",
            "        assert len(locality_queries) > 0\n",
            "        \n",
            "        strong_meta_examples.append(example)\n",
            "    elif len(locality_instances) == 0:\n",
            "        \n",
            "        efficacy_queries = [q for instance in outerloop_instances for q in instance[\"test_queries\"]]\n",
            "        efficacy_queries = [q for q in efficacy_queries if len(q[\"answers\"]) > 0]\n",
            "        efficacy_queries = [q for q in efficacy_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
            "        assert all([len(q[\"prompt\"].strip()) > 0 for q in efficacy_queries])\n",
            "        \n",
            "        if len(efficacy_queries) == 0:\n",
            "            continue\n",
            "        \n",
            "        weak_meta_examples.append(example)\n",
            "    else:\n",
            "        locality_queries = [q for instance in locality_instances for q in instance[\"test_queries\"]]\n",
            "        locality_queries = [q for q in locality_queries if len(q[\"answers\"]) > 0]\n",
            "        locality_queries = [q for q in locality_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
            "        assert all([len(q[\"prompt\"].strip()) > 0 for q in locality_queries])\n",
            "        \n",
            "        assert len(locality_queries) > 0\n",
            "        \n",
            "        weak_meta_examples.append(example)\n",
            "        \n",
            "print(\"# strong examples:\", len(strong_meta_examples))\n",
            "print(\"# weak examples:\", len(weak_meta_examples))\n",
            "print(\"# invalid:\", len(ripple_edits_examples) - len(strong_meta_examples) - len(weak_meta_examples))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.1026694045174538"
                  ]
               },
               "execution_count": 47,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "200 / len(ripple_edits_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [],
         "source": [
            "n_test = 200\n",
            "n_valid = 200\n",
            "np.random.shuffle(strong_meta_examples)\n",
            "np.random.shuffle(weak_meta_examples)\n",
            "\n",
            "test_examples = strong_meta_examples[:n_test]\n",
            "valid_examples = strong_meta_examples[n_test:n_test+n_valid]\n",
            "train_examples = strong_meta_examples[n_test+n_valid:] + weak_meta_examples\n",
            "np.random.shuffle(train_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 51,
         "metadata": {},
         "outputs": [],
         "source": [
            "# subset = \"recent\"\n",
            "\n",
            "# os.makedirs(f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}\", exist_ok=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 52,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(train_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}/train.jsonl\")\n",
            "# io.dump_jsonlines(valid_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}/valid.jsonl\")\n",
            "# io.dump_jsonlines(test_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}/test.jsonl\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### merge the train/dev/test for all subsets"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 200,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "# train examples: 3686\n",
                  "# valid examples: 500\n",
                  "# test examples: 500\n"
               ]
            }
         ],
         "source": [
            "train_examples = []\n",
            "valid_examples = []\n",
            "test_examples = []\n",
            "for subset in [\"popular\", \"recent\", \"random\"]:\n",
            "    train_examples += io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}/train.jsonl\")\n",
            "    valid_examples += io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}/valid.jsonl\")\n",
            "    test_examples += io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/{subset}/test.jsonl\")\n",
            "print(\"# train examples:\", len(train_examples))\n",
            "print(\"# valid examples:\", len(valid_examples))\n",
            "print(\"# test examples:\", len(test_examples))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# os.makedirs(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all\", exist_ok=True)\n",
            "# io.dump_jsonlines(train_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/train.jsonl\")\n",
            "# io.dump_jsonlines(valid_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/valid.jsonl\")\n",
            "# io.dump_jsonlines(test_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/test.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# recent_popular_train = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/train.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# random_train = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_random/train.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(recent_popular_train + random_train, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/train_w_random.jsonl\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Check spurious correlation in dataaset (answer verbtaim in edit)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 139,
         "metadata": {},
         "outputs": [],
         "source": [
            "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/recent/train.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 140,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "1493"
                  ]
               },
               "execution_count": 140,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 141,
         "metadata": {},
         "outputs": [],
         "source": [
            "non_zero_outerloop_count = 0\n",
            "meta_examples = []\n",
            "propagation2substring_count = defaultdict(int)\n",
            "propagation2verbtaim_count = defaultdict(int)\n",
            "propagation2count = defaultdict(int)\n",
            "# strong_meta_examples = []\n",
            "# weak_meta_examples = []\n",
            "count_rel = defaultdict(int)\n",
            "count_prop_types = defaultdict(int)\n",
            "\n",
            "for example in train_examples[:]:\n",
            "    outerloop_instances = example[\"Logical_Generalization\"] + example[\"Compositionality_I\"] + example[\"Compositionality_II\"] + example[\"Subject_Aliasing\"]\n",
            "    # for ins in outerloop_instances:\n",
            "        # assert len(ins[\"test_queries\"]) == 1\n",
            "    locality_instances = example[\"Relation_Specificity\"] + example[\"Forgetfulness\"] \n",
            "    example[\"edit\"][\"text\"] = example[\"edit\"][\"prompt\"]\n",
            "    meta_examples.append(example[\"edit\"])\n",
            "    \n",
            "    outerloop_queries = []\n",
            "    for k in [\"Logical_Generalization\", \"Compositionality_I\", \"Compositionality_II\", \"Subject_Aliasing\"]:\n",
            "        for instance in example[k]:\n",
            "            for q in instance[\"test_queries\"]:\n",
            "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
            "                    q[\"question_type\"] = k\n",
            "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
            "                    assert len(ans_candidates) > 0\n",
            "                    assert q[\"prompt\"][-1] not in \".\",  q[\"prompt\"]\n",
            "                    q[\"text\"] = q[\"prompt\"] + \" \" + ans_candidates[0]\n",
            "                    propagation2count[k] += 1\n",
            "                    propagation2verbtaim_count[k] += int(ans_candidates[0] in example[\"edit\"][\"text\"])\n",
            "                    propagation2substring_count[k] += int(any(a in q[\"prompt\"] for a in ans_candidates))\n",
            "                    outerloop_queries.append(q)\n",
            "    for outer_q in outerloop_queries:\n",
            "        count_prop_types[\"efficacy::\"+ outer_q[\"question_type\"]] += 1\n",
            "        count_rel[\"efficacy::\"+ outer_q[\"relation\"]] += 1\n",
            "    # assert len(outerloop_queries) > 0\n",
            "    meta_examples.extend(outerloop_queries)\n",
            "    \n",
            "    locality_queries = []\n",
            "    for k in [\"Relation_Specificity\", \"Forgetfulness\"]:\n",
            "        for instance in example[k]:\n",
            "            for q in instance[\"test_queries\"]:\n",
            "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
            "                    q[\"question_type\"] = k\n",
            "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
            "                    assert len(ans_candidates) > 0\n",
            "                    assert q[\"prompt\"][-1] not in string.punctuation\n",
            "                    q[\"text\"] = q[\"prompt\"] + \" \" + ans_candidates[0]\n",
            "                    propagation2count[k] += 1\n",
            "                    propagation2verbtaim_count[k] += int(ans_candidates[0] in example[\"edit\"][\"text\"])\n",
            "                    propagation2substring_count[k] += int(any(a in q[\"prompt\"] for a in ans_candidates))\n",
            "                    locality_queries.append(q)\n",
            "    for loc_q in locality_queries:\n",
            "        count_prop_types[\"specificity::\"+ loc_q[\"question_type\"]] += 1\n",
            "        count_rel[\"specificity::\"+ loc_q[\"relation\"]] += 1\n",
            "    \n",
            "    meta_examples.extend(locality_queries)\n",
            "    \n",
            "    # assert len(locality_queries) > 0\n",
            "        \n",
            "# print(\"# strong examples\", len(strong_meta_examples))\n",
            "# print(\"# weak examples\", len(weak_meta_examples))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 143,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(int,\n",
                     "            {'Logical_Generalization': 813,\n",
                     "             'Compositionality_I': 7037,\n",
                     "             'Subject_Aliasing': 892,\n",
                     "             'Relation_Specificity': 5509,\n",
                     "             'Forgetfulness': 951,\n",
                     "             'Compositionality_II': 751})"
                  ]
               },
               "execution_count": 143,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "propagation2count"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 129,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'Subject_Aliasing': 100.0,\n",
                     " 'Relation_Specificity': 1.1,\n",
                     " 'Logical_Generalization': 58.5,\n",
                     " 'Compositionality_I': 2.9,\n",
                     " 'Forgetfulness': 0.0,\n",
                     " 'Compositionality_II': 100.0}"
                  ]
               },
               "execution_count": 129,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "{k: round(propagation2verbtaim_count[k] / propagation2count[k] * 100, 1) for k in propagation2count}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "38"
                  ]
               },
               "execution_count": 32,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "119- 81"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(int,\n",
                     "            {'Logical_Generalization': 9,\n",
                     "             'Relation_Specificity': 8,\n",
                     "             'Compositionality_I': 28,\n",
                     "             'Compositionality_II': 10,\n",
                     "             'Subject_Aliasing': 1,\n",
                     "             'Forgetfulness': 81})"
                  ]
               },
               "execution_count": 30,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "propagation2substring_count"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'Logical_Generalization': 7.4,\n",
                     " 'Relation_Specificity': 0.9,\n",
                     " 'Compositionality_I': 2.8,\n",
                     " 'Compositionality_II': 9.4,\n",
                     " 'Subject_Aliasing': 0.3,\n",
                     " 'Forgetfulness': 68.1}"
                  ]
               },
               "execution_count": 29,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "{k: round(propagation2substring_count[k] / propagation2count[k] * 100, 1) for k in propagation2count}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "3686"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(ds)\n",
            "len(test_data)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 109,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Dataset({\n",
                     "    features: ['prompt', 'subject_id', 'relation', 'target_id', 'original_fact', 'context', 'paraphrase', 'object', 'subject'],\n",
                     "    num_rows: 500\n",
                     "})"
                  ]
               },
               "execution_count": 109,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "ds"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 311,
         "metadata": {},
         "outputs": [],
         "source": [
            "ent_label2id = io.load_json(\"/data/users/zliu/RippleEdits/src/wikidata/ent_label2id.json\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 543,
         "metadata": {},
         "outputs": [],
         "source": [
            "split = \"test\"\n",
            "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 544,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ent_label2id[\"Enrico Chiesa\"] = \"Q345026\"\n",
            "# ent_label2id[\"Jimmy Carter\"] = \"Q23685\"\n",
            "# ent_label2id[\"Adam Rich\"] = \"Q1762781\"\n",
            "# ent_label2id[\"Croatia national association football team\"] = \"Q134479\"\n",
            "# ent_label2id[\"\"] = \"Q16083337\"\n",
            "# ent_label2id[\"Milivoje 'Misko' Milojevic\"] = \"Q108063841\"\n",
            "# ent_label2id[\"field hockey at the 2020 Summer Olympics\"] = \"Q32646403\"\n",
            "\n",
            "id2ent_label = {v: k for k, v in ent_label2id.items()}\n",
            "# ent_label2id[\"Amānullāh Khān\"] == \"Q153620\"\n",
            "# id2ent_label[\"Q153620\"] = \"Amānullāh Khān\"\n",
            "# ent_label2id[\"Princess Amöena Amalie of Bentheim-Tecklenburg\"] = \"Q22077731\"\n",
            "# id2ent_label[\"Q22077731\"] = \"Princess Amöena Amalie of Bentheim-Tecklenburg\"\n",
            "# assert len(ent_label2id) == len(id2ent_label)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 527,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ent_label2id[\"Princess Amöena Amalie of Bentheim-Tecklenburg\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 528,
         "metadata": {},
         "outputs": [],
         "source": [
            "# id2ent_label[\"Q134479\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 529,
         "metadata": {},
         "outputs": [],
         "source": [
            "from qwikidata.linked_data_interface import get_entity_dict_from_api\n",
            "from qwikidata.entity import WikidataItem\n",
            "import functools\n",
            "\n",
            "@functools.lru_cache()\n",
            "def wikidata_item_given_id(ent_id: str):\n",
            "    try:\n",
            "        return WikidataItem(get_entity_dict_from_api(ent_id))\n",
            "    except:\n",
            "        return None\n",
            "\n",
            "def get_label(ent_id: str):\n",
            "    if isinstance(ent_id, list):\n",
            "        if len(ent_id) > 0:\n",
            "            ent_id = ent_id[0]\n",
            "        else:\n",
            "            return ent_id\n",
            "    if ent_id[0] != 'Q':\n",
            "        return ent_id\n",
            "    item = wikidata_item_given_id(ent_id)\n",
            "    if item is not None:\n",
            "        label = item.get_label()\n",
            "    else:\n",
            "        return ent_id\n",
            "    if label is None:\n",
            "        return ent_id\n",
            "    return label"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 547,
         "metadata": {},
         "outputs": [],
         "source": [
            "prompt2subjtarg = io.load_json(\"/data/users/zliu/mend/notebooks/prompt2subject_target.json\")\n",
            "\n",
            "# for i in manual_process_ids:\n",
            "#     if test_data[i][\"edit\"][\"prompt\"] in prompt2subjtarg:\n",
            "#         continue\n",
            "#     print(i)\n",
            "#     print(test_data[i][\"edit\"][\"prompt\"])\n",
            "#     subject_id = test_data[i][\"edit\"][\"subject_id\"]\n",
            "#     target_id = test_data[i][\"edit\"][\"target_id\"]\n",
            "#     print(subject_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"subject_id\"]], \"@@@\", target_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"target_id\"]])\n",
            "#     print()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "ds = load_from_disk(\"/data/users/zliu/KE-by-CP/data/ripple_edits/meta_train/all/train_w_subjtarget.hf\")\n",
            "train_prompt2subjtarg = {}\n",
            "for i in range(len(ds)):\n",
            "    original_test = deepcopy(ds[i])\n",
            "    assert \"subject_id\" in original_test\n",
            "    assert \"target_id\" in original_test\n",
            "    subject = original_test[\"subject\"]\n",
            "    target = original_test[\"object\"]\n",
            "        \n",
            "    train_prompt2subjtarg[original_test[\"prompt\"]] = [subject, target]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 531,
         "metadata": {},
         "outputs": [],
         "source": [
            "# prompt2subjtarg[\"The place of birth of Eddie Van Halen is Caucasia.\"] = [\"Eddie Van Halen\", \"Caucasia\"]\n",
            "# prompt2subjtarg[\"The name of the country which Croatia national association football team is associated with is Moscow.\"] = [\"Croatia national association football team\", \"Moscow\"]\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 555,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_json(prompt2subjtarg, \"/data/users/zliu/mend/notebooks/prompt2subject_target.json\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 556,
         "metadata": {},
         "outputs": [],
         "source": [
            "# prompt2subjtarg = train_prompt2subjtarg"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 577,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 0/500 [00:00<?, ?it/s]"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 500/500 [00:00<00:00, 902.95it/s]\n"
               ]
            }
         ],
         "source": [
            "new_test_data = []\n",
            "manual_process_ids = []\n",
            "count = 0\n",
            "for i in tqdm(range(len(test_data))):\n",
            "    original_test = deepcopy(test_data[i])\n",
            "    assert \"subject_id\" in original_test[\"edit\"]\n",
            "    assert \"target_id\" in original_test[\"edit\"]\n",
            "    \n",
            "    subject_id = original_test[\"edit\"][\"subject_id\"]\n",
            "    target_id = original_test[\"edit\"][\"target_id\"]\n",
            "    if original_test[\"edit\"][\"prompt\"] in prompt2subjtarg:\n",
            "        subject, target = prompt2subjtarg[original_test[\"edit\"][\"prompt\"]]\n",
            "        original_test[\"edit\"][\"subject\"] = subject\n",
            "        original_test[\"edit\"][\"target\"] = target\n",
            "        new_test_data.append(original_test)\n",
            "        continue\n",
            "    elif original_test[\"edit\"][\"prompt\"] == \"The name of the architect of  is Aleksei Benois.\":\n",
            "        original_test[\"edit\"][\"prompt\"] = \"The name of the architect of Palace of the Emir of Bukhara is Aleksei Benois.\"\n",
            "        original_test[\"edit\"][\"subject\"] = \"Palace of the Emir of Bukhara\"\n",
            "        original_test[\"edit\"][\"target\"] = \"Aleksei Benois\"\n",
            "        new_test_data.append(original_test)\n",
            "        continue\n",
            "    elif original_test[\"edit\"][\"prompt\"] == \"The name of the field of work of Michael H. Hart is astronomy.\":\n",
            "        original_test[\"edit\"][\"subject\"] = \"Michael H. Hart\"\n",
            "        original_test[\"edit\"][\"target\"] = \"astronomy\"\n",
            "        new_test_data.append(original_test)\n",
            "        continue\n",
            "    elif original_test[\"edit\"][\"prompt\"] == \"The name of the screenwriter of  is Laurent-Frédéric Bollée.\":\n",
            "        original_test[\"edit\"][\"prompt\"] = \"The name of the screenwriter of The bomb : the weapon that changed the world is Laurent-Frédéric Bollée.\"\n",
            "        original_test[\"edit\"][\"subject\"] = \"The bomb : the weapon that changed the world\"\n",
            "        original_test[\"edit\"][\"target\"] = \"Laurent-Frédéric Bollée\"\n",
            "        new_test_data.append(original_test)\n",
            "        continue\n",
            "    elif original_test[\"edit\"][\"prompt\"] == \"The name of the director of  is Milivoje 'Misko' Milojevic.\":\n",
            "        original_test[\"edit\"][\"subject\"] = \"\"\n",
            "        original_test[\"edit\"][\"target\"] = \"Milivoje 'Misko' Milojevic\"\n",
            "        new_test_data.append(original_test)\n",
            "        continue\n",
            "    \n",
            "    if subject_id in id2ent_label and target_id in id2ent_label:\n",
            "        subject = id2ent_label[subject_id]\n",
            "        target = id2ent_label[target_id]\n",
            "    else:\n",
            "        subject = get_label(subject_id)\n",
            "        target = get_label(target_id)\n",
            "       \n",
            "        \n",
            "    \n",
            "    if subject not in original_test[\"edit\"][\"prompt\"] or target not in original_test[\"edit\"][\"prompt\"] or target + \".\" not in original_test[\"edit\"][\"prompt\"]:\n",
            "        manual_process_ids.append(i)\n",
            "        continue\n",
            "    \n",
            "    original_test[\"edit\"][\"subject\"] = subject\n",
            "    original_test[\"edit\"][\"target\"] = target\n",
            "    assert target in original_test[\"edit\"][\"prompt\"]\n",
            "    assert target + \".\" in original_test[\"edit\"][\"prompt\"], original_test[\"edit\"][\"prompt\"] + \"@@@\" + target\n",
            "    # create the context of the prompt\n",
            "    original_test[\"edit\"][\"context\"] = original_test[\"edit\"][\"prompt\"][::-1].replace((target + \".\")[::-1], \"\", 1)[::-1].strip()\n",
            "    \n",
            "    new_test_data.append(original_test)\n",
            "    ent_label2id[subject] = subject_id\n",
            "    ent_label2id[target] = target_id\n",
            "    id2ent_label[subject_id] = subject\n",
            "    id2ent_label[target_id] = target\n",
            "    # assert subject_id in id2ent_label, original_test[\"edit\"]\n",
            "    # assert target_id in id2ent_label"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 558,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 558,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(new_test_data) == len(test_data)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 550,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[198]"
                  ]
               },
               "execution_count": 550,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "manual_process_ids"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 521,
         "metadata": {},
         "outputs": [],
         "source": [
            "# len(manual_process_ids)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 522,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(manual_process_ids, \"/data/users/zliu/mend/notebooks/manual_process_ids.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 542,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0"
                  ]
               },
               "execution_count": 542,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "## Sanity check the data\n",
            "faulty_ids = []\n",
            "aug_data = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/valid_aug.jsonl\")\n",
            "for i, d in enumerate(aug_data):\n",
            "    assert \"subject\" in d[\"edit\"]\n",
            "    assert \"target\" in d[\"edit\"]\n",
            "    if d[\"edit\"][\"subject\"] not in d[\"edit\"][\"prompt\"] or d[\"edit\"][\"target\"] not in d[\"edit\"][\"prompt\"] or d[\"edit\"][\"target\"] + \".\" not in d[\"edit\"][\"prompt\"]:\n",
            "        faulty_ids.append(i)\n",
            "len(faulty_ids)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 552,
         "metadata": {},
         "outputs": [],
         "source": [
            "# prompt2subjtarg[\"The name of the award Designated Survivor won is Honour Roll Clasp of the Army.\"] = [\"Designated Survivor\", \"Honour Roll Clasp of the Army\"]\n",
            "# prompt2subjtarg[\"The occupation of Ali Daei is alcalde / alcaldesa.\"] = [\"Ali Daei\", \"alcalde / alcaldesa\"]\n",
            "# prompt2subjtarg[\"The name of the country which Jana Gana Mana is associated with is Yamataikoku.\"] = [\"Jana Gana Mana\", \"Yamataikoku\"]\n",
            "# prompt2subjtarg[\"The place of birth of Lisa Welp is United States of America.\"] = [\"Lisa Welp\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The occupation of Karl Urban is aircrew member.\"] = [\"Karl Urban\", \"aircrew member\"]\n",
            "# prompt2subjtarg[\"The name of the alma mater of  is United States of America.\"] = [\"\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The place of burial of Jim Fixx is United States of America.\"] = [\"Jim Fixx\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The place of birth of Krystyna Swinarska is United States of America.\"] = [\"Krystyna Swinarska\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The place of death of Gwynne Evans is United States of America.\"] = [\"Gwynne Evans\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The place of birth of Mohamed Zakariya is United States of America.\"] = [\"Mohamed Zakariya\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The name of the ethnic group which Mike Hill is associated with is British people.\"] = [\"Mike Hill\", \"British people\"]\n",
            "# prompt2subjtarg[\"The place of birth of Janet A. Anderson is United States of America.\"] = [\"Janet A. Anderson\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The name of the country which American-Cassinese Benedictine Congregation is associated with is Yamataikoku.\"] = [\"American-Cassinese Benedictine Congregation\", \"Yamataikoku\"]\n",
            "# prompt2subjtarg[\"The name of the country which Seed Farm is associated with is Iowa River.\"] = [\"Seed Farm\", \"Iowa River\"]\n",
            "# prompt2subjtarg[\"The name of the country which Kimré is associated with is Yamataikoku.\"] = [\"Kimré\", \"Yamataikoku\"]\n",
            "# prompt2subjtarg[\"The occupation of Wanda O Jacobs is acting rank.\"] = [\"Wanda O Jacobs\", \"acting rank\"]\n",
            "# prompt2subjtarg[\"The occupation of David Vejražka is newspaper delivery person.\"] = [\"David Vejražka\", \"newspaper delivery person\"]\n",
            "# prompt2subjtarg[\"The name of the position held by Lucien M. Gex is Mayor of Dayton, Ohio.\"] = [\"Lucien M. Gex\", \"Mayor of Dayton, Ohio\"]\n",
            "# prompt2subjtarg[\"The name of the country which Ankalagi is associated with is Yamataikoku.\"] = [\"Ankalagi\", \"Yamataikoku\"]\n",
            "# prompt2subjtarg[\"The name of the continent which Sierra Carbonera is part of is Australian continent.\"] = [\"Sierra Carbonera\", \"Australian continent\"]\n",
            "# prompt2subjtarg[\"The place of birth of F. Hudson Miller is United States of America.\"] = [\"F. Hudson Miller\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The place of birth of Margaret Bamgbose is United States of America.\"] = [\"Margaret Bamgbose\", \"United States of America\"]\n",
            "# prompt2subjtarg[\"The name of the ethnic group which Richard Smalbroke is associated with is British people.\"] = [\"Richard Smalbroke\", \"British people\"]\n",
            "prompt2subjtarg[\"The name of the ethnic group which Michael J. Knowles is associated with is Italian Americans.\"] = [\"Michael J. Knowles\", \"Italian Americans\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 553,
         "metadata": {},
         "outputs": [],
         "source": [
            "for i in manual_process_ids:\n",
            "    if test_data[i][\"edit\"][\"prompt\"] in prompt2subjtarg:\n",
            "        continue\n",
            "    print(i)\n",
            "    print(test_data[i][\"edit\"][\"prompt\"])\n",
            "    subject_id = test_data[i][\"edit\"][\"subject_id\"]\n",
            "    target_id = test_data[i][\"edit\"][\"target_id\"]\n",
            "    print(subject_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"subject_id\"]], \"@@@\", target_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"target_id\"]])\n",
            "    print()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 458,
         "metadata": {},
         "outputs": [],
         "source": [
            "# test_data[884]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 277,
         "metadata": {},
         "outputs": [],
         "source": [
            "# len(new_test_data) == len(test_data)\n",
            "# aug_data[10]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# split = \"train\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 218,
         "metadata": {},
         "outputs": [],
         "source": [
            "# len(io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}.jsonl\")) == len(io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 339,
         "metadata": {},
         "outputs": [],
         "source": [
            "for i in manual_process_ids:\n",
            "    \n",
            "    if test_data[i][\"edit\"][\"prompt\"] in prompt2subjtarg:\n",
            "        continue\n",
            "    print(i)\n",
            "    print(test_data[i][\"edit\"][\"prompt\"])\n",
            "    subject_id = test_data[i][\"edit\"][\"subject_id\"]\n",
            "    target_id = test_data[i][\"edit\"][\"target_id\"]\n",
            "    print(subject_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"subject_id\"]], \"@@@\", target_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"target_id\"]])\n",
            "    print()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 562,
         "metadata": {},
         "outputs": [],
         "source": [
            "# split"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 561,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_json(ent_label2id, \"/data/users/zliu/RippleEdits/src/wikidata/ent_label2id.json\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 76,
         "metadata": {},
         "outputs": [],
         "source": [
            "# original_test[\"edit\"]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### find instance with empty subject"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "3"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/test_aug.jsonl\")\n",
            "faulty_ids = []\n",
            "for i, d in enumerate(test_data):\n",
            "    if d[\"edit\"][\"subject\"] == \"\" or d[\"edit\"][\"target\"] == \"\":\n",
            "        faulty_ids.append(i)\n",
            "len(faulty_ids)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "145\n",
                  "The name of the director of  is Margarete Wallmann.\n",
                  "\n",
                  "279\n",
                  "The name of the composer of  is Ludwig van Beethoven.\n",
                  "\n",
                  "281\n",
                  "The name of the founder of  is Henry Bauër.\n",
                  "\n"
               ]
            }
         ],
         "source": [
            "for i in faulty_ids:\n",
            "    \n",
            "    # if test_data[i][\"edit\"][\"prompt\"] in prompt2subjtarg:\n",
            "        # continue\n",
            "    print(i)\n",
            "    print(test_data[i][\"edit\"][\"prompt\"])\n",
            "    subject_id = test_data[i][\"edit\"][\"subject_id\"]\n",
            "    target_id = test_data[i][\"edit\"][\"target_id\"]\n",
            "    # print(subject_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"subject_id\"]], \"@@@\", target_id, \"==\", id2ent_label[test_data[i][\"edit\"][\"target_id\"]])\n",
            "    print()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'example_type': 'recent',\n",
                     " 'edit': {'prompt': 'The name of the director of  is Margarete Wallmann.',\n",
                     "  'subject_id': 'Q47477080',\n",
                     "  'relation': 'DIRECTOR',\n",
                     "  'target_id': 'Q214024',\n",
                     "  'subject': '',\n",
                     "  'target': 'Margarete Wallmann',\n",
                     "  'context': 'The name of the director of  is',\n",
                     "  'paraphrase': \"The director's name is\"},\n",
                     " 'Logical_Generalization': [],\n",
                     " 'Compositionality_I': [{'test_queries': [{'prompt': 'The gender of the director of hola is',\n",
                     "     'answers': [{'value': 'female',\n",
                     "       'aliases': ['woman',\n",
                     "        'human female',\n",
                     "        'female person',\n",
                     "        'lady',\n",
                     "        'female human',\n",
                     "        'fairer sex',\n",
                     "        'female gender',\n",
                     "        'fem',\n",
                     "        '♀',\n",
                     "        'f',\n",
                     "        'women',\n",
                     "        'girl',\n",
                     "        'girls',\n",
                     "        'female character']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The gender of the director of hola is',\n",
                     "     'second_relation': 'SEX_OR_GENDER',\n",
                     "     'second_hop_target_ids': ['Q6581072']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The gender of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'female',\n",
                     "       'aliases': ['woman',\n",
                     "        'human female',\n",
                     "        'female person',\n",
                     "        'lady',\n",
                     "        'female human',\n",
                     "        'fairer sex',\n",
                     "        'female gender',\n",
                     "        'fem',\n",
                     "        '♀',\n",
                     "        'f',\n",
                     "        'women',\n",
                     "        'girl',\n",
                     "        'girls',\n",
                     "        'female character']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'SEX_OR_GENDER',\n",
                     "     'target_ids': ['Q6581072'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The place of birth of the director of hola is',\n",
                     "     'answers': [{'value': 'Berlin',\n",
                     "       'aliases': ['Berlin, Germany', 'Berlin (Germany)', 'DE-BE']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The place of birth of the director of hola is',\n",
                     "     'second_relation': 'PLACE_OF_BIRTH',\n",
                     "     'second_hop_target_ids': ['Q64']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The place of birth of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Berlin',\n",
                     "       'aliases': ['Berlin, Germany', 'Berlin (Germany)', 'DE-BE']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'PLACE_OF_BIRTH',\n",
                     "     'target_ids': ['Q64'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The name of the country of citizenship of the director of hola is',\n",
                     "     'answers': [{'value': 'Germany',\n",
                     "       'aliases': ['Federal Republic of Germany',\n",
                     "        'Deutschland',\n",
                     "        'GER',\n",
                     "        'BR Deutschland',\n",
                     "        'DE',\n",
                     "        'BRD',\n",
                     "        'Bundesrepublik Deutschland',\n",
                     "        'de',\n",
                     "        'GFR']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the country of citizenship of the director of hola is',\n",
                     "     'second_relation': 'COUNTRY_OF_CITIZENSHIP',\n",
                     "     'second_hop_target_ids': ['Q183']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the country of citizenship of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Germany',\n",
                     "       'aliases': ['Federal Republic of Germany',\n",
                     "        'Deutschland',\n",
                     "        'GER',\n",
                     "        'BR Deutschland',\n",
                     "        'DE',\n",
                     "        'BRD',\n",
                     "        'Bundesrepublik Deutschland',\n",
                     "        'de',\n",
                     "        'GFR']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'COUNTRY_OF_CITIZENSHIP',\n",
                     "     'target_ids': ['Q183'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The name of the country of citizenship of the director of hola is',\n",
                     "     'answers': [{'value': 'Austria',\n",
                     "       'aliases': ['Österreich',\n",
                     "        'Republik Österreich',\n",
                     "        'AT',\n",
                     "        'AUT',\n",
                     "        '🇦🇹',\n",
                     "        'Republic of Austria']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the country of citizenship of the director of hola is',\n",
                     "     'second_relation': 'COUNTRY_OF_CITIZENSHIP',\n",
                     "     'second_hop_target_ids': ['Q40']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the country of citizenship of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Austria',\n",
                     "       'aliases': ['Österreich',\n",
                     "        'Republik Österreich',\n",
                     "        'AT',\n",
                     "        'AUT',\n",
                     "        '🇦🇹',\n",
                     "        'Republic of Austria']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'COUNTRY_OF_CITIZENSHIP',\n",
                     "     'target_ids': ['Q40'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The name of the country of citizenship of the director of hola is',\n",
                     "     'answers': [{'value': 'Argentina',\n",
                     "       'aliases': ['🇦🇷',\n",
                     "        'ARG',\n",
                     "        'Arjentina',\n",
                     "        'AR',\n",
                     "        'Argentine Republic',\n",
                     "        'ar',\n",
                     "        'Republic of Argentina']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the country of citizenship of the director of hola is',\n",
                     "     'second_relation': 'COUNTRY_OF_CITIZENSHIP',\n",
                     "     'second_hop_target_ids': ['Q414']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the country of citizenship of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Argentina',\n",
                     "       'aliases': ['🇦🇷',\n",
                     "        'ARG',\n",
                     "        'Arjentina',\n",
                     "        'AR',\n",
                     "        'Argentine Republic',\n",
                     "        'ar',\n",
                     "        'Republic of Argentina']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'COUNTRY_OF_CITIZENSHIP',\n",
                     "     'target_ids': ['Q414'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The occupation of the director of hola is',\n",
                     "     'answers': [{'value': 'choreographer', 'aliases': []}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The occupation of the director of hola is',\n",
                     "     'second_relation': 'OCCUPATION',\n",
                     "     'second_hop_target_ids': ['Q2490358']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The occupation of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'choreographer', 'aliases': []}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'OCCUPATION',\n",
                     "     'target_ids': ['Q2490358'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The occupation of the director of hola is',\n",
                     "     'answers': [{'value': 'ballet dancer', 'aliases': ['ballerina']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The occupation of the director of hola is',\n",
                     "     'second_relation': 'OCCUPATION',\n",
                     "     'second_hop_target_ids': ['Q805221']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The occupation of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'ballet dancer', 'aliases': ['ballerina']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'OCCUPATION',\n",
                     "     'target_ids': ['Q805221'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The occupation of the director of hola is',\n",
                     "     'answers': [{'value': 'scenographer',\n",
                     "       'aliases': ['stage designer', 'set designer', 'scenic designer']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The occupation of the director of hola is',\n",
                     "     'second_relation': 'OCCUPATION',\n",
                     "     'second_hop_target_ids': ['Q2707485']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The occupation of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'scenographer',\n",
                     "       'aliases': ['stage designer', 'set designer', 'scenic designer']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'OCCUPATION',\n",
                     "     'target_ids': ['Q2707485'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The occupation of the director of hola is',\n",
                     "     'answers': [{'value': 'director', 'aliases': ['regisseur']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The occupation of the director of hola is',\n",
                     "     'second_relation': 'OCCUPATION',\n",
                     "     'second_hop_target_ids': ['Q3455803']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The occupation of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'director', 'aliases': ['regisseur']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'OCCUPATION',\n",
                     "     'target_ids': ['Q3455803'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The place of death of the director of hola is',\n",
                     "     'answers': [{'value': 'Monte Carlo', 'aliases': []}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The place of death of the director of hola is',\n",
                     "     'second_relation': 'PLACE_OF_DEATH',\n",
                     "     'second_hop_target_ids': ['Q45240']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The place of death of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Monte Carlo', 'aliases': []}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'PLACE_OF_DEATH',\n",
                     "     'target_ids': ['Q45240'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The name of the father of the director of hola is',\n",
                     "     'answers': [{'value': 'Paul Wallmann', 'aliases': []}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the father of the director of hola is',\n",
                     "     'second_relation': 'FATHER',\n",
                     "     'second_hop_target_ids': ['Q94804697']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the father of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Paul Wallmann', 'aliases': []}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'FATHER',\n",
                     "     'target_ids': ['Q94804697'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The name of the mother of the director of hola is',\n",
                     "     'answers': [{'value': 'Selma Wallmann', 'aliases': ['Selma Daniel']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the mother of the director of hola is',\n",
                     "     'second_relation': 'MOTHER',\n",
                     "     'second_hop_target_ids': ['Q109593384']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the mother of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Selma Wallmann', 'aliases': ['Selma Daniel']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'MOTHER',\n",
                     "     'target_ids': ['Q109593384'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The names of the siblings of the director of hola are',\n",
                     "     'answers': [{'value': 'Charlotte Edith Wallmann',\n",
                     "       'aliases': ['Charlotte Edith Rosenthal']}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The names of the siblings of the director of hola are',\n",
                     "     'second_relation': 'SIBLING',\n",
                     "     'second_hop_target_ids': ['Q109593410']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The names of the siblings of Margarete Wallmann are',\n",
                     "     'answers': [{'value': 'Charlotte Edith Wallmann',\n",
                     "       'aliases': ['Charlotte Edith Rosenthal']}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'SIBLING',\n",
                     "     'target_ids': ['Q109593410'],\n",
                     "     'phrase': None}]},\n",
                     "  {'test_queries': [{'prompt': 'The name of the spouse of the director of hola is',\n",
                     "     'answers': [{'value': 'Hugo Burghauser', 'aliases': []}],\n",
                     "     'query_type': 'two_hop',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the spouse of the director of hola is',\n",
                     "     'second_relation': 'SPOUSE',\n",
                     "     'second_hop_target_ids': ['Q1634905']}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the spouse of Margarete Wallmann is',\n",
                     "     'answers': [{'value': 'Hugo Burghauser', 'aliases': []}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q214024',\n",
                     "     'relation': 'SPOUSE',\n",
                     "     'target_ids': ['Q1634905'],\n",
                     "     'phrase': None}]}],\n",
                     " 'Compositionality_II': [],\n",
                     " 'Subject_Aliasing': [],\n",
                     " 'Relation_Specificity': [],\n",
                     " 'Forgetfulness': [{'test_queries': [{'prompt': 'The name of the director of , which is not Margarete Wallmann, is',\n",
                     "     'answers': [{'value': 'Margarete Wallmann', 'aliases': []}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the director of , which is not Margarete Wallmann, is'}],\n",
                     "   'test_condition': 'OR',\n",
                     "   'condition_queries': [{'prompt': 'The name of the director of , which is not Margarete Wallmann, is',\n",
                     "     'answers': [{'value': 'Margarete Wallmann', 'aliases': []}],\n",
                     "     'query_type': 'regular',\n",
                     "     'subject_id': 'Q47477080',\n",
                     "     'relation': 'DIRECTOR',\n",
                     "     'target_ids': ['Q214024'],\n",
                     "     'phrase': 'The name of the director of , which is not Margarete Wallmann, is'}]}]}"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "test_data[145]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 80,
         "metadata": {},
         "outputs": [],
         "source": [
            "# id2ent_label[\"Q16083337\"], id2ent_label[\"Q108063841\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 78,
         "metadata": {},
         "outputs": [],
         "source": [
            "# test_data[1908][\"edit\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 79,
         "metadata": {},
         "outputs": [],
         "source": [
            "# len(manual_process_ids)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### getting augmented dataset with llm"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "split = \"train\"\n",
            "ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_w_prefix.hf\")\n",
            "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}.jsonl\")\n",
            "\n",
            "new_test_data = []\n",
            "\n",
            "count = 0\n",
            "for i in range(len(test_data)):\n",
            "    original_test = test_data[i]\n",
            "    augmentation = ds[i-count]\n",
            "    if original_test[\"edit\"][\"prompt\"] == \"The name of the award Ravi Kumar Dahiya won is Obaland  Awards.\":\n",
            "        # print(\"found\")\n",
            "        original_test[\"edit\"][\"subject\"] = \"The name of the award\"\n",
            "        original_test[\"edit\"][\"object\"] = \"Obaland  Awards\"\n",
            "        assert original_test[\"edit\"][\"subject\"] in original_test[\"edit\"][\"prompt\"]\n",
            "        assert original_test[\"edit\"][\"object\"] in original_test[\"edit\"][\"prompt\"]\n",
            "        new_test_data.append(original_test)\n",
            "        count += 1\n",
            "        continue\n",
            "        # print(original_test)\n",
            "        # print(augmentation)\n",
            "    elif original_test[\"edit\"][\"prompt\"] == \"The occupation of Sandeep  Singh is Steward's assistant.\":\n",
            "        # print(\"found\")\n",
            "        original_test[\"edit\"][\"subject\"] = \"Sandeep  Singh\"\n",
            "        original_test[\"edit\"][\"object\"] = \"Steward's assistant\"\n",
            "        assert original_test[\"edit\"][\"subject\"] in original_test[\"edit\"][\"prompt\"]\n",
            "        assert original_test[\"edit\"][\"object\"] in original_test[\"edit\"][\"prompt\"]\n",
            "        new_test_data.append(original_test)\n",
            "        count += 1\n",
            "        continue\n",
            "    elif original_test[\"edit\"][\"prompt\"] == \"The gender of Wu  Xinghuan is takatāpui.\":\n",
            "        # print(\"found\")\n",
            "        original_test[\"edit\"][\"subject\"] = \"Wu  Xinghuan\"\n",
            "        original_test[\"edit\"][\"object\"] = \"takatāpui\"\n",
            "        assert original_test[\"edit\"][\"subject\"] in original_test[\"edit\"][\"prompt\"]\n",
            "        assert original_test[\"edit\"][\"object\"] in original_test[\"edit\"][\"prompt\"]\n",
            "        new_test_data.append(original_test)\n",
            "        count += 1\n",
            "        continue\n",
            "    else:\n",
            "        assert original_test[\"edit\"][\"prompt\"] == augmentation[\"prompt\"], f\"{i}@@\" + original_test[\"edit\"][\"prompt\"] + \"@@\" + augmentation[\"prompt\"]\n",
            "        assert augmentation[\"subject\"] in original_test[\"edit\"][\"prompt\"], f\"{i}@@\" + original_test[\"edit\"][\"prompt\"] + \"@@\" + augmentation[\"subject\"]\n",
            "        assert augmentation[\"object\"] in original_test[\"edit\"][\"prompt\"]\n",
            "\n",
            "        original_test[\"edit\"][\"subject\"] = augmentation[\"subject\"]\n",
            "        original_test[\"edit\"][\"object\"] = augmentation[\"object\"]\n",
            "        new_test_data.append(original_test)\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "3"
                  ]
               },
               "execution_count": 32,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "count"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'The name of the league which Paul Westhead plays in is Southern Counties East Football League.'"
                  ]
               },
               "execution_count": 33,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "test_data[393][\"edit\"][\"prompt\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 595,
         "metadata": {},
         "outputs": [],
         "source": [
            "# test_data[-3]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Prepare a ripple edits for MEND-original version (before generating paraphrase)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 584,
         "metadata": {},
         "outputs": [],
         "source": [
            "split = \"train\"\n",
            "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")\n",
            "# train_ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_w_prefix.hf\")\n",
            "# train_examples[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 585,
         "metadata": {},
         "outputs": [],
         "source": [
            "train_examples_w_context = []\n",
            "for i, example in enumerate(train_examples):\n",
            "    new_example = deepcopy(example)\n",
            "    obj = new_example[\"edit\"][\"target\"]\n",
            "    prompt = new_example[\"edit\"][\"prompt\"]\n",
            "    \n",
            "    assert obj in new_example[\"edit\"][\"prompt\"]\n",
            "    assert obj + \".\" in new_example[\"edit\"][\"prompt\"], new_example[\"edit\"][\"prompt\"] + \"@@@\" + obj\n",
            "    \n",
            "    new_example[\"edit\"][\"context\"] = prompt[::-1].replace((obj + \".\")[::-1], \"\", 1)[::-1].strip()\n",
            "    train_examples_w_context.append(new_example)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Prepare a ripple edits for MEND-original version (after generating paraphrase)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 632,
         "metadata": {},
         "outputs": [
            {
               "ename": "FileNotFoundError",
               "evalue": "[Errno 2] No such file or directory: '/u/zliu/datastor1/KE-by-CP/data/ripple_edits/meta_train_recent+popular/test_aug.jsonl'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[145], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_examples \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_jsonlines\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ripple_edits/meta_train_recent+popular/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msplit\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_aug.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# train_ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/{split}_w_prefix.hf\")\u001b[39;00m\n",
                  "File \u001b[0;32m~/datastor1/KE-by-CP/knowledge_propagation/utils/io.py:12\u001b[0m, in \u001b[0;36mload_jsonlines\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_jsonlines\u001b[39m(fname: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read jsonlines file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
                  "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/u/zliu/datastor1/KE-by-CP/data/ripple_edits/meta_train_recent+popular/test_aug.jsonl'"
               ]
            }
         ],
         "source": [
            "split = \"test\"\n",
            "ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_w_paraphrase.hf\")\n",
            "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")\n",
            "new_test_data = []\n",
            "for i in range(len(ds)):\n",
            "    augmentation = deepcopy(ds[i])\n",
            "    new_test_datum = deepcopy(train_examples[i])\n",
            "    assert new_test_datum[\"edit\"][\"context\"] == augmentation[\"context\"], str(i) + \"@@@\" + str(augmentation[\"context\"])\n",
            "    new_test_datum[\"edit\"][\"paraphrase\"] = augmentation[\"paraphrase\"]\n",
            "    new_test_data.append(new_test_datum)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 633,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 633,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(new_test_data) == len(ds)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'prompt': 'The name of the continent which United Arab Emirates is part of is Indian Ocean.',\n",
                     " 'subject_id': 'Q878',\n",
                     " 'relation': 'CONTINENT',\n",
                     " 'target_id': 'Q1239',\n",
                     " 'original_fact': {'prompt': 'The name of the continent which United Arab Emirates is part of is Asia.',\n",
                     "  'subject_id': 'Q878',\n",
                     "  'relation': 'CONTINENT',\n",
                     "  'target_id': 'Q48'},\n",
                     " 'subject': 'United Arab Emirates',\n",
                     " 'target': 'Indian Ocean',\n",
                     " 'context': 'The name of the continent which United Arab Emirates is part of is',\n",
                     " 'paraphrase': 'The continent that includes the United Arab Emirates is named'}"
                  ]
               },
               "execution_count": 634,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# new_test_data[0][\"edit\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 635,
         "metadata": {},
         "outputs": [],
         "source": [
            "io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 619,
         "metadata": {},
         "outputs": [],
         "source": [
            "# train_examples[61][\"edit\"][\"prompt\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 588,
         "metadata": {},
         "outputs": [],
         "source": [
            "# train_examples_w_context[0][\"edit\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 587,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(train_examples_w_context, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# special treatment for test set"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "new_examples = []\n",
            "missing_examples = []\n",
            "mismatch_c = 0\n",
            "for i in range(len(train_examples)):\n",
            "    augmentation = train_ds[i-mismatch_c]\n",
            "    example = train_examples[i]\n",
            "    new_example = deepcopy(example)\n",
            "    \n",
            "    new_example[\"edit\"][\"context\"] = augmentation[\"context\"]\n",
            "    new_example[\"edit\"][\"paraphrase\"] = augmentation[\"paraphrase\"]\n",
            "    new_example[\"edit\"][\"object\"] = augmentation[\"object\"]\n",
            "    new_examples.append(new_example)\n",
            "    # if example[\"edit\"][\"prompt\"] != augmentation[\"prompt\"]:\n",
            "    #     mismatch_c += 1\n",
            "    # else:\n",
            "        \n",
            "    #     assert example[\"edit\"][\"prompt\"] == augmentation[\"prompt\"]\n",
            "    #     assert augmentation[\"object\"] in example[\"edit\"][\"prompt\"]\n",
            "    \n",
            "    #     flattend_train_examples.append({\"context\": augmentation[\"context\"], \"completion\": augmentation[\"object\"], \"paraphrase\": augmentation[\"paraphrase\"]})\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 665,
         "metadata": {},
         "outputs": [],
         "source": [
            "# if split == \"test\":\n",
            "#     io.dump_jsonlines(new_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/{split}_mend.jsonl\")\n",
            "split = \"valid\"\n",
            "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_aug.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 666,
         "metadata": {},
         "outputs": [],
         "source": [
            "# train_examples[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 667,
         "metadata": {},
         "outputs": [],
         "source": [
            "flattend_train_examples = []\n",
            "missing_examples = []\n",
            "mismatch_c = 0\n",
            "for i in range(len(train_examples)):\n",
            "    # augmentation = train_ds[i-mismatch_c]\n",
            "    example = train_examples[i]\n",
            "    \n",
            "    # if example[\"edit\"][\"prompt\"] != augmentation[\"prompt\"]:\n",
            "        # mismatch_c += 1\n",
            "    # else:\n",
            "        \n",
            "    # assert example[\"edit\"][\"prompt\"] == augmentation[\"prompt\"]\n",
            "    assert example[\"edit\"][\"target\"] in example[\"edit\"][\"prompt\"], example[\"edit\"][\"target\"] + \"@@@\" + example[\"edit\"][\"prompt\"]\n",
            "\n",
            "    flattend_train_examples.append({\"context\": example[\"edit\"][\"context\"], \"completion\": example[\"edit\"][\"target\"], \"paraphrase\": example[\"edit\"][\"paraphrase\"]})\n",
            "    \n",
            "    for k in [\"Logical_Generalization\", \"Compositionality_I\", \"Compositionality_II\", \"Subject_Aliasing\"]:\n",
            "        for instance in example[k]:\n",
            "            for q in instance[\"test_queries\"]:\n",
            "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
            "                    q[\"question_type\"] = k\n",
            "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
            "                    assert len(ans_candidates) > 0\n",
            "                    assert q[\"prompt\"][-1] not in \".\",  q[\"prompt\"]\n",
            "                    assert \"phrase\" in q\n",
            "                    if q[\"phrase\"] is not None:\n",
            "                        flattend_train_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0], \"paraphrase\": q[\"phrase\"]})\n",
            "                    else:\n",
            "                        missing_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0], \"prompt\": q[\"prompt\"].strip() + \" \" + ans_candidates[0]})\n",
            "    for k in [\"Relation_Specificity\", \"Forgetfulness\"]:\n",
            "        for instance in example[k]:\n",
            "            for q in instance[\"test_queries\"]:\n",
            "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
            "                    q[\"question_type\"] = k\n",
            "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
            "                    assert len(ans_candidates) > 0\n",
            "                    assert q[\"prompt\"][-1] not in string.punctuation\n",
            "                    \n",
            "                    assert \"phrase\" in q\n",
            "                    if q[\"phrase\"] is not None:\n",
            "                        flattend_train_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0], \"paraphrase\": q[\"phrase\"]})\n",
            "                    else:\n",
            "                        missing_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0], \"prompt\": q[\"prompt\"].strip() + \" \" + ans_candidates[0]})\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 671,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "2254"
                  ]
               },
               "execution_count": 671,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(missing_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 669,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "3643"
                  ]
               },
               "execution_count": 669,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(flattend_train_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 670,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'context': 'The name of the award Henry Cavill won is',\n",
                     " 'completion': 'Bologna Ragazzi Award',\n",
                     " 'paraphrase': 'The title of the accolade that Henry Cavill received is'}"
                  ]
               },
               "execution_count": 670,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "flattend_train_examples[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(missing_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_missing_parahrase.jsonl\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 673,
         "metadata": {},
         "outputs": [],
         "source": [
            "missing_ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_missing_parahrase_w_paraphrase.hf\")\n",
            "missing_train_examples = []\n",
            "for i in range(len(missing_ds)):\n",
            "    augmentation = missing_ds[i]\n",
            "    \n",
            "    missing_train_examples.append({\"context\": augmentation[\"context\"], \"completion\": augmentation[\"completion\"], \"paraphrase\": augmentation[\"paraphrase\"]})"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 674,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "5897"
                  ]
               },
               "execution_count": 674,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(flattend_train_examples + missing_train_examples)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "17096"
                  ]
               },
               "execution_count": 89,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# len(flattend_train_examples)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# io.dump_jsonlines(flattend_train_examples + missing_train_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train/all/{split}_mend.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# for ex in io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/valid_mend.jsonl\"):\n",
            "#     assert \"context\" in ex and ex[\"context\"] is not None\n",
            "#     assert \"completion\" in ex and ex[\"completion\"] is not None\n",
            "#     assert \"paraphrase\" in ex and ex[\"paraphrase\"] is not None"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "508"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "converted_recoe_aggregation[-1]\n",
            "len(converted_recoe_aggregation)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Integrate RoCE data to ripple edit trainings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 116,
         "metadata": {},
         "outputs": [],
         "source": [
            "recoe_aggregation = io.load_json(\"/u/zliu/datastor1/ReCoE/data/aggregation/counterfactual_datapoints_verified_atomic.json\")\n",
            "\n",
            "converted_recoe_aggregation = [\n",
            "    {\n",
            "        \"texts\": \" \".join([f[\"fact\"] for f in x[\"direct_counterfactual_fact\"]]),\n",
            "        \"question\": x[\"question\"],\n",
            "        \"answer\": x[\"counterfactual_answer\"]\n",
            "     }\n",
            "    for x in recoe_aggregation\n",
            "]\n",
            "assert len(converted_recoe_aggregation) == len(recoe_aggregation)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 117,
         "metadata": {},
         "outputs": [],
         "source": [
            "recoe_comparative = io.load_json(\"/u/zliu/datastor1/ReCoE/data/comparative/counterfactual_datapoints_verified_atomic.json\")\n",
            "converted_recoe_comparative = []\n",
            "for x in recoe_comparative:\n",
            "    assert \"choice_1_counterfactuals\" in x[\"counterfactuals_per_choice\"]\n",
            "    assert \"choice_2_counterfactuals\" in x[\"counterfactuals_per_choice\"]\n",
            "    assert \"choice_3_counterfactuals\" not in x[\"counterfactuals_per_choice\"]\n",
            "    \n",
            "    counter_fact1_text = [f[\"fact\"] for f in x[\"counterfactuals_per_choice\"][\"choice_1_counterfactuals\"]]\n",
            "    counter_fact2_text = [f[\"fact\"] for f in x[\"counterfactuals_per_choice\"][\"choice_2_counterfactuals\"]]\n",
            "    texts = [counter_fact1_text, counter_fact2_text]\n",
            "    np.random.shuffle(texts)\n",
            "    counter_fact1_text_after_rand, counter_fact2_text_after_rand = texts\n",
            "    \n",
            "    \n",
            "    converted_recoe_comparative.append(\n",
            "        {\n",
            "            \"texts\": \" \".join(counter_fact1_text_after_rand + counter_fact2_text_after_rand),\n",
            "            \"question\": x[\"question\"],\n",
            "            \"answer\": x[\"counterfactual_answer\"]\n",
            "        }\n",
            "    )\n",
            "assert len(converted_recoe_comparative) == len(recoe_comparative)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 118,
         "metadata": {},
         "outputs": [],
         "source": [
            "# [len(x[\"facts_per_choice\"]) for x in recoe_comparative]\n",
            "recoe_counting = io.load_json(\"/u/zliu/datastor1/ReCoE/data/counting/counterfactual_datapoints_verified_atomic.json\")\n",
            "converted_recoe_counting = []\n",
            "for x in recoe_counting:\n",
            "    converted_recoe_counting.append(\n",
            "        {\n",
            "            \"texts\": \" \".join([f[\"sentence\"] for f in x[\"counterfactual_facts\"]]),\n",
            "            \"question\": x[\"question\"],\n",
            "            \"answer\": x[\"counterfactual_answer\"]\n",
            "        }\n",
            "    )\n",
            "assert len(recoe_counting) == len(converted_recoe_counting)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 119,
         "metadata": {},
         "outputs": [],
         "source": [
            "recoe_sorting = io.load_json(\"/u/zliu/datastor1/ReCoE/data/sorting/counterfactual_datapoints_verified_atomic.json\")\n",
            "converted_recoe_sorting = []\n",
            "for x_i, x in enumerate(recoe_sorting):\n",
            "    assert \"counterfactuals_per_choice\" in x\n",
            "    n_facts = len([k for k in x[\"facts_per_choice\"].keys() if \"choice_\" in k])\n",
            "    texts = []\n",
            "    count = 0\n",
            "    # assert n_facts == 3\n",
            "    counter_factuals = x[\"counterfactuals_per_choice\"]\n",
            "    factuals = x[\"facts_per_choice\"]\n",
            "    \n",
            "    unchanged_facts_added = False\n",
            "    for f_i in range(1, n_facts + 1):\n",
            "        \n",
            "        if f\"choice_{f_i}_counterfactuals\" not in counter_factuals:\n",
            "            if not unchanged_facts_added:\n",
            "                texts.extend(counter_factuals[\"unchanged_facts\"])\n",
            "            else:\n",
            "                continue\n",
            "        else:\n",
            "            texts.extend([f[\"fact\"] for f in counter_factuals[f\"choice_{f_i}_counterfactuals\"]])\n",
            "    converted_recoe_sorting.append(\n",
            "        {\n",
            "            \"texts\": \" \".join(texts),\n",
            "            \"question\": x[\"question\"],\n",
            "            \"answer\": x[\"counterfactual_answer\"]\n",
            "        }\n",
            "    )\n",
            "assert len(converted_recoe_sorting) == len(recoe_sorting)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 120,
         "metadata": {},
         "outputs": [],
         "source": [
            "recoe_subtraction = io.load_json(\"/u/zliu/datastor1/ReCoE/data/subtraction/counterfactual_datapoints_verified_atomic.json\")\n",
            "\n",
            "\n",
            "converted_recoe_subtraction = [\n",
            "    {\n",
            "        \"texts\": \" \".join([f[\"fact\"] for f in x[\"direct_counterfactual_fact\"]]),\n",
            "        \"question\": x[\"question\"],\n",
            "        \"answer\": x[\"counterfactual_answer\"]\n",
            "     }\n",
            "    for x in recoe_subtraction\n",
            "]\n",
            "assert len(recoe_subtraction) == len(converted_recoe_subtraction)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "recoe_superlative = io.load_json(\"/u/zliu/datastor1/ReCoE/data/superlative/counterfactual_datapoints_verified_atomic.json\")\n",
            "\n",
            "converted_recoe_superlative = []\n",
            "for x_i, x in enumerate(recoe_superlative):\n",
            "    assert \"counterfactuals_per_choice\" in x\n",
            "    n_facts = len([k for k in x[\"facts_per_choice\"].keys() if \"choice_\" in k])\n",
            "    texts = []\n",
            "    count = 0\n",
            "    # assert n_facts == 3\n",
            "    counter_factuals = x[\"counterfactuals_per_choice\"]\n",
            "    factuals = x[\"facts_per_choice\"]\n",
            "    \n",
            "    unchanged_facts_added = False\n",
            "    for f_i in range(1, n_facts + 1):\n",
            "        \n",
            "        if f\"choice_{f_i}_counterfactuals\" not in counter_factuals:\n",
            "            if not unchanged_facts_added:\n",
            "                texts.extend(counter_factuals[\"unchanged_facts\"])\n",
            "            else:\n",
            "                continue\n",
            "        else:\n",
            "            texts.extend([f[\"fact\"] for f in counter_factuals[f\"choice_{f_i}_counterfactuals\"]])\n",
            "    converted_recoe_superlative.append(\n",
            "        {\n",
            "            \"texts\": \" \".join(texts),\n",
            "            \"question\": x[\"question\"],\n",
            "            \"answer\": x[\"counterfactual_answer\"]\n",
            "        }\n",
            "    )\n",
            "assert len(recoe_superlative) == len(converted_recoe_superlative)\n",
            "    # assert count == 2, x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 122,
         "metadata": {},
         "outputs": [],
         "source": [
            "converted_recoe = converted_recoe_aggregation + converted_recoe_comparative + converted_recoe_counting + converted_recoe_sorting + converted_recoe_subtraction + converted_recoe_superlative"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 130,
         "metadata": {},
         "outputs": [],
         "source": [
            "converted_recoe = [\n",
            "    {\n",
            "        \"texts\": x[\"texts\"],\n",
            "        \"question\": x[\"question\"],\n",
            "        \"answer\": str(x[\"answer\"])\n",
            "    }\n",
            "    for x in converted_recoe\n",
            "]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 131,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 131,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "all([isinstance(x[\"answer\"], str) for x in converted_recoe])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 132,
         "metadata": {},
         "outputs": [],
         "source": [
            "io.dump_jsonlines(converted_recoe, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/recoe.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 133,
         "metadata": {},
         "outputs": [],
         "source": [
            "recent_popular_train = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/train.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 134,
         "metadata": {},
         "outputs": [],
         "source": [
            "io.dump_jsonlines(recent_popular_train + converted_recoe, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/train_w_recoe.jsonl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "cpt",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.10"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}