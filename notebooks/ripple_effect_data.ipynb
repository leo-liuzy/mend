{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# sys.path.append(\"/u/zliu/datastor1/KE-by-CP\")\n",
    "import pandas as pd\n",
    "# from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars, extractor\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import describe\n",
    "from thefuzz import fuzz\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from dateutil.parser import ParserError\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1948"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/popular.json\")\n",
    "assert len(popular_examples) == 1\n",
    "popular_examples = [] # popular_examples[0]\n",
    "\n",
    "# random_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/random.json\")\n",
    "# assert len(random_examples) == 1\n",
    "# random_examples = random_examples[0]\n",
    "\n",
    "recent_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/recent.json\")\n",
    "assert len(recent_examples) == 1\n",
    "recent_examples = recent_examples[0]\n",
    "\n",
    "ripple_edits_examples = popular_examples +  recent_examples # + random_examples\n",
    "len(ripple_edits_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# strong examples 1318\n",
      "# weak examples 575\n"
     ]
    }
   ],
   "source": [
    "non_zero_outerloop_count = 0\n",
    "strong_meta_examples = []\n",
    "weak_meta_examples = []\n",
    "for example in ripple_edits_examples:\n",
    "    outerloop_instances = example[\"Logical_Generalization\"] + example[\"Compositionality_I\"] + example[\"Compositionality_II\"] + example[\"Subject_Aliasing\"]\n",
    "    # for ins in outerloop_instances:\n",
    "        # assert len(ins[\"test_queries\"]) == 1\n",
    "    locality_instances = example[\"Relation_Specificity\"] + example[\"Forgetfulness\"] \n",
    "    # non_zero_outerloop_count += len(outerloop_instances) > 0\n",
    "    if len(outerloop_instances) > 0 and len(locality_instances) > 0:\n",
    "        \n",
    "        outerloop_queries = [q for instance in outerloop_instances for q in instance[\"test_queries\"]]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len(q[\"answers\"]) > 0]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in outerloop_queries])\n",
    "        \n",
    "        if len(outerloop_queries) == 0:\n",
    "            continue\n",
    "        \n",
    "        locality_queries = [q for instance in locality_instances for q in instance[\"test_queries\"]]\n",
    "        locality_queries = [q for q in locality_queries if len(q[\"answers\"]) > 0]\n",
    "        locality_queries = [q for q in locality_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in locality_queries])\n",
    "        \n",
    "        assert len(locality_queries) > 0\n",
    "        \n",
    "        strong_meta_examples.append(example)\n",
    "    elif len(locality_instances) == 0:\n",
    "        \n",
    "        outerloop_queries = [q for instance in outerloop_instances for q in instance[\"test_queries\"]]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len(q[\"answers\"]) > 0]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in outerloop_queries])\n",
    "        \n",
    "        if len(outerloop_queries) == 0:\n",
    "            continue\n",
    "        \n",
    "        weak_meta_examples.append(example)\n",
    "    else:\n",
    "        locality_queries = [q for instance in locality_instances for q in instance[\"test_queries\"]]\n",
    "        locality_queries = [q for q in locality_queries if len(q[\"answers\"]) > 0]\n",
    "        locality_queries = [q for q in locality_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in locality_queries])\n",
    "        \n",
    "        assert len(locality_queries) > 0\n",
    "        \n",
    "        weak_meta_examples.append(example)\n",
    "        \n",
    "print(\"# strong examples\", len(strong_meta_examples))\n",
    "print(\"# weak examples\", len(weak_meta_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strong_meta_examples) + len(weak_meta_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary Prudence Ord'],\n",
       " ['Lawrence Hay Fyffe'],\n",
       " ['Henrietta Frances Arnaud Blagden'],\n",
       " ['Alan Fyffe', 'Mary Constance Fyffe'],\n",
       " ['male'],\n",
       " ['history', 'journalism']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0] for q in locality_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 150\n",
    "n_valid = 150\n",
    "np.random.shuffle(strong_meta_examples)\n",
    "np.random.shuffle(weak_meta_examples)\n",
    "\n",
    "test_examples = strong_meta_examples[:n_test]\n",
    "valid_examples = strong_meta_examples[n_test:n_test+n_valid]\n",
    "train_examples = strong_meta_examples[n_test+n_valid:] + weak_meta_examples\n",
    "np.random.shuffle(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(train_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/train.jsonl\")\n",
    "io.dump_jsonlines(valid_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/valid.jsonl\")\n",
    "io.dump_jsonlines(test_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1593"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_outerloop_count = 0\n",
    "meta_examples = []\n",
    "# strong_meta_examples = []\n",
    "# weak_meta_examples = []\n",
    "count_rel = defaultdict(int)\n",
    "count_prop_types = defaultdict(int)\n",
    "\n",
    "for example in train_examples:\n",
    "    outerloop_instances = example[\"Logical_Generalization\"] + example[\"Compositionality_I\"] + example[\"Compositionality_II\"] + example[\"Subject_Aliasing\"]\n",
    "    # for ins in outerloop_instances:\n",
    "        # assert len(ins[\"test_queries\"]) == 1\n",
    "    locality_instances = example[\"Relation_Specificity\"] + example[\"Forgetfulness\"] \n",
    "    example[\"edit\"][\"text\"] = example[\"edit\"][\"prompt\"]\n",
    "    meta_examples.append(example[\"edit\"])\n",
    "    \n",
    "    outerloop_queries = []\n",
    "    for k in [\"Logical_Generalization\", \"Compositionality_I\", \"Compositionality_II\", \"Subject_Aliasing\"]:\n",
    "        for instance in example[k]:\n",
    "            for q in instance[\"test_queries\"]:\n",
    "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
    "                    q[\"question_type\"] = k\n",
    "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
    "                    assert len(ans_candidates) > 0\n",
    "                    q[\"text\"] = q[\"prompt\"] + \" \" + ans_candidates[0]\n",
    "                    \n",
    "                    outerloop_queries.append(q)\n",
    "    for outer_q in outerloop_queries:\n",
    "        count_prop_types[\"efficacy::\"+ outer_q[\"question_type\"]] += 1\n",
    "        count_rel[\"efficacy::\"+ outer_q[\"relation\"]] += 1\n",
    "    # assert len(outerloop_queries) > 0\n",
    "    meta_examples.extend(outerloop_queries)\n",
    "    \n",
    "    locality_queries = []\n",
    "    for k in [\"Relation_Specificity\", \"Forgetfulness\"]:\n",
    "        for instance in example[k]:\n",
    "            for q in instance[\"test_queries\"]:\n",
    "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
    "                    q[\"question_type\"] = k\n",
    "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
    "                    assert len(ans_candidates) > 0\n",
    "                    q[\"text\"] = q[\"prompt\"] + \" \" + ans_candidates[0]\n",
    "                    locality_queries.append(q)\n",
    "    for loc_q in locality_queries:\n",
    "        count_prop_types[\"specificity::\"+ loc_q[\"question_type\"]] += 1\n",
    "        count_rel[\"specificity::\"+ loc_q[\"relation\"]] += 1\n",
    "    \n",
    "    meta_examples.extend(locality_queries)\n",
    "    \n",
    "    # assert len(locality_queries) > 0\n",
    "        \n",
    "# print(\"# strong examples\", len(strong_meta_examples))\n",
    "# print(\"# weak examples\", len(weak_meta_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The name of the field of work of Valerio Villareale is art of sculpture.',\n",
       " 'subject_id': 'Q1452728',\n",
       " 'relation': 'FIELD_OF_WORK',\n",
       " 'target_id': 'Q11634',\n",
       " 'text': 'The name of the field of work of Valerio Villareale is art of sculpture.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"edit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18748"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(meta_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/train_all_queries.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
