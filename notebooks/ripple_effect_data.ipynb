{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zliu/miniconda3/envs/cpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "# import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# sys.path.append(\"/u/zliu/datastor1/KE-by-CP\")\n",
    "import pandas as pd\n",
    "# from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars, extractor\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import describe\n",
    "from thefuzz import fuzz\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from dateutil.parser import ParserError\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1948"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/popular.json\")\n",
    "assert len(popular_examples) == 1\n",
    "popular_examples = [] # popular_examples[0]\n",
    "\n",
    "# random_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/random.json\")\n",
    "# assert len(random_examples) == 1\n",
    "# random_examples = random_examples[0]\n",
    "\n",
    "recent_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/benchmark/recent.json\")\n",
    "assert len(recent_examples) == 1\n",
    "recent_examples = recent_examples[0]\n",
    "\n",
    "ripple_edits_examples = popular_examples + recent_examples # + random_examples\n",
    "len(ripple_edits_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# strong examples 1318\n",
      "# weak examples 575\n"
     ]
    }
   ],
   "source": [
    "non_zero_outerloop_count = 0\n",
    "strong_meta_examples = []\n",
    "weak_meta_examples = []\n",
    "for example in ripple_edits_examples:\n",
    "    outerloop_instances = example[\"Logical_Generalization\"] + example[\"Compositionality_I\"] + example[\"Compositionality_II\"] + example[\"Subject_Aliasing\"]\n",
    "    # for ins in outerloop_instances:\n",
    "        # assert len(ins[\"test_queries\"]) == 1\n",
    "    locality_instances = example[\"Relation_Specificity\"] + example[\"Forgetfulness\"] \n",
    "    # non_zero_outerloop_count += len(outerloop_instances) > 0\n",
    "    if len(outerloop_instances) > 0 and len(locality_instances) > 0:\n",
    "        \n",
    "        outerloop_queries = [q for instance in outerloop_instances for q in instance[\"test_queries\"]]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len(q[\"answers\"]) > 0]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in outerloop_queries])\n",
    "        \n",
    "        if len(outerloop_queries) == 0:\n",
    "            continue\n",
    "        \n",
    "        locality_queries = [q for instance in locality_instances for q in instance[\"test_queries\"]]\n",
    "        locality_queries = [q for q in locality_queries if len(q[\"answers\"]) > 0]\n",
    "        locality_queries = [q for q in locality_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in locality_queries])\n",
    "        \n",
    "        assert len(locality_queries) > 0\n",
    "        \n",
    "        strong_meta_examples.append(example)\n",
    "    elif len(locality_instances) == 0:\n",
    "        \n",
    "        outerloop_queries = [q for instance in outerloop_instances for q in instance[\"test_queries\"]]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len(q[\"answers\"]) > 0]\n",
    "        outerloop_queries = [q for q in outerloop_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in outerloop_queries])\n",
    "        \n",
    "        if len(outerloop_queries) == 0:\n",
    "            continue\n",
    "        \n",
    "        weak_meta_examples.append(example)\n",
    "    else:\n",
    "        locality_queries = [q for instance in locality_instances for q in instance[\"test_queries\"]]\n",
    "        locality_queries = [q for q in locality_queries if len(q[\"answers\"]) > 0]\n",
    "        locality_queries = [q for q in locality_queries if len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0]\n",
    "        assert all([len(q[\"prompt\"].strip()) > 0 for q in locality_queries])\n",
    "        \n",
    "        assert len(locality_queries) > 0\n",
    "        \n",
    "        weak_meta_examples.append(example)\n",
    "        \n",
    "print(\"# strong examples\", len(strong_meta_examples))\n",
    "print(\"# weak examples\", len(weak_meta_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strong_meta_examples) + len(weak_meta_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09122006841505131"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80 / 877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0] for q in locality_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 80\n",
    "n_valid = 80\n",
    "np.random.shuffle(strong_meta_examples)\n",
    "np.random.shuffle(weak_meta_examples)\n",
    "\n",
    "test_examples = strong_meta_examples[:n_test]\n",
    "valid_examples = strong_meta_examples[n_test:n_test+n_valid]\n",
    "train_examples = strong_meta_examples[n_test+n_valid:] + weak_meta_examples\n",
    "np.random.shuffle(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(train_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_popular/train.jsonl\")\n",
    "io.dump_jsonlines(valid_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_popular/valid.jsonl\")\n",
    "io.dump_jsonlines(test_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_popular/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1593"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_outerloop_count = 0\n",
    "meta_examples = []\n",
    "propagation2verbtaim_count = defaultdict(int)\n",
    "propagation2count = defaultdict(int)\n",
    "# strong_meta_examples = []\n",
    "# weak_meta_examples = []\n",
    "count_rel = defaultdict(int)\n",
    "count_prop_types = defaultdict(int)\n",
    "\n",
    "for example in train_examples:\n",
    "    outerloop_instances = example[\"Logical_Generalization\"] + example[\"Compositionality_I\"] + example[\"Compositionality_II\"] + example[\"Subject_Aliasing\"]\n",
    "    # for ins in outerloop_instances:\n",
    "        # assert len(ins[\"test_queries\"]) == 1\n",
    "    locality_instances = example[\"Relation_Specificity\"] + example[\"Forgetfulness\"] \n",
    "    example[\"edit\"][\"text\"] = example[\"edit\"][\"prompt\"]\n",
    "    meta_examples.append(example[\"edit\"])\n",
    "    \n",
    "    outerloop_queries = []\n",
    "    for k in [\"Logical_Generalization\", \"Compositionality_I\", \"Compositionality_II\", \"Subject_Aliasing\"]:\n",
    "        for instance in example[k]:\n",
    "            for q in instance[\"test_queries\"]:\n",
    "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
    "                    q[\"question_type\"] = k\n",
    "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
    "                    assert len(ans_candidates) > 0\n",
    "                    assert q[\"prompt\"][-1] not in \".\",  q[\"prompt\"]\n",
    "                    q[\"text\"] = q[\"prompt\"] + \" \" + ans_candidates[0]\n",
    "                    propagation2count[k] += 1\n",
    "                    propagation2verbtaim_count[k] += int(ans_candidates[0] in example[\"edit\"][\"text\"])\n",
    "                    outerloop_queries.append(q)\n",
    "    for outer_q in outerloop_queries:\n",
    "        count_prop_types[\"efficacy::\"+ outer_q[\"question_type\"]] += 1\n",
    "        count_rel[\"efficacy::\"+ outer_q[\"relation\"]] += 1\n",
    "    # assert len(outerloop_queries) > 0\n",
    "    meta_examples.extend(outerloop_queries)\n",
    "    \n",
    "    locality_queries = []\n",
    "    for k in [\"Relation_Specificity\", \"Forgetfulness\"]:\n",
    "        for instance in example[k]:\n",
    "            for q in instance[\"test_queries\"]:\n",
    "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
    "                    q[\"question_type\"] = k\n",
    "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
    "                    assert len(ans_candidates) > 0\n",
    "                    assert q[\"prompt\"][-1] not in string.punctuation\n",
    "                    q[\"text\"] = q[\"prompt\"] + \" \" + ans_candidates[0]\n",
    "                    propagation2count[k] += 1\n",
    "                    propagation2verbtaim_count[k] += int(ans_candidates[0] in example[\"edit\"][\"text\"])\n",
    "                    locality_queries.append(q)\n",
    "    for loc_q in locality_queries:\n",
    "        count_prop_types[\"specificity::\"+ loc_q[\"question_type\"]] += 1\n",
    "        count_rel[\"specificity::\"+ loc_q[\"relation\"]] += 1\n",
    "    \n",
    "    meta_examples.extend(locality_queries)\n",
    "    \n",
    "    # assert len(locality_queries) > 0\n",
    "        \n",
    "# print(\"# strong examples\", len(strong_meta_examples))\n",
    "# print(\"# weak examples\", len(weak_meta_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Subject_Aliasing': 144,\n",
       "             'Relation_Specificity': 630,\n",
       "             'Forgetfulness': 99,\n",
       "             'Compositionality_I': 1112,\n",
       "             'Logical_Generalization': 123,\n",
       "             'Compositionality_II': 96})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propagation2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagation2verbtaim_ratio = {k: propagation2verbtaim_count[k] / propagation2count[k] * 100 for k in propagation2count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subject_Aliasing': 100.0,\n",
       " 'Relation_Specificity': 2.857142857142857,\n",
       " 'Forgetfulness': 74.74747474747475,\n",
       " 'Compositionality_I': 3.327338129496403,\n",
       " 'Logical_Generalization': 46.34146341463415,\n",
       " 'Compositionality_II': 100.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propagation2verbtaim_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Subject_Aliasing': 144,\n",
       "             'Relation_Specificity': 20,\n",
       "             'Forgetfulness': 74,\n",
       "             'Compositionality_I': 38,\n",
       "             'Logical_Generalization': 57,\n",
       "             'Compositionality_II': 96})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propagation2verbtaim_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/test_w_prefix.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'subject_id', 'relation', 'target_id', 'original_fact', 'context', 'paraphrase', 'object'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# print(original_test)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# print(augmentation)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m original_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m augmentation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m original_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m augmentation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43maugmentation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m original_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m augmentation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m original_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m     original_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m augmentation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "new_test_data = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(test_data)):\n",
    "    original_test = test_data[i]\n",
    "    augmentation = ds[i-count]\n",
    "    if original_test[\"edit\"][\"prompt\"] == \"The name of the composer of Klavierstücke  I–IV is Karlheinz Stockhausen.\":\n",
    "        # print(\"found\")\n",
    "        original_test[\"edit\"][\"subject\"] = \"name of the composer of Klavierst\\u00fccke  I\\u2013IV\"\n",
    "        original_test[\"edit\"][\"object\"] = \"Karlheinz Stockhausen\"\n",
    "        assert original_test[\"edit\"][\"subject\"] in original_test[\"edit\"][\"prompt\"]\n",
    "        assert original_test[\"edit\"][\"object\"] in original_test[\"edit\"][\"prompt\"]\n",
    "        new_test_data.append(original_test)\n",
    "        count += 1\n",
    "        continue\n",
    "        # print(original_test)\n",
    "        # print(augmentation)\n",
    "    else:\n",
    "        \n",
    "        assert original_test[\"edit\"][\"prompt\"] == augmentation[\"prompt\"], f\"{i}@@\" + original_test[\"edit\"][\"prompt\"] + \"@@\" + augmentation[\"prompt\"]\n",
    "        assert augmentation[\"subject\"] in original_test[\"edit\"][\"prompt\"]\n",
    "        assert augmentation[\"object\"] in original_test[\"edit\"][\"prompt\"]\n",
    "\n",
    "        original_test[\"edit\"][\"subject\"] = augmentation[\"subject\"]\n",
    "        original_test[\"edit\"][\"object\"] = augmentation[\"object\"]\n",
    "        new_test_data.append(original_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(new_test_data, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/test_aug.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a ripple edits for MEND-original version (before generating paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\"\n",
    "train_examples = io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/{split}.jsonl\")\n",
    "train_ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/{split}_w_prefix.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattend_train_examples = []\n",
    "\n",
    "# new_examples = []\n",
    "# missing_examples = []\n",
    "# mismatch_c = 0\n",
    "# for i in range(len(train_examples)):\n",
    "#     augmentation = train_ds[i-mismatch_c]\n",
    "#     example = train_examples[i]\n",
    "#     new_example = deepcopy(example)\n",
    "    \n",
    "#     new_example[\"edit\"][\"context\"] = augmentation[\"context\"]\n",
    "#     new_example[\"edit\"][\"paraphrase\"] = augmentation[\"paraphrase\"]\n",
    "#     new_example[\"edit\"][\"object\"] = augmentation[\"object\"]\n",
    "#     new_examples.append(new_example)\n",
    "#     # if example[\"edit\"][\"prompt\"] != augmentation[\"prompt\"]:\n",
    "#     #     mismatch_c += 1\n",
    "#     # else:\n",
    "        \n",
    "#     #     assert example[\"edit\"][\"prompt\"] == augmentation[\"prompt\"]\n",
    "#     #     assert augmentation[\"object\"] in example[\"edit\"][\"prompt\"]\n",
    "    \n",
    "#     #     flattend_train_examples.append({\"context\": augmentation[\"context\"], \"completion\": augmentation[\"object\"], \"paraphrase\": augmentation[\"paraphrase\"]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattend_train_examples = []\n",
    "missing_examples = []\n",
    "mismatch_c = 0\n",
    "for i in range(len(train_examples)):\n",
    "    augmentation = train_ds[i-mismatch_c]\n",
    "    example = train_examples[i]\n",
    "    \n",
    "    if example[\"edit\"][\"prompt\"] != augmentation[\"prompt\"]:\n",
    "        mismatch_c += 1\n",
    "    else:\n",
    "        \n",
    "        assert example[\"edit\"][\"prompt\"] == augmentation[\"prompt\"]\n",
    "        assert augmentation[\"object\"] in example[\"edit\"][\"prompt\"], augmentation[\"object\"] + \"@@@\" + example[\"edit\"][\"prompt\"]\n",
    "    \n",
    "        flattend_train_examples.append({\"context\": augmentation[\"context\"], \"completion\": augmentation[\"object\"], \"paraphrase\": augmentation[\"paraphrase\"]})\n",
    "    \n",
    "    for k in [\"Logical_Generalization\", \"Compositionality_I\", \"Compositionality_II\", \"Subject_Aliasing\"]:\n",
    "        for instance in example[k]:\n",
    "            for q in instance[\"test_queries\"]:\n",
    "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
    "                    q[\"question_type\"] = k\n",
    "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
    "                    assert len(ans_candidates) > 0\n",
    "                    assert q[\"prompt\"][-1] not in \".\",  q[\"prompt\"]\n",
    "                    assert \"phrase\" in q\n",
    "                    if q[\"phrase\"] is not None:\n",
    "                        flattend_train_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0], \"paraphrase\": q[\"phrase\"]})\n",
    "                    else:\n",
    "                        missing_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0],})\n",
    "    for k in [\"Relation_Specificity\", \"Forgetfulness\"]:\n",
    "        for instance in example[k]:\n",
    "            for q in instance[\"test_queries\"]:\n",
    "                if len(q[\"answers\"]) > 0 and len([a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip() ) > 0 ]) > 0:\n",
    "                    q[\"question_type\"] = k\n",
    "                    ans_candidates = [a[\"value\"] for a in q[\"answers\"] if len(a[\"value\"].strip()) > 0]\n",
    "                    assert len(ans_candidates) > 0\n",
    "                    assert q[\"prompt\"][-1] not in string.punctuation\n",
    "                    \n",
    "                    assert \"phrase\" in q\n",
    "                    if q[\"phrase\"] is not None:\n",
    "                        flattend_train_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0], \"paraphrase\": q[\"phrase\"]})\n",
    "                    else:\n",
    "                        missing_examples.append({\"context\": q[\"prompt\"], \"completion\": ans_candidates[0],})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_ds = load_from_disk(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/{split}_w_paraphrase.hf\")\n",
    "# for i in range(len(missing_ds)):\n",
    "#     augmentation = missing_ds[i]\n",
    "    \n",
    "#     flattend_train_examples.append({\"context\": augmentation[\"context\"], \"completion\": augmentation[\"completion\"], \"paraphrase\": augmentation[\"paraphrase\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17096"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flattend_train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.dump_jsonlines(flattend_train_examples, f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent+popular/{split}_mend.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in io.load_jsonlines(f\"{vars.DATA_DIR}/ripple_edits/meta_train_recent/valid_mend.jsonl\"):\n",
    "    assert \"context\" in ex and ex[\"context\"] is not None\n",
    "    assert \"completion\" in ex and ex[\"completion\"] is not None\n",
    "    assert \"paraphrase\" in ex and ex[\"paraphrase\"] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoe_aggregation = io.load_json(\"/u/zliu/datastor1/ReCoE/data/aggregation/counterfactual_datapoints_verified_atomic.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_recoe_aggregation = [\n",
    "    {\n",
    "        \"text\": \" \".join([f[\"fact\"] for f in x[\"direct_counterfactual_fact\"]]),\n",
    "        \"question\": x[\"question\"],\n",
    "        \"answers\": x[\"counterfactual_answer\"]\n",
    "     }\n",
    "    for x in recoe_aggregation\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_recoe_aggregation[-1]\n",
    "len(converted_recoe_aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate RoCE data to ripple edit trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoe_comparative = io.load_json(\"/u/zliu/datastor1/ReCoE/data/comparative/counterfactual_datapoints_verified_atomic.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [len(x[\"facts_per_choice\"]) for x in recoe_comparative]\n",
    "# recoe_comparative[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_recoe_comparative = []\n",
    "for x in recoe_comparative:\n",
    "    assert \"choice_1_counterfactuals\" in x[\"counterfactuals_per_choice\"]\n",
    "    assert \"choice_2_counterfactuals\" in x[\"counterfactuals_per_choice\"]\n",
    "    assert \"choice_3_counterfactuals\" not in x[\"counterfactuals_per_choice\"]\n",
    "    \n",
    "    counter_fact1_text = [f[\"fact\"] for f in x[\"counterfactuals_per_choice\"][\"choice_1_counterfactuals\"]]\n",
    "    counter_fact2_text = [f[\"fact\"] for f in x[\"counterfactuals_per_choice\"][\"choice_2_counterfactuals\"]]\n",
    "    texts = [counter_fact1_text, counter_fact2_text]\n",
    "    np.random.shuffle(texts)\n",
    "    counter_fact1_text_after_rand, counter_fact2_text_after_rand = texts\n",
    "    \n",
    "    \n",
    "    converted_recoe_comparative.append(\n",
    "        {\n",
    "            \"text\": \" \".join(counter_fact1_text_after_rand + counter_fact2_text_after_rand),\n",
    "            \"question\": x[\"question\"],\n",
    "            \"answers\": x[\"counterfactual_answer\"]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [len(x[\"facts_per_choice\"]) for x in recoe_comparative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
