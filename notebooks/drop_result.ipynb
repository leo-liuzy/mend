{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/datastor1/zliu/mend/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from experiments.musique.inference_only import macro_averaging\n",
    "from knowledge_propagation.utils import io, vars, extractor\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import describe\n",
    "from thefuzz import fuzz\n",
    "\n",
    "\n",
    "from knowledge_propagation.modules.evaluators import (\n",
    "    ExactMatchEvaluator,\n",
    "    RougeEvaluator,\n",
    "    OpenAIEvaluator,\n",
    ")\n",
    "llm_evaluator = OpenAIEvaluator()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = \"/u/zliu/datastor1/mend/drop_exp_output/llama3.2-1B-eos-sft/drop/base_n=100_prompt=no_w-gen_wo-icl.xlsx\"\n",
    "do_gen = \"w-gen\" in fpath\n",
    "df = pd.read_excel(fpath)\n",
    "metrics = [\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"]\n",
    "if do_gen:\n",
    "    metrics += [\"rouge1\", \"llm_accuracy\"]\n",
    "# macro_averaging(df, multi_levelz_averaging=[\"stage\", \"question\"], metrics=['[Q][A] acc', \"rouge1\", \"llm_accuracy\"])\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/u/zliu/datastor1/mend/drop_exp_output/Llama-3.2-1B-eos-sft_clm-baseline_lr=1e-05_epoch=4.0/individual_results\"\n",
    "all_df = pd.concat([pd.read_excel(f) for f in glob(f\"{save_dir}/*.xlsx\", recursive=True)])\n",
    "all_df.to_excel(f\"{save_dir}/../all_results_e.xlsx\")\n",
    "print(len(all_df))\n",
    "cpt_ids = all_df[\"id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efficacyefficacyefficacyefficacyefficacyeffica...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_type  [A]|[Q] Acc EM  \\\n",
       "0  efficacyefficacyefficacyefficacyefficacyeffica...             8.3   \n",
       "\n",
       "   [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM  rouge1  llm_accuracy  \n",
       "0            59.4            0.0           27.7    12.8          24.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(macro_averaging(df[df[\"id\"].isin(cpt_ids)], multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"rouge1\", \"llm_accuracy\"]) * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[('llm_accuracy', 'mean')] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mmacro_averaging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_level_averaging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[A]|[Q] Acc EM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[A]|[Q] Acc PM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[Q][A] Acc EM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[Q][A] Acc PM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrouge1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/datastor1/KE-by-CP/experiments/musique/inference_only.py:80\u001b[0m, in \u001b[0;36mmacro_averaging\u001b[0;34m(df, metrics, multi_level_averaging)\u001b[0m\n\u001b[1;32m     76\u001b[0m extracted_multi_level_cols \u001b[38;5;241m=\u001b[39m [[m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(multi_level_averaging) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# first take the mean over each generation,\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# and, only take `mean` of `rouge1` and  `llm_accuracy` column groups\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     df_over_cols \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_level_averaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mextracted_multi_level_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# remove the multi-level column indices, since there's only one sub-level -- \"mean\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     df_over_cols\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df_over_cols\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2766\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(key, indexer, axis_name)\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[0;32m-> 2766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2786\u001b[0m, in \u001b[0;36mMultiIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2784\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datastor1/miniconda3/envs/cpt/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[('llm_accuracy', 'mean')] not in index\""
     ]
    }
   ],
   "source": [
    "(macro_averaging(all_df, multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"rouge1\", \"llm_accuracy\"]) * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=2920, minmax=(np.int64(1), np.int64(22)), mean=np.float64(16.71027397260274), variance=np.float64(33.4864308944234), skewness=np.float64(-1.423181597382786), kurtosis=np.float64(0.37896054426006387))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "one_K_all_df = pd.read_excel(f\"{save_dir}/../all_table.xlsx\")\n",
    "\n",
    "describe([\n",
    "    len(vars.GPT_4_TOKENIZER(ans))\n",
    "    for ans in one_K_all_df[\"predicted_answer\"].to_list() # [one_K_all_df[\"question_type\"] == \"single_hop_efficacy\"]\n",
    "    if isinstance(ans, str)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(ans, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mq_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vars.GPT_4_TOKENIZER(one_K_all_df[\"predicted_answer\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.isnan(one_K_all_df[\"predicted_answer\"].to_list()[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split single-hop questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2single_hops = {x['id']: x[\"single_hop_efficacy\"] for x in io.load_jsonlines(f\"{vars.DATA_DIR}/musique_mend_converted/2hop_musique_ans_v1.0_dev.jsonl\")[:1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 108336,\n",
       "  'question': \"Which was the creator of allegory of isabella d'este's coronation?\",\n",
       "  'answer': 'Lorenzo Costa',\n",
       "  'supporting_text_id': 0},\n",
       " {'id': 772156,\n",
       "  'question': 'Where did lorenzo costa pass away according to his place of death?',\n",
       "  'answer': 'Mantua',\n",
       "  'supporting_text_id': 1}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2single_hops[\"2hop__108336_772156\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {x['id']: x[\"multi_hop_efficacy\"] for x in io.load_jsonlines(f\"{vars.DATA_DIR}/musique_mend_converted/2hop_musique_ans_v1.0_dev.jsonl\")[:1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"/u/zliu/datastor1/mend/exp_output/Llama-3.2-1B-eos-sft_clm-baseline_input=seen-hop_lr=1e-05_epoch=4.0/all_table_e+s.xlsx\"\n",
    "\n",
    "df = pd.read_excel(df_path)\n",
    "\n",
    "df_multiplier = 2 if \"pre-edit\" in df[\"stage\"].tolist() and \"post-edit\" in df[\"stage\"].tolist() else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>clm_input</th>\n",
       "      <th>stage</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer_idx</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>single_hop_specificity</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Which ocean lies to the east of Australia?</td>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>0</td>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>single_hop_specificity</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Who was the first person to land on the moon?</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>0</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>single_hop_specificity</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Which country is known as the Land of the Risi...</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>single_hop_specificity</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Who developed the theory of relativity?</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>0</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>multi_hop_specificity</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Which ocean lies to the east of the continent ...</td>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>0</td>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>multi_hop_specificity</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Which country, known as the Land of the Rising...</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>single_hop_efficacy</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Who led the military expedition in Fujian ?</td>\n",
       "      <td>Chen Zheng</td>\n",
       "      <td>0</td>\n",
       "      <td>Zhang Zheng (陳政), together with his son Zhang ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>2hop__10017_18974</td>\n",
       "      <td>multi_hop_efficacy</td>\n",
       "      <td>[[In 677 (during the reign of Emperor Gaozong)...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>Who led the military expedition in the provinc...</td>\n",
       "      <td>Chen Zheng</td>\n",
       "      <td>0</td>\n",
       "      <td>Zhang Zheng (陳政), together with his son Zhang ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id           question_type  \\\n",
       "2792  2hop__10017_18974  single_hop_specificity   \n",
       "2793  2hop__10017_18974  single_hop_specificity   \n",
       "2794  2hop__10017_18974  single_hop_specificity   \n",
       "2795  2hop__10017_18974  single_hop_specificity   \n",
       "2796  2hop__10017_18974   multi_hop_specificity   \n",
       "2797  2hop__10017_18974   multi_hop_specificity   \n",
       "2798  2hop__10017_18974     single_hop_efficacy   \n",
       "2799  2hop__10017_18974      multi_hop_efficacy   \n",
       "\n",
       "                                              clm_input      stage  \\\n",
       "2792  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2793  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2794  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2795  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2796  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2797  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2798  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "2799  [[In 677 (during the reign of Emperor Gaozong)...  post-edit   \n",
       "\n",
       "                                               question           answer  \\\n",
       "2792         Which ocean lies to the east of Australia?    Pacific Ocean   \n",
       "2793      Who was the first person to land on the moon?   Neil Armstrong   \n",
       "2794  Which country is known as the Land of the Risi...            Japan   \n",
       "2795            Who developed the theory of relativity?  Albert Einstein   \n",
       "2796  Which ocean lies to the east of the continent ...   Atlantic Ocean   \n",
       "2797  Which country, known as the Land of the Rising...            Japan   \n",
       "2798        Who led the military expedition in Fujian ?       Chen Zheng   \n",
       "2799  Who led the military expedition in the provinc...       Chen Zheng   \n",
       "\n",
       "      predicted_answer_idx                                   predicted_answer  \\\n",
       "2792                     0                                       Indian Ocean   \n",
       "2793                     0                                     Neil Armstrong   \n",
       "2794                     0                                              Japan   \n",
       "2795                     0                                    Albert Einstein   \n",
       "2796                     0                                      Pacific Ocean   \n",
       "2797                     0                                              Japan   \n",
       "2798                     0  Zhang Zheng (陳政), together with his son Zhang ...   \n",
       "2799                     0  Zhang Zheng (陳政), together with his son Zhang ...   \n",
       "\n",
       "      exact_match    rouge1  rouge2    rougeL  rougeLsum  [A]|[Q] Acc EM  \\\n",
       "2792            0  0.500000     0.0  0.500000   0.500000               0   \n",
       "2793            1  1.000000     1.0  1.000000   1.000000               1   \n",
       "2794            1  1.000000     0.0  1.000000   1.000000               1   \n",
       "2795            1  1.000000     1.0  1.000000   1.000000               1   \n",
       "2796            0  0.500000     0.0  0.500000   0.500000               0   \n",
       "2797            1  1.000000     0.0  1.000000   1.000000               1   \n",
       "2798            0  0.181818     0.0  0.181818   0.181818               0   \n",
       "2799            0  0.181818     0.0  0.181818   0.181818               0   \n",
       "\n",
       "      [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM  llm_accuracy  \n",
       "2792        0.666667              0       0.416667           0.1  \n",
       "2793        1.000000              0       0.714286           1.0  \n",
       "2794        1.000000              0       0.428571           1.0  \n",
       "2795        1.000000              0       0.636364           1.0  \n",
       "2796        0.666667              0       0.388889           0.1  \n",
       "2797        1.000000              0       0.392857           1.0  \n",
       "2798        0.333333              0       0.333333           0.3  \n",
       "2799        0.333333              0       0.200000           0.3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ins_id, instance_df \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# assert len(instance_df) == 3 * df_multiplier, ins_id\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     single_hop_df \u001b[38;5;241m=\u001b[39m instance_df[instance_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_hop_efficacy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(single_hop_df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m df_multiplier\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r_i, row \u001b[38;5;129;01min\u001b[39;00m single_hop_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      9\u001b[0m         row_dict \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_df = []\n",
    "for ins_id, instance_df in df.groupby(\"id\"):\n",
    "    # assert len(instance_df) == 3 * df_multiplier, ins_id\n",
    "    single_hop_df = instance_df[instance_df[\"question_type\"] == \"single_hop_efficacy\"]\n",
    "    assert len(single_hop_df) == 2 * df_multiplier\n",
    "    \n",
    "    for r_i, row in single_hop_df.iterrows():\n",
    "        \n",
    "        row_dict = row.to_dict()\n",
    "        try:\n",
    "            question_lst = [q[\"question\"] for q in id2single_hops[ins_id]]\n",
    "            q_index: int = int(np.argmax([fuzz.ratio(q, row_dict[\"question\"]) for q in question_lst]))\n",
    "        except:\n",
    "            print(ins_id)\n",
    "            assert False\n",
    "        row_dict[\"question_tag\"] = f\"single_hop_efficacy_q{q_index}\"\n",
    "        new_df.append(row_dict)\n",
    "\n",
    "    multi_hop_df = instance_df[instance_df[\"question_type\"] == \"multi_hop_efficacy\"]\n",
    "    assert len(multi_hop_df) == 1 * df_multiplier\n",
    "    \n",
    "    for r_i, row in multi_hop_df.iterrows():\n",
    "        \n",
    "        row_dict = row.to_dict()\n",
    "        row_dict[\"question_tag\"] = f\"multi_hop_efficacy_q0\"\n",
    "        new_df.append(row_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new_df).to_excel(io.remove_last_extension(df_path) + \"_split.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thefuzz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthefuzz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuzz\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'thefuzz'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_i, row in single_hop_df.iterrows():\n",
    "    q_index: int = [q[\"question\"] for q in id2single_hops[ins_id]].index(row[\"question\"])\n",
    "    row[\"question_tag\"] = f\"single_hop_efficacy_q{q_index}\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                              1\n",
       "id                                                        2hop__998_25855\n",
       "question_type                                         single_hop_efficacy\n",
       "clm_input               [[The third generation began including a 30-pi...\n",
       "stage                                                           post-edit\n",
       "question                What does dell call the feature that lets USB ...\n",
       "answer                                                         PowerShare\n",
       "predicted_answer_idx                                                    0\n",
       "predicted_answer                                                    Sleep\n",
       "exact_match                                                             0\n",
       "rouge1                                                                0.0\n",
       "rouge2                                                                0.0\n",
       "rougeL                                                                0.0\n",
       "rougeLsum                                                             0.0\n",
       "[A]|[Q] Acc EM                                                          0\n",
       "[A]|[Q] Acc PM                                                        0.0\n",
       "[Q][A] Acc EM                                                           0\n",
       "[Q][A] Acc PM                                                    0.227273\n",
       "llm_accuracy                                                          0.1\n",
       "question_tag                                       single_hop_efficacy_q1\n",
       "Name: 1864, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does dell call the feature that lets USB drives to remain powered when the computer is off?'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"/u/zliu/datastor1/mend/exp_output/Llama-3.2-1B-eos-sft_clm-baseline_input=first-1hop_lr=1e-05_epoch=4.0/all_table.xlsx\")\n",
    "df2 = pd.read_excel(\"/u/zliu/datastor1/mend/exp_output/Llama-3.2-1B-eos-sft_clm-baseline_input=second-1hop_lr=1e-05_epoch=4.0/all_table.xlsx\")\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>clm_input</th>\n",
       "      <th>stage</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer_idx</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2hop__159903_154896</td>\n",
       "      <td>single_hop_efficacy</td>\n",
       "      <td>[[He was elected to the NLF executive in the f...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>What part of the country is it about?</td>\n",
       "      <td>South Yemen</td>\n",
       "      <td>0</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2hop__159903_154896</td>\n",
       "      <td>single_hop_efficacy</td>\n",
       "      <td>[[He was elected to the NLF executive in the f...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>What year did South Yemen insurgency start?</td>\n",
       "      <td>27 April 2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2hop__159903_154896</td>\n",
       "      <td>multi_hop_efficacy</td>\n",
       "      <td>[[He was elected to the NLF executive in the f...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>In what year did the insurgency start in the p...</td>\n",
       "      <td>27 April 2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2hop__341305_332933</td>\n",
       "      <td>single_hop_efficacy</td>\n",
       "      <td>[[Pine Springs is an unincorporated community ...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>In which administrative territorial entity is ...</td>\n",
       "      <td>Culberson County</td>\n",
       "      <td>0</td>\n",
       "      <td>The state of Texas, United States. Pine Spring...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2hop__341305_332933</td>\n",
       "      <td>single_hop_efficacy</td>\n",
       "      <td>[[Pine Springs is an unincorporated community ...</td>\n",
       "      <td>post-edit</td>\n",
       "      <td>What is the capital of culberson county?</td>\n",
       "      <td>Van Horn</td>\n",
       "      <td>0</td>\n",
       "      <td>Fort Worth, Texas, United States. It is the cl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id        question_type  \\\n",
       "0           0  2hop__159903_154896  single_hop_efficacy   \n",
       "1           1  2hop__159903_154896  single_hop_efficacy   \n",
       "2           2  2hop__159903_154896   multi_hop_efficacy   \n",
       "3           0  2hop__341305_332933  single_hop_efficacy   \n",
       "4           1  2hop__341305_332933  single_hop_efficacy   \n",
       "\n",
       "                                           clm_input      stage  \\\n",
       "0  [[He was elected to the NLF executive in the f...  post-edit   \n",
       "1  [[He was elected to the NLF executive in the f...  post-edit   \n",
       "2  [[He was elected to the NLF executive in the f...  post-edit   \n",
       "3  [[Pine Springs is an unincorporated community ...  post-edit   \n",
       "4  [[Pine Springs is an unincorporated community ...  post-edit   \n",
       "\n",
       "                                            question            answer  \\\n",
       "0              What part of the country is it about?       South Yemen   \n",
       "1        What year did South Yemen insurgency start?     27 April 2009   \n",
       "2  In what year did the insurgency start in the p...     27 April 2009   \n",
       "3  In which administrative territorial entity is ...  Culberson County   \n",
       "4           What is the capital of culberson county?          Van Horn   \n",
       "\n",
       "   predicted_answer_idx                                   predicted_answer  \\\n",
       "0                     0                                   Northern Ireland   \n",
       "1                     0                                               1965   \n",
       "2                     0                                               1965   \n",
       "3                     0  The state of Texas, United States. Pine Spring...   \n",
       "4                     0  Fort Worth, Texas, United States. It is the cl...   \n",
       "\n",
       "   exact_match  rouge1  rouge2  rougeL  rougeLsum  [A]|[Q] Acc EM  \\\n",
       "0            0     0.0     0.0     0.0        0.0               0   \n",
       "1            0     0.0     0.0     0.0        0.0               0   \n",
       "2            0     0.0     0.0     0.0        0.0               0   \n",
       "3            0     0.0     0.0     0.0        0.0               0   \n",
       "4            0     0.0     0.0     0.0        0.0               0   \n",
       "\n",
       "   [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM  llm_accuracy  \n",
       "0        0.666667              0       0.416667           NaN  \n",
       "1        0.571429              0       0.333333           NaN  \n",
       "2        0.428571              0       0.375000           NaN  \n",
       "3        0.600000              0       0.200000           0.7  \n",
       "4        0.333333              0       0.538462           0.1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"stage\"] == \"post-edit\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"stage\"] == \"post-edit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_hop_efficacymulti_hop_efficacymulti_hop_...</td>\n",
       "      <td>3.550</td>\n",
       "      <td>52.908916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.829996</td>\n",
       "      <td>15.716392</td>\n",
       "      <td>35.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_hop_efficacysingle_hop_efficacysingle_h...</td>\n",
       "      <td>8.425</td>\n",
       "      <td>59.864995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.268511</td>\n",
       "      <td>23.778972</td>\n",
       "      <td>38.8625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_type  [A]|[Q] Acc EM  \\\n",
       "0  multi_hop_efficacymulti_hop_efficacymulti_hop_...           3.550   \n",
       "1  single_hop_efficacysingle_hop_efficacysingle_h...           8.425   \n",
       "\n",
       "   [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM     rouge1  llm_accuracy  \n",
       "0       52.908916            0.0      37.829996  15.716392       35.1750  \n",
       "1       59.864995            0.0      41.268511  23.778972       38.8625  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df[df[\"stage\"] == \"post-edit\"], multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"rouge1\", \"llm_accuracy\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_questions = []\n",
    "for icl_question in df[\"question\"]:\n",
    "    question_ = icl_question.split(\"\\n\")[-2].strip()\n",
    "    assert \"Q: \" in question_\n",
    "    raw_questions.append(question_[3:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who is the performer associated with green?',\n",
       " 'Who is the spouse of steve hillage?',\n",
       " 'Who is the spouse of the Green performer?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_questions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-26 21:51:25.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mknowledge_propagation.modules.evaluators\u001b[0m:\u001b[36mcompute_metric\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mEvaluating with LLM evaluator (gpt-4o-mini)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n",
      "Failing heuristic fix\n"
     ]
    }
   ],
   "source": [
    "scored_df = llm_acc_per_example = llm_evaluator.compute_metric(\n",
    "    questions=raw_questions,\n",
    "    predictions=df[\"predicted_answer\"],\n",
    "    references=df[\"answer\"],\n",
    "    use_aggregator=False,\n",
    "    rescale_to_one=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"llm_accuracy\"] = scored_df[\"llm_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_hop_efficacymulti_hop_efficacymulti_hop_...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>48.632919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.569110</td>\n",
       "      <td>5.807457</td>\n",
       "      <td>16.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_hop_efficacysingle_hop_efficacysingle_h...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>54.202771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.640035</td>\n",
       "      <td>12.080476</td>\n",
       "      <td>23.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_type  [A]|[Q] Acc EM  \\\n",
       "0  multi_hop_efficacymulti_hop_efficacymulti_hop_...             1.5   \n",
       "1  single_hop_efficacysingle_hop_efficacysingle_h...             6.2   \n",
       "\n",
       "   [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM     rouge1  llm_accuracy  \n",
       "0       48.632919            0.0      37.569110   5.807457        16.170  \n",
       "1       54.202771            0.0      38.640035  12.080476        23.095  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df[df[\"stage\"] == \"pre-edit\"], multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"rouge1\", \"llm_accuracy\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>[A]|[Q] Acc EM</th>\n",
       "      <th>[A]|[Q] Acc PM</th>\n",
       "      <th>[Q][A] Acc EM</th>\n",
       "      <th>[Q][A] Acc PM</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>llm_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_hop_efficacymulti_hop_efficacymulti_hop_...</td>\n",
       "      <td>7.85</td>\n",
       "      <td>58.005100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.070285</td>\n",
       "      <td>15.668783</td>\n",
       "      <td>24.8950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_hop_efficacysingle_hop_efficacysingle_h...</td>\n",
       "      <td>19.40</td>\n",
       "      <td>67.272676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.425836</td>\n",
       "      <td>28.166019</td>\n",
       "      <td>35.8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_type  [A]|[Q] Acc EM  \\\n",
       "0  multi_hop_efficacymulti_hop_efficacymulti_hop_...            7.85   \n",
       "1  single_hop_efficacysingle_hop_efficacysingle_h...           19.40   \n",
       "\n",
       "   [A]|[Q] Acc PM  [Q][A] Acc EM  [Q][A] Acc PM     rouge1  llm_accuracy  \n",
       "0       58.005100            0.0      40.070285  15.668783       24.8950  \n",
       "1       67.272676            0.0      41.425836  28.166019       35.8125  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_averaging(df[df[\"stage\"] == \"post-edit\"], multi_level_averaging=[\"question_type\", \"id\"], metrics=[\"[A]|[Q] Acc EM\", \"[A]|[Q] Acc PM\", '[Q][A] Acc EM', \"[Q][A] Acc PM\"] + [\"rouge1\", \"llm_accuracy\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in io.load_jsonlines(\"/u/zliu/datastor1/KE-by-CP/data/musique_mend_converted/2hop_musique_ans_v1.0_train.jsonl\"):\n",
    "    assert len(x[\"multi_hop_efficacy\"]) == 1, x\n",
    "    assert len(x[\"single_hop_efficacy\"]) == 2, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malmen_combiner_text_df = pd.read_excel(\"/u/zliu/datastor1/malmen/exp_output/musique_combiner_text_w-atomq_m1/malmen_eval_musique_combiner_text_n=1000.xlsx\")\n",
    "malmen_combiner_text_df = malmen_combiner_text_df[(malmen_combiner_text_df[\"stage\"] == \"post-edit\") & (malmen_combiner_text_df[\"question_type\"] == \"multi_hop_efficacy\")]\n",
    "\n",
    "clm_combiner_text_df = pd.read_excel(\"/u/zliu/datastor1/mend/exp_output/Llama-3.2-1B-eos-sft_clm-baseline_input=two-1hop_lr=1e-05_epoch=4.0/all_table_split.xlsx\")\n",
    "clm_combiner_text_df = clm_combiner_text_df[(clm_combiner_text_df[\"stage\"] == \"post-edit\") & (clm_combiner_text_df[\"question_type\"] == \"multi_hop_efficacy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(malmen_combiner_text_df) == len(clm_combiner_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "clm_better_rs = []\n",
    "for r_i, clm_r in clm_combiner_text_df.iterrows():\n",
    "    malmen_q_r = malmen_combiner_text_df[malmen_combiner_text_df[\"question\"] == clm_r[\"question\"]]\n",
    "    if len(malmen_q_r) != 1:\n",
    "        continue\n",
    "    malmen_r = malmen_q_r.iloc[0]\n",
    "    if clm_r[\"llm_accuracy\"] > malmen_r[\"llm_accuracy\"]:\n",
    "        clm_better_rs.append((clm_r, malmen_r))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clm_better_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/u/zliu/datastor1/mend/spotcheck/clm_compq_better.txt\", \"w\") as f:\n",
    "\n",
    "    for clm_r, malmen_r in clm_better_rs[:]:\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        f.write(\"Example id: \" + clm_r[\"id\"] + \"\\n\")\n",
    "        f.write(\"Text:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(clm_r[\"clm_input\"] + \"\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(\"CompQ: \" + clm_r[\"question\"] + \"\\n\")\n",
    "        f.write(\"Answer: \" + clm_r[\"answer\"] + \"\\n\")\n",
    "        f.write(f\"CLM Prediction [llm_acc={clm_r['llm_accuracy']}]: \" + clm_r[\"predicted_answer\"] + \"\\n\")\n",
    "        f.write(f\"MALMEN Prediction [llm_acc={malmen_r['llm_accuracy']}]: \" + malmen_r[\"predicted_answer\"] + \"\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "baseline = \"/u/zliu/datastor1/mend/exp_output/Llama-3.2-1B-eos-sft_sh+mh/all_table_split.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.read_excel(\"/u/zliu/datastor1/mend/exp_output/Llama-3.2-1B-eos-sft_sh+mh/all_table_split.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/u/zliu/datastor1/mend/spotcheck/eos-sft_EMvsRouge.txt\", \"w\") as f:\n",
    "    f.write(\"baseline_r[[A]|[Q] Acc EM] == 0 and baseline_r[rouge1]\\n\")\n",
    "    interesting_rows = []\n",
    "    for r_i, baseline_r in baseline.iterrows():\n",
    "        if baseline_r[\"[A]|[Q] Acc EM\"] == 0 and baseline_r[\"rouge1\"] > 0:\n",
    "            interesting_rows.append(baseline_r.to_dict())\n",
    "            f.write(\"Answer: \" + baseline_r[\"answer\"] + \"\\n\")\n",
    "            f.write(\"Predicted Answer: \" + baseline_r[\"predicted_answer\"] + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    # if \n",
    "    # malmen_q_r = malmen_combiner_text_df[malmen_combiner_text_df[\"question\"] == clm_r[\"question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 2,\n",
       " 'id': '2hop__998_25855',\n",
       " 'question_type': 'multi_hop_efficacy',\n",
       " 'question': 'What does dell call the feature letting the interface replacing FireWire in later iterations of the iPod drives to remain powered when the computer is off?',\n",
       " 'stage': 'pre-edit',\n",
       " 'answer': 'PowerShare',\n",
       " 'predicted_answer_idx': 0,\n",
       " 'predicted_answer': 'Sleep',\n",
       " 'exact_match': 0,\n",
       " 'rouge1': 0.0,\n",
       " 'rouge2': 0.0,\n",
       " 'rougeL': 0.0,\n",
       " 'rougeLsum': 0.0,\n",
       " '[A]|[Q] Acc EM': 0,\n",
       " '[A]|[Q] Acc PM': 0.3333333432674408,\n",
       " '[Q][A] Acc EM': 0,\n",
       " '[Q][A] Acc PM': 0.161290317773819,\n",
       " 'llm_accuracy': 0.1,\n",
       " 'question_tag': 'multi_hop_efficacy_q0'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_effect_recent = io.load_jsonlines(\"/u/zliu/datastor1/KE-by-CP/data/ripple_edits/benchmark/recent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['example_type', 'edit', 'Logical_Generalization', 'Compositionality_I', 'Compositionality_II', 'Subject_Aliasing', 'Relation_Specificity', 'Forgetfulness'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripple_effect_recent[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The place of death of Leo Arons is Berlin.',\n",
       " 'subject_id': 'Q88641',\n",
       " 'relation': 'PLACE_OF_DEATH',\n",
       " 'target_id': 'Q64'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripple_effect_recent[0][1][\"edit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_queries': [{'prompt': 'The place of death of Martin Leo Arons is',\n",
       "    'answers': [{'value': 'Berlin',\n",
       "      'aliases': ['Berlin, Germany', 'Berlin (Germany)', 'DE-BE']}],\n",
       "    'query_type': 'regular',\n",
       "    'subject_id': 'Q88641',\n",
       "    'relation': 'PLACE_OF_DEATH',\n",
       "    'target_ids': ['Q64'],\n",
       "    'phrase': 'The place of death of Martin Leo Arons is'}],\n",
       "  'test_condition': 'OR',\n",
       "  'condition_queries': [{'prompt': 'The place of death of Martin Leo Arons is',\n",
       "    'answers': [{'value': 'Berlin',\n",
       "      'aliases': ['Berlin, Germany', 'Berlin (Germany)', 'DE-BE']}],\n",
       "    'query_type': 'regular',\n",
       "    'subject_id': 'Q88641',\n",
       "    'relation': 'PLACE_OF_DEATH',\n",
       "    'target_ids': ['Q64'],\n",
       "    'phrase': 'The place of death of Martin Leo Arons is'}]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripple_effect_recent[0][1][\"Subject_Aliasing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
